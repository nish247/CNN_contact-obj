{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install librosa\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython.display\n",
    "import pandas as pd\n",
    "import statistics as sta\n",
    "import torch\n",
    "\n",
    "print(librosa.__version__)\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ファイル読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# # 変数定義\n",
    "sr = 44100 #サンプリング周波数\n",
    "\n",
    "# #ファイルパスの指定\n",
    "# train = \"../raw_data/contacting_object/train_data/\" #NASのデータ\n",
    "# # audio_dir = \"../Data_contacting_object/initial/FOLDER02\" #ローカルデータ\n",
    "# eval = \"../raw_data/contacting_object/initial/FOLDER03/\" \n",
    "\n",
    "\n",
    "# #学習用データの読み込み\n",
    "# audio_dir = train\n",
    "# subFolders = [f for f in os.listdir(audio_dir) if os.path.isdir(os.path.join(audio_dir, f))]\n",
    "# subFolders = sorted(subFolders) #昇順に並び替え\n",
    "\n",
    "# #ファイル読み込み\n",
    "# # originDatasに音声データを格納していく\n",
    "# originDatas = []\n",
    "# for subFolder in subFolders:\n",
    "#     filePath = audio_dir+\"/\"+subFolder+\"/\"+subFolder+\"_Tr1.WAV\"\n",
    "#     originData, sr = librosa.load(filePath, sr = sr)\n",
    "#     originDatas.append(originData)\n",
    "\n",
    "# #評価用データの読み込み\n",
    "# folderPath = eval\n",
    "# subFolders = [f for f in os.listdir(folderPath) if os.path.isdir(os.path.join(folderPath, f))]\n",
    "# subFolders = sorted(subFolders) #昇順に並び替え\n",
    "\n",
    "# #ファイル読み込み\n",
    "# # originDatas_eに音声データを格納していく\n",
    "# originDatas_e = []\n",
    "# for subFolder in subFolders:\n",
    "#     filePath = folderPath+\"/\"+subFolder+\"/\"+subFolder+\"_Tr1.WAV\"\n",
    "#     originData_e, sr = librosa.load(filePath, sr = sr)\n",
    "#     originDatas_e.append(originData_e)\n",
    "\n",
    "\n",
    "# #1データから30試行をトリミングを22パターン分行い，soundDatasetに格納する\n",
    "# # soundDatasetの構造：[パターン(10)][試行(50)][サンプリングデータ(66150)]\n",
    "\n",
    "# flag_amp = 0.1 #各試行の合図を検知する基準振幅\n",
    "# trimSkip = int(sr*0.4)\n",
    "# trimTime = int(sr*1.5)#1試行あたりのデータ長\n",
    "# dataNum = 50\n",
    "# trial = 0\n",
    "# soundDataset =([])\n",
    "\n",
    "# while trial <len(originDatas):\n",
    "#     index = 0\n",
    "#     trimDatas = ([]) #1データ(30試行)分のトリミングデータのリストを初期化\n",
    "#     originData = np.array(originDatas[trial])\n",
    "#     while index <len(originData):\n",
    "#         if originData[index] >= flag_amp:\n",
    "#             trimData = np.array(originData[index+trimSkip:index+trimTime+trimSkip]) #trim_dataにそのindexからindex+trimTimeのデータを格納する\n",
    "#             trimDatas = np.append(trimDatas ,trimData, axis=0)  #trimDatasに追加する\n",
    "#             index += trimTime\n",
    "#         else:\n",
    "#             index +=1\n",
    "#         if len(trimDatas) >=dataNum*trimTime:\n",
    "#             break\n",
    "#     soundDataset = np.append(soundDataset,np.array(trimDatas),axis=0)\n",
    "#     trial += 1\n",
    "\n",
    "# soundDataset = soundDataset.reshape(len(originDatas),dataNum,trimTime)\n",
    "\n",
    "# print(soundDataset.shape)\n",
    "\n",
    "# import pickle\n",
    "# f = open('soundDataset.pickle','wb')\n",
    "# pickle.dump(soundDataset,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "f = open('soundDataset.pickle','rb')\n",
    "soundDataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "#正解ラベルリストの作成\n",
    "\n",
    "#object層\n",
    "objectLabel = [\n",
    "    \"Y-shirt\", \n",
    "    \"Jeans\", \n",
    "    \"Sweatshirt\", \n",
    "\n",
    "    \"Blanket\", \n",
    "    \"bedquilt\", \n",
    "    \"Pillow\", \n",
    "    \n",
    "    \"Thick Book\", \n",
    "    \"Thin Book\", \n",
    "    \"Cardboard\", \n",
    "    \n",
    "    \"Mousepad\", \n",
    "    \"Chair\", \n",
    "    \"Sofa\", \n",
    "    \n",
    "    \"Metal Desk\", \n",
    "    \"Laptop\", \n",
    "    \"AlumiRack\", \n",
    "    \n",
    "    \"WoodDesk\", \n",
    "    \"WoodShelf\", \n",
    "    \"Floor\", \n",
    "    \n",
    "    \"Small Organizer\", \n",
    "    \"PlaBag\", \n",
    "    \"PlaShelf\"\n",
    "]\n",
    "\n",
    "#material層\n",
    "matLabel = [\n",
    "    \"Clothing\",\n",
    "    \"Clothing\", \n",
    "    \"Paper\", \n",
    "    \"Memory Foam\", \n",
    "    \"Metal\", \n",
    "    \"Wood\", \n",
    "    \"Plastic\"\n",
    "]\n",
    "\n",
    "matNum = [0,0,1,2,3,4,5]\n",
    "\n",
    "#soft-hard層\n",
    "shLabel = [\n",
    "    \"soft\",\n",
    "    \"hard\",\n",
    "]\n",
    "\n",
    "shNum = [0,1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "print(len(soundDataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価データセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "IPython.display.Audio(data=soundDataset[1][0], rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スペクトログラムの描写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# # パターンごとにスペクロログラムの描写\n",
    "# for patern in range(len(soundDataset)):\n",
    "#     trimData = soundDataset[patern,0]\n",
    "#     spectrogram = librosa.feature.melspectrogram(y=trimData, sr=sr)# スペクトログラムを計算\n",
    "#     librosa.display.specshow(librosa.power_to_db(spectrogram, ref=np.max)\\\n",
    "#                              , y_axis='mel', x_axis='time')# スペクトログラムを表示\n",
    "    # plt.colorbar(format='%+2.0f dB')# カラーバーを追加\n",
    "    # plt.ylim(0,500)\n",
    "    # plt.title('Mel Spectrogram_'+objectLabel[patern])# グラフのタイトルを設定\n",
    "    # plt.show()# グラフを表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(soundDataset.shape[0]):\n",
    "    title = 'FFT_'+objectLabel[i]\n",
    "    #FFT\n",
    "    data = soundDataset[i][0] # checked data\n",
    "    win_wid = 4096\n",
    "    win_ham = np.blackman(win_wid)\n",
    "\n",
    "    #window幅で割り切れない分を削除する\n",
    "    if data.shape[0] % win_wid != 0:\n",
    "        data = data[0:-(data.shape[0] % win_wid)]\n",
    "\n",
    "\n",
    "\n",
    "    #overlap & split window \n",
    "    overlap_rate = 0.5\n",
    "    overlap = int(win_wid*overlap_rate)\n",
    "    step = win_wid - overlap\n",
    "    frames = []\n",
    "    for start in range(0, len(data),step):\n",
    "        end = start + win_wid  # 'end'を定義\n",
    "        if end > len(data):\n",
    "            break\n",
    "        frame = data[start:end]\n",
    "        frames.append(frame)\n",
    "\n",
    "    #FFT\n",
    "    fft_ret = np.fft.rfft(frames * win_ham) #FFT\n",
    "    fft_freq = np.fft.rfftfreq(win_wid, 1/sr) #周波数軸のデータ作成\n",
    "\n",
    "    #transfer amp to log\n",
    "    log_fft_ret = 20*np.log10(np.abs(fft_ret)) # 対数データの取得←データを見やすくするため\n",
    "\n",
    "\n",
    "    #plot result\n",
    "    result_fft = np.mean(log_fft_ret, axis = 0)\n",
    "    plt.title(title)\n",
    "    plt.plot(fft_freq,result_fft)\n",
    "    plt.xlim(100,2000)\n",
    "    plt.ylim(-40,40)\n",
    "    # plt.savefig('data/figure_obj/'+title+'.pdf')\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# 特徴量の次元数\n",
    "num_feature = 40\n",
    "\n",
    "# 空のmfccSetを初期化\n",
    "mfccSet = np.empty((0, num_feature))\n",
    "\n",
    "# ループを使用してMFCCを抽出してmfccSetに追加\n",
    "for pattern in range(soundDataset.shape[0]):\n",
    "    for trial in range(soundDataset.shape[1]):\n",
    "        # MFCCを計算\n",
    "        mfccs = librosa.feature.mfcc(y=soundDataset[pattern][trial], sr=sr)\n",
    "        \n",
    "        # MFCCの各次元の平均を算出\n",
    "        mean = mfccs.mean(axis=1)\n",
    "        \n",
    "        # MFCCの各次元の標準偏差を算出\n",
    "        std = np.std(mfccs, axis=1)\n",
    "        \n",
    "        # mean, max_val, min_val, std をまとめた配列を作成\n",
    "        combined_stats = np.concatenate([mean,  std])\n",
    "\n",
    "        # mfccSetに追加\n",
    "        mfccSet = np.append(mfccSet, [combined_stats], axis=0)\n",
    "\n",
    "# 形状を確認\n",
    "print(mfccSet.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# 形状を確認\n",
    "print(mfccSet.shape)\n",
    "print(mfccs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# num_feature次元のMFCCのデータフレームを作成\n",
    "Dataset = pd.DataFrame(data=mfccSet)\n",
    "\n",
    "\n",
    "Dataset['objectNum'] = [i // soundDataset.shape[1] for i in range(mfccSet.shape[0])]\n",
    "Dataset['matNum'] = np.repeat(matNum, 150)[:1050]\n",
    "Dataset['shNum'] = np.repeat(shNum, 600)[:1050]\n",
    "\n",
    "# データセットに'objectLabel'の列を追加\n",
    "Dataset['object'] = np.repeat(objectLabel, 50)[:1050]\n",
    "\n",
    "# # データセットに'matLabel'の列を追加\n",
    "Dataset['mat'] = np.repeat(matLabel, 150)[:1050]\n",
    "\n",
    "# # データセットに'SHLabel'の列を追加\n",
    "Dataset['sh'] = np.repeat(shLabel, 600)[:1050]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "! ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# trial1 = Dataset.iloc[Dataset.index // 10 % 10 <= 4]\n",
    "# trial2 = Dataset.iloc[Dataset.index // 10 % 10 > 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 日本時間のタイムゾーンを取得\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "# 現在の日本時間を取得\n",
    "now = datetime.now(jst)\n",
    "\n",
    "# 時刻を指定された形式の文字列に変換\n",
    "time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 物体推定モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "\n",
    "audio_origin = soundDataset.reshape(1050, -1)\n",
    "\n",
    "t_df = Dataset.objectNum\n",
    "\n",
    "\n",
    "audio_tensor_dataset = torch.tensor(audio_origin, dtype=torch.float32)\n",
    "label_tensor_sh = torch.tensor(t_df, dtype=torch.int64)\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset_origin = torch.utils.data.TensorDataset(audio_tensor_dataset, label_tensor_sh)\n",
    "dataset_origin\n",
    "\n",
    "# データセットを指定する\n",
    "dataset = dataset_origin\n",
    "print(len(dataset))\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 60%　: 20% : 20%\n",
    "\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train_origin, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "print(train_origin)\n",
    "\n",
    "\n",
    "#学習データをnpへ変換\n",
    "train_np = np.array([data.numpy() for data, _ in train_origin])\n",
    "train_np_label = np.array([label for _, label in train_origin])\n",
    "\n",
    "# #augmentation\n",
    "train_aug_up = train_np*1.1\n",
    "train_aug_down = train_np * 0.9\n",
    "wn = np.random.randn(train_np.shape[0],66150)\n",
    "train_aug_wn = train_np + wn\n",
    "# print(train_np)\n",
    "# print(train_aug_up)\n",
    "\n",
    "\n",
    "train_np_aug = np.concatenate([train_aug_up,train_aug_down])\n",
    "label_all = np.concatenate([train_np_label,train_np_label])\n",
    "print(len(train_np_aug))\n",
    "print(label_all)\n",
    "\n",
    "train_np_aug = torch.tensor(train_np_aug,dtype=torch.float32)\n",
    "label_all = torch.tensor(label_all, dtype=torch.int64)\n",
    "\n",
    "train_aug = torch.utils.data.TensorDataset(train_np_aug, label_all)\n",
    "\n",
    "\n",
    "\n",
    "train = train_origin\n",
    "\n",
    "print(len(train))\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 50\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class objNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(objNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 40, 8),\n",
    "            nn.BatchNorm1d(40),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(40, 40, 8),\n",
    "            nn.BatchNorm1d(40),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(40, 21, 8),\n",
    "            nn.BatchNorm1d(21),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(21, 21, 8),\n",
    "            nn.BatchNorm1d(21),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(42, 21),  # 入力サイズを修正\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(21, 21),  # 出力サイズを修正\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Linear(21,1),\n",
    "            # nn.Dropout(0.25)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.conv2(h)\n",
    "        h = F.max_pool1d(h, kernel_size=160)\n",
    "          \n",
    "        h = self.conv3(h)\n",
    "        h = F.max_pool1d(h, kernel_size=3) \n",
    "        h = self.conv4(h) \n",
    "        h = F.max_pool1d(h, kernel_size=3) \n",
    "        h = self.classifier(h)\n",
    "        h = h.view(h.size(0), -1)  # Flatten\n",
    "        return h\n",
    "\n",
    "# モデルのインスタンス化\n",
    "objnet = objNet()\n",
    "\n",
    "# モデルの出力を計算してみる\n",
    "input_data = torch.randn(10,1,66150)\n",
    "print(input_data.shape)  \n",
    "output = objnet(input_data)\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# エポックの数\n",
    "max_epoch = 50\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net = objNet().to(device)\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "criterion     \n",
    "\n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        # t = torch.unsqueeze(t, 0)\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y = net(x)\n",
    "        loss = criterion(y, t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "            x = torch.unsqueeze(x, 1)\n",
    "            # t = torch.unsqueeze(t, 0)\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            \n",
    "            y = net(x)\n",
    "            loss = criterion(y, t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 日本時間のタイムゾーンを取得\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "# 現在の日本時間を取得\n",
    "now = datetime.now(jst)\n",
    "\n",
    "# 時刻を指定された形式の文字列に変換\n",
    "time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "# 学習曲線の可視化\n",
    "\n",
    "title = 'Training and Validation Losses object'\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.title(title)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,5)\n",
    "plt.legend()\n",
    "# plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# # y_labelとtを同じデバイスに移動\n",
    "# y_label = y_label.to(y.device)\n",
    "# t = t.to(y.device)\n",
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y, dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net(x)\n",
    "            \n",
    "            y_label = torch.argmax(y, dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 材質推定モデル\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "audio_origin = soundDataset.reshape(1050, -1)\n",
    "print(soundDataset.shape)\n",
    "print(audio_origin.shape)\n",
    "\n",
    "t_df = Dataset.matNum\n",
    "audio_tensor_dataset = torch.tensor(audio_origin, dtype=torch.float32)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset_origin = torch.utils.data.TensorDataset(audio_tensor_dataset, label_tensor)\n",
    "dataset_origin\n",
    "\n",
    "dataset_augu = augumentation(audio_origin,66150,Dataset.matNum)\n",
    "\n",
    "# データセットを指定する\n",
    "dataset = dataset_origin\n",
    "print(len(dataset))\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 60%　: 20% : 20%\n",
    "\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "train = train \n",
    "print(len(train))\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 50\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "\n",
    "audio_origin = soundDataset.reshape(1050, -1)\n",
    "\n",
    "t_df = Dataset.matNum\n",
    "\n",
    "\n",
    "audio_tensor_dataset = torch.tensor(audio_origin, dtype=torch.float32)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset_origin = torch.utils.data.TensorDataset(audio_tensor_dataset, label_tensor)\n",
    "dataset_origin\n",
    "\n",
    "# データセットを指定する\n",
    "dataset = dataset_origin\n",
    "print(len(dataset))\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 60%　: 20% : 20%\n",
    "\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train_origin, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "print(train_origin)\n",
    "\n",
    "\n",
    "#学習データをnpへ変換\n",
    "train_np = np.array([data.numpy() for data, _ in train_origin])\n",
    "train_np_label = np.array([label for _, label in train_origin])\n",
    "\n",
    "# #augmentation\n",
    "train_aug_up = train_np*1.2\n",
    "train_aug_down = train_np * 0.8\n",
    "wn = np.random.randn(train_np.shape[0],66150)\n",
    "train_aug_wn = train_np + wn\n",
    "print(train_aug_up.shape)\n",
    "\n",
    "\n",
    "train_np_aug = np.concatenate([train_aug_up,train_aug_down,train_aug_wn])\n",
    "label_all = np.concatenate([train_np_label,train_np_label,train_np_label])\n",
    "print(len(train_np_aug))\n",
    "print(label_all)\n",
    "\n",
    "train_np_aug = torch.tensor(train_np_aug,dtype=torch.float32)\n",
    "label_all = torch.tensor(label_all, dtype=torch.int64)\n",
    "\n",
    "train_aug = torch.utils.data.TensorDataset(train_np_aug, label_all)\n",
    "\n",
    "\n",
    "\n",
    "train = train_origin\n",
    "\n",
    "print(len(train))\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 50\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class matNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(matNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 40, 8),\n",
    "            nn.BatchNorm1d(40),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.25),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(40, 40, 8),\n",
    "            nn.BatchNorm1d(40),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(40, 6, 8),\n",
    "            nn.BatchNorm1d(6),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(6, 6, 8),\n",
    "            nn.BatchNorm1d(6),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(42, 21),  # 入力サイズを修正\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(21, 10),  # 出力サイズを修正\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.25),\n",
    "\n",
    "            nn.Linear(10, 10),  # 出力サイズを修正\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.conv2(h)\n",
    "        h = F.max_pool1d(h, kernel_size=160)\n",
    "          \n",
    "        h = self.conv3(h)\n",
    "        h = F.max_pool1d(h, kernel_size=3) \n",
    "        h = self.conv4(h) \n",
    "        h = F.max_pool1d(h, kernel_size=3) \n",
    "        h = self.classifier(h)\n",
    "        h = h.view(h.size(0), -1)  # Flatten\n",
    "        return h\n",
    "\n",
    "# モデルのインスタンス化\n",
    "matnet = matNet()\n",
    "\n",
    "# モデルの出力を計算してみる\n",
    "input_data = torch.randn(10,1,66150)\n",
    "print(input_data.shape)  \n",
    "output = matnet(input_data)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# エポックの数\n",
    "max_epoch = 100\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net = matNet().to(device)\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "criterion     \n",
    "\n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        # t = torch.unsqueeze(t, 0)\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y = net(x)\n",
    "        loss = criterion(y, t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "            x = torch.unsqueeze(x, 1)\n",
    "            # t = torch.unsqueeze(t, 0)\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            \n",
    "            y = net(x)\n",
    "            loss = criterion(y, t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 日本時間のタイムゾーンを取得\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "# 現在の日本時間を取得\n",
    "now = datetime.now(jst)\n",
    "\n",
    "# 時刻を指定された形式の文字列に変換\n",
    "time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "# 学習曲線の可視化\n",
    "\n",
    "title = 'Training and Validation Losses material'\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.title(title)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,5)\n",
    "plt.legend()\n",
    "plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# y_labelとtを同じデバイスに移動\n",
    "y_label = y_label.to(y.device)\n",
    "t = t.to(y.device)\n",
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y, dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net(x)\n",
    "            \n",
    "            y_label = torch.argmax(y, dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "device = torch.cuda.is_available() \n",
    "print(device)\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 剛柔推定モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "audio_origin = soundDataset.reshape(1050, -1)\n",
    "print(soundDataset.shape)\n",
    "print(audio_origin.shape)\n",
    "\n",
    "t_df = Dataset.shNum\n",
    "audio_tensor_dataset = torch.tensor(audio_origin, dtype=torch.float32)\n",
    "label_tensor_sh = torch.tensor(t_df, dtype=torch.int64)\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset_origin = torch.utils.data.TensorDataset(audio_tensor_dataset, label_tensor_sh)\n",
    "dataset_origin\n",
    "\n",
    "# dataset_augu = augumentation(audio_origin,66150,Dataset.shNum)\n",
    "\n",
    "# データセットを指定する\n",
    "dataset = dataset_origin\n",
    "print(len(dataset))\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 60%　: 20% : 20%\n",
    "\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "train = train \n",
    "print(len(train))\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 50\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "\n",
    "audio_origin = soundDataset.reshape(1050, -1) # type: ignore\n",
    "\n",
    "t_df = Dataset.shNum\n",
    "\n",
    "\n",
    "audio_tensor_dataset = torch.tensor(audio_origin, dtype=torch.float32)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset_origin = torch.utils.data.TensorDataset(audio_tensor_dataset, label_tensor)\n",
    "dataset_origin\n",
    "\n",
    "# データセットを指定する\n",
    "dataset = dataset_origin\n",
    "print(len(dataset))\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 60%　: 20% : 20%\n",
    "\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train_origin, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "print(train_origin)\n",
    "\n",
    "\n",
    "#学習データをnpへ変換\n",
    "train_np = np.array([data.numpy() for data, _ in train_origin])\n",
    "train_np_label = np.array([label for _, label in train_origin])\n",
    "\n",
    "# #augmentation\n",
    "train_aug_up = train_np*1.2\n",
    "train_aug_down = train_np * 0.8\n",
    "wn = np.random.randn(train_np.shape[0],66150)\n",
    "train_aug_wn = train_np + wn\n",
    "print(train_aug_up.shape)\n",
    "\n",
    "\n",
    "train_np_aug = np.concatenate([train_aug_up,train_aug_down,train_aug_wn])\n",
    "label_all = np.concatenate([train_np_label,train_np_label,train_np_label])\n",
    "print(len(train_np_aug))\n",
    "print(label_all)\n",
    "\n",
    "train_np_aug = torch.tensor(train_np_aug,dtype=torch.float32)\n",
    "label_all = torch.tensor(label_all, dtype=torch.int64)\n",
    "\n",
    "train_aug = torch.utils.data.TensorDataset(train_np_aug, label_all)\n",
    "\n",
    "\n",
    "\n",
    "train = train_origin \n",
    "\n",
    "print(len(train))\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 50\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class shNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(shNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 40, 8),\n",
    "            nn.BatchNorm1d(40),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.25),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(40, 40, 8),\n",
    "            nn.BatchNorm1d(40),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(40, 2, 8),\n",
    "            nn.BatchNorm1d(2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(2, 2, 8),\n",
    "            nn.BatchNorm1d(2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(42, 21),  # 入力サイズを修正\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(21, 2),  # 出力サイズを修正\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.25),\n",
    "\n",
    "            nn.Linear(2,2),  # 出力サイズを修正\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.conv2(h)\n",
    "        h = F.max_pool1d(h, kernel_size=160)\n",
    "          \n",
    "        h = self.conv3(h)\n",
    "        h = F.max_pool1d(h, kernel_size=3) \n",
    "        h = self.conv4(h) \n",
    "        h = F.max_pool1d(h, kernel_size=3) \n",
    "        h = self.classifier(h)\n",
    "        h = h.view(h.size(0), -1)  # Flatten\n",
    "        return h\n",
    "\n",
    "# モデルのインスタンス化\n",
    "shnet = shNet()\n",
    "\n",
    "# モデルの出力を計算してみる\n",
    "input_data = torch.randn(10,1,66150)\n",
    "print(input_data.shape)  \n",
    "output = shnet(input_data)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# エポックの数\n",
    "max_epoch = 100\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net = shNet().to(device)\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "# criterion     \n",
    "\n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        # t = torch.unsqueeze(t, 0)\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y = net(x)\n",
    "        loss = criterion(y, t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "            x = torch.unsqueeze(x, 1)\n",
    "            # t = torch.unsqueeze(t, 0)\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            \n",
    "            y = net(x)\n",
    "            loss = criterion(y, t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 日本時間のタイムゾーンを取得\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "# 現在の日本時間を取得\n",
    "now = datetime.now(jst)\n",
    "\n",
    "# 時刻を指定された形式の文字列に変換\n",
    "time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "# 学習曲線の可視化\n",
    "\n",
    "title = 'Training and Validation Losses Soft-hard'\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.title(title)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,5)\n",
    "plt.legend()\n",
    "# plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y, dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net(x)\n",
    "            \n",
    "            y_label = torch.argmax(y, dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 転移学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "audio_origin = soundDataset.reshape(1050, -1)\n",
    "print(soundDataset.shape)\n",
    "print(audio_origin.shape)\n",
    "\n",
    "t_df = Dataset.matNum\n",
    "audio_tensor_dataset = torch.tensor(audio_origin, dtype=torch.float32)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset_origin = torch.utils.data.TensorDataset(audio_tensor_dataset, label_tensor)\n",
    "dataset_origin\n",
    "\n",
    "# データセットを指定する\n",
    "dataset = dataset_origin\n",
    "print(len(dataset))\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 60%　: 20% : 20%\n",
    "\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "train = train \n",
    "print(len(train))\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 50\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# 転移学習\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "\n",
    "# 前提としてshNetが定義されている必要があります\n",
    "# print(net)\n",
    "\n",
    "transNet = shNet()\n",
    "\n",
    "# パラメータ固定\n",
    "for param in transNet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(transNet.classifier)\n",
    "\n",
    "# 畳み込み層の出力を計算するための入力サイズ（例：入力の長さが42の場合）\n",
    "input_length = 42\n",
    "conv_kernel_size = 8\n",
    "conv_output_size = input_length - conv_kernel_size + 1\n",
    "\n",
    "transNet.classifier = nn.Sequential(\n",
    "    nn.Conv1d(2, 6, conv_kernel_size),\n",
    "    nn.BatchNorm1d(6),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Flatten(),  # 畳み込み層の出力をフラット化する\n",
    "\n",
    "    nn.Linear(6 * conv_output_size, 21),  # 入力サイズを修正\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Linear(21, 10),  # 出力サイズを修正\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Linear(10, 10),  # 出力サイズを修正\n",
    ")\n",
    "\n",
    "print(transNet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# エポックの数\n",
    "max_epoch = 100\n",
    "     \n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net = transNet\n",
    "\n",
    "net = net.to(device)\n",
    "# net = trans_net\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "  \n",
    "\n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        # t = torch.unsqueeze(t, 0)\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y = net(x)\n",
    "        loss = criterion(y, t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "            x = torch.unsqueeze(x, 1)\n",
    "            # t = torch.unsqueeze(t, 0)\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            \n",
    "            y = net(x)\n",
    "            loss = criterion(y, t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 日本時間のタイムゾーンを取得\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "# 現在の日本時間を取得\n",
    "now = datetime.now(jst)\n",
    "\n",
    "# 時刻を指定された形式の文字列に変換\n",
    "time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "# 学習曲線の可視化\n",
    "\n",
    "title = 'Training and Validation Losses Soft-hard'\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.title(title)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,5)\n",
    "plt.legend()\n",
    "# plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y, dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net(x)\n",
    "            \n",
    "            y_label = torch.argmax(y, dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientATのファインチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchデータセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# パターンごとにスペクロログラムの保存\n",
    "df = []\n",
    "trial_num = 50\n",
    "for patern in range (len(soundDataset)):\n",
    "    for trial in range(trial_num):\n",
    "        trimData = soundDataset[patern,trial]\n",
    "        spectrogram = librosa.feature.melspectrogram(y=trimData, sr=sr)# スペクトログラムを計算\n",
    "        spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)    \n",
    "        df.append(spectrogram_db)\n",
    "\n",
    "df = np.array(df)\n",
    "print(df.shape)\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "print(df.shape) #(1050,128,130)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### soft-hard 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "\n",
    "# ラベルの指定\n",
    "t_df = Dataset.shNum\n",
    "\n",
    "# テンソル形式に変換\n",
    "df_tenosor = torch.tensor(df, dtype=torch.float32)\n",
    "df_tenosor = torch.unsqueeze(df_tenosor, 1)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "print(df_tenosor.size())\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset = torch.utils.data.TensorDataset(df_tenosor, label_tensor)\n",
    "\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 50%　: 25% : 25%\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 25\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# modelのインポート\n",
    "from models.dymn.model import get_model as get_dymn\n",
    "model = get_dymn(pretrained_name=\"dymn10_as\")\n",
    "\n",
    "#パラメータの更新を許可\n",
    "for param in model.parameters():\n",
    "    param.requires_gred = True\n",
    "\n",
    "\n",
    "# print(model.classifier)\n",
    "\n",
    "# 出力層の最後だけ変更\n",
    "# model.classifier[5] = torch.nn.Linear(1280,2)\n",
    "model.classifier= nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(output_size=1),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    nn.Linear(in_features=960, out_features=1280, bias=True),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=527, bias=True),\n",
    "    nn.Linear(in_features=527, out_features=176, bias=True),  # 新しい層\n",
    "    nn.Linear(in_features=176, out_features=2, bias=True)  # 新しい層\n",
    "\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# エポックの数\n",
    "max_epoch = 20\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net1 = model.cuda()\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "  \n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net1.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net1.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y = net1(x)\n",
    "        loss = criterion(y[0], t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net1.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "  \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net1(x)\n",
    "            loss = criterion(y[0], t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "shModel_trained = net1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "def ShowTrainLoss(train_losses,val_losses,save):\n",
    "    # 日本時間のタイムゾーンを取得\n",
    "    jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "    # 現在の日本時間を取得\n",
    "    now = datetime.now(jst)\n",
    "\n",
    "    # 時刻を指定された形式の文字列に変換\n",
    "    time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # 学習曲線の可視化\n",
    "\n",
    "    title = 'Training and Validation Losses Soft-hard'\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0,5)\n",
    "    plt.legend()\n",
    "    if save == True:\n",
    "        plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "ShowTrainLoss(train_losses,val_losses,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y[0], dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            # x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net1(x)\n",
    "            \n",
    "            y_label = torch.argmax(y[0], dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# from models.dymn.model import get_model as get_dymn\n",
    "# dymn10 = get_dymn(pretrained_name=\"dymn10_as\")\n",
    "\n",
    "# DataLoder(df,Dataset.matNum,25)\n",
    "# FineTune(dymn10,5,1280,6)\n",
    "# print(dymn10)\n",
    "# TrainVall(dymn10,train_loader,val_loader,8)\n",
    "\n",
    "# ShowTrainLoss(train_losses,val_losses,False)\n",
    "# calc_acc(FineTune.net,val_loader)\n",
    "# calc_acc(net,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### material 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# ラベルの指定\n",
    "t_df = Dataset.matNum\n",
    "\n",
    "# テンソル形式に変換\n",
    "df_tenosor = torch.tensor(df, dtype=torch.float32)\n",
    "df_tenosor = torch.unsqueeze(df_tenosor, 1)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "print(df_tenosor.size())\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset = torch.utils.data.TensorDataset(df_tenosor, label_tensor)\n",
    "\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 50%　: 25% : 25%\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 25\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "matModel = shModel_trained\n",
    "\n",
    "#パラメータの更新を許可\n",
    "for param in matModel.parameters():\n",
    "    param.requires_gred = True\n",
    "\n",
    "\n",
    "# print(model.classifier)\n",
    "\n",
    "# 出力層の最後だけ変更\n",
    "# model.classifier[5] = torch.nn.Linear(1280,2)\n",
    "matModel.classifier= nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(output_size=1),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    nn.Linear(in_features=960, out_features=1280, bias=True),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=527, bias=True),\n",
    "    nn.Linear(in_features=527, out_features=176, bias=True),  # 新しい層\n",
    "    nn.Linear(in_features=176, out_features=6, bias=True)  # 新しい層\n",
    "\n",
    ")\n",
    "print(matModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# エポックの数\n",
    "max_epoch = 150\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net2 = matModel.cuda()\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "  \n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net2.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net2.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y = net2(x)\n",
    "        loss = criterion(y[0], t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net2.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "  \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net2(x)\n",
    "            loss = criterion(y[0], t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "\n",
    "matModel_trained = net2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "def ShowTrainLoss(train_losses,val_losses,save):\n",
    "    # 日本時間のタイムゾーンを取得\n",
    "    jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "    # 現在の日本時間を取得\n",
    "    now = datetime.now(jst)\n",
    "\n",
    "    # 時刻を指定された形式の文字列に変換\n",
    "    time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # 学習曲線の可視化\n",
    "\n",
    "    title = 'Training and Validation Losses Material'\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0,5)\n",
    "    plt.legend()\n",
    "    if save == True:\n",
    "        plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "ShowTrainLoss(train_losses,val_losses,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y[0], dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            # x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net2(x)\n",
    "            \n",
    "            y_label = torch.argmax(y[0], dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### object 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# ラベルの指定\n",
    "t_df = Dataset.objectNum\n",
    "\n",
    "# テンソル形式に変換\n",
    "df_tenosor = torch.tensor(df, dtype=torch.float32)\n",
    "df_tenosor = torch.unsqueeze(df_tenosor, 1)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "print(df_tenosor.size())\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset = torch.utils.data.TensorDataset(df_tenosor, label_tensor)\n",
    "\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 50%　: 25% : 25%\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 25\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "objModel = matModel_trained\n",
    "\n",
    "#パラメータの更新を許可\n",
    "for param in objModel.parameters():\n",
    "    param.requires_gred = True\n",
    "\n",
    "\n",
    "# print(model.classifier)\n",
    "\n",
    "# 出力層の最後だけ変更\n",
    "# model.classifier[5] = torch.nn.Linear(1280,2)\n",
    "objModel.classifier= nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(output_size=1),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    nn.Linear(in_features=960, out_features=1280, bias=True),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=527, bias=True),\n",
    "    nn.Linear(in_features=527, out_features=176, bias=True),  # 新しい層\n",
    "    nn.Linear(in_features=176, out_features=21, bias=True)  # 新しい層\n",
    "\n",
    ")\n",
    "print(objModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# エポックの数\n",
    "max_epoch = 150\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net3 = objModel.cuda()\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "  \n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net3.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net3.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y = net3(x)\n",
    "        loss = criterion(y[0], t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net3.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "  \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net3(x)\n",
    "            loss = criterion(y[0], t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "\n",
    "objModel_trained = net3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "def ShowTrainLoss(train_losses,val_losses,save):\n",
    "    # 日本時間のタイムゾーンを取得\n",
    "    jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "    # 現在の日本時間を取得\n",
    "    now = datetime.now(jst)\n",
    "\n",
    "    # 時刻を指定された形式の文字列に変換\n",
    "    time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # 学習曲線の可視化\n",
    "\n",
    "    title = 'Training and Validation Losses Object'\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0,5)\n",
    "    plt.legend()\n",
    "    if save == True:\n",
    "        plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "ShowTrainLoss(train_losses,val_losses,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y[0], dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            # x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net3(x)\n",
    "            \n",
    "            y_label = torch.argmax(y[0], dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### soft-hard 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# ラベルの指定\n",
    "t_df = Dataset.shNum\n",
    "\n",
    "# テンソル形式に変換\n",
    "df_tenosor = torch.tensor(df, dtype=torch.float32)\n",
    "df_tenosor = torch.unsqueeze(df_tenosor, 1)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "print(df_tenosor.size())\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset = torch.utils.data.TensorDataset(df_tenosor, label_tensor)\n",
    "\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 50%　: 25% : 25%\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 25\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "shModel_2 = objModel_trained\n",
    "\n",
    "#パラメータの更新を許可\n",
    "for param in shModel_2.parameters():\n",
    "    param.requires_gred = False\n",
    "\n",
    "\n",
    "# print(model.classifier)\n",
    "\n",
    "# 出力層の最後だけ変更\n",
    "# model.classifier[5] = torch.nn.Linear(1280,2)\n",
    "shModel_2.classifier= nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(output_size=1),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    nn.Linear(in_features=960, out_features=1280, bias=False),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(p=0.2, inplace=False),\n",
    "    nn.Linear(in_features=1280, out_features=527, bias=False),\n",
    "    nn.Linear(in_features=527, out_features=176, bias=False),  # 新しい層\n",
    "    nn.Linear(in_features=176, out_features=21, bias=False),  # 新しい層\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=21, out_features=2, bias=True),  # 新しい層\n",
    "\n",
    "\n",
    ")\n",
    "print(shModel_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# エポックの数\n",
    "max_epoch = 50\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net4 = shModel_2.cuda()\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "  \n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net4.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net4.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y = net4(x)\n",
    "        loss = criterion(y[0], t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net4.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "  \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net4(x)\n",
    "            loss = criterion(y[0], t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "shModel_2_trained = net4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "def ShowTrainLoss(train_losses,val_losses,save):\n",
    "    # 日本時間のタイムゾーンを取得\n",
    "    jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "    # 現在の日本時間を取得\n",
    "    now = datetime.now(jst)\n",
    "\n",
    "    # 時刻を指定された形式の文字列に変換\n",
    "    time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # 学習曲線の可視化\n",
    "\n",
    "    title = 'Training and Validation Losses Soft-hard'\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0,5)\n",
    "    plt.legend()\n",
    "    if save == True:\n",
    "        plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "ShowTrainLoss(train_losses,val_losses,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y[0], dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            # x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net4(x)\n",
    "            \n",
    "            y_label = torch.argmax(y[0], dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### material 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# ラベルの指定\n",
    "t_df = Dataset.matNum\n",
    "\n",
    "# テンソル形式に変換\n",
    "df_tenosor = torch.tensor(df, dtype=torch.float32)\n",
    "df_tenosor = torch.unsqueeze(df_tenosor, 1)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "print(df_tenosor.size())\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset = torch.utils.data.TensorDataset(df_tenosor, label_tensor)\n",
    "\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 50%　: 25% : 25%\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 25\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "matModel_2 = shModel_2_trained\n",
    "\n",
    "#パラメータの更新を許可\n",
    "for param in matModel_2.parameters():\n",
    "    param.requires_gred = False\n",
    "\n",
    "\n",
    "# print(model.classifier)\n",
    "\n",
    "# 出力層の最後だけ変更\n",
    "# model.classifier[5] = torch.nn.Linear(1280,2)\n",
    "matModel_2.classifier= nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(output_size=1),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    nn.Linear(in_features=960, out_features=1280, bias=False),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(p=0.2, inplace=False),\n",
    "    nn.Linear(in_features=1280, out_features=527, bias=False),\n",
    "    nn.Linear(in_features=527, out_features=176, bias=False),  # 新しい層\n",
    "    nn.Linear(in_features=176, out_features=21, bias=False),  # 新しい層\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=21, out_features=6, bias=True),  # 新しい層\n",
    "    # nn.ReLU(),\n",
    "    # nn.Linear(in_features=2, out_features=21, bias=True),  # 新しい層\n",
    "    # nn.ReLU(),\n",
    "    # nn.Linear(in_features=21, out_features=6, bias=True),  # 新しい層\n",
    ")\n",
    "print(matModel_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# エポックの数\n",
    "epoch = 0\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net5 = matModel_2.cuda()\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "  \n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net5.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "# for epoch in range(max_epoch):\n",
    "train_epoch_loss = 1.0\n",
    "val_epoch_loss = 1.0\n",
    "\n",
    "while train_epoch_loss > 0.1 or val_epoch_loss  > 0.1 or epoch<50:\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net5.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y = net5(x)\n",
    "        loss = criterion(y[0], t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net5.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "  \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net5(x)\n",
    "            loss = criterion(y[0], t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "    epoch+=1\n",
    "\n",
    "matModel_2_trained = net5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "def ShowTrainLoss(train_losses,val_losses,save):\n",
    "    # 日本時間のタイムゾーンを取得\n",
    "    jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "    # 現在の日本時間を取得\n",
    "    now = datetime.now(jst)\n",
    "\n",
    "    # 時刻を指定された形式の文字列に変換\n",
    "    time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # 学習曲線の可視化\n",
    "\n",
    "    title = 'Training and Validation Losses Material'\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0,5)\n",
    "    plt.legend()\n",
    "    if save == True:\n",
    "        plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "ShowTrainLoss(train_losses,val_losses,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y[0], dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            # x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net5(x)\n",
    "            \n",
    "            y_label = torch.argmax(y[0], dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### object 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "# ラベルの指定\n",
    "t_df = Dataset.objectNum\n",
    "\n",
    "# テンソル形式に変換\n",
    "df_tenosor = torch.tensor(df, dtype=torch.float32)\n",
    "df_tenosor = torch.unsqueeze(df_tenosor, 1)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "print(df_tenosor.size())\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset = torch.utils.data.TensorDataset(df_tenosor, label_tensor)\n",
    "\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 50%　: 25% : 25%\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 25\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "objModel_2 = matModel_2_trained\n",
    "\n",
    "# パラメータの更新を許可\n",
    "for param in objModel_2.parameters():\n",
    "    param.requires_grad = False  # requires_gred -> requires_grad\n",
    "\n",
    "# 新しい層の追加とBatch Normalizationの導入\n",
    "objModel_2.classifier = nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(output_size=1),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    nn.Linear(in_features=960, out_features=1280, bias=False),\n",
    "    nn.BatchNorm1d(1280),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(p=0.2, inplace=False),\n",
    "    nn.Linear(in_features=1280, out_features=527, bias=False),\n",
    "    nn.BatchNorm1d(527),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=527, out_features=176, bias=False),\n",
    "    nn.BatchNorm1d(176),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=176, out_features=21, bias=False),\n",
    "    nn.BatchNorm1d(21),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=21, out_features=2, bias=False),\n",
    "    nn.BatchNorm1d(2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=2, out_features=21, bias=False),\n",
    "    nn.BatchNorm1d(21),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=21, out_features=6, bias=False),\n",
    "    nn.BatchNorm1d(6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=6, out_features=21, bias=True),\n",
    "    nn.BatchNorm1d(21),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=21, out_features=21, bias=True),\n",
    ")\n",
    "\n",
    "print(objModel_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# エポックの数\n",
    "epoch = 0\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net6 = objModel_2.cuda()\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "  \n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net6.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "train_epoch_loss = 1.0\n",
    "val_epoch_loss = 1.0\n",
    "# 学習ループ\n",
    "while (train_epoch_loss > 0.1 or val_epoch_loss  > 0.2 )or epoch<100:\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net6.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y = net6(x)\n",
    "        loss = criterion(y[0], t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net6.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "  \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net6(x)\n",
    "            loss = criterion(y[0], t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "    epoch+=1\n",
    "\n",
    "objModel_2_trained = net6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "def ShowTrainLoss(train_losses,val_losses,save):\n",
    "    # 日本時間のタイムゾーンを取得\n",
    "    jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "    # 現在の日本時間を取得\n",
    "    now = datetime.now(jst)\n",
    "\n",
    "    # 時刻を指定された形式の文字列に変換\n",
    "    time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # 学習曲線の可視化\n",
    "\n",
    "    title = 'Training and Validation Losses Material'\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0,5)\n",
    "    plt.legend()\n",
    "    if save == True:\n",
    "        plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "ShowTrainLoss(train_losses,val_losses,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y[0], dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            # x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net6(x)\n",
    "            \n",
    "            y_label = torch.argmax(y[0], dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31m詳細については、Jupyter [ログ] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
