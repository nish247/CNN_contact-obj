{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install librosa\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.2.post1\n",
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython.display\n",
    "import pandas as pd\n",
    "import statistics as sta\n",
    "import torch\n",
    "\n",
    "print(librosa.__version__)\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ファイル読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 変数定義\n",
    "sr = 44100 #サンプリング周波数\n",
    "\n",
    "# #ファイルパスの指定\n",
    "# train = \"../raw_data/contacting_object/train_data/\" #NASのデータ\n",
    "# # audio_dir = \"../Data_contacting_object/initial/FOLDER02\" #ローカルデータ\n",
    "# eval = \"../raw_data/contacting_object/initial/FOLDER03/\" \n",
    "\n",
    "\n",
    "# #学習用データの読み込み\n",
    "# audio_dir = train\n",
    "# subFolders = [f for f in os.listdir(audio_dir) if os.path.isdir(os.path.join(audio_dir, f))]\n",
    "# subFolders = sorted(subFolders) #昇順に並び替え\n",
    "\n",
    "# #ファイル読み込み\n",
    "# # originDatasに音声データを格納していく\n",
    "# originDatas = []\n",
    "# for subFolder in subFolders:\n",
    "#     filePath = audio_dir+\"/\"+subFolder+\"/\"+subFolder+\"_Tr1.WAV\"\n",
    "#     originData, sr = librosa.load(filePath, sr = sr)\n",
    "#     originDatas.append(originData)\n",
    "\n",
    "# #評価用データの読み込み\n",
    "# folderPath = eval\n",
    "# subFolders = [f for f in os.listdir(folderPath) if os.path.isdir(os.path.join(folderPath, f))]\n",
    "# subFolders = sorted(subFolders) #昇順に並び替え\n",
    "\n",
    "# #ファイル読み込み\n",
    "# # originDatas_eに音声データを格納していく\n",
    "# originDatas_e = []\n",
    "# for subFolder in subFolders:\n",
    "#     filePath = folderPath+\"/\"+subFolder+\"/\"+subFolder+\"_Tr1.WAV\"\n",
    "#     originData_e, sr = librosa.load(filePath, sr = sr)\n",
    "#     originDatas_e.append(originData_e)\n",
    "\n",
    "\n",
    "# #1データから30試行をトリミングを22パターン分行い，soundDatasetに格納する\n",
    "# # soundDatasetの構造：[パターン(10)][試行(50)][サンプリングデータ(66150)]\n",
    "\n",
    "# flag_amp = 0.1 #各試行の合図を検知する基準振幅\n",
    "# trimSkip = int(sr*0.4)\n",
    "# trimTime = int(sr*1.5)#1試行あたりのデータ長\n",
    "# dataNum = 50\n",
    "# trial = 0\n",
    "# soundDataset =([])\n",
    "\n",
    "# while trial <len(originDatas):\n",
    "#     index = 0\n",
    "#     trimDatas = ([]) #1データ(30試行)分のトリミングデータのリストを初期化\n",
    "#     originData = np.array(originDatas[trial])\n",
    "#     while index <len(originData):\n",
    "#         if originData[index] >= flag_amp:\n",
    "#             trimData = np.array(originData[index+trimSkip:index+trimTime+trimSkip]) #trim_dataにそのindexからindex+trimTimeのデータを格納する\n",
    "#             trimDatas = np.append(trimDatas ,trimData, axis=0)  #trimDatasに追加する\n",
    "#             index += trimTime\n",
    "#         else:\n",
    "#             index +=1\n",
    "#         if len(trimDatas) >=dataNum*trimTime:\n",
    "#             break\n",
    "#     soundDataset = np.append(soundDataset,np.array(trimDatas),axis=0)\n",
    "#     trial += 1\n",
    "\n",
    "# soundDataset = soundDataset.reshape(len(originDatas),dataNum,trimTime)\n",
    "\n",
    "# print(soundDataset.shape)\n",
    "\n",
    "# import pickle\n",
    "# f = open('soundDataset.pickle','wb')\n",
    "# pickle.dump(soundDataset,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('soundDataset_20240619.pickle','rb')\n",
    "soundDataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正解ラベルリストの作成\n",
    "\n",
    "#object層\n",
    "objectLabel = [\n",
    "    \"Y-shirt\", \n",
    "    \"Jeans\", \n",
    "    \"Sweatshirt\", \n",
    "\n",
    "    \"Blanket\", \n",
    "    \"bedquilt\", \n",
    "    \"Pillow\", \n",
    "    \n",
    "    \"Thick Book\", \n",
    "    \"Thin Book\", \n",
    "    \"Cardboard\", \n",
    "    \n",
    "    \"Mousepad\", \n",
    "    \"Chair\", \n",
    "    \"Sofa\", \n",
    "    \n",
    "    \"Metal Desk\", \n",
    "    \"Laptop\", \n",
    "    \"AlumiRack\", \n",
    "    \n",
    "    \"WoodDesk\", \n",
    "    \"WoodShelf\", \n",
    "    \"Floor\", \n",
    "    \n",
    "    \"Small Organizer\", \n",
    "    \"PlaBag\", \n",
    "    \"PlaShelf\"\n",
    "]\n",
    "\n",
    "#material層\n",
    "matLabel = [\n",
    "    \"Clothing\",\n",
    "    \"Clothing\", \n",
    "    \"Paper\", \n",
    "    \"Memory Foam\", \n",
    "    \"Metal\", \n",
    "    \"Wood\", \n",
    "    \"Plastic\"\n",
    "]\n",
    "\n",
    "matNum = [0,0,1,2,3,4,5]\n",
    "\n",
    "#soft-hard層\n",
    "shLabel = [\n",
    "    \"soft\",\n",
    "    \"hard\",\n",
    "]\n",
    "\n",
    "shNum = [0,1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(soundDataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価データセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Audio(data=soundDataset[1][0], rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スペクトログラムの描写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # パターンごとにスペクロログラムの描写\n",
    "# for patern in range(len(soundDataset)):\n",
    "#     trimData = soundDataset[patern,0]\n",
    "#     spectrogram = librosa.feature.melspectrogram(y=trimData, sr=sr)# スペクトログラムを計算\n",
    "#     librosa.display.specshow(librosa.power_to_db(spectrogram, ref=np.max)\\\n",
    "#                              , y_axis='mel', x_axis='time')# スペクトログラムを表示\n",
    "    # plt.colorbar(format='%+2.0f dB')# カラーバーを追加\n",
    "    # plt.ylim(0,500)\n",
    "    # plt.title('Mel Spectrogram_'+objectLabel[patern])# グラフのタイトルを設定\n",
    "    # plt.show()# グラフを表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for i in range(soundDataset.shape[0]):\n",
    "    title = 'FFT_'+objectLabel[i]\n",
    "    #FFT\n",
    "    data = soundDataset[i][0] # checked data\n",
    "    win_wid = 4096\n",
    "    win_ham = np.blackman(win_wid)\n",
    "\n",
    "    #window幅で割り切れない分を削除する\n",
    "    if data.shape[0] % win_wid != 0:\n",
    "        data = data[0:-(data.shape[0] % win_wid)]\n",
    "\n",
    "\n",
    "\n",
    "    #overlap & split window \n",
    "    overlap_rate = 0.5\n",
    "    overlap = int(win_wid*overlap_rate)\n",
    "    step = win_wid - overlap\n",
    "    frames = []\n",
    "    for start in range(0, len(data),step):\n",
    "        end = start + win_wid  # 'end'を定義\n",
    "        if end > len(data):\n",
    "            break\n",
    "        frame = data[start:end]\n",
    "        frames.append(frame)\n",
    "\n",
    "    #FFT\n",
    "    fft_ret = np.fft.rfft(frames * win_ham) #FFT\n",
    "    fft_freq = np.fft.rfftfreq(win_wid, 1/sr) #周波数軸のデータ作成\n",
    "\n",
    "    #transfer amp to log\n",
    "    log_fft_ret = 20*np.log10(np.abs(fft_ret)) # 対数データの取得←データを見やすくするため\n",
    "\n",
    "\n",
    "    #plot result\n",
    "    result_fft = np.mean(log_fft_ret, axis = 0)\n",
    "    plt.title(title)\n",
    "    plt.plot(fft_freq,result_fft)\n",
    "    plt.xlim(100,2000)\n",
    "    plt.ylim(-40,40)\n",
    "    # plt.savefig('data/figure_obj/'+title+'.pdf')\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 40)\n"
     ]
    }
   ],
   "source": [
    "# 特徴量の次元数\n",
    "num_feature = 40\n",
    "\n",
    "# 空のmfccSetを初期化\n",
    "mfccSet = np.empty((0, num_feature))\n",
    "\n",
    "# ループを使用してMFCCを抽出してmfccSetに追加\n",
    "for pattern in range(soundDataset.shape[0]):\n",
    "    for trial in range(soundDataset.shape[1]):\n",
    "        # MFCCを計算\n",
    "        mfccs = librosa.feature.mfcc(y=soundDataset[pattern][trial], sr=sr)\n",
    "        \n",
    "        # MFCCの各次元の平均を算出\n",
    "        mean = mfccs.mean(axis=1)\n",
    "        \n",
    "        # MFCCの各次元の標準偏差を算出\n",
    "        std = np.std(mfccs, axis=1)\n",
    "        \n",
    "        # mean, max_val, min_val, std をまとめた配列を作成\n",
    "        combined_stats = np.concatenate([mean,  std])\n",
    "\n",
    "        # mfccSetに追加\n",
    "        mfccSet = np.append(mfccSet, [combined_stats], axis=0)\n",
    "\n",
    "# 形状を確認\n",
    "print(mfccSet.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 40)\n",
      "(20, 130)\n"
     ]
    }
   ],
   "source": [
    "# 形状を確認\n",
    "print(mfccSet.shape)\n",
    "print(mfccs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>objectNum</th>\n",
       "      <th>matNum</th>\n",
       "      <th>shNum</th>\n",
       "      <th>object</th>\n",
       "      <th>mat</th>\n",
       "      <th>sh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-478.001703</td>\n",
       "      <td>63.457280</td>\n",
       "      <td>36.144773</td>\n",
       "      <td>26.225528</td>\n",
       "      <td>16.727231</td>\n",
       "      <td>14.407245</td>\n",
       "      <td>13.285984</td>\n",
       "      <td>9.590793</td>\n",
       "      <td>9.811856</td>\n",
       "      <td>5.082892</td>\n",
       "      <td>...</td>\n",
       "      <td>3.645248</td>\n",
       "      <td>3.399917</td>\n",
       "      <td>3.804335</td>\n",
       "      <td>3.734329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y-shirt</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-476.196495</td>\n",
       "      <td>67.811489</td>\n",
       "      <td>42.117584</td>\n",
       "      <td>28.188400</td>\n",
       "      <td>15.583791</td>\n",
       "      <td>13.266734</td>\n",
       "      <td>12.080886</td>\n",
       "      <td>8.774526</td>\n",
       "      <td>8.174143</td>\n",
       "      <td>4.179097</td>\n",
       "      <td>...</td>\n",
       "      <td>3.640349</td>\n",
       "      <td>3.322606</td>\n",
       "      <td>3.285746</td>\n",
       "      <td>3.343535</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y-shirt</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-477.773147</td>\n",
       "      <td>65.936731</td>\n",
       "      <td>41.942033</td>\n",
       "      <td>28.753131</td>\n",
       "      <td>17.348440</td>\n",
       "      <td>16.986556</td>\n",
       "      <td>15.279845</td>\n",
       "      <td>11.019433</td>\n",
       "      <td>9.088018</td>\n",
       "      <td>5.031381</td>\n",
       "      <td>...</td>\n",
       "      <td>3.156580</td>\n",
       "      <td>3.407280</td>\n",
       "      <td>3.517655</td>\n",
       "      <td>3.547526</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y-shirt</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-482.200915</td>\n",
       "      <td>63.764375</td>\n",
       "      <td>39.955530</td>\n",
       "      <td>26.105635</td>\n",
       "      <td>15.753873</td>\n",
       "      <td>13.904783</td>\n",
       "      <td>13.131842</td>\n",
       "      <td>9.218075</td>\n",
       "      <td>7.482949</td>\n",
       "      <td>4.541441</td>\n",
       "      <td>...</td>\n",
       "      <td>3.725960</td>\n",
       "      <td>3.272637</td>\n",
       "      <td>3.092343</td>\n",
       "      <td>3.604951</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y-shirt</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-479.097029</td>\n",
       "      <td>65.641729</td>\n",
       "      <td>40.932618</td>\n",
       "      <td>27.617450</td>\n",
       "      <td>16.556075</td>\n",
       "      <td>14.817480</td>\n",
       "      <td>14.321870</td>\n",
       "      <td>10.350258</td>\n",
       "      <td>8.893235</td>\n",
       "      <td>4.703604</td>\n",
       "      <td>...</td>\n",
       "      <td>3.328177</td>\n",
       "      <td>3.571923</td>\n",
       "      <td>3.805326</td>\n",
       "      <td>4.301650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Y-shirt</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>-462.453427</td>\n",
       "      <td>78.334440</td>\n",
       "      <td>45.349090</td>\n",
       "      <td>29.702114</td>\n",
       "      <td>15.009005</td>\n",
       "      <td>12.011045</td>\n",
       "      <td>13.299042</td>\n",
       "      <td>9.038196</td>\n",
       "      <td>6.716250</td>\n",
       "      <td>1.844909</td>\n",
       "      <td>...</td>\n",
       "      <td>3.297809</td>\n",
       "      <td>3.660277</td>\n",
       "      <td>3.493659</td>\n",
       "      <td>4.016997</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>PlaShelf</td>\n",
       "      <td>Plastic</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>-462.308041</td>\n",
       "      <td>79.059942</td>\n",
       "      <td>46.864514</td>\n",
       "      <td>30.124729</td>\n",
       "      <td>14.844601</td>\n",
       "      <td>12.301888</td>\n",
       "      <td>14.513218</td>\n",
       "      <td>10.563808</td>\n",
       "      <td>7.084634</td>\n",
       "      <td>1.905388</td>\n",
       "      <td>...</td>\n",
       "      <td>3.441372</td>\n",
       "      <td>3.365149</td>\n",
       "      <td>3.482850</td>\n",
       "      <td>4.577083</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>PlaShelf</td>\n",
       "      <td>Plastic</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>-461.417660</td>\n",
       "      <td>80.208434</td>\n",
       "      <td>46.588974</td>\n",
       "      <td>29.178092</td>\n",
       "      <td>14.371811</td>\n",
       "      <td>11.147610</td>\n",
       "      <td>12.965775</td>\n",
       "      <td>10.084192</td>\n",
       "      <td>7.170428</td>\n",
       "      <td>2.227163</td>\n",
       "      <td>...</td>\n",
       "      <td>3.539720</td>\n",
       "      <td>3.766647</td>\n",
       "      <td>4.083665</td>\n",
       "      <td>4.772348</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>PlaShelf</td>\n",
       "      <td>Plastic</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>-464.390102</td>\n",
       "      <td>76.848395</td>\n",
       "      <td>45.564795</td>\n",
       "      <td>31.331828</td>\n",
       "      <td>17.138878</td>\n",
       "      <td>14.709765</td>\n",
       "      <td>15.806167</td>\n",
       "      <td>10.320537</td>\n",
       "      <td>7.870815</td>\n",
       "      <td>3.794003</td>\n",
       "      <td>...</td>\n",
       "      <td>3.418645</td>\n",
       "      <td>3.032147</td>\n",
       "      <td>3.479765</td>\n",
       "      <td>4.267387</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>PlaShelf</td>\n",
       "      <td>Plastic</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>-464.331221</td>\n",
       "      <td>77.494024</td>\n",
       "      <td>46.013428</td>\n",
       "      <td>30.236395</td>\n",
       "      <td>15.410224</td>\n",
       "      <td>11.137606</td>\n",
       "      <td>14.633425</td>\n",
       "      <td>11.408875</td>\n",
       "      <td>7.633750</td>\n",
       "      <td>3.438667</td>\n",
       "      <td>...</td>\n",
       "      <td>3.561853</td>\n",
       "      <td>3.131706</td>\n",
       "      <td>3.513493</td>\n",
       "      <td>3.492387</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>PlaShelf</td>\n",
       "      <td>Plastic</td>\n",
       "      <td>hard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1050 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2          3          4          5  \\\n",
       "0    -478.001703  63.457280  36.144773  26.225528  16.727231  14.407245   \n",
       "1    -476.196495  67.811489  42.117584  28.188400  15.583791  13.266734   \n",
       "2    -477.773147  65.936731  41.942033  28.753131  17.348440  16.986556   \n",
       "3    -482.200915  63.764375  39.955530  26.105635  15.753873  13.904783   \n",
       "4    -479.097029  65.641729  40.932618  27.617450  16.556075  14.817480   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "1045 -462.453427  78.334440  45.349090  29.702114  15.009005  12.011045   \n",
       "1046 -462.308041  79.059942  46.864514  30.124729  14.844601  12.301888   \n",
       "1047 -461.417660  80.208434  46.588974  29.178092  14.371811  11.147610   \n",
       "1048 -464.390102  76.848395  45.564795  31.331828  17.138878  14.709765   \n",
       "1049 -464.331221  77.494024  46.013428  30.236395  15.410224  11.137606   \n",
       "\n",
       "              6          7         8         9  ...        36        37  \\\n",
       "0     13.285984   9.590793  9.811856  5.082892  ...  3.645248  3.399917   \n",
       "1     12.080886   8.774526  8.174143  4.179097  ...  3.640349  3.322606   \n",
       "2     15.279845  11.019433  9.088018  5.031381  ...  3.156580  3.407280   \n",
       "3     13.131842   9.218075  7.482949  4.541441  ...  3.725960  3.272637   \n",
       "4     14.321870  10.350258  8.893235  4.703604  ...  3.328177  3.571923   \n",
       "...         ...        ...       ...       ...  ...       ...       ...   \n",
       "1045  13.299042   9.038196  6.716250  1.844909  ...  3.297809  3.660277   \n",
       "1046  14.513218  10.563808  7.084634  1.905388  ...  3.441372  3.365149   \n",
       "1047  12.965775  10.084192  7.170428  2.227163  ...  3.539720  3.766647   \n",
       "1048  15.806167  10.320537  7.870815  3.794003  ...  3.418645  3.032147   \n",
       "1049  14.633425  11.408875  7.633750  3.438667  ...  3.561853  3.131706   \n",
       "\n",
       "            38        39  objectNum  matNum  shNum    object       mat    sh  \n",
       "0     3.804335  3.734329          0       0      0   Y-shirt  Clothing  soft  \n",
       "1     3.285746  3.343535          0       0      0   Y-shirt  Clothing  soft  \n",
       "2     3.517655  3.547526          0       0      0   Y-shirt  Clothing  soft  \n",
       "3     3.092343  3.604951          0       0      0   Y-shirt  Clothing  soft  \n",
       "4     3.805326  4.301650          0       0      0   Y-shirt  Clothing  soft  \n",
       "...        ...       ...        ...     ...    ...       ...       ...   ...  \n",
       "1045  3.493659  4.016997         20       5      1  PlaShelf   Plastic  hard  \n",
       "1046  3.482850  4.577083         20       5      1  PlaShelf   Plastic  hard  \n",
       "1047  4.083665  4.772348         20       5      1  PlaShelf   Plastic  hard  \n",
       "1048  3.479765  4.267387         20       5      1  PlaShelf   Plastic  hard  \n",
       "1049  3.513493  3.492387         20       5      1  PlaShelf   Plastic  hard  \n",
       "\n",
       "[1050 rows x 46 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# num_feature次元のMFCCのデータフレームを作成\n",
    "Dataset = pd.DataFrame(data=mfccSet)\n",
    "\n",
    "\n",
    "Dataset['objectNum'] = [i // soundDataset.shape[1] for i in range(mfccSet.shape[0])]\n",
    "Dataset['matNum'] = np.repeat(matNum, 150)[:1050]\n",
    "Dataset['shNum'] = np.repeat(shNum, 600)[:1050]\n",
    "\n",
    "# データセットに'objectLabel'の列を追加\n",
    "Dataset['object'] = np.repeat(objectLabel, 50)[:1050]\n",
    "\n",
    "# # データセットに'matLabel'の列を追加\n",
    "Dataset['mat'] = np.repeat(matLabel, 150)[:1050]\n",
    "\n",
    "# # データセットに'SHLabel'の列を追加\n",
    "Dataset['sh'] = np.repeat(shLabel, 600)[:1050]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGC-DL-CONTAINER-LICENSE    dev    lib64   proc      srv  workspace\n",
      "app\t\t\t    etc    libx32  raw_data  sys\n",
      "bin\t\t\t    home   media   root      tmp\n",
      "boot\t\t\t    lib    mnt\t   run\t     usr\n",
      "cuda-keyring_1.0-1_all.deb  lib32  opt\t   sbin      var\n"
     ]
    }
   ],
   "source": [
    "! ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial1 = Dataset.iloc[Dataset.index // 10 % 10 <= 4]\n",
    "# trial2 = Dataset.iloc[Dataset.index // 10 % 10 > 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_202406070908\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 日本時間のタイムゾーンを取得\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "# 現在の日本時間を取得\n",
    "now = datetime.now(jst)\n",
    "\n",
    "# 時刻を指定された形式の文字列に変換\n",
    "time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 物体推定モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050\n",
      "525 262 263\n",
      "<torch.utils.data.dataset.Subset object at 0x7f941bcf5ff0>\n",
      "1050\n",
      "[ 9  1 14 ...  2 12  4]\n",
      "525\n"
     ]
    }
   ],
   "source": [
    "\n",
    "audio_origin = soundDataset.reshape(1050, -1)\n",
    "\n",
    "t_df = Dataset.objectNum\n",
    "\n",
    "\n",
    "audio_tensor_dataset = torch.tensor(audio_origin, dtype=torch.float32)\n",
    "label_tensor_sh = torch.tensor(t_df, dtype=torch.int64)\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset_origin = torch.utils.data.TensorDataset(audio_tensor_dataset, label_tensor_sh)\n",
    "dataset_origin\n",
    "\n",
    "# データセットを指定する\n",
    "dataset = dataset_origin\n",
    "print(len(dataset))\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 60%　: 20% : 20%\n",
    "\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train_origin, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "print(train_origin)\n",
    "\n",
    "\n",
    "#学習データをnpへ変換\n",
    "train_np = np.array([data.numpy() for data, _ in train_origin])\n",
    "train_np_label = np.array([label for _, label in train_origin])\n",
    "\n",
    "# #augmentation\n",
    "train_aug_up = train_np*1.1\n",
    "train_aug_down = train_np * 0.9\n",
    "wn = np.random.randn(train_np.shape[0],66150)\n",
    "train_aug_wn = train_np + wn\n",
    "# print(train_np)\n",
    "# print(train_aug_up)\n",
    "\n",
    "\n",
    "train_np_aug = np.concatenate([train_aug_up,train_aug_down])\n",
    "label_all = np.concatenate([train_np_label,train_np_label])\n",
    "print(len(train_np_aug))\n",
    "print(label_all)\n",
    "\n",
    "train_np_aug = torch.tensor(train_np_aug,dtype=torch.float32)\n",
    "label_all = torch.tensor(label_all, dtype=torch.int64)\n",
    "\n",
    "train_aug = torch.utils.data.TensorDataset(train_np_aug, label_all)\n",
    "\n",
    "\n",
    "\n",
    "train = train_origin\n",
    "\n",
    "print(len(train))\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 50\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 66150])\n",
      "Output shape: torch.Size([10, 21])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class objNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(objNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 40, 8),\n",
    "            nn.BatchNorm1d(40),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(40, 40, 8),\n",
    "            nn.BatchNorm1d(40),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(40, 21, 8),\n",
    "            nn.BatchNorm1d(21),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(21, 21, 8),\n",
    "            nn.BatchNorm1d(21),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(42, 21),  # 入力サイズを修正\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(21, 21),  # 出力サイズを修正\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Linear(21,1),\n",
    "            # nn.Dropout(0.25)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.conv2(h)\n",
    "        h = F.max_pool1d(h, kernel_size=160)\n",
    "          \n",
    "        h = self.conv3(h)\n",
    "        h = F.max_pool1d(h, kernel_size=3) \n",
    "        h = self.conv4(h) \n",
    "        h = F.max_pool1d(h, kernel_size=3) \n",
    "        h = self.classifier(h)\n",
    "        h = h.view(h.size(0), -1)  # Flatten\n",
    "        return h\n",
    "\n",
    "# モデルのインスタンス化\n",
    "objnet = objNet()\n",
    "\n",
    "# モデルの出力を計算してみる\n",
    "input_data = torch.randn(10,1,66150)\n",
    "print(input_data.shape)  \n",
    "output = objnet(input_data)\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エポックの数\n",
    "max_epoch = 50\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net = objNet().to(device)\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "criterion     \n",
    "\n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        # t = torch.unsqueeze(t, 0)\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y = net(x)\n",
    "        loss = criterion(y, t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "            x = torch.unsqueeze(x, 1)\n",
    "            # t = torch.unsqueeze(t, 0)\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            \n",
    "            y = net(x)\n",
    "            loss = criterion(y, t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 日本時間のタイムゾーンを取得\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "# 現在の日本時間を取得\n",
    "now = datetime.now(jst)\n",
    "\n",
    "# 時刻を指定された形式の文字列に変換\n",
    "time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "# 学習曲線の可視化\n",
    "\n",
    "title = 'Training and Validation Losses object'\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.title(title)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,5)\n",
    "plt.legend()\n",
    "# plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y_labelとtを同じデバイスに移動\n",
    "# y_label = y_label.to(y.device)\n",
    "# t = t.to(y.device)\n",
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y, dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net(x)\n",
    "            \n",
    "            y_label = torch.argmax(y, dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 材質推定モデル\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "audio_origin = soundDataset.reshape(1050, -1)\n",
    "print(soundDataset.shape)\n",
    "print(audio_origin.shape)\n",
    "\n",
    "t_df = Dataset.matNum\n",
    "audio_tensor_dataset = torch.tensor(audio_origin, dtype=torch.float32)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset_origin = torch.utils.data.TensorDataset(audio_tensor_dataset, label_tensor)\n",
    "dataset_origin\n",
    "\n",
    "dataset_augu = augumentation(audio_origin,66150,Dataset.matNum)\n",
    "\n",
    "# データセットを指定する\n",
    "dataset = dataset_origin\n",
    "print(len(dataset))\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 60%　: 20% : 20%\n",
    "\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "train = train \n",
    "print(len(train))\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 50\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "audio_origin = soundDataset.reshape(1050, -1)\n",
    "\n",
    "t_df = Dataset.matNum\n",
    "\n",
    "\n",
    "audio_tensor_dataset = torch.tensor(audio_origin, dtype=torch.float32)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset_origin = torch.utils.data.TensorDataset(audio_tensor_dataset, label_tensor)\n",
    "dataset_origin\n",
    "\n",
    "# データセットを指定する\n",
    "dataset = dataset_origin\n",
    "print(len(dataset))\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 60%　: 20% : 20%\n",
    "\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train_origin, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "print(train_origin)\n",
    "\n",
    "\n",
    "#学習データをnpへ変換\n",
    "train_np = np.array([data.numpy() for data, _ in train_origin])\n",
    "train_np_label = np.array([label for _, label in train_origin])\n",
    "\n",
    "# #augmentation\n",
    "train_aug_up = train_np*1.2\n",
    "train_aug_down = train_np * 0.8\n",
    "wn = np.random.randn(train_np.shape[0],66150)\n",
    "train_aug_wn = train_np + wn\n",
    "print(train_aug_up.shape)\n",
    "\n",
    "\n",
    "train_np_aug = np.concatenate([train_aug_up,train_aug_down,train_aug_wn])\n",
    "label_all = np.concatenate([train_np_label,train_np_label,train_np_label])\n",
    "print(len(train_np_aug))\n",
    "print(label_all)\n",
    "\n",
    "train_np_aug = torch.tensor(train_np_aug,dtype=torch.float32)\n",
    "label_all = torch.tensor(label_all, dtype=torch.int64)\n",
    "\n",
    "train_aug = torch.utils.data.TensorDataset(train_np_aug, label_all)\n",
    "\n",
    "\n",
    "\n",
    "train = train_origin\n",
    "\n",
    "print(len(train))\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 50\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class matNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(matNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 40, 8),\n",
    "            nn.BatchNorm1d(40),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.25),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(40, 40, 8),\n",
    "            nn.BatchNorm1d(40),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(40, 6, 8),\n",
    "            nn.BatchNorm1d(6),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(6, 6, 8),\n",
    "            nn.BatchNorm1d(6),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(42, 21),  # 入力サイズを修正\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(21, 10),  # 出力サイズを修正\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.25),\n",
    "\n",
    "            nn.Linear(10, 10),  # 出力サイズを修正\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.conv2(h)\n",
    "        h = F.max_pool1d(h, kernel_size=160)\n",
    "          \n",
    "        h = self.conv3(h)\n",
    "        h = F.max_pool1d(h, kernel_size=3) \n",
    "        h = self.conv4(h) \n",
    "        h = F.max_pool1d(h, kernel_size=3) \n",
    "        h = self.classifier(h)\n",
    "        h = h.view(h.size(0), -1)  # Flatten\n",
    "        return h\n",
    "\n",
    "# モデルのインスタンス化\n",
    "matnet = matNet()\n",
    "\n",
    "# モデルの出力を計算してみる\n",
    "input_data = torch.randn(10,1,66150)\n",
    "print(input_data.shape)  \n",
    "output = matnet(input_data)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エポックの数\n",
    "max_epoch = 100\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net = matNet().to(device)\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "criterion     \n",
    "\n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        # t = torch.unsqueeze(t, 0)\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y = net(x)\n",
    "        loss = criterion(y, t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "            x = torch.unsqueeze(x, 1)\n",
    "            # t = torch.unsqueeze(t, 0)\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            \n",
    "            y = net(x)\n",
    "            loss = criterion(y, t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 日本時間のタイムゾーンを取得\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "# 現在の日本時間を取得\n",
    "now = datetime.now(jst)\n",
    "\n",
    "# 時刻を指定された形式の文字列に変換\n",
    "time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "# 学習曲線の可視化\n",
    "\n",
    "title = 'Training and Validation Losses material'\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.title(title)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,5)\n",
    "plt.legend()\n",
    "plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_labelとtを同じデバイスに移動\n",
    "y_label = y_label.to(y.device)\n",
    "t = t.to(y.device)\n",
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y, dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net(x)\n",
    "            \n",
    "            y_label = torch.argmax(y, dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.is_available() \n",
    "print(device)\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 剛柔推定モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "audio_origin = soundDataset.reshape(1050, -1)\n",
    "print(soundDataset.shape)\n",
    "print(audio_origin.shape)\n",
    "\n",
    "t_df = Dataset.shNum\n",
    "audio_tensor_dataset = torch.tensor(audio_origin, dtype=torch.float32)\n",
    "label_tensor_sh = torch.tensor(t_df, dtype=torch.int64)\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset_origin = torch.utils.data.TensorDataset(audio_tensor_dataset, label_tensor_sh)\n",
    "dataset_origin\n",
    "\n",
    "# dataset_augu = augumentation(audio_origin,66150,Dataset.shNum)\n",
    "\n",
    "# データセットを指定する\n",
    "dataset = dataset_origin\n",
    "print(len(dataset))\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 60%　: 20% : 20%\n",
    "\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "train = train \n",
    "print(len(train))\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 50\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "audio_origin = soundDataset.reshape(1050, -1) # type: ignore\n",
    "\n",
    "t_df = Dataset.shNum\n",
    "\n",
    "\n",
    "audio_tensor_dataset = torch.tensor(audio_origin, dtype=torch.float32)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset_origin = torch.utils.data.TensorDataset(audio_tensor_dataset, label_tensor)\n",
    "dataset_origin\n",
    "\n",
    "# データセットを指定する\n",
    "dataset = dataset_origin\n",
    "print(len(dataset))\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 60%　: 20% : 20%\n",
    "\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train_origin, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "print(train_origin)\n",
    "\n",
    "\n",
    "#学習データをnpへ変換\n",
    "train_np = np.array([data.numpy() for data, _ in train_origin])\n",
    "train_np_label = np.array([label for _, label in train_origin])\n",
    "\n",
    "# #augmentation\n",
    "train_aug_up = train_np*1.2\n",
    "train_aug_down = train_np * 0.8\n",
    "wn = np.random.randn(train_np.shape[0],66150)\n",
    "train_aug_wn = train_np + wn\n",
    "print(train_aug_up.shape)\n",
    "\n",
    "\n",
    "train_np_aug = np.concatenate([train_aug_up,train_aug_down,train_aug_wn])\n",
    "label_all = np.concatenate([train_np_label,train_np_label,train_np_label])\n",
    "print(len(train_np_aug))\n",
    "print(label_all)\n",
    "\n",
    "train_np_aug = torch.tensor(train_np_aug,dtype=torch.float32)\n",
    "label_all = torch.tensor(label_all, dtype=torch.int64)\n",
    "\n",
    "train_aug = torch.utils.data.TensorDataset(train_np_aug, label_all)\n",
    "\n",
    "\n",
    "\n",
    "train = train_origin \n",
    "\n",
    "print(len(train))\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 50\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class shNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(shNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 40, 8),\n",
    "            nn.BatchNorm1d(40),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.25),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(40, 40, 8),\n",
    "            nn.BatchNorm1d(40),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(40, 2, 8),\n",
    "            nn.BatchNorm1d(2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(2, 2, 8),\n",
    "            nn.BatchNorm1d(2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(42, 21),  # 入力サイズを修正\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(21, 2),  # 出力サイズを修正\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.25),\n",
    "\n",
    "            nn.Linear(2,2),  # 出力サイズを修正\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.conv2(h)\n",
    "        h = F.max_pool1d(h, kernel_size=160)\n",
    "          \n",
    "        h = self.conv3(h)\n",
    "        h = F.max_pool1d(h, kernel_size=3) \n",
    "        h = self.conv4(h) \n",
    "        h = F.max_pool1d(h, kernel_size=3) \n",
    "        h = self.classifier(h)\n",
    "        h = h.view(h.size(0), -1)  # Flatten\n",
    "        return h\n",
    "\n",
    "# モデルのインスタンス化\n",
    "shnet = shNet()\n",
    "\n",
    "# モデルの出力を計算してみる\n",
    "input_data = torch.randn(10,1,66150)\n",
    "print(input_data.shape)  \n",
    "output = shnet(input_data)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エポックの数\n",
    "max_epoch = 100\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net = shNet().to(device)\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "# criterion     \n",
    "\n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        # t = torch.unsqueeze(t, 0)\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y = net(x)\n",
    "        loss = criterion(y, t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "            x = torch.unsqueeze(x, 1)\n",
    "            # t = torch.unsqueeze(t, 0)\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            \n",
    "            y = net(x)\n",
    "            loss = criterion(y, t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 日本時間のタイムゾーンを取得\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "# 現在の日本時間を取得\n",
    "now = datetime.now(jst)\n",
    "\n",
    "# 時刻を指定された形式の文字列に変換\n",
    "time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "# 学習曲線の可視化\n",
    "\n",
    "title = 'Training and Validation Losses Soft-hard'\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.title(title)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,5)\n",
    "plt.legend()\n",
    "# plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y, dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net(x)\n",
    "            \n",
    "            y_label = torch.argmax(y, dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 転移学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "audio_origin = soundDataset.reshape(1050, -1)\n",
    "print(soundDataset.shape)\n",
    "print(audio_origin.shape)\n",
    "\n",
    "t_df = Dataset.matNum\n",
    "audio_tensor_dataset = torch.tensor(audio_origin, dtype=torch.float32)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset_origin = torch.utils.data.TensorDataset(audio_tensor_dataset, label_tensor)\n",
    "dataset_origin\n",
    "\n",
    "# データセットを指定する\n",
    "dataset = dataset_origin\n",
    "print(len(dataset))\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 60%　: 20% : 20%\n",
    "\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "train = train \n",
    "print(len(train))\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 50\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 転移学習\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "\n",
    "# 前提としてshNetが定義されている必要があります\n",
    "# print(net)\n",
    "\n",
    "transNet = shNet()\n",
    "\n",
    "# パラメータ固定\n",
    "for param in transNet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(transNet.classifier)\n",
    "\n",
    "# 畳み込み層の出力を計算するための入力サイズ（例：入力の長さが42の場合）\n",
    "input_length = 42\n",
    "conv_kernel_size = 8\n",
    "conv_output_size = input_length - conv_kernel_size + 1\n",
    "\n",
    "transNet.classifier = nn.Sequential(\n",
    "    nn.Conv1d(2, 6, conv_kernel_size),\n",
    "    nn.BatchNorm1d(6),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Flatten(),  # 畳み込み層の出力をフラット化する\n",
    "\n",
    "    nn.Linear(6 * conv_output_size, 21),  # 入力サイズを修正\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Linear(21, 10),  # 出力サイズを修正\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Linear(10, 10),  # 出力サイズを修正\n",
    ")\n",
    "\n",
    "print(transNet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エポックの数\n",
    "max_epoch = 100\n",
    "     \n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net = transNet\n",
    "\n",
    "net = net.to(device)\n",
    "# net = trans_net\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "  \n",
    "\n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        # t = torch.unsqueeze(t, 0)\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y = net(x)\n",
    "        loss = criterion(y, t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "            x = torch.unsqueeze(x, 1)\n",
    "            # t = torch.unsqueeze(t, 0)\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            \n",
    "            y = net(x)\n",
    "            loss = criterion(y, t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# 日本時間のタイムゾーンを取得\n",
    "jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "# 現在の日本時間を取得\n",
    "now = datetime.now(jst)\n",
    "\n",
    "# 時刻を指定された形式の文字列に変換\n",
    "time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "# 学習曲線の可視化\n",
    "\n",
    "title = 'Training and Validation Losses Soft-hard'\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.title(title)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0,5)\n",
    "plt.legend()\n",
    "# plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y, dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net(x)\n",
    "            \n",
    "            y_label = torch.argmax(y, dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientATのファインチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchデータセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 128, 130)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# パターンごとにスペクロログラムの保存\n",
    "df = []\n",
    "trial_num = 50\n",
    "for patern in range (len(soundDataset)):\n",
    "    for trial in range(trial_num):\n",
    "        trimData = soundDataset[patern,trial]\n",
    "        spectrogram = librosa.feature.melspectrogram(y=trimData, sr=sr)# スペクトログラムを計算\n",
    "        spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)    \n",
    "        df.append(spectrogram_db)\n",
    "\n",
    "df = np.array(df)\n",
    "print(df.shape)\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 128, 130)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape) #(1050,128,130)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1050, 1, 128, 130])\n",
      "525 262 263\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f68f02880a0>\n",
      "[tensor([[[[-16.1880, -10.2756, -10.2136,  ...,  -9.4156, -14.5458, -21.3748],\n",
      "          [-16.2891, -15.6456, -12.7290,  ..., -14.3924, -25.2283, -24.1254],\n",
      "          [-17.3913, -15.9702, -20.0184,  ..., -20.0343, -24.3928, -26.5555],\n",
      "          ...,\n",
      "          [-48.4910, -45.6473, -44.6052,  ..., -42.5551, -43.2055, -45.9880],\n",
      "          [-48.3502, -44.7486, -43.4806,  ..., -42.5986, -43.2013, -46.5223],\n",
      "          [-47.4865, -44.2736, -44.7912,  ..., -44.1931, -44.0013, -45.5822]]],\n",
      "\n",
      "\n",
      "        [[[ -9.1079,  -7.2102,  -5.1802,  ...,  -3.1219,  -1.4221,  -1.6282],\n",
      "          [ -9.1465, -10.0313, -10.1490,  ..., -14.1699,  -9.0928,  -7.1825],\n",
      "          [-13.8148, -13.5277, -15.6352,  ..., -26.3621, -20.8560, -18.8614],\n",
      "          ...,\n",
      "          [-45.3104, -40.8363, -42.2715,  ..., -42.5708, -41.7785, -42.7498],\n",
      "          [-46.9087, -43.1651, -41.5075,  ..., -43.9106, -44.0809, -43.9444],\n",
      "          [-45.5507, -43.2805, -42.7816,  ..., -43.1379, -43.3027, -45.0362]]],\n",
      "\n",
      "\n",
      "        [[[-21.9538, -17.8468, -18.5859,  ..., -17.2805, -17.2143, -17.5165],\n",
      "          [-23.6664, -22.3130, -25.8596,  ..., -28.0734, -25.3133, -21.3765],\n",
      "          [-32.0604, -36.5037, -41.6331,  ..., -35.7640, -33.9399, -26.0094],\n",
      "          ...,\n",
      "          [-67.2539, -64.8069, -65.7577,  ..., -65.7734, -64.8902, -67.4874],\n",
      "          [-69.7678, -66.6096, -66.1510,  ..., -64.5831, -64.4422, -67.3266],\n",
      "          [-69.3025, -67.2379, -65.7721,  ..., -65.6959, -66.2200, -68.3164]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-16.1495,  -8.6172,  -8.5552,  ..., -12.1880,  -9.9977, -14.1546],\n",
      "          [-19.2951, -12.4130, -11.6621,  ..., -18.6645, -18.1632, -21.7046],\n",
      "          [-29.8199, -26.5843, -24.0601,  ..., -28.0448, -30.6980, -26.9015],\n",
      "          ...,\n",
      "          [-54.6694, -52.7589, -52.6917,  ..., -51.8022, -51.5131, -54.2737],\n",
      "          [-54.2254, -51.0742, -51.7544,  ..., -52.1907, -51.2633, -54.0069],\n",
      "          [-55.0881, -52.9277, -52.3263,  ..., -53.5566, -51.4434, -54.8920]]],\n",
      "\n",
      "\n",
      "        [[[-17.7715,  -9.5052,  -8.7757,  ...,  -2.4660,  -3.5174,  -9.9958],\n",
      "          [-17.4795, -14.4194, -17.4666,  ..., -10.6221,  -9.2412, -12.3387],\n",
      "          [-21.9506, -22.8319, -22.1609,  ..., -25.5773, -19.6839, -22.5344],\n",
      "          ...,\n",
      "          [-48.7584, -47.2439, -48.7927,  ..., -46.6711, -47.0849, -50.3600],\n",
      "          [-53.2702, -49.1122, -46.9601,  ..., -47.5542, -46.2338, -48.1493],\n",
      "          [-49.0959, -48.0344, -47.8656,  ..., -48.4941, -47.1972, -48.9839]]],\n",
      "\n",
      "\n",
      "        [[[ -6.3721,  -2.9440,  -3.4502,  ...,  -7.7154,  -5.5990,  -6.4269],\n",
      "          [-10.2517,  -8.3416,  -9.8827,  ..., -14.5667, -12.0482, -11.1314],\n",
      "          [-18.7083, -21.1876, -22.4474,  ..., -20.6590, -25.0544, -20.5907],\n",
      "          ...,\n",
      "          [-53.3725, -51.7865, -50.8111,  ..., -49.4618, -49.8466, -54.1556],\n",
      "          [-53.7968, -49.8189, -49.6426,  ..., -50.0451, -49.5946, -53.0844],\n",
      "          [-54.3547, -50.0201, -49.0470,  ..., -50.1826, -48.7919, -50.9261]]]]), tensor([1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0])]\n",
      "[tensor([[[[ -8.5122,  -5.5297,  -4.3257,  ..., -10.0484, -13.9686, -16.9585],\n",
      "          [-12.3318, -12.3895, -13.1427,  ..., -12.0882, -15.9287, -19.3138],\n",
      "          [-21.9346, -20.6902, -21.5579,  ..., -22.1088, -24.8373, -22.0265],\n",
      "          ...,\n",
      "          [-55.8519, -53.6629, -52.1597,  ..., -51.2897, -50.6702, -54.1591],\n",
      "          [-54.1112, -51.4574, -49.8106,  ..., -52.2163, -50.3903, -53.3253],\n",
      "          [-53.7577, -51.3703, -51.9648,  ..., -53.0552, -52.0386, -53.6618]]],\n",
      "\n",
      "\n",
      "        [[[-11.4936, -10.2340, -14.6096,  ..., -10.6913, -13.7340, -12.5734],\n",
      "          [-16.3616, -18.5148, -14.4024,  ..., -18.6630, -20.9853, -15.7801],\n",
      "          [-21.3954, -22.4256, -13.0898,  ..., -20.4323, -18.7797, -18.3552],\n",
      "          ...,\n",
      "          [-51.0282, -48.1659, -48.0742,  ..., -51.0699, -49.2700, -51.2364],\n",
      "          [-50.8351, -49.5277, -49.0928,  ..., -48.4704, -47.5582, -51.0951],\n",
      "          [-50.0818, -48.6704, -47.0075,  ..., -47.9632, -48.1176, -50.2061]]],\n",
      "\n",
      "\n",
      "        [[[-22.5586, -16.8831, -13.5510,  ..., -15.0987, -16.9338, -18.2700],\n",
      "          [-25.8318, -24.3678, -20.3781,  ..., -16.5563, -14.3698, -17.9758],\n",
      "          [-28.0029, -29.3818, -28.5559,  ..., -12.1700, -11.1684, -20.2807],\n",
      "          ...,\n",
      "          [-52.7445, -50.5905, -50.7615,  ..., -49.2888, -50.1954, -52.0019],\n",
      "          [-52.4493, -51.8289, -51.2524,  ..., -48.0633, -49.3590, -52.7063],\n",
      "          [-54.1401, -51.5973, -51.1932,  ..., -49.2670, -50.1814, -51.7242]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-15.7425, -11.6248, -17.2644,  ..., -12.2777, -14.7604, -17.6460],\n",
      "          [-16.7569, -12.4618, -14.4422,  ..., -17.6799, -20.9050, -21.6735],\n",
      "          [-23.4431, -22.6480, -24.7191,  ..., -26.4295, -25.3781, -27.3810],\n",
      "          ...,\n",
      "          [-54.5073, -51.4119, -50.6721,  ..., -48.3418, -49.1658, -53.0769],\n",
      "          [-51.3283, -50.8495, -50.2682,  ..., -48.8591, -50.1309, -53.0761],\n",
      "          [-51.9168, -50.2575, -49.6054,  ..., -49.8138, -50.0373, -52.7472]]],\n",
      "\n",
      "\n",
      "        [[[-11.9812,  -9.3662,  -8.2135,  ...,  -1.1906,  -0.6894,  -3.6515],\n",
      "          [-16.3086, -15.0678, -14.3896,  ..., -11.4367,  -7.9205,  -7.8565],\n",
      "          [-18.7677, -18.1802, -19.4712,  ..., -27.1771, -19.4822, -16.4020],\n",
      "          ...,\n",
      "          [-49.5920, -45.6910, -45.4978,  ..., -46.6986, -47.2830, -49.4382],\n",
      "          [-49.0766, -48.2190, -49.7512,  ..., -49.4684, -47.8071, -47.9136],\n",
      "          [-50.1675, -49.3558, -48.8929,  ..., -48.4979, -47.7015, -48.6849]]],\n",
      "\n",
      "\n",
      "        [[[-15.5925,  -9.8917,  -6.2494,  ...,  -6.1327,  -7.8223, -13.9311],\n",
      "          [-15.7371, -16.2064, -12.4782,  ..., -12.5573, -15.2687, -16.8661],\n",
      "          [-20.1785, -21.2282, -23.8110,  ..., -26.8669, -25.0673, -22.5346],\n",
      "          ...,\n",
      "          [-54.0961, -50.5082, -49.2234,  ..., -47.3080, -48.0680, -50.7246],\n",
      "          [-50.5850, -48.4395, -48.9797,  ..., -48.1561, -48.9869, -49.1019],\n",
      "          [-50.4302, -48.2401, -47.2810,  ..., -48.1306, -48.6112, -49.0590]]]]), tensor([0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0])]\n",
      "[tensor([[[[-13.9394, -10.5694, -16.0491,  ..., -10.2286, -15.0758, -12.9375],\n",
      "          [-14.3733, -12.5477, -16.6358,  ..., -13.9083, -16.0409, -14.4126],\n",
      "          [-19.7291, -20.4859, -24.7765,  ..., -24.5085, -22.9955, -20.5152],\n",
      "          ...,\n",
      "          [-52.5821, -49.4393, -48.3784,  ..., -47.7837, -47.6095, -49.5270],\n",
      "          [-51.4517, -48.9139, -49.5501,  ..., -47.5021, -46.6415, -49.5999],\n",
      "          [-49.3316, -47.3930, -47.3847,  ..., -48.0914, -47.0663, -49.3941]]],\n",
      "\n",
      "\n",
      "        [[[-11.2354,  -1.5329,  -0.5303,  ...,  -9.0600,  -9.2190, -15.0871],\n",
      "          [-13.7955,  -8.6613,  -9.4718,  ..., -13.4429, -12.8798, -22.8411],\n",
      "          [-24.0538, -24.4401, -22.1362,  ..., -23.9585, -22.7527, -23.3338],\n",
      "          ...,\n",
      "          [-60.6562, -56.1004, -54.2633,  ..., -54.0730, -54.7079, -58.5940],\n",
      "          [-58.0015, -56.5455, -55.3610,  ..., -54.9214, -56.2456, -59.1577],\n",
      "          [-56.3426, -55.3571, -56.6946,  ..., -54.5223, -56.9576, -58.9818]]],\n",
      "\n",
      "\n",
      "        [[[-18.9487, -12.0472,  -9.0427,  ..., -13.2672, -12.0017, -15.3819],\n",
      "          [-19.6618, -13.1719, -10.7332,  ..., -15.8404, -21.5801, -24.2027],\n",
      "          [-26.3460, -23.6914, -24.1820,  ..., -18.7605, -22.7578, -33.7019],\n",
      "          ...,\n",
      "          [-47.1468, -45.2757, -44.2731,  ..., -41.2905, -41.9300, -44.2335],\n",
      "          [-46.1171, -42.6339, -42.9646,  ..., -42.9828, -43.3523, -45.9778],\n",
      "          [-45.7657, -43.5260, -44.3953,  ..., -43.1380, -42.5473, -44.9960]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-25.3776, -18.9886, -21.0958,  ..., -14.5489, -16.8580, -19.3545],\n",
      "          [-27.5822, -22.3466, -25.0474,  ..., -20.6698, -23.3655, -20.5494],\n",
      "          [-35.1404, -31.9660, -29.9652,  ..., -33.7203, -26.2127, -20.7004],\n",
      "          ...,\n",
      "          [-56.5509, -55.1140, -54.0172,  ..., -56.2855, -56.0135, -59.1184],\n",
      "          [-55.8567, -53.2790, -52.8079,  ..., -54.9586, -54.9523, -57.8705],\n",
      "          [-55.2805, -53.4553, -54.1794,  ..., -54.0189, -54.4789, -56.9093]]],\n",
      "\n",
      "\n",
      "        [[[-20.2675, -15.8836, -12.5611,  ..., -21.7920, -23.9503, -25.5775],\n",
      "          [-26.4369, -21.3591, -19.3508,  ..., -26.8392, -27.5172, -25.2326],\n",
      "          [-27.7834, -28.4080, -31.0924,  ..., -36.1091, -33.0402, -28.8451],\n",
      "          ...,\n",
      "          [-59.2258, -56.2316, -57.1497,  ..., -56.6798, -56.8833, -58.9511],\n",
      "          [-59.1653, -57.5009, -57.4782,  ..., -54.7645, -56.0875, -58.3455],\n",
      "          [-59.5959, -56.0621, -55.8988,  ..., -55.5493, -56.2114, -59.0562]]],\n",
      "\n",
      "\n",
      "        [[[-28.1159, -23.0255, -23.7556,  ..., -24.0344, -30.1324, -34.9646],\n",
      "          [-33.2312, -28.3495, -24.4752,  ..., -27.6229, -35.4252, -35.3043],\n",
      "          [-35.7280, -30.5013, -26.9301,  ..., -30.6318, -32.1604, -29.7907],\n",
      "          ...,\n",
      "          [-58.9061, -55.1405, -55.7099,  ..., -56.4490, -55.9626, -57.7966],\n",
      "          [-57.6493, -55.4497, -55.6548,  ..., -54.6139, -54.4188, -55.7965],\n",
      "          [-58.3800, -55.9322, -56.7930,  ..., -54.9729, -56.7058, -59.1461]]]]), tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1])]\n",
      "[tensor([[[[-18.8253, -15.8321, -16.1005,  ..., -14.4386, -12.6022, -12.5053],\n",
      "          [-23.7418, -22.3810, -25.0243,  ..., -26.4987, -18.8213, -14.6709],\n",
      "          [-34.2701, -41.5558, -38.8525,  ..., -32.9407, -29.2899, -19.6036],\n",
      "          ...,\n",
      "          [-58.6158, -54.8394, -53.2518,  ..., -53.3161, -54.3527, -56.8580],\n",
      "          [-57.0358, -53.4477, -53.1400,  ..., -54.0887, -53.9556, -58.1356],\n",
      "          [-57.6629, -54.7959, -54.5720,  ..., -54.6139, -54.3768, -57.3533]]],\n",
      "\n",
      "\n",
      "        [[[-21.2066, -18.3942, -19.1911,  ..., -22.7502, -20.3933, -25.1467],\n",
      "          [-28.1017, -27.1700, -31.3264,  ..., -24.3970, -22.5500, -27.5876],\n",
      "          [-39.9712, -41.9908, -36.2706,  ..., -32.7207, -31.0028, -34.6425],\n",
      "          ...,\n",
      "          [-61.1123, -57.7213, -58.5888,  ..., -57.6709, -58.4993, -60.3505],\n",
      "          [-60.9945, -57.0853, -56.1953,  ..., -56.5356, -56.3161, -59.0836],\n",
      "          [-60.3138, -57.7479, -55.9964,  ..., -55.1499, -55.3583, -57.9607]]],\n",
      "\n",
      "\n",
      "        [[[-17.5878, -10.7688,  -3.3939,  ..., -11.3596, -15.1069, -23.9499],\n",
      "          [-17.9310, -15.0259, -11.0286,  ..., -13.5549, -14.2118, -24.4188],\n",
      "          [-19.8636, -19.0046, -23.3147,  ..., -22.2563, -21.5016, -30.4344],\n",
      "          ...,\n",
      "          [-47.1172, -45.2374, -44.5973,  ..., -46.1754, -45.9668, -46.5913],\n",
      "          [-47.4587, -45.3684, -45.6143,  ..., -43.7100, -44.2249, -48.3597],\n",
      "          [-46.9357, -44.9930, -44.4385,  ..., -45.0885, -45.3449, -48.7781]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-21.7576, -10.2887,  -5.8703,  ...,  -8.8246,  -7.3222, -10.8374],\n",
      "          [-23.6989, -19.2175, -13.5686,  ..., -15.0546, -12.6977, -12.1867],\n",
      "          [-35.0648, -30.8188, -31.0750,  ..., -21.7611, -22.6761, -17.2266],\n",
      "          ...,\n",
      "          [-51.7617, -49.2570, -48.9262,  ..., -49.0737, -49.0304, -50.1831],\n",
      "          [-52.5187, -50.7692, -48.9373,  ..., -47.4823, -48.6833, -50.6175],\n",
      "          [-51.4213, -48.7805, -49.7251,  ..., -49.0806, -48.4289, -49.4728]]],\n",
      "\n",
      "\n",
      "        [[[-28.7621, -20.2105, -14.4694,  ..., -17.8411, -17.7702, -17.5384],\n",
      "          [-29.9145, -30.1816, -21.5041,  ..., -24.4324, -24.1051, -22.1177],\n",
      "          [-35.0581, -36.5620, -29.6490,  ..., -27.5105, -27.8664, -29.8223],\n",
      "          ...,\n",
      "          [-58.9452, -55.0164, -54.4145,  ..., -53.8304, -53.9026, -56.1843],\n",
      "          [-58.5020, -55.1012, -54.8890,  ..., -53.3748, -53.0486, -54.1019],\n",
      "          [-57.9996, -55.2797, -54.6468,  ..., -54.4856, -53.0633, -55.3699]]],\n",
      "\n",
      "\n",
      "        [[[-21.3328, -19.9475, -20.9102,  ..., -17.6458, -22.6680, -18.5663],\n",
      "          [-21.7492, -19.6018, -18.9021,  ..., -16.3833, -21.1309, -20.6573],\n",
      "          [-28.7572, -27.8334, -24.5542,  ..., -22.8735, -29.0823, -26.6163],\n",
      "          ...,\n",
      "          [-60.0366, -58.6037, -59.5400,  ..., -58.0679, -57.8913, -59.5577],\n",
      "          [-60.6983, -58.4885, -59.4000,  ..., -58.2383, -57.9659, -58.9711],\n",
      "          [-60.9608, -57.3524, -57.0450,  ..., -57.3915, -57.9668, -59.2798]]]]), tensor([1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[-20.4181, -20.5480, -23.7134,  ..., -20.0150, -18.1348, -16.9084],\n",
      "          [-18.1349, -16.6080, -21.1846,  ..., -26.3372, -30.6337, -22.2518],\n",
      "          [-21.7251, -23.1864, -22.1697,  ..., -24.1980, -28.0945, -23.5867],\n",
      "          ...,\n",
      "          [-55.9383, -52.8677, -54.0667,  ..., -53.8361, -52.3375, -52.8477],\n",
      "          [-54.4004, -51.1068, -51.5138,  ..., -51.1167, -51.3174, -53.8391],\n",
      "          [-54.3922, -53.1081, -52.0855,  ..., -51.0251, -51.0940, -54.4313]]],\n",
      "\n",
      "\n",
      "        [[[-13.7082,  -7.1759,  -3.5153,  ..., -14.6693, -11.1537, -14.9539],\n",
      "          [-14.8496, -15.3325, -11.1583,  ..., -21.4546, -15.8847, -16.4374],\n",
      "          [-19.3115, -21.4173, -25.2090,  ..., -26.4488, -28.5255, -23.7063],\n",
      "          ...,\n",
      "          [-57.9415, -51.7436, -49.7366,  ..., -50.3407, -50.3481, -51.7939],\n",
      "          [-54.1816, -50.1140, -50.0449,  ..., -50.7771, -49.8299, -51.5929],\n",
      "          [-52.8897, -49.8649, -50.0550,  ..., -49.3119, -49.7404, -52.7071]]],\n",
      "\n",
      "\n",
      "        [[[-18.8913, -10.0289, -10.3459,  ...,  -6.4626,  -7.7293, -14.0188],\n",
      "          [-20.8310, -14.5190, -10.8157,  ..., -14.4226, -18.1400, -20.0873],\n",
      "          [-27.3530, -20.3386, -18.9331,  ..., -19.3518, -20.1918, -20.8414],\n",
      "          ...,\n",
      "          [-48.3286, -45.7313, -45.2582,  ..., -43.6651, -46.3539, -48.1775],\n",
      "          [-46.7097, -43.3864, -42.9476,  ..., -43.8660, -45.5223, -46.8057],\n",
      "          [-44.9587, -42.1577, -42.3510,  ..., -42.3994, -43.9425, -46.3296]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-11.7046,  -9.1298,  -9.8116,  ...,  -7.5575,  -6.9401, -13.3816],\n",
      "          [-13.6630, -12.6117, -11.9290,  ..., -16.8512, -14.1255, -15.7268],\n",
      "          [-22.2301, -18.9886, -16.5447,  ..., -35.6252, -28.0495, -27.2411],\n",
      "          ...,\n",
      "          [-56.4785, -54.7419, -56.0776,  ..., -55.1176, -55.5975, -57.6097],\n",
      "          [-59.1581, -57.6228, -57.2908,  ..., -56.2457, -56.3957, -58.3482],\n",
      "          [-60.8028, -57.9434, -57.6026,  ..., -56.2074, -55.9088, -57.9031]]],\n",
      "\n",
      "\n",
      "        [[[ -9.8310,  -5.7371,  -6.3068,  ..., -11.1047,  -7.7510,  -7.9631],\n",
      "          [-14.7004, -10.5117, -13.4470,  ..., -19.4098, -12.6903, -10.3309],\n",
      "          [-22.1434, -18.6457, -20.4092,  ..., -27.9641, -23.8942, -17.0636],\n",
      "          ...,\n",
      "          [-49.2017, -46.2627, -45.1024,  ..., -44.9568, -46.5415, -49.8222],\n",
      "          [-49.0544, -47.0451, -46.5732,  ..., -45.5566, -46.2460, -48.8646],\n",
      "          [-48.2317, -46.1320, -48.1923,  ..., -45.6452, -46.0132, -48.5322]]],\n",
      "\n",
      "\n",
      "        [[[ -9.1675,  -8.3517, -14.1963,  ...,  -3.6277,  -3.8390, -10.5550],\n",
      "          [ -7.8971,  -7.4584, -11.3463,  ...,  -5.7554,  -6.4468, -14.9051],\n",
      "          [-12.0965, -15.3578, -19.9800,  ..., -16.9846, -17.8627, -25.4272],\n",
      "          ...,\n",
      "          [-53.5100, -51.4542, -52.2433,  ..., -50.7160, -51.7923, -53.1774],\n",
      "          [-52.8660, -50.4481, -50.0075,  ..., -50.2209, -50.4349, -52.8609],\n",
      "          [-52.4136, -50.4616, -49.1989,  ..., -51.2131, -51.0178, -52.8710]]]]), tensor([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0])]\n",
      "[tensor([[[[ -8.4363,  -6.5172,  -5.0361,  ...,  -6.9494,  -6.8389, -11.8205],\n",
      "          [-14.0438, -15.8891, -11.1240,  ..., -14.7579, -13.5607, -14.7249],\n",
      "          [-18.7723, -22.7254, -23.4796,  ..., -19.9954, -19.6702, -18.2833],\n",
      "          ...,\n",
      "          [-42.7022, -42.6909, -43.8495,  ..., -44.8853, -44.2687, -45.9884],\n",
      "          [-45.6354, -43.4665, -43.5859,  ..., -44.8624, -43.4834, -45.4119],\n",
      "          [-47.5413, -44.1620, -43.9343,  ..., -43.4389, -43.1794, -44.8784]]],\n",
      "\n",
      "\n",
      "        [[[-12.6232, -12.5824, -14.3640,  ...,  -2.3306,  -2.3509,  -3.5920],\n",
      "          [-16.8378, -18.7286, -12.6980,  ...,  -8.3642,  -9.2613,  -9.1306],\n",
      "          [-23.9793, -25.4245, -18.5549,  ..., -13.8851, -18.5964, -22.4285],\n",
      "          ...,\n",
      "          [-48.9622, -46.7448, -46.9816,  ..., -47.9503, -48.7583, -50.6553],\n",
      "          [-50.8977, -46.7056, -46.0312,  ..., -46.8611, -47.3365, -48.3360],\n",
      "          [-50.5283, -46.7782, -46.8278,  ..., -46.5984, -46.0038, -48.6501]]],\n",
      "\n",
      "\n",
      "        [[[-11.1783,  -7.6338,  -5.4151,  ...,  -7.3284,  -8.6714,  -9.9773],\n",
      "          [-17.3977, -14.4746, -12.1227,  ..., -12.7333, -16.4074, -15.2015],\n",
      "          [-18.0315, -21.0889, -29.7641,  ..., -11.9037, -14.0564, -15.2246],\n",
      "          ...,\n",
      "          [-55.4254, -52.5733, -49.9775,  ..., -50.1800, -49.8477, -51.6824],\n",
      "          [-53.1328, -50.6852, -49.8025,  ..., -49.9720, -49.6142, -51.3629],\n",
      "          [-51.9711, -50.2546, -50.8793,  ..., -50.7494, -50.2770, -52.1782]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-21.4902, -21.6436, -21.6535,  ..., -25.3027, -23.7207, -29.6967],\n",
      "          [-25.7962, -29.1196, -32.4776,  ..., -24.6808, -23.5726, -29.9458],\n",
      "          [-32.1618, -36.7636, -38.0848,  ..., -36.7611, -30.7631, -28.3839],\n",
      "          ...,\n",
      "          [-60.4379, -57.3935, -56.6516,  ..., -56.8138, -56.6759, -58.7539],\n",
      "          [-59.9882, -57.2267, -57.0910,  ..., -58.0623, -57.3348, -58.5740],\n",
      "          [-61.7397, -58.3971, -58.3632,  ..., -57.0764, -56.7705, -58.5347]]],\n",
      "\n",
      "\n",
      "        [[[-35.8278, -22.1066, -16.7061,  ..., -15.1273, -10.5713, -11.1996],\n",
      "          [-30.1492, -23.0492, -16.0556,  ..., -15.0766, -13.0939, -14.7526],\n",
      "          [-30.1255, -27.3209, -21.8964,  ..., -13.0971, -15.7214, -25.3884],\n",
      "          ...,\n",
      "          [-58.8437, -56.4816, -56.0311,  ..., -55.6610, -56.2917, -57.8542],\n",
      "          [-59.2296, -57.3141, -56.7437,  ..., -55.2280, -56.1519, -57.6873],\n",
      "          [-58.4194, -56.4311, -56.4027,  ..., -54.9022, -56.1576, -58.0420]]],\n",
      "\n",
      "\n",
      "        [[[ -4.9400,  -1.9036,  -2.5980,  ...,  -5.9622,  -8.1251, -15.0442],\n",
      "          [-10.6579, -10.0903, -12.4076,  ..., -11.1645, -13.7812, -19.1813],\n",
      "          [-20.4031, -25.3213, -33.5289,  ..., -28.5586, -25.3225, -23.5617],\n",
      "          ...,\n",
      "          [-51.8966, -49.1630, -48.8168,  ..., -48.6939, -48.8835, -51.0364],\n",
      "          [-51.4623, -49.2924, -50.6637,  ..., -47.6875, -46.3137, -48.7400],\n",
      "          [-49.5172, -48.3110, -49.6894,  ..., -48.2982, -47.1892, -49.6237]]]]), tensor([0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0])]\n",
      "[tensor([[[[-28.4496, -21.3480, -18.5663,  ..., -20.2523, -18.3646, -20.6975],\n",
      "          [-37.5055, -27.6420, -24.8004,  ..., -25.1457, -21.5115, -21.7303],\n",
      "          [-40.4242, -34.5669, -32.1039,  ..., -34.7395, -31.4070, -29.2479],\n",
      "          ...,\n",
      "          [-60.1039, -55.7289, -55.3596,  ..., -57.7754, -57.9268, -59.5301],\n",
      "          [-61.0756, -58.0284, -55.9271,  ..., -58.6687, -57.4396, -58.7824],\n",
      "          [-61.1424, -58.5417, -57.1150,  ..., -58.3889, -59.0333, -59.7134]]],\n",
      "\n",
      "\n",
      "        [[[-14.8084,  -7.7240,  -5.9121,  ...,  -8.7143, -10.9181, -14.2202],\n",
      "          [-15.6328, -12.2244, -12.6979,  ..., -13.3606, -15.4395, -14.4284],\n",
      "          [-23.8974, -27.0493, -24.0151,  ..., -29.1591, -22.9547, -19.5348],\n",
      "          ...,\n",
      "          [-55.8806, -54.2454, -53.8291,  ..., -52.2477, -52.6790, -53.3496],\n",
      "          [-56.9570, -54.4307, -52.9961,  ..., -54.2905, -54.3644, -54.8875],\n",
      "          [-55.3034, -52.9864, -52.4884,  ..., -53.6592, -53.9502, -57.8818]]],\n",
      "\n",
      "\n",
      "        [[[-16.8329, -13.6328, -11.7601,  ...,  -7.4715,  -4.9934,  -7.7386],\n",
      "          [-20.5302, -20.6771, -16.6654,  ..., -14.3709, -12.7447, -14.0274],\n",
      "          [-24.7811, -25.5486, -26.2880,  ..., -14.6594, -12.9530, -12.9801],\n",
      "          ...,\n",
      "          [-52.3715, -50.4132, -51.0367,  ..., -50.3536, -50.5125, -53.7689],\n",
      "          [-52.3075, -50.1374, -50.6118,  ..., -50.6505, -50.3699, -52.1913],\n",
      "          [-53.6802, -51.1906, -51.8840,  ..., -49.7958, -51.4352, -52.2877]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-14.5853, -11.6692, -15.5351,  ...,  -8.7539, -13.2901, -13.7414],\n",
      "          [-19.5203, -16.6903, -22.3898,  ..., -15.6632, -14.8590, -16.8749],\n",
      "          [-29.4660, -24.8455, -27.8791,  ..., -29.3313, -20.9178, -20.8799],\n",
      "          ...,\n",
      "          [-56.1830, -53.4776, -53.8492,  ..., -52.9995, -53.7431, -55.7120],\n",
      "          [-54.9853, -53.9373, -54.2477,  ..., -53.2432, -52.5611, -55.8889],\n",
      "          [-57.1454, -54.9191, -55.6454,  ..., -52.7012, -54.1473, -57.3108]]],\n",
      "\n",
      "\n",
      "        [[[-10.4944,  -5.5068,  -4.4203,  ..., -18.1621, -10.9490, -11.8473],\n",
      "          [-14.8204, -14.8422, -10.4915,  ..., -20.8312, -15.0862, -13.3515],\n",
      "          [-21.5193, -22.2157, -15.8947,  ..., -23.6889, -23.0826, -17.5499],\n",
      "          ...,\n",
      "          [-46.7716, -42.6505, -41.6851,  ..., -42.9021, -43.4766, -45.3656],\n",
      "          [-45.2616, -42.2546, -43.0180,  ..., -43.9335, -43.9594, -43.8517],\n",
      "          [-47.0623, -44.7340, -44.7867,  ..., -44.3338, -42.8675, -43.8628]]],\n",
      "\n",
      "\n",
      "        [[[-16.8567,  -8.9258,  -8.9082,  ..., -15.4936, -10.8712, -13.4382],\n",
      "          [-18.4956, -15.3451, -17.4864,  ..., -22.7261, -13.9191, -13.6907],\n",
      "          [-27.8606, -32.2352, -35.8876,  ..., -32.1483, -24.2191, -21.1400],\n",
      "          ...,\n",
      "          [-58.8529, -56.1353, -55.3843,  ..., -55.8005, -56.4734, -57.3707],\n",
      "          [-59.1419, -55.8753, -54.9922,  ..., -55.9837, -55.4216, -56.7294],\n",
      "          [-58.9722, -55.6279, -55.8894,  ..., -54.4442, -54.7268, -56.5850]]]]), tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1])]\n",
      "[tensor([[[[-21.3703, -15.4542, -18.4694,  ...,  -6.7557,  -5.1860, -10.7650],\n",
      "          [-24.8481, -15.1485, -14.5117,  ..., -10.6293,  -9.3536, -14.4635],\n",
      "          [-31.2698, -21.5177, -20.7863,  ..., -20.8563, -24.3408, -24.9594],\n",
      "          ...,\n",
      "          [-51.2144, -48.1096, -49.1061,  ..., -51.0820, -49.4591, -51.1729],\n",
      "          [-52.3428, -48.4573, -47.8904,  ..., -50.7917, -48.7870, -51.9110],\n",
      "          [-50.8631, -48.7530, -48.7021,  ..., -49.2459, -49.0703, -51.3561]]],\n",
      "\n",
      "\n",
      "        [[[-14.2740, -14.6878, -16.3678,  ...,  -7.6559,  -6.9207, -10.9879],\n",
      "          [-15.4590, -14.2033, -13.5962,  ..., -13.3940, -12.1453, -12.0229],\n",
      "          [-21.0673, -21.5104, -15.9092,  ..., -20.1350, -25.0609, -19.5544],\n",
      "          ...,\n",
      "          [-46.8445, -44.1763, -44.3326,  ..., -44.1807, -44.3453, -46.4737],\n",
      "          [-45.7295, -43.0612, -43.7683,  ..., -42.9383, -43.8151, -46.4361],\n",
      "          [-46.8281, -43.4723, -42.6682,  ..., -44.1990, -43.3089, -45.7182]]],\n",
      "\n",
      "\n",
      "        [[[ -8.3833,  -3.7065,  -4.9825,  ...,  -9.4379,  -9.9210, -10.4927],\n",
      "          [-14.1493,  -7.8292,  -7.6194,  ..., -11.9195,  -8.7797, -10.8261],\n",
      "          [-15.2193, -10.7733,  -9.5967,  ...,  -8.5518, -11.5993, -16.0169],\n",
      "          ...,\n",
      "          [-47.5169, -45.1862, -45.7089,  ..., -46.7601, -47.7222, -48.1418],\n",
      "          [-47.9430, -45.2128, -45.2774,  ..., -45.8736, -47.4532, -48.2681],\n",
      "          [-49.8750, -46.4834, -46.8744,  ..., -44.6874, -45.9764, -49.7474]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -6.7301,  -3.1395,  -3.1589,  ...,  -2.7027,  -4.0007,  -7.7915],\n",
      "          [-13.1272, -10.1335, -11.4181,  ..., -10.4572, -10.7996, -11.7543],\n",
      "          [-27.2795, -21.1449, -21.0141,  ..., -29.7542, -23.7961, -22.7664],\n",
      "          ...,\n",
      "          [-51.8707, -49.3925, -48.9688,  ..., -48.8549, -49.5670, -51.7689],\n",
      "          [-52.4164, -50.3727, -49.4590,  ..., -48.9758, -50.3056, -51.0990],\n",
      "          [-54.2243, -51.6352, -51.0096,  ..., -50.2432, -51.1182, -50.8141]]],\n",
      "\n",
      "\n",
      "        [[[ -6.5707,  -5.1804,  -4.4279,  ..., -19.9528, -17.5417, -18.1619],\n",
      "          [-11.2420, -11.8383, -14.3521,  ..., -24.0097, -22.3988, -19.9873],\n",
      "          [-21.7239, -19.6298, -19.8476,  ..., -21.8949, -25.9308, -24.0137],\n",
      "          ...,\n",
      "          [-52.6528, -49.8638, -50.7778,  ..., -49.3393, -48.8146, -52.0558],\n",
      "          [-51.5734, -51.0452, -50.6542,  ..., -50.6822, -50.7363, -50.7225],\n",
      "          [-51.2300, -49.8601, -50.4417,  ..., -49.9802, -48.8380, -49.7939]]],\n",
      "\n",
      "\n",
      "        [[[-15.7050, -12.6975, -17.5095,  ..., -10.3771, -19.2084, -24.2549],\n",
      "          [-16.7090, -13.5627, -16.2912,  ..., -10.1943, -15.1348, -23.7044],\n",
      "          [-25.0627, -23.9584, -23.3737,  ..., -20.8690, -23.6321, -25.2325],\n",
      "          ...,\n",
      "          [-54.4831, -50.2017, -49.9220,  ..., -49.6720, -48.0367, -50.0712],\n",
      "          [-53.3712, -50.8083, -50.4475,  ..., -49.4437, -50.0482, -52.4494],\n",
      "          [-53.5473, -51.0856, -51.1177,  ..., -48.2522, -49.9984, -51.7540]]]]), tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])]\n",
      "[tensor([[[[-23.1319, -20.1916, -15.4917,  ...,  -4.6617,  -3.9877,  -3.9032],\n",
      "          [-25.6635, -27.6090, -16.3582,  ..., -12.7672, -10.1592,  -6.3986],\n",
      "          [-23.9620, -24.5984, -21.5911,  ..., -22.6810, -19.9907, -12.7007],\n",
      "          ...,\n",
      "          [-49.2304, -47.7734, -48.9830,  ..., -47.9364, -48.4787, -47.9724],\n",
      "          [-50.7086, -47.8494, -49.0827,  ..., -47.4351, -48.3029, -50.5229],\n",
      "          [-52.9449, -49.1922, -48.2749,  ..., -48.3076, -49.3530, -51.7323]]],\n",
      "\n",
      "\n",
      "        [[[-16.5674,  -7.9166,  -7.1252,  ..., -12.3512, -10.9816, -16.1900],\n",
      "          [-14.3557,  -9.4163, -12.1039,  ..., -10.2800, -11.2468, -14.7911],\n",
      "          [-16.5447, -16.7023, -16.4165,  ..., -20.4350, -22.7101, -20.0915],\n",
      "          ...,\n",
      "          [-50.5867, -46.7147, -46.3951,  ..., -44.5520, -43.9189, -47.0678],\n",
      "          [-48.0054, -45.6379, -46.2175,  ..., -45.5112, -45.3910, -49.4032],\n",
      "          [-48.6765, -47.0682, -46.8633,  ..., -46.1918, -45.9225, -49.6684]]],\n",
      "\n",
      "\n",
      "        [[[ -9.7198, -10.6016, -16.8646,  ..., -19.6169, -19.8675, -20.5742],\n",
      "          [-10.7422, -13.0875, -26.4357,  ..., -15.5780, -18.2259, -19.9731],\n",
      "          [-15.1962, -18.3132, -24.1867,  ..., -19.1898, -24.7898, -23.7910],\n",
      "          ...,\n",
      "          [-49.3459, -46.6421, -46.2616,  ..., -44.7669, -46.7393, -49.0070],\n",
      "          [-50.2996, -46.9952, -46.7304,  ..., -47.3191, -46.9546, -47.9113],\n",
      "          [-49.6005, -46.1547, -45.6566,  ..., -46.7553, -45.4780, -48.2346]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -7.4916,  -5.1973,  -8.1599,  ...,  -1.0534,  -4.7707,  -8.6324],\n",
      "          [ -9.2590,  -9.7779, -13.1722,  ...,  -8.1436, -14.3662, -16.7768],\n",
      "          [-16.5048, -19.8066, -19.0205,  ..., -19.1943, -22.7244, -22.2352],\n",
      "          ...,\n",
      "          [-44.1857, -41.3281, -40.8708,  ..., -42.6360, -42.0899, -44.3636],\n",
      "          [-46.7770, -43.5617, -42.4771,  ..., -42.5826, -43.5938, -45.5621],\n",
      "          [-48.3091, -44.4327, -42.5378,  ..., -43.6418, -44.7133, -46.4113]]],\n",
      "\n",
      "\n",
      "        [[[-12.4140,  -5.7695,  -5.9886,  ...,  -5.9448,  -5.6542, -11.7949],\n",
      "          [-16.7567, -14.1693, -13.1855,  ...,  -7.1810,  -7.9263, -17.8834],\n",
      "          [-21.8835, -23.2691, -23.2952,  ..., -19.2254, -18.0508, -20.2292],\n",
      "          ...,\n",
      "          [-46.6937, -44.7909, -45.2983,  ..., -46.5276, -45.8357, -48.1477],\n",
      "          [-47.5659, -45.9185, -47.0801,  ..., -47.9654, -47.0082, -48.0421],\n",
      "          [-51.4891, -49.0060, -47.2021,  ..., -48.2341, -46.5313, -46.7991]]],\n",
      "\n",
      "\n",
      "        [[[-23.1839, -18.7714, -19.3193,  ...,  -3.1630,  -5.0980,  -8.8698],\n",
      "          [-32.1908, -27.3375, -25.0675,  ..., -11.1423, -13.9655, -18.9763],\n",
      "          [-36.5156, -34.5471, -31.0450,  ..., -27.2272, -29.9352, -26.4735],\n",
      "          ...,\n",
      "          [-54.2087, -51.6500, -51.7130,  ..., -51.7112, -51.0370, -51.6131],\n",
      "          [-54.5460, -51.9328, -51.9028,  ..., -50.4208, -49.7885, -51.6476],\n",
      "          [-56.7507, -53.6250, -52.8569,  ..., -52.4591, -51.3461, -50.8630]]]]), tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0])]\n",
      "[tensor([[[[-10.4789,  -6.5961, -11.1222,  ...,  -4.2689,  -3.6899,  -7.1001],\n",
      "          [-12.9899, -11.4545, -14.1799,  ..., -14.5856, -11.5984,  -8.1304],\n",
      "          [-19.3272, -19.0086, -20.3134,  ..., -21.8353, -18.8761, -13.2334],\n",
      "          ...,\n",
      "          [-46.4182, -43.2631, -42.4250,  ..., -44.1247, -42.2881, -44.5767],\n",
      "          [-46.4459, -43.0375, -42.5799,  ..., -43.0931, -43.9915, -47.5409],\n",
      "          [-46.2422, -44.4888, -43.1437,  ..., -44.1255, -44.2767, -48.0428]]],\n",
      "\n",
      "\n",
      "        [[[-35.7625, -31.3968, -28.9119,  ..., -33.6095, -31.9846, -32.9025],\n",
      "          [-33.2794, -31.1779, -31.9334,  ..., -35.2933, -30.8031, -30.2075],\n",
      "          [-34.3222, -35.1136, -40.3560,  ..., -44.3422, -41.7105, -33.4639],\n",
      "          ...,\n",
      "          [-68.6905, -65.4809, -64.5042,  ..., -65.0022, -64.7763, -67.6492],\n",
      "          [-68.5838, -65.1890, -64.4826,  ..., -67.5171, -64.9807, -66.3474],\n",
      "          [-67.3442, -65.3369, -66.8738,  ..., -66.6567, -65.5799, -66.8768]]],\n",
      "\n",
      "\n",
      "        [[[-16.8452, -13.5354, -12.3457,  ...,  -7.5718, -15.1092, -13.7799],\n",
      "          [-22.9378, -22.2728, -17.5959,  ...,  -9.8604, -13.8434, -15.4190],\n",
      "          [-33.2246, -27.4122, -23.2496,  ..., -20.7066, -23.7417, -20.9818],\n",
      "          ...,\n",
      "          [-58.4331, -55.4495, -54.6389,  ..., -55.7004, -55.8007, -56.9540],\n",
      "          [-58.3111, -54.8712, -54.6139,  ..., -55.5884, -57.3441, -60.4165],\n",
      "          [-58.7135, -55.9777, -55.3581,  ..., -55.8698, -55.7188, -58.2434]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -7.2312,  -5.5502, -10.8106,  ..., -12.0728, -11.6270, -18.3879],\n",
      "          [-12.8379, -10.4328, -11.1139,  ..., -12.1149, -13.3988, -21.4119],\n",
      "          [-17.1522, -15.3204, -16.6874,  ..., -17.0701, -16.8169, -19.4256],\n",
      "          ...,\n",
      "          [-49.6324, -47.1806, -45.9081,  ..., -45.9792, -44.4437, -46.8701],\n",
      "          [-48.1928, -46.0230, -45.6793,  ..., -44.2725, -44.1523, -48.1270],\n",
      "          [-48.9057, -45.5202, -46.2662,  ..., -45.4411, -45.9650, -48.7489]]],\n",
      "\n",
      "\n",
      "        [[[-20.2793, -15.9593, -16.0003,  ..., -25.7411, -24.8820, -24.8051],\n",
      "          [-28.1146, -23.7630, -24.4079,  ..., -20.8823, -20.5412, -24.0058],\n",
      "          [-36.0960, -31.3383, -29.4620,  ..., -18.6521, -18.2717, -22.6301],\n",
      "          ...,\n",
      "          [-59.8770, -58.7391, -57.3887,  ..., -56.1967, -56.5258, -59.1237],\n",
      "          [-61.4826, -58.7915, -56.9553,  ..., -56.4838, -57.1133, -58.6255],\n",
      "          [-60.6579, -56.5620, -56.3909,  ..., -57.0654, -56.4107, -57.0795]]],\n",
      "\n",
      "\n",
      "        [[[-21.3166, -21.6216, -18.6459,  ...,  -2.6323,  -3.1223, -10.1047],\n",
      "          [-18.1810, -19.2957, -19.8383,  ...,  -5.6711,  -5.5017, -12.5959],\n",
      "          [-19.2162, -17.4341, -21.1660,  ..., -17.8896, -14.7039, -20.5785],\n",
      "          ...,\n",
      "          [-56.8154, -54.1182, -53.0325,  ..., -52.8521, -52.1302, -55.1932],\n",
      "          [-55.1258, -53.8096, -53.4958,  ..., -53.0106, -52.0204, -54.0954],\n",
      "          [-54.8296, -51.9627, -52.1642,  ..., -53.1097, -53.8528, -56.6984]]]]), tensor([0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1])]\n",
      "[tensor([[[[-18.3992, -10.2579,  -9.1728,  ..., -11.8962, -11.3040, -17.5288],\n",
      "          [-20.7860, -17.6318, -19.1732,  ..., -12.2297, -12.6828, -20.9876],\n",
      "          [-27.0568, -27.1267, -27.2713,  ..., -15.9593, -19.3389, -31.4808],\n",
      "          ...,\n",
      "          [-48.7616, -47.7058, -48.6367,  ..., -46.6357, -46.0906, -48.4607],\n",
      "          [-48.8595, -45.7127, -45.1317,  ..., -45.5931, -46.2077, -48.4918],\n",
      "          [-47.9680, -44.9970, -45.1969,  ..., -48.1054, -47.0117, -47.2977]]],\n",
      "\n",
      "\n",
      "        [[[-10.0324,  -6.8167,  -9.4455,  ...,  -1.8871,  -0.1813,  -4.1778],\n",
      "          [-15.2550, -14.6181, -15.4070,  ...,  -6.9043,  -4.9680,  -6.2971],\n",
      "          [-23.5452, -26.0273, -22.3096,  ..., -24.0114, -19.1774, -14.2859],\n",
      "          ...,\n",
      "          [-54.5733, -51.9087, -52.7556,  ..., -52.0562, -51.1155, -52.2600],\n",
      "          [-54.4794, -50.1651, -50.3410,  ..., -52.0226, -51.4731, -52.6752],\n",
      "          [-54.8790, -51.6402, -51.6746,  ..., -52.6833, -53.7281, -54.0992]]],\n",
      "\n",
      "\n",
      "        [[[-25.1372, -14.5803, -11.9241,  ..., -21.5351, -24.9570, -27.0441],\n",
      "          [-32.9019, -22.7252, -20.9056,  ..., -25.5040, -26.0616, -26.2596],\n",
      "          [-36.0133, -30.1175, -29.7196,  ..., -31.6793, -32.4025, -25.8160],\n",
      "          ...,\n",
      "          [-59.3108, -55.9124, -54.7571,  ..., -55.4589, -55.8586, -57.3539],\n",
      "          [-60.1984, -57.4479, -56.8552,  ..., -54.3047, -55.6271, -59.9377],\n",
      "          [-61.1461, -57.8009, -56.7371,  ..., -55.1088, -56.9293, -59.3068]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-22.5703, -12.4751, -11.0317,  ..., -16.8495, -11.9128, -14.1363],\n",
      "          [-30.6228, -16.5823, -15.9442,  ..., -16.6768, -17.6831, -21.2804],\n",
      "          [-33.7585, -21.7304, -20.6026,  ..., -19.3142, -25.3469, -31.3883],\n",
      "          ...,\n",
      "          [-46.3924, -43.1917, -42.6461,  ..., -42.0371, -41.5477, -44.9678],\n",
      "          [-47.7071, -44.5656, -42.7299,  ..., -44.1709, -42.5213, -42.1146],\n",
      "          [-46.7153, -43.8093, -43.5639,  ..., -44.7635, -43.6103, -44.2153]]],\n",
      "\n",
      "\n",
      "        [[[-28.5887, -20.3025,  -5.8588,  ...,  -7.8266, -13.0578, -19.2805],\n",
      "          [-23.4921, -18.4488,  -9.2170,  ..., -12.8492, -17.2844, -18.9900],\n",
      "          [-24.8397, -20.1964, -18.1915,  ..., -21.5089, -23.2129, -23.4977],\n",
      "          ...,\n",
      "          [-49.7923, -47.4711, -46.8951,  ..., -46.0321, -45.5153, -48.8076],\n",
      "          [-48.5787, -45.5300, -45.5185,  ..., -45.2121, -45.2603, -47.7423],\n",
      "          [-46.9642, -46.4979, -47.1442,  ..., -44.8945, -45.1639, -48.3275]]],\n",
      "\n",
      "\n",
      "        [[[-30.2123, -22.0915, -22.2938,  ..., -11.4991, -15.7080, -22.2339],\n",
      "          [-30.7622, -25.8282, -23.7345,  ..., -17.9001, -22.1856, -29.0883],\n",
      "          [-38.6461, -38.5591, -32.2956,  ..., -29.9840, -34.4236, -34.6991],\n",
      "          ...,\n",
      "          [-56.5985, -52.6381, -52.0494,  ..., -52.4203, -52.9909, -53.8917],\n",
      "          [-57.0893, -53.6196, -53.4424,  ..., -52.6212, -53.3133, -55.4037],\n",
      "          [-54.4446, -52.7070, -53.1618,  ..., -53.5154, -53.8757, -54.0577]]]]), tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0])]\n",
      "[tensor([[[[-14.0138, -10.4232, -12.1621,  ...,  -0.1700,  -0.5594,  -4.0858],\n",
      "          [-11.6160, -10.3030, -11.2037,  ...,  -6.6612,  -6.6283,  -8.4188],\n",
      "          [-13.6865, -10.3747,  -9.6956,  ...,  -7.7254, -11.7362, -14.4328],\n",
      "          ...,\n",
      "          [-45.4570, -41.5075, -41.3144,  ..., -43.2865, -43.1733, -45.8124],\n",
      "          [-44.1278, -40.9178, -41.9018,  ..., -42.6584, -44.2854, -47.4519],\n",
      "          [-46.5010, -42.3474, -43.4429,  ..., -42.6971, -41.9993, -43.7599]]],\n",
      "\n",
      "\n",
      "        [[[-31.4876, -27.3059, -26.4187,  ..., -19.3138, -22.1257, -25.0901],\n",
      "          [-32.2265, -32.6507, -31.1343,  ..., -28.1924, -30.0881, -27.3598],\n",
      "          [-38.6645, -36.4801, -37.9872,  ..., -41.2261, -39.6015, -31.0914],\n",
      "          ...,\n",
      "          [-65.6073, -64.2376, -63.6606,  ..., -65.2444, -65.1494, -67.3947],\n",
      "          [-69.7269, -65.3600, -65.3383,  ..., -65.0214, -65.1299, -66.8171],\n",
      "          [-70.0989, -67.2473, -66.3604,  ..., -63.4561, -63.4527, -65.8128]]],\n",
      "\n",
      "\n",
      "        [[[-13.3389,  -6.7270,  -6.2232,  ..., -10.6118,  -8.3265, -11.5142],\n",
      "          [-14.0491,  -9.2939, -10.7980,  ..., -16.5513, -15.8983, -20.0727],\n",
      "          [-22.4270, -22.8455, -24.3687,  ..., -22.6098, -23.0452, -23.9248],\n",
      "          ...,\n",
      "          [-51.3686, -47.8188, -48.1049,  ..., -49.9329, -51.1349, -53.2594],\n",
      "          [-54.4276, -50.7557, -49.0074,  ..., -51.4571, -52.2250, -51.9653],\n",
      "          [-55.2476, -51.0642, -50.3692,  ..., -49.6292, -49.8711, -51.8736]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-20.1464, -15.7755, -13.6936,  ..., -18.0209, -19.5932, -31.4534],\n",
      "          [-25.4643, -22.5765, -23.1809,  ..., -24.9911, -22.9648, -25.2959],\n",
      "          [-38.5306, -40.4403, -31.1508,  ..., -26.2896, -31.0882, -26.1620],\n",
      "          ...,\n",
      "          [-59.4231, -55.5442, -55.3393,  ..., -56.5145, -56.7491, -57.0284],\n",
      "          [-60.6382, -57.3800, -57.4618,  ..., -56.1540, -55.8989, -56.8114],\n",
      "          [-59.0872, -56.9304, -56.6265,  ..., -56.2802, -56.5342, -56.2394]]],\n",
      "\n",
      "\n",
      "        [[[-17.1314,  -9.4003,  -9.0690,  ..., -11.2905, -10.7288, -20.9616],\n",
      "          [-20.0756, -15.9321, -17.0553,  ..., -14.4405, -11.8830, -16.5035],\n",
      "          [-30.2058, -31.0364, -27.4156,  ..., -25.8332, -21.3887, -21.2943],\n",
      "          ...,\n",
      "          [-52.9406, -50.4179, -49.3469,  ..., -48.8939, -50.5529, -53.1905],\n",
      "          [-53.2699, -50.1342, -50.4543,  ..., -50.4109, -48.8431, -50.7181],\n",
      "          [-52.3662, -49.5403, -50.6518,  ..., -50.4186, -49.2742, -50.0702]]],\n",
      "\n",
      "\n",
      "        [[[ -4.2349,  -4.2060, -11.6171,  ...,  -4.5850,  -2.3392,  -4.6950],\n",
      "          [ -8.1829,  -8.1417,  -9.1384,  ...,  -9.3716,  -7.5392,  -8.7933],\n",
      "          [-15.4456, -18.7682, -18.6392,  ..., -24.1354, -25.3703, -19.9606],\n",
      "          ...,\n",
      "          [-49.5988, -46.1539, -47.1427,  ..., -47.8709, -46.2236, -47.6446],\n",
      "          [-51.7154, -47.2285, -46.4777,  ..., -46.8495, -46.5221, -47.1445],\n",
      "          [-50.7884, -48.4751, -47.4803,  ..., -46.7356, -45.6787, -46.9924]]]]), tensor([0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0])]\n",
      "[tensor([[[[-11.5259,  -7.6272,  -6.1347,  ...,  -9.8747, -16.1968, -28.6835],\n",
      "          [-17.4604, -15.4170, -12.6110,  ..., -14.1640, -18.1669, -21.8951],\n",
      "          [-29.4669, -24.1204, -21.8934,  ..., -23.5289, -23.5516, -22.9509],\n",
      "          ...,\n",
      "          [-50.2667, -46.5848, -46.8939,  ..., -48.4796, -47.6342, -47.8877],\n",
      "          [-50.2778, -48.3558, -47.2272,  ..., -45.9138, -46.4274, -49.0873],\n",
      "          [-50.7217, -48.1209, -46.3096,  ..., -46.6518, -47.2104, -49.0671]]],\n",
      "\n",
      "\n",
      "        [[[ -1.6687,   0.0000,  -1.9437,  ...,  -9.2447, -13.8568, -20.8081],\n",
      "          [ -5.6301,  -6.3429, -11.3366,  ..., -14.7721, -24.0374, -26.0508],\n",
      "          [-12.3676, -17.8012, -23.7757,  ..., -24.2872, -22.9049, -23.1295],\n",
      "          ...,\n",
      "          [-48.8766, -48.1391, -47.6972,  ..., -48.6263, -48.0024, -50.2248],\n",
      "          [-47.4605, -46.3736, -47.6852,  ..., -48.9554, -48.1644, -50.1563],\n",
      "          [-49.6892, -48.1642, -47.5942,  ..., -46.9402, -47.3687, -49.2560]]],\n",
      "\n",
      "\n",
      "        [[[-11.7722,  -6.4970,  -8.8768,  ...,  -8.4280,  -7.4842, -12.2289],\n",
      "          [-11.8956,  -7.5758,  -8.9045,  ..., -18.1307, -17.1608, -19.2235],\n",
      "          [-19.7252, -16.8228, -14.6520,  ..., -26.3872, -28.7890, -33.6384],\n",
      "          ...,\n",
      "          [-50.0473, -45.2424, -43.7083,  ..., -45.0022, -45.4437, -47.6010],\n",
      "          [-49.6590, -45.4734, -44.9418,  ..., -45.1720, -45.3693, -47.7974],\n",
      "          [-48.0313, -45.3882, -46.0704,  ..., -44.0431, -44.2720, -46.9249]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-15.9847, -14.0179, -16.7141,  ..., -11.6346,  -9.9125, -14.6149],\n",
      "          [-21.8142, -21.0827, -20.5922,  ..., -19.2682, -17.4382, -16.4676],\n",
      "          [-22.9617, -23.3284, -28.8567,  ..., -26.7881, -25.0587, -22.8177],\n",
      "          ...,\n",
      "          [-55.1120, -50.9917, -50.0754,  ..., -50.1730, -50.7218, -52.4482],\n",
      "          [-52.4033, -50.2543, -49.7233,  ..., -50.8123, -49.8012, -50.6934],\n",
      "          [-52.2780, -51.1951, -51.2470,  ..., -51.4042, -49.9473, -53.1411]]],\n",
      "\n",
      "\n",
      "        [[[-18.3196, -13.3216, -13.2562,  ...,  -7.5902,  -7.4110, -10.4413],\n",
      "          [-20.6282, -21.6406, -21.3385,  ..., -11.6644, -13.6845, -15.2870],\n",
      "          [-23.8585, -23.7857, -28.7961,  ..., -13.2266, -14.4664, -24.2409],\n",
      "          ...,\n",
      "          [-53.5980, -49.2211, -47.7839,  ..., -49.4069, -49.1947, -50.7528],\n",
      "          [-54.6366, -50.5590, -48.2576,  ..., -49.6840, -49.6201, -50.2961],\n",
      "          [-53.7999, -50.0323, -50.3504,  ..., -50.1086, -50.4327, -52.9363]]],\n",
      "\n",
      "\n",
      "        [[[-19.9970, -15.1637, -12.2984,  ..., -10.7766, -20.2767, -30.5286],\n",
      "          [-22.6639, -23.1932, -20.6569,  ..., -13.3077, -18.5638, -26.1111],\n",
      "          [-24.9933, -26.6483, -25.8331,  ..., -26.0720, -23.2497, -28.2095],\n",
      "          ...,\n",
      "          [-55.7489, -52.8567, -52.7822,  ..., -53.6828, -53.5180, -54.6768],\n",
      "          [-56.0969, -53.0238, -53.0957,  ..., -53.3073, -53.3866, -55.6636],\n",
      "          [-55.4514, -52.7263, -53.9187,  ..., -54.4855, -53.0298, -55.1999]]]]), tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0])]\n",
      "[tensor([[[[-18.7262, -11.8394, -10.0279,  ..., -12.9071, -11.8699, -14.3534],\n",
      "          [-19.7830, -21.4070, -20.1274,  ..., -19.2748, -18.6100, -19.1210],\n",
      "          [-23.6363, -26.8016, -33.9756,  ..., -31.3742, -34.0349, -26.7250],\n",
      "          ...,\n",
      "          [-59.8917, -55.0003, -54.6919,  ..., -54.2388, -55.1427, -57.2387],\n",
      "          [-58.1188, -54.9648, -55.1942,  ..., -55.4787, -55.7088, -56.9568],\n",
      "          [-59.0119, -56.4354, -55.7445,  ..., -55.9867, -55.9755, -55.9698]]],\n",
      "\n",
      "\n",
      "        [[[-27.9054, -21.3185, -17.2335,  ...,  -6.2513,  -3.8156,  -6.1752],\n",
      "          [-28.2472, -29.3647, -24.8184,  ..., -14.5159,  -9.2674,  -7.7449],\n",
      "          [-31.7981, -34.8332, -35.8450,  ..., -20.3331, -19.4879, -15.6258],\n",
      "          ...,\n",
      "          [-65.4482, -59.7881, -58.5384,  ..., -60.2495, -60.0008, -61.0674],\n",
      "          [-61.3109, -58.2625, -58.9933,  ..., -58.6127, -58.8356, -61.6086],\n",
      "          [-63.0044, -59.4113, -59.7527,  ..., -59.3174, -59.6244, -61.4854]]],\n",
      "\n",
      "\n",
      "        [[[-36.5700, -26.3935, -20.2113,  ..., -28.3572, -26.9126, -27.8535],\n",
      "          [-32.0337, -24.8408, -22.7003,  ..., -24.4552, -29.6622, -28.1213],\n",
      "          [-34.6047, -34.5102, -35.7962,  ..., -26.9137, -33.9496, -32.3677],\n",
      "          ...,\n",
      "          [-56.0537, -54.6892, -56.2404,  ..., -54.7373, -55.0124, -57.3151],\n",
      "          [-57.9875, -54.5320, -55.6409,  ..., -55.3609, -56.4543, -59.0605],\n",
      "          [-59.2444, -55.7921, -55.3012,  ..., -54.0299, -55.0039, -57.4470]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-24.9274, -18.5918, -16.2354,  ...,  -2.2811,  -6.8957, -27.4467],\n",
      "          [-25.3009, -16.0771, -11.9135,  ...,  -5.8315,  -8.1934, -17.5414],\n",
      "          [-22.6354, -18.3868, -14.1303,  ..., -15.3063, -16.2279, -16.6850],\n",
      "          ...,\n",
      "          [-44.1985, -41.3367, -40.8194,  ..., -38.3325, -40.3172, -43.4737],\n",
      "          [-44.4597, -41.6266, -40.2604,  ..., -40.8034, -42.0627, -44.1573],\n",
      "          [-44.0227, -41.1435, -40.2705,  ..., -41.1555, -39.9313, -41.3415]]],\n",
      "\n",
      "\n",
      "        [[[-10.2811,  -6.0495,  -6.3916,  ...,  -6.5447,  -7.4464,  -9.8147],\n",
      "          [-17.8376, -12.1016, -13.5835,  ..., -11.5389, -11.7135, -15.1167],\n",
      "          [-27.4695, -24.8073, -18.9002,  ..., -17.1402, -17.8270, -22.3128],\n",
      "          ...,\n",
      "          [-47.2690, -44.5893, -45.7008,  ..., -44.4658, -44.4696, -46.1615],\n",
      "          [-47.4598, -43.7327, -43.7412,  ..., -43.7695, -42.0419, -44.2085],\n",
      "          [-47.1809, -44.6242, -45.2936,  ..., -43.1634, -42.5732, -45.4749]]],\n",
      "\n",
      "\n",
      "        [[[ -4.7074,  -4.1009, -10.1987,  ..., -14.6820, -10.2472, -12.5021],\n",
      "          [ -8.6393,  -9.8406, -19.1549,  ..., -16.6343, -14.2776, -12.8814],\n",
      "          [-16.3561, -20.4085, -23.7052,  ..., -20.4854, -19.7781, -18.0814],\n",
      "          ...,\n",
      "          [-47.5005, -44.2963, -44.3100,  ..., -42.7650, -42.7237, -44.9854],\n",
      "          [-45.7315, -43.2427, -43.7464,  ..., -42.7360, -43.5781, -46.9531],\n",
      "          [-48.5273, -45.2927, -43.3432,  ..., -42.8443, -44.5595, -47.4890]]]]), tensor([1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "        0])]\n",
      "[tensor([[[[ -6.5089,  -7.2313, -11.5833,  ...,  -4.1774,  -6.6380, -14.7105],\n",
      "          [-10.0787, -13.7219, -12.8223,  ...,  -9.0118,  -8.4450, -14.0699],\n",
      "          [-11.7811, -11.7776, -13.4551,  ...,  -9.7220,  -9.6488, -12.5836],\n",
      "          ...,\n",
      "          [-49.0866, -46.7478, -46.6426,  ..., -46.6265, -45.5678, -47.3407],\n",
      "          [-50.5234, -46.1109, -45.9583,  ..., -46.4997, -46.6901, -48.8989],\n",
      "          [-48.3384, -45.0521, -46.2175,  ..., -45.9267, -45.8513, -48.0670]]],\n",
      "\n",
      "\n",
      "        [[[-41.9585, -30.2702, -28.3199,  ..., -18.6160, -16.6913, -19.4897],\n",
      "          [-42.0062, -33.1979, -33.2323,  ..., -25.8040, -21.7878, -22.6405],\n",
      "          [-37.3466, -33.8410, -37.1245,  ..., -43.2181, -38.8977, -31.5059],\n",
      "          ...,\n",
      "          [-69.4513, -65.8063, -65.1254,  ..., -65.5881, -66.0669, -68.4613],\n",
      "          [-68.6379, -65.9239, -64.5094,  ..., -66.9272, -65.4451, -66.6778],\n",
      "          [-67.6542, -65.0607, -64.6939,  ..., -67.1344, -66.2468, -68.1654]]],\n",
      "\n",
      "\n",
      "        [[[-16.4787, -12.1215, -11.6666,  ..., -11.8546, -10.4254, -12.9287],\n",
      "          [-16.8780, -17.0428, -17.5545,  ..., -11.0382, -12.9874, -12.1877],\n",
      "          [-22.1252, -26.1955, -24.0451,  ..., -15.6223, -15.7245, -14.1402],\n",
      "          ...,\n",
      "          [-53.2268, -49.4688, -49.8012,  ..., -49.8471, -50.0093, -51.7353],\n",
      "          [-53.0810, -49.6801, -48.4958,  ..., -49.1406, -49.6151, -51.7191],\n",
      "          [-53.0012, -50.0339, -50.3143,  ..., -48.8393, -49.4450, -50.5075]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -9.9778,  -3.9949,  -4.7254,  ...,  -7.3415,  -6.9696,  -9.8242],\n",
      "          [-10.9017,  -8.4362,  -8.2410,  ..., -11.3936, -10.8893, -12.3804],\n",
      "          [-14.5288, -11.9366,  -7.2172,  ..., -10.8531,  -8.3659,  -9.3872],\n",
      "          ...,\n",
      "          [-46.4954, -44.2760, -44.2288,  ..., -43.5122, -43.5099, -45.7855],\n",
      "          [-47.3326, -43.8942, -42.4244,  ..., -43.7358, -43.2779, -45.5442],\n",
      "          [-46.4955, -43.3611, -43.5752,  ..., -44.2565, -42.9369, -44.8432]]],\n",
      "\n",
      "\n",
      "        [[[-11.1941,  -5.4080,  -5.8019,  ...,  -4.6166,  -5.7642, -10.3268],\n",
      "          [-12.8507, -12.9629, -10.0325,  ..., -10.5448, -12.1609, -15.1020],\n",
      "          [-16.1519, -15.5327, -16.3936,  ..., -23.1698, -31.4796, -26.6092],\n",
      "          ...,\n",
      "          [-47.4982, -46.6867, -45.9013,  ..., -47.2873, -45.9264, -48.9026],\n",
      "          [-46.6341, -44.6583, -45.9753,  ..., -45.1657, -46.4965, -50.2127],\n",
      "          [-46.6026, -44.0240, -45.2960,  ..., -45.2975, -45.2794, -47.8318]]],\n",
      "\n",
      "\n",
      "        [[[-11.7009, -13.1880, -17.4303,  ...,  -1.5614,  -2.8116,  -4.0205],\n",
      "          [-10.9554,  -8.8982, -12.3855,  ..., -10.5946, -12.4663, -10.3461],\n",
      "          [-16.2755, -15.0870, -16.4361,  ..., -26.2661, -23.3382, -17.4136],\n",
      "          ...,\n",
      "          [-51.2146, -48.8812, -48.9750,  ..., -47.9386, -46.7696, -48.2462],\n",
      "          [-51.2449, -48.7205, -49.1729,  ..., -48.7808, -48.4788, -50.2118],\n",
      "          [-53.2106, -50.4894, -49.9958,  ..., -47.7947, -48.6908, -51.7360]]]]), tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0])]\n",
      "[tensor([[[[-13.0675,  -7.9908,  -7.6553,  ..., -14.9032, -15.9204, -17.0141],\n",
      "          [-16.7026, -14.9558, -12.8837,  ..., -18.8584, -21.5642, -21.0590],\n",
      "          [-22.3299, -24.1841, -21.9885,  ..., -27.6806, -28.2226, -27.9260],\n",
      "          ...,\n",
      "          [-55.6558, -53.1644, -53.5995,  ..., -51.8833, -53.3409, -55.9219],\n",
      "          [-57.2805, -55.1917, -53.1954,  ..., -51.9842, -52.6225, -56.8017],\n",
      "          [-55.5412, -52.9830, -52.5753,  ..., -52.0533, -53.3135, -55.3917]]],\n",
      "\n",
      "\n",
      "        [[[-15.3524,  -9.9197, -12.8283,  ..., -18.5419, -17.5714, -23.6406],\n",
      "          [-16.9098, -11.7714, -12.1251,  ..., -20.3553, -20.4315, -26.4948],\n",
      "          [-26.3316, -22.9307, -19.7580,  ..., -28.8533, -32.4405, -29.6913],\n",
      "          ...,\n",
      "          [-59.5951, -56.3774, -56.0543,  ..., -54.1596, -55.7811, -55.4955],\n",
      "          [-59.2116, -54.7403, -54.6556,  ..., -55.2404, -55.2025, -55.0895],\n",
      "          [-59.0407, -54.6832, -53.8964,  ..., -55.0127, -55.2956, -56.4898]]],\n",
      "\n",
      "\n",
      "        [[[ -3.7358,  -0.2531,  -1.2429,  ...,  -4.5890,  -5.2181,  -7.8236],\n",
      "          [ -7.0818,  -5.6979,  -7.6197,  ..., -11.5637, -13.1514, -14.4632],\n",
      "          [-16.1163, -21.8438, -22.4506,  ..., -26.0329, -26.7221, -24.5581],\n",
      "          ...,\n",
      "          [-52.9120, -51.9544, -51.8734,  ..., -54.6577, -54.0950, -54.2338],\n",
      "          [-53.4077, -53.2199, -53.0217,  ..., -54.5063, -52.7088, -53.4087],\n",
      "          [-55.7857, -54.5364, -55.1644,  ..., -53.2600, -52.6673, -54.1412]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-19.3481, -15.2829, -11.8810,  ..., -23.9421, -22.8525, -24.3331],\n",
      "          [-27.0722, -23.9060, -18.6913,  ..., -23.4864, -22.0060, -24.9464],\n",
      "          [-35.0333, -33.9625, -33.7638,  ..., -31.4088, -28.7178, -32.9007],\n",
      "          ...,\n",
      "          [-57.5748, -53.2601, -53.1944,  ..., -53.9430, -52.9499, -54.7934],\n",
      "          [-58.7426, -55.6686, -54.4803,  ..., -53.7229, -52.7154, -55.6677],\n",
      "          [-57.6064, -54.0783, -54.9383,  ..., -54.7633, -54.8707, -58.0782]]],\n",
      "\n",
      "\n",
      "        [[[-18.7589, -17.0870, -11.0528,  ...,  -7.0617,  -6.5454, -12.2901],\n",
      "          [-17.1912, -13.4462, -12.2086,  ..., -14.1075, -13.5112, -15.6719],\n",
      "          [-21.0180, -21.0280, -20.9458,  ..., -29.7874, -20.9348, -18.4390],\n",
      "          ...,\n",
      "          [-51.4241, -47.2915, -45.0926,  ..., -44.1794, -44.2714, -46.1724],\n",
      "          [-50.3867, -47.5947, -46.6455,  ..., -45.6756, -46.4311, -47.7794],\n",
      "          [-49.3894, -45.4212, -45.9279,  ..., -46.5714, -47.0104, -49.2187]]],\n",
      "\n",
      "\n",
      "        [[[-39.8160, -39.4277, -34.0719,  ..., -26.5273, -27.4813, -28.5300],\n",
      "          [-37.5213, -37.2991, -39.2982,  ..., -31.0198, -34.9170, -31.6323],\n",
      "          [-37.3448, -39.3381, -46.6293,  ..., -33.6917, -41.4453, -35.7523],\n",
      "          ...,\n",
      "          [-67.9484, -64.7562, -64.3061,  ..., -66.7727, -65.4096, -66.6625],\n",
      "          [-69.6489, -66.5437, -65.5165,  ..., -66.0132, -65.5687, -66.6903],\n",
      "          [-67.8323, -65.8058, -65.8754,  ..., -64.2769, -65.6449, -67.4393]]]]), tensor([0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        1])]\n",
      "[tensor([[[[ -8.4136,  -5.1015,  -5.4654,  ..., -15.0353, -13.6969, -18.6192],\n",
      "          [-11.0636, -10.0460, -12.3200,  ..., -18.6281, -17.7831, -20.8178],\n",
      "          [-18.5054, -22.2372, -23.8721,  ..., -25.8203, -26.6553, -31.8905],\n",
      "          ...,\n",
      "          [-50.6858, -45.8738, -45.3640,  ..., -46.0789, -46.5514, -48.6362],\n",
      "          [-48.6096, -45.7913, -46.1169,  ..., -47.1293, -46.4737, -47.8803],\n",
      "          [-48.8919, -46.2155, -46.4882,  ..., -46.0134, -45.6994, -47.3711]]],\n",
      "\n",
      "\n",
      "        [[[-10.6024,  -3.1394,  -4.5699,  ...,  -2.9464,  -6.0645, -15.4969],\n",
      "          [-12.8161,  -7.8406,  -8.6427,  ...,  -9.2525, -12.1167, -19.4653],\n",
      "          [-20.7148, -17.4277, -14.8582,  ..., -14.8088, -14.9928, -18.0760],\n",
      "          ...,\n",
      "          [-51.5093, -47.5956, -46.8289,  ..., -47.9128, -48.9800, -52.0452],\n",
      "          [-52.2566, -48.6051, -48.1989,  ..., -48.9494, -49.0289, -50.6086],\n",
      "          [-51.8149, -48.8338, -47.3673,  ..., -49.5245, -48.9747, -51.3466]]],\n",
      "\n",
      "\n",
      "        [[[ -7.5912,  -6.3112,  -7.1174,  ...,  -5.6053,  -7.1954, -18.8176],\n",
      "          [ -8.5957,  -9.0492,  -7.9612,  ...,  -4.2352,  -4.4967, -12.4908],\n",
      "          [-11.3077,  -7.6556,  -9.5536,  ...,  -3.7168,  -5.8609, -11.7514],\n",
      "          ...,\n",
      "          [-45.5638, -44.0349, -44.3270,  ..., -45.0604, -46.2145, -48.2845],\n",
      "          [-45.4925, -43.8724, -45.0810,  ..., -44.1801, -43.9341, -45.9295],\n",
      "          [-47.9110, -45.6487, -45.6354,  ..., -43.6443, -44.2658, -46.2148]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-18.7811, -13.0837,  -9.2445,  ...,  -6.3456, -16.7675, -22.8936],\n",
      "          [-18.5282, -20.6409, -15.4925,  ..., -12.5110, -17.5203, -17.0393],\n",
      "          [-21.0574, -22.1818, -22.8525,  ..., -24.1733, -22.6247, -17.9153],\n",
      "          ...,\n",
      "          [-46.1887, -43.3815, -42.9426,  ..., -41.5208, -42.2284, -45.2708],\n",
      "          [-46.6824, -44.5033, -44.8085,  ..., -42.1893, -43.9039, -46.5497],\n",
      "          [-46.3209, -42.4828, -42.3022,  ..., -45.4170, -45.4483, -46.6491]]],\n",
      "\n",
      "\n",
      "        [[[-16.9692, -10.9938,  -7.2436,  ..., -12.5421, -11.7898,  -7.9700],\n",
      "          [-16.1618, -15.6745, -11.1743,  ...,  -9.6513, -11.8732, -10.1223],\n",
      "          [-17.6735, -17.8165, -19.0604,  ..., -15.8944, -20.3624, -15.6833],\n",
      "          ...,\n",
      "          [-49.3982, -46.1515, -46.9484,  ..., -47.1967, -47.5454, -48.5651],\n",
      "          [-49.9186, -45.8361, -45.4003,  ..., -47.0138, -48.8478, -50.7162],\n",
      "          [-50.4007, -46.8016, -46.8817,  ..., -48.1239, -47.6188, -48.5854]]],\n",
      "\n",
      "\n",
      "        [[[-15.7938, -13.6094, -15.8898,  ..., -13.1712, -15.9171, -24.8090],\n",
      "          [-20.6010, -19.7287, -23.0496,  ..., -19.6744, -20.6925, -26.1282],\n",
      "          [-28.9972, -31.0247, -26.0393,  ..., -29.4253, -35.6633, -35.1078],\n",
      "          ...,\n",
      "          [-57.9193, -54.3215, -54.0550,  ..., -53.8247, -55.0106, -57.7770],\n",
      "          [-58.5576, -55.1727, -54.9465,  ..., -56.4473, -57.5574, -59.6790],\n",
      "          [-58.4684, -55.5789, -55.9712,  ..., -56.2973, -57.4389, -59.6278]]]]), tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[-41.1949, -33.7950, -32.1102,  ..., -31.0195, -28.4534, -30.1717],\n",
      "          [-39.0958, -33.4054, -32.5954,  ..., -35.9830, -36.1311, -37.3672],\n",
      "          [-42.1050, -43.7895, -40.8722,  ..., -37.8441, -36.3328, -33.2965],\n",
      "          ...,\n",
      "          [-67.4724, -64.6612, -63.8652,  ..., -63.6457, -64.2297, -65.1253],\n",
      "          [-68.2352, -66.0410, -64.4523,  ..., -64.2188, -64.2456, -64.4905],\n",
      "          [-68.3075, -65.6869, -64.7849,  ..., -64.5318, -65.3609, -64.9155]]],\n",
      "\n",
      "\n",
      "        [[[-11.8701,  -5.1386,  -5.3225,  ...,  -6.1795,  -5.2751,  -6.9758],\n",
      "          [-16.4584, -11.6083, -11.1369,  ..., -13.2716, -12.4387, -14.6307],\n",
      "          [-26.7326, -27.6372, -21.9570,  ..., -21.5297, -19.5282, -18.8123],\n",
      "          ...,\n",
      "          [-48.4768, -44.7051, -44.7552,  ..., -43.2998, -43.8978, -44.9145],\n",
      "          [-47.7888, -44.1241, -43.8366,  ..., -43.8489, -43.4634, -44.8217],\n",
      "          [-47.1278, -43.2830, -44.0731,  ..., -43.6275, -43.6848, -45.0503]]],\n",
      "\n",
      "\n",
      "        [[[-12.6443,  -6.8938,  -6.8797,  ...,  -7.0270,  -6.7778, -10.8544],\n",
      "          [-18.7761, -12.6750, -13.4944,  ..., -14.7566, -13.5511, -12.8078],\n",
      "          [-31.0924, -26.5430, -28.5650,  ..., -10.5273, -13.2091, -17.9717],\n",
      "          ...,\n",
      "          [-52.3474, -48.3905, -48.4627,  ..., -49.1647, -50.1195, -51.9069],\n",
      "          [-52.8063, -48.9490, -47.7982,  ..., -49.4884, -48.6921, -50.5465],\n",
      "          [-53.5234, -49.7839, -49.3843,  ..., -50.7942, -48.3005, -49.0676]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.2413,  -5.4883,  -6.2477,  ...,  -5.0032, -12.4964, -22.6195],\n",
      "          [-16.1631, -11.2228, -14.9500,  ...,  -8.0530,  -9.0140, -18.8700],\n",
      "          [-24.8997, -23.6124, -23.4956,  ..., -15.5985, -14.4410, -22.9818],\n",
      "          ...,\n",
      "          [-46.9674, -44.3465, -43.3159,  ..., -44.4402, -44.6733, -46.5689],\n",
      "          [-47.1709, -44.1952, -44.9875,  ..., -43.8711, -43.6865, -44.4507],\n",
      "          [-47.8180, -44.8910, -45.6635,  ..., -45.2993, -44.5552, -46.5973]]],\n",
      "\n",
      "\n",
      "        [[[-19.5113, -17.2796, -14.4552,  ..., -13.1453, -16.7523, -21.4737],\n",
      "          [-21.5721, -16.4613, -14.3386,  ..., -15.7047, -17.8305, -23.1605],\n",
      "          [-25.4645, -18.5985, -16.3696,  ..., -24.3923, -27.7689, -32.7296],\n",
      "          ...,\n",
      "          [-56.0407, -52.8178, -53.6353,  ..., -54.4710, -52.3425, -53.4535],\n",
      "          [-54.9521, -52.3320, -51.4570,  ..., -53.0415, -53.5251, -54.5961],\n",
      "          [-58.4391, -53.9993, -51.9105,  ..., -54.3236, -54.9264, -57.4498]]],\n",
      "\n",
      "\n",
      "        [[[-17.9371,  -8.8496,  -6.3261,  ..., -13.9192, -21.8050, -22.0796],\n",
      "          [-26.7650, -13.6657, -10.6994,  ..., -18.6351, -18.8937, -18.8669],\n",
      "          [-26.6272, -24.3254, -20.4215,  ..., -25.1762, -21.4706, -20.6638],\n",
      "          ...,\n",
      "          [-58.3328, -55.1749, -54.1579,  ..., -51.6787, -52.0903, -54.8871],\n",
      "          [-55.9069, -55.2050, -53.9617,  ..., -53.3950, -53.2598, -55.3331],\n",
      "          [-58.3590, -55.9967, -54.2897,  ..., -55.5331, -55.6569, -56.5664]]]]), tensor([1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[-22.8555, -24.2541, -16.6347,  ..., -11.2893, -14.4270, -19.0776],\n",
      "          [-24.6231, -19.3687, -18.7396,  ..., -17.3641, -23.6286, -20.7037],\n",
      "          [-32.2432, -23.2202, -21.9211,  ..., -27.3695, -31.9737, -25.2001],\n",
      "          ...,\n",
      "          [-54.5143, -50.5154, -49.3703,  ..., -51.1961, -49.5663, -52.1481],\n",
      "          [-54.9329, -51.1490, -49.7381,  ..., -52.1047, -49.7063, -52.0732],\n",
      "          [-54.6152, -50.7141, -49.8980,  ..., -50.8353, -50.2627, -52.4290]]],\n",
      "\n",
      "\n",
      "        [[[-10.4650,  -9.9319, -10.6126,  ...,  -5.6315,  -9.1701, -11.8183],\n",
      "          [-13.9745, -15.6682, -21.3903,  ..., -13.7312, -14.3409, -15.9523],\n",
      "          [-22.3743, -26.8724, -24.9791,  ..., -16.0099, -17.4028, -18.8327],\n",
      "          ...,\n",
      "          [-47.2042, -45.3369, -46.6831,  ..., -45.5166, -46.0548, -46.7728],\n",
      "          [-48.4423, -46.4752, -47.3491,  ..., -46.0382, -46.5351, -49.3588],\n",
      "          [-49.3104, -45.9807, -46.7723,  ..., -47.7996, -49.1514, -51.6120]]],\n",
      "\n",
      "\n",
      "        [[[-17.8809, -13.8008,  -9.8253,  ...,  -2.4269,  -4.3484, -11.5332],\n",
      "          [-16.9889, -13.5854, -14.1926,  ...,  -6.6071,  -6.6040, -13.1782],\n",
      "          [-18.5040, -12.2775, -14.0794,  ..., -19.0771, -15.7229, -16.7653],\n",
      "          ...,\n",
      "          [-48.0407, -44.8657, -44.8810,  ..., -46.9175, -46.3401, -46.9754],\n",
      "          [-49.1498, -46.1655, -47.3097,  ..., -47.0366, -46.0475, -46.9693],\n",
      "          [-51.6866, -49.2761, -48.0664,  ..., -46.5795, -46.0712, -46.5958]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-15.7064, -10.5204, -14.6517,  ...,  -4.1848,  -6.5355,  -8.8473],\n",
      "          [-20.9488, -12.5750, -12.2427,  ..., -13.9895, -16.4761, -16.8074],\n",
      "          [-25.1002, -18.7478, -19.4846,  ..., -21.9419, -24.9376, -28.9792],\n",
      "          ...,\n",
      "          [-51.5935, -48.1440, -48.3793,  ..., -49.6091, -48.7894, -50.3025],\n",
      "          [-52.0209, -50.0159, -49.8198,  ..., -49.9798, -49.7740, -51.7097],\n",
      "          [-50.8838, -48.6046, -48.1864,  ..., -48.1219, -48.9926, -50.5705]]],\n",
      "\n",
      "\n",
      "        [[[-18.8101, -11.5525, -10.9057,  ...,  -4.9904,  -5.1883,  -7.2390],\n",
      "          [-23.4721, -15.4364, -14.3454,  ..., -14.9830, -13.9275, -14.0722],\n",
      "          [-25.1900, -19.9314, -21.8553,  ..., -33.3615, -31.5091, -27.5234],\n",
      "          ...,\n",
      "          [-48.3025, -47.0525, -47.6390,  ..., -48.3545, -47.3473, -49.0810],\n",
      "          [-50.8745, -47.7280, -46.6648,  ..., -46.4865, -48.0186, -49.5519],\n",
      "          [-49.1337, -45.4763, -46.1205,  ..., -47.1147, -48.6637, -51.1573]]],\n",
      "\n",
      "\n",
      "        [[[-10.1274,  -5.9119,  -4.1281,  ...,  -7.2018, -19.5273, -21.2902],\n",
      "          [-17.5092, -11.5427, -12.7912,  ...,  -9.6925, -18.7047, -25.3449],\n",
      "          [-16.6953, -15.7948, -19.8496,  ..., -17.6058, -18.5355, -23.7677],\n",
      "          ...,\n",
      "          [-46.9153, -45.2315, -46.0059,  ..., -43.2691, -44.0982, -46.9078],\n",
      "          [-45.0146, -43.7958, -46.3014,  ..., -42.8968, -44.1179, -46.6675],\n",
      "          [-48.7471, -45.9719, -45.5182,  ..., -43.2579, -45.7593, -48.7857]]]]), tensor([0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[-15.1184,  -9.4343,  -8.2362,  ...,  -6.3266,  -7.2460, -16.7910],\n",
      "          [-17.7937, -15.3535, -18.4485,  ..., -14.9163, -13.0186, -19.9594],\n",
      "          [-28.6480, -32.0281, -32.3770,  ..., -25.7283, -22.8822, -29.8659],\n",
      "          ...,\n",
      "          [-49.6466, -47.5167, -48.0708,  ..., -47.2744, -47.4415, -49.9900],\n",
      "          [-53.1427, -50.1131, -49.7006,  ..., -46.3640, -48.0802, -51.9863],\n",
      "          [-51.7267, -48.8992, -48.2699,  ..., -48.5649, -49.0722, -51.2357]]],\n",
      "\n",
      "\n",
      "        [[[-27.5294, -18.5158, -18.2623,  ..., -22.8309, -21.4782, -24.8627],\n",
      "          [-31.6981, -26.3764, -28.2322,  ..., -21.0839, -22.2649, -26.8836],\n",
      "          [-39.2783, -31.9371, -28.1963,  ..., -29.8527, -25.8604, -25.4194],\n",
      "          ...,\n",
      "          [-55.3907, -53.6379, -53.6388,  ..., -54.0645, -53.4637, -54.7766],\n",
      "          [-58.1384, -54.4396, -51.9244,  ..., -56.1977, -55.9815, -57.3627],\n",
      "          [-58.8829, -55.8472, -54.5590,  ..., -53.6793, -54.0845, -56.2372]]],\n",
      "\n",
      "\n",
      "        [[[-30.1029, -28.7746, -29.5509,  ..., -27.4118, -32.0831, -30.6466],\n",
      "          [-35.5354, -37.0603, -36.5865,  ..., -32.2555, -33.0942, -31.0621],\n",
      "          [-43.4481, -45.3240, -44.2588,  ..., -41.8420, -38.7018, -37.6239],\n",
      "          ...,\n",
      "          [-67.5778, -64.8246, -64.6996,  ..., -63.7943, -63.4831, -65.2169],\n",
      "          [-69.5713, -66.5785, -65.1402,  ..., -63.0538, -64.3220, -66.8071],\n",
      "          [-67.1146, -65.5332, -64.9934,  ..., -65.0173, -65.0477, -66.8118]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-13.6412,  -5.4165,  -2.1325,  ..., -12.6002,  -8.8502, -10.3922],\n",
      "          [-16.0816, -11.6584,  -8.6494,  ..., -19.6240, -14.6532, -14.4022],\n",
      "          [-27.9327, -24.1669, -21.8922,  ..., -21.7183, -20.4345, -23.8000],\n",
      "          ...,\n",
      "          [-52.6999, -49.7184, -49.8079,  ..., -48.0061, -48.9112, -50.1159],\n",
      "          [-54.0926, -49.8909, -48.6383,  ..., -48.0585, -48.1513, -51.1475],\n",
      "          [-53.6642, -50.4717, -49.8699,  ..., -50.8396, -50.4109, -52.7609]]],\n",
      "\n",
      "\n",
      "        [[[-10.8312,  -7.3994,  -8.6193,  ...,  -7.5110,  -7.9843, -10.7971],\n",
      "          [-11.6024, -11.3676, -13.0134,  ..., -11.2276, -12.9780, -16.9640],\n",
      "          [-16.8336, -19.8734, -21.1728,  ..., -19.3163, -19.4975, -19.6286],\n",
      "          ...,\n",
      "          [-47.5731, -45.3314, -46.2222,  ..., -47.7452, -48.4497, -48.4899],\n",
      "          [-47.5139, -45.3951, -45.9444,  ..., -48.1398, -48.0337, -49.5193],\n",
      "          [-48.6693, -46.1327, -46.6714,  ..., -47.7664, -46.7817, -48.1800]]],\n",
      "\n",
      "\n",
      "        [[[-10.0004,  -6.0338,  -5.4519,  ...,  -9.3916, -14.0991, -17.7488],\n",
      "          [-12.6107, -10.7381, -10.4863,  ..., -15.0660, -19.2472, -18.7346],\n",
      "          [-21.7686, -19.3505, -19.4746,  ..., -23.2183, -22.3331, -25.6650],\n",
      "          ...,\n",
      "          [-48.5911, -45.9721, -46.6742,  ..., -46.5609, -47.4897, -50.2312],\n",
      "          [-48.5103, -46.0117, -45.8219,  ..., -44.7655, -46.7104, -50.2358],\n",
      "          [-48.9068, -45.2403, -44.7524,  ..., -45.4604, -44.7634, -47.7342]]]]), tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[-17.1291, -13.6198, -18.3667,  ...,  -8.8328,  -7.8416,  -9.6588],\n",
      "          [-18.6298, -15.0062, -17.7475,  ..., -17.1704, -19.7612, -17.1512],\n",
      "          [-25.1929, -25.2588, -28.1525,  ..., -23.8154, -32.2125, -24.7290],\n",
      "          ...,\n",
      "          [-54.6480, -52.5216, -51.4360,  ..., -52.8301, -51.9521, -54.4906],\n",
      "          [-55.2629, -52.3876, -51.6727,  ..., -53.2011, -52.2692, -53.5675],\n",
      "          [-57.7487, -52.6664, -52.5092,  ..., -53.7989, -53.9842, -54.4772]]],\n",
      "\n",
      "\n",
      "        [[[-11.8188,  -8.7170, -12.4019,  ...,  -4.5528,  -4.1791,  -4.5850],\n",
      "          [-16.0335, -16.1069, -17.9722,  ..., -12.3224, -12.1459,  -9.0556],\n",
      "          [-19.8896, -20.0999, -24.1499,  ..., -24.6412, -18.1940, -13.0155],\n",
      "          ...,\n",
      "          [-47.8361, -45.8764, -46.6226,  ..., -46.9297, -47.2287, -47.5030],\n",
      "          [-49.7483, -47.0332, -47.9437,  ..., -45.8161, -45.9232, -47.2497],\n",
      "          [-50.4586, -46.9036, -46.0024,  ..., -45.4710, -44.8270, -45.3368]]],\n",
      "\n",
      "\n",
      "        [[[-27.7187, -17.0642, -12.4365,  ...,  -6.6634,  -9.7795, -20.2406],\n",
      "          [-33.2266, -23.8471, -18.1023,  ..., -15.9706, -17.1794, -20.3262],\n",
      "          [-32.4595, -26.4541, -29.7807,  ..., -23.2194, -22.8858, -28.4983],\n",
      "          ...,\n",
      "          [-52.3107, -50.6930, -52.0260,  ..., -51.0089, -51.1247, -51.9354],\n",
      "          [-53.3393, -50.4500, -50.6053,  ..., -53.6100, -52.2932, -52.2276],\n",
      "          [-53.6962, -50.1491, -50.3150,  ..., -52.6747, -52.3957, -53.6904]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-18.6866, -17.1649, -15.7347,  ..., -16.8562, -18.2204, -22.6623],\n",
      "          [-17.8641, -18.2604, -21.5557,  ..., -22.8556, -20.6296, -20.6859],\n",
      "          [-19.7122, -21.1669, -24.5682,  ..., -30.9367, -27.7772, -26.2025],\n",
      "          ...,\n",
      "          [-52.3181, -49.4693, -49.8590,  ..., -48.5194, -48.8919, -51.2905],\n",
      "          [-52.6133, -50.8172, -50.9413,  ..., -48.9688, -49.8872, -52.4662],\n",
      "          [-53.4691, -50.8451, -49.0670,  ..., -50.3713, -51.2559, -52.8653]]],\n",
      "\n",
      "\n",
      "        [[[-18.1195, -14.4148, -15.0866,  ...,  -7.6863,  -9.2004, -15.2753],\n",
      "          [-18.6531, -14.6132, -12.4539,  ..., -10.5999, -16.9559, -18.6128],\n",
      "          [-26.1218, -25.8747, -20.5850,  ..., -18.9200, -20.7639, -26.4954],\n",
      "          ...,\n",
      "          [-56.3707, -53.4329, -53.5689,  ..., -48.6412, -50.6176, -51.4642],\n",
      "          [-56.7034, -54.2275, -53.3234,  ..., -49.8426, -51.6824, -55.6917],\n",
      "          [-57.3613, -53.0635, -53.9056,  ..., -50.1740, -53.6289, -56.0077]]],\n",
      "\n",
      "\n",
      "        [[[-12.1502,  -6.6314,  -6.5102,  ..., -12.0918, -13.8648, -15.8436],\n",
      "          [-16.7818, -12.8079, -13.5594,  ..., -19.9806, -19.6111, -15.4617],\n",
      "          [-25.3891, -23.7117, -28.0104,  ..., -20.9761, -19.5573, -16.0741],\n",
      "          ...,\n",
      "          [-47.2648, -44.1705, -44.9595,  ..., -45.5091, -46.6284, -48.0430],\n",
      "          [-48.7183, -45.8644, -45.3904,  ..., -44.8253, -45.1271, -48.7331],\n",
      "          [-48.3245, -45.7225, -46.7482,  ..., -46.6990, -45.6198, -48.1998]]]]), tensor([1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0])]\n"
     ]
    }
   ],
   "source": [
    "# ラベルの指定\n",
    "t_df = Dataset.shNum\n",
    "\n",
    "# テンソル形式に変換\n",
    "df_tenosor = torch.tensor(df, dtype=torch.float32)\n",
    "df_tenosor = torch.unsqueeze(df_tenosor, 1)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "print(df_tenosor.size())\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset = torch.utils.data.TensorDataset(df_tenosor, label_tensor)\n",
    "\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 50%　: 25% : 25%\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 25\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### soft-hard 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1050, 1, 128, 130])\n",
      "525 262 263\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fdd2629e680>\n",
      "[tensor([[[[-15.7372, -12.7907, -12.2806,  ..., -16.2258, -12.1957, -14.6959],\n",
      "          [-15.7418, -11.8346, -11.9373,  ..., -12.7932, -11.7111, -12.4843],\n",
      "          [-22.5785, -21.3953, -21.5793,  ..., -20.6679, -21.5296, -17.3727],\n",
      "          ...,\n",
      "          [-58.1976, -55.0280, -55.0888,  ..., -53.4471, -52.7718, -53.7474],\n",
      "          [-56.4661, -53.7698, -54.6103,  ..., -54.0908, -53.9045, -56.2288],\n",
      "          [-57.3117, -54.9557, -55.6911,  ..., -54.7845, -54.3604, -56.0656]]],\n",
      "\n",
      "\n",
      "        [[[ -5.8755,  -1.3352,   0.0000,  ...,  -8.2323,  -7.3307,  -8.7717],\n",
      "          [ -7.0860,  -4.6320,  -2.7805,  ...,  -6.8078,  -5.4152,  -6.6856],\n",
      "          [-14.4937, -18.4999, -18.0805,  ..., -15.1023, -14.4274, -11.6789],\n",
      "          ...,\n",
      "          [-50.1694, -46.3330, -44.8377,  ..., -47.9001, -46.6421, -47.7369],\n",
      "          [-49.2638, -46.9567, -46.7122,  ..., -46.9204, -46.5079, -49.3187],\n",
      "          [-46.9555, -45.9099, -47.1923,  ..., -47.8846, -48.9719, -50.9079]]],\n",
      "\n",
      "\n",
      "        [[[-14.0626, -12.4793, -12.4311,  ...,  -6.8308,  -6.2901, -10.4582],\n",
      "          [-18.8385, -19.3206, -16.3264,  ...,  -9.3470,  -9.8862, -12.6103],\n",
      "          [-26.0905, -30.3457, -25.2675,  ..., -20.0117, -23.9119, -21.9449],\n",
      "          ...,\n",
      "          [-53.3047, -52.0847, -53.4519,  ..., -52.4061, -53.3940, -56.5739],\n",
      "          [-58.1525, -54.5277, -52.5746,  ..., -53.0982, -53.9163, -56.1266],\n",
      "          [-55.2106, -52.8737, -53.1973,  ..., -52.8028, -52.4231, -54.3603]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -9.9831,  -7.1871, -11.7807,  ..., -11.2343,  -9.8302, -13.3886],\n",
      "          [-11.8676,  -9.5992, -15.2492,  ..., -12.9284, -12.4264, -17.9736],\n",
      "          [-19.0413, -18.4740, -26.9585,  ..., -21.7851, -23.7197, -26.1367],\n",
      "          ...,\n",
      "          [-53.6593, -52.2464, -51.7386,  ..., -51.2787, -51.4993, -56.2754],\n",
      "          [-55.0183, -52.9384, -52.6564,  ..., -51.3566, -51.8909, -54.7269],\n",
      "          [-56.5075, -52.0982, -52.3580,  ..., -51.7871, -52.0791, -53.2282]]],\n",
      "\n",
      "\n",
      "        [[[-17.2652, -11.0746,  -9.8907,  ...,  -0.6295,   0.0000,  -3.5875],\n",
      "          [-18.6370, -15.4748, -16.1502,  ...,  -6.1369,  -3.3467,  -4.0424],\n",
      "          [-28.6770, -30.6238, -34.6265,  ..., -19.3636, -16.2683, -12.0035],\n",
      "          ...,\n",
      "          [-56.7433, -54.9483, -56.3357,  ..., -56.7504, -55.6961, -54.8034],\n",
      "          [-59.7806, -56.2284, -55.0864,  ..., -54.5428, -54.2212, -54.7591],\n",
      "          [-60.2414, -56.0917, -55.5884,  ..., -56.2427, -55.2146, -53.6850]]],\n",
      "\n",
      "\n",
      "        [[[ -9.3511,  -5.2951,  -9.8728,  ..., -10.9083,  -9.2532, -11.2135],\n",
      "          [ -8.2031,  -6.5688, -12.9695,  ..., -10.1815, -11.6199, -10.9543],\n",
      "          [-13.0035, -13.6482, -18.5944,  ..., -16.5582, -14.2727, -13.9899],\n",
      "          ...,\n",
      "          [-45.4077, -44.2285, -46.0337,  ..., -45.8847, -45.8283, -47.6377],\n",
      "          [-47.8298, -45.4274, -44.8245,  ..., -45.7963, -45.1360, -47.9109],\n",
      "          [-46.2646, -44.5052, -46.9336,  ..., -47.0090, -46.8320, -47.4182]]]]), tensor([1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0])]\n",
      "[tensor([[[[ -6.0762,  -3.5017,  -3.3377,  ...,  -4.1093,  -2.1572,  -5.0010],\n",
      "          [ -8.7918,  -7.3907,  -5.0249,  ...,  -8.1448,  -4.9479,  -9.1982],\n",
      "          [ -9.1813,  -6.6263, -11.7422,  ...,  -8.8395, -12.1046, -19.2009],\n",
      "          ...,\n",
      "          [-52.7497, -48.8865, -48.6537,  ..., -51.1285, -49.8177, -50.1686],\n",
      "          [-50.9880, -48.3031, -49.1782,  ..., -49.3246, -50.4652, -51.6474],\n",
      "          [-53.7844, -50.3416, -49.3829,  ..., -49.5337, -51.0771, -51.4142]]],\n",
      "\n",
      "\n",
      "        [[[-23.0836, -17.6527, -16.0622,  ..., -10.6483, -10.1918, -12.0575],\n",
      "          [-23.1806, -22.3402, -18.6569,  ..., -13.4887, -13.7516, -13.3281],\n",
      "          [-26.3015, -25.4151, -28.7933,  ..., -27.0607, -24.7454, -19.3046],\n",
      "          ...,\n",
      "          [-66.6998, -62.6790, -60.6387,  ..., -61.7790, -61.7823, -62.4379],\n",
      "          [-63.1558, -60.9635, -61.3787,  ..., -63.1781, -63.1277, -62.9624],\n",
      "          [-64.4473, -63.1082, -63.1545,  ..., -62.6057, -62.2202, -63.7380]]],\n",
      "\n",
      "\n",
      "        [[[-19.4677, -13.8089, -14.6049,  ..., -10.6197,  -9.1130, -14.6017],\n",
      "          [-26.8576, -22.7456, -24.1618,  ..., -10.5441, -12.6558, -19.9263],\n",
      "          [-35.0707, -34.8668, -34.4597,  ..., -19.6834, -21.1026, -24.3130],\n",
      "          ...,\n",
      "          [-57.2477, -53.7524, -52.4263,  ..., -53.7950, -53.9968, -55.4982],\n",
      "          [-55.1792, -53.1644, -54.2603,  ..., -52.6724, -53.1959, -54.9959],\n",
      "          [-54.3971, -52.5030, -52.5609,  ..., -53.9797, -53.4432, -55.9142]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -6.2664,  -2.9890,  -5.2798,  ...,  -5.7535,  -4.7177,  -6.9648],\n",
      "          [ -7.5614,  -3.9616,  -7.6979,  ...,  -7.0264,  -8.9588, -11.5580],\n",
      "          [-15.4290, -14.8272, -17.7061,  ..., -19.6478, -22.2260, -23.2930],\n",
      "          ...,\n",
      "          [-51.9192, -50.1242, -49.7132,  ..., -47.8093, -47.7594, -49.0973],\n",
      "          [-52.1852, -48.6977, -48.1595,  ..., -47.4365, -47.7249, -49.1994],\n",
      "          [-51.3106, -48.8156, -48.8151,  ..., -47.7161, -48.4147, -50.3677]]],\n",
      "\n",
      "\n",
      "        [[[-12.9531,  -8.4623, -10.9949,  ..., -13.9743, -12.5583, -12.9040],\n",
      "          [-12.9575,  -9.1291,  -9.6971,  ..., -12.4427, -10.5136, -12.3491],\n",
      "          [-18.2892, -20.0374, -20.3422,  ..., -16.5155, -15.7638, -17.3400],\n",
      "          ...,\n",
      "          [-54.6013, -51.4329, -50.6813,  ..., -50.8779, -51.4110, -53.4678],\n",
      "          [-52.1137, -49.6309, -49.8039,  ..., -51.3086, -50.1676, -51.5474],\n",
      "          [-52.6111, -51.0972, -51.9317,  ..., -52.1191, -50.8958, -52.4753]]],\n",
      "\n",
      "\n",
      "        [[[-25.9034, -21.9119, -14.0451,  ...,  -5.3250,  -9.2805, -16.3978],\n",
      "          [-19.3675, -13.7969, -12.1835,  ...,  -7.1418,  -7.7071, -15.4302],\n",
      "          [-19.0328, -17.3201, -16.0753,  ..., -17.0908, -13.7243, -22.8432],\n",
      "          ...,\n",
      "          [-48.0925, -46.5962, -46.7822,  ..., -47.8841, -46.8159, -47.6297],\n",
      "          [-47.8132, -45.3680, -44.6936,  ..., -46.3455, -46.1164, -49.3973],\n",
      "          [-49.8005, -47.0284, -47.1830,  ..., -46.4303, -46.3429, -48.1432]]]]), tensor([0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0])]\n",
      "[tensor([[[[-10.0279,  -7.8579, -11.8001,  ..., -12.3195,  -7.2473,  -9.8667],\n",
      "          [-10.8272,  -8.6687, -14.2134,  ..., -12.5902,  -6.6770,  -8.9679],\n",
      "          [-17.5238, -18.0341, -23.8566,  ..., -20.1754, -14.4655, -14.4317],\n",
      "          ...,\n",
      "          [-53.8049, -51.9219, -53.2467,  ..., -50.7193, -51.2442, -53.0188],\n",
      "          [-54.4185, -52.8468, -53.4759,  ..., -52.1240, -51.0827, -54.4927],\n",
      "          [-55.8065, -52.5886, -52.4451,  ..., -53.5472, -51.6183, -53.5764]]],\n",
      "\n",
      "\n",
      "        [[[-10.7324,  -4.6517,  -3.8478,  ...,  -8.2309, -14.8002, -18.0520],\n",
      "          [-11.8236,  -6.3387,  -9.1619,  ..., -12.2978, -17.8332, -16.8948],\n",
      "          [-21.9459, -15.6345, -17.6357,  ..., -23.1039, -19.1691, -19.0841],\n",
      "          ...,\n",
      "          [-53.8330, -49.2684, -48.2273,  ..., -48.3188, -49.0298, -52.3784],\n",
      "          [-53.0411, -49.3866, -48.0516,  ..., -49.6745, -49.0690, -51.8535],\n",
      "          [-53.7364, -49.5175, -48.6195,  ..., -50.3162, -49.5507, -49.6395]]],\n",
      "\n",
      "\n",
      "        [[[ -7.1616,  -0.9457,   0.0000,  ...,  -5.7713,  -8.1283, -18.2104],\n",
      "          [ -7.6271,  -3.1601,  -2.3634,  ...,  -8.6473,  -7.9879, -13.6696],\n",
      "          [-13.9333, -14.6354, -14.1242,  ..., -19.9669, -18.1613, -17.1388],\n",
      "          ...,\n",
      "          [-54.6771, -51.6242, -50.7401,  ..., -50.1866, -50.7028, -51.4649],\n",
      "          [-54.6167, -51.3566, -50.3548,  ..., -51.2736, -51.6761, -52.4059],\n",
      "          [-52.7593, -50.6332, -51.0717,  ..., -49.3423, -51.7091, -53.6027]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -8.3681,  -5.1823,  -7.4577,  ...,  -3.7348,  -2.5485,  -6.6958],\n",
      "          [ -8.0277,  -4.9073,  -4.9623,  ...,  -4.2416,  -4.8608,  -9.5555],\n",
      "          [-13.0840, -13.7098, -12.8687,  ..., -17.7461, -19.1325, -21.0760],\n",
      "          ...,\n",
      "          [-50.0689, -46.2291, -45.4716,  ..., -46.8236, -47.4431, -49.0650],\n",
      "          [-50.4353, -47.2231, -45.5502,  ..., -46.8992, -46.7623, -48.7872],\n",
      "          [-48.1989, -46.7950, -47.2719,  ..., -46.1326, -46.5750, -47.0558]]],\n",
      "\n",
      "\n",
      "        [[[-24.0054, -16.5717, -12.2069,  ..., -10.8894, -11.0717, -14.5653],\n",
      "          [-26.5346, -21.9115, -16.5898,  ..., -15.5828, -16.0140, -14.1760],\n",
      "          [-30.1219, -23.5671, -23.9182,  ..., -19.3224, -19.7878, -16.0493],\n",
      "          ...,\n",
      "          [-55.0039, -50.1655, -47.9797,  ..., -48.1771, -49.0459, -50.6193],\n",
      "          [-50.9413, -48.6363, -49.1542,  ..., -50.7510, -50.4623, -51.4882],\n",
      "          [-51.2350, -50.3329, -50.0501,  ..., -51.2576, -50.9684, -51.8375]]],\n",
      "\n",
      "\n",
      "        [[[ -9.2767,  -5.4631,  -1.6625,  ..., -10.1021,  -7.4068,  -9.1599],\n",
      "          [ -7.2520,  -3.3959,  -2.4361,  ...,  -7.8024,  -6.9836,  -7.6628],\n",
      "          [-12.1627, -14.2867, -15.8049,  ..., -17.6147, -16.5750, -12.0232],\n",
      "          ...,\n",
      "          [-56.9290, -53.3854, -53.6736,  ..., -53.6213, -53.0371, -55.1418],\n",
      "          [-55.0039, -54.3032, -54.7474,  ..., -54.4607, -53.4741, -54.6051],\n",
      "          [-55.0830, -54.0245, -54.1530,  ..., -54.0167, -54.1413, -55.7217]]]]), tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1])]\n",
      "[tensor([[[[ -8.9003,  -5.6950,  -8.4137,  ...,  -7.9397, -14.6901, -13.7975],\n",
      "          [ -7.0621,  -4.2965,  -5.2679,  ...,  -6.8257, -10.7655, -12.5228],\n",
      "          [-12.1692, -14.2089, -16.3282,  ..., -14.7645, -16.9071, -14.4980],\n",
      "          ...,\n",
      "          [-51.3359, -48.0489, -47.7460,  ..., -48.3099, -47.7784, -49.3869],\n",
      "          [-49.6297, -48.2010, -48.3301,  ..., -48.2575, -48.2402, -50.6874],\n",
      "          [-50.8940, -48.3321, -48.8617,  ..., -48.8092, -48.8599, -50.0928]]],\n",
      "\n",
      "\n",
      "        [[[-17.7462, -15.1062, -26.7662,  ...,  -8.3707, -11.2060, -17.8887],\n",
      "          [-19.8870, -15.9270, -17.0375,  ..., -11.2934, -13.8616, -16.8674],\n",
      "          [-27.6479, -24.2454, -21.9514,  ..., -25.1244, -26.2341, -22.6001],\n",
      "          ...,\n",
      "          [-61.9573, -58.3460, -58.4538,  ..., -57.4640, -59.4890, -60.6936],\n",
      "          [-60.5880, -58.2899, -57.2648,  ..., -59.2312, -58.1507, -59.4468],\n",
      "          [-59.8953, -57.4230, -57.5208,  ..., -58.3148, -57.9805, -58.8456]]],\n",
      "\n",
      "\n",
      "        [[[-13.5176, -11.6368,  -8.7873,  ..., -17.7489, -16.9146, -20.3726],\n",
      "          [-16.1134, -14.8937, -12.4694,  ..., -18.9430, -14.6921, -16.7794],\n",
      "          [-22.4209, -19.2131, -22.1324,  ..., -22.3883, -22.1521, -21.7480],\n",
      "          ...,\n",
      "          [-51.0376, -48.7682, -49.6154,  ..., -49.2334, -49.2060, -50.9532],\n",
      "          [-54.0740, -50.1427, -49.8437,  ..., -49.6026, -50.2182, -51.0737],\n",
      "          [-50.7706, -48.5343, -48.9691,  ..., -50.4240, -50.7928, -52.9936]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-15.8294, -11.2537, -10.9465,  ..., -11.9487, -14.0252, -14.7746],\n",
      "          [-17.5562, -16.3954, -18.2899,  ..., -14.2846, -11.2523, -12.0967],\n",
      "          [-25.0954, -28.1919, -22.7930,  ..., -19.2034, -19.1958, -15.9922],\n",
      "          ...,\n",
      "          [-50.6322, -49.0325, -47.4819,  ..., -48.4302, -47.1102, -48.7352],\n",
      "          [-51.8628, -47.9553, -48.7344,  ..., -49.1368, -49.6521, -51.7342],\n",
      "          [-51.8983, -47.6698, -48.2550,  ..., -47.4888, -47.7807, -50.4829]]],\n",
      "\n",
      "\n",
      "        [[[-14.3831, -12.1354, -12.6169,  ..., -15.8074, -16.5729, -17.3791],\n",
      "          [-18.5885, -19.1402, -17.1982,  ..., -10.2863, -16.8677, -18.6861],\n",
      "          [-22.7160, -21.8464, -18.4663,  ..., -16.2206, -17.2931, -20.8829],\n",
      "          ...,\n",
      "          [-53.3006, -49.5118, -47.8410,  ..., -48.6413, -49.1530, -49.6687],\n",
      "          [-51.7591, -49.3027, -49.3969,  ..., -48.9461, -49.3949, -50.4807],\n",
      "          [-51.4795, -50.4085, -50.9016,  ..., -50.5438, -49.8652, -51.7285]]],\n",
      "\n",
      "\n",
      "        [[[-11.6841, -10.6428, -10.8915,  ...,  -1.7235,  -4.8453, -10.9071],\n",
      "          [-13.1581, -10.0602, -10.0689,  ...,  -3.7508,  -5.8531, -10.0624],\n",
      "          [-19.0680, -19.6948, -21.7907,  ..., -19.0947, -19.8550, -18.1728],\n",
      "          ...,\n",
      "          [-56.3883, -55.2090, -55.1556,  ..., -54.6343, -55.5138, -58.5798],\n",
      "          [-57.3524, -55.6003, -55.8850,  ..., -54.4737, -53.9710, -56.3188],\n",
      "          [-56.3898, -54.3298, -55.1854,  ..., -54.6399, -55.4026, -57.7112]]]]), tensor([1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[ -9.1439,  -6.3815,  -8.6553,  ...,  -9.9656, -15.8904, -22.7964],\n",
      "          [-12.4257, -10.7954, -15.2085,  ..., -11.7822, -20.2603, -23.9475],\n",
      "          [-20.7228, -24.3895, -28.4178,  ..., -24.0787, -26.8945, -27.7306],\n",
      "          ...,\n",
      "          [-50.6917, -48.3092, -48.8301,  ..., -50.6481, -49.7191, -51.0505],\n",
      "          [-51.6069, -48.9763, -49.3845,  ..., -50.7629, -50.2760, -51.0789],\n",
      "          [-52.5421, -50.3477, -51.9593,  ..., -49.8749, -50.1946, -52.2247]]],\n",
      "\n",
      "\n",
      "        [[[-12.8183,  -8.8736,  -9.9669,  ...,  -0.9775,  -1.1875,  -3.4887],\n",
      "          [-17.7811, -14.6838, -12.9425,  ...,  -5.8998,  -5.5387,  -6.5439],\n",
      "          [-26.6312, -26.0636, -23.6724,  ..., -25.0167, -22.3263, -16.4586],\n",
      "          ...,\n",
      "          [-58.4294, -54.7695, -54.3107,  ..., -55.4369, -54.4335, -56.1671],\n",
      "          [-59.0020, -54.6001, -54.8849,  ..., -52.7717, -53.4871, -55.4511],\n",
      "          [-58.0232, -54.3704, -54.5316,  ..., -54.1423, -53.6740, -55.1368]]],\n",
      "\n",
      "\n",
      "        [[[-15.6181, -17.4919, -20.0049,  ..., -11.2635, -18.8130, -19.6856],\n",
      "          [-17.4799, -19.6151, -21.3630,  ..., -11.9547, -16.5333, -17.9439],\n",
      "          [-23.0230, -26.7643, -25.9644,  ..., -21.4136, -18.9200, -21.3353],\n",
      "          ...,\n",
      "          [-57.8216, -55.8503, -55.6969,  ..., -53.9801, -54.6264, -56.9200],\n",
      "          [-59.3948, -56.9479, -56.4685,  ..., -53.6779, -54.0244, -55.7368],\n",
      "          [-57.8211, -55.0197, -55.2547,  ..., -55.0715, -54.6728, -57.3392]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-19.3755, -15.8834, -19.4765,  ..., -15.2986, -18.9731, -28.3482],\n",
      "          [-18.2080, -16.1983, -15.6329,  ..., -20.2465, -22.4688, -29.8424],\n",
      "          [-22.2617, -25.5475, -24.1155,  ..., -31.1005, -25.8298, -27.9543],\n",
      "          ...,\n",
      "          [-59.2608, -56.9048, -56.1722,  ..., -54.8316, -56.1192, -58.8295],\n",
      "          [-58.3115, -55.2242, -55.7536,  ..., -55.2191, -55.8394, -58.2460],\n",
      "          [-58.3019, -55.6733, -56.1740,  ..., -56.5903, -55.3230, -55.6876]]],\n",
      "\n",
      "\n",
      "        [[[-20.7064, -12.7469, -10.5713,  ...,  -5.6322, -11.0249, -23.3230],\n",
      "          [-23.0129, -15.8259, -15.6464,  ...,  -9.6322, -13.9740, -25.6630],\n",
      "          [-32.3584, -28.0187, -26.3400,  ..., -21.2980, -21.1598, -23.0218],\n",
      "          ...,\n",
      "          [-58.6716, -54.6895, -55.8372,  ..., -56.8688, -56.7343, -59.0497],\n",
      "          [-58.0728, -55.9267, -56.6812,  ..., -55.3060, -55.7754, -58.9926],\n",
      "          [-57.1548, -55.0041, -56.1730,  ..., -55.2742, -56.0316, -58.6850]]],\n",
      "\n",
      "\n",
      "        [[[-17.7484,  -7.8096,  -5.0597,  ...,  -7.1552, -10.3615, -15.7479],\n",
      "          [-24.1250, -11.6381,  -9.1836,  ..., -10.0575, -14.9263, -20.7033],\n",
      "          [-24.6713, -22.2962, -22.8559,  ..., -17.8255, -21.8843, -28.1199],\n",
      "          ...,\n",
      "          [-52.9812, -49.4930, -49.4893,  ..., -47.8044, -48.4419, -50.2379],\n",
      "          [-51.8783, -48.7094, -48.4333,  ..., -49.4847, -48.6194, -51.0819],\n",
      "          [-51.4531, -49.4110, -49.6053,  ..., -48.9175, -49.1056, -51.0907]]]]), tensor([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0])]\n",
      "[tensor([[[[-17.0427, -14.9856, -19.9267,  ...,  -5.5589,  -7.6223,  -9.4907],\n",
      "          [-18.2477, -14.8280, -17.3509,  ...,  -6.7090, -12.1974, -12.1394],\n",
      "          [-26.8981, -25.3371, -20.1127,  ..., -16.3102, -16.0153, -16.4981],\n",
      "          ...,\n",
      "          [-53.9200, -51.8853, -52.4520,  ..., -53.6749, -51.8540, -53.6749],\n",
      "          [-55.1911, -52.7323, -53.3232,  ..., -54.3976, -54.8286, -56.5963],\n",
      "          [-54.7715, -52.9818, -53.6572,  ..., -53.8595, -53.5804, -54.8806]]],\n",
      "\n",
      "\n",
      "        [[[-10.5205, -12.1467, -11.9641,  ..., -11.1011,  -7.8841, -10.2488],\n",
      "          [-10.7204, -10.2712, -14.8051,  ..., -17.4890, -10.1350,  -9.9657],\n",
      "          [-15.4316, -14.7884, -19.3225,  ..., -20.4244, -19.5974, -16.2358],\n",
      "          ...,\n",
      "          [-48.4588, -47.1349, -46.9040,  ..., -47.7909, -47.2344, -49.7415],\n",
      "          [-50.3802, -47.2370, -45.4467,  ..., -47.3579, -46.4145, -48.9298],\n",
      "          [-51.0459, -48.2725, -48.0139,  ..., -46.4444, -47.2485, -48.7807]]],\n",
      "\n",
      "\n",
      "        [[[-11.1962,  -5.1562,  -3.9529,  ..., -13.7877, -13.9695, -18.9762],\n",
      "          [-11.6165, -10.5394, -10.5728,  ..., -20.3477, -17.0996, -21.1129],\n",
      "          [-17.8774, -21.0547, -26.0836,  ..., -28.4353, -27.5213, -30.6109],\n",
      "          ...,\n",
      "          [-55.0200, -53.2546, -53.1739,  ..., -54.1681, -53.8253, -56.4622],\n",
      "          [-57.6203, -53.9981, -53.5916,  ..., -53.0469, -53.1876, -55.7428],\n",
      "          [-58.0921, -53.5759, -52.9358,  ..., -54.2606, -55.0854, -56.0155]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-13.0929,  -8.1490,  -6.0740,  ...,  -9.0175,  -8.1026, -11.2404],\n",
      "          [-10.8897,  -6.2664,  -5.4600,  ..., -10.1410, -10.2522, -13.9232],\n",
      "          [-16.1681, -14.1593, -16.3334,  ..., -17.0501, -17.4465, -21.9007],\n",
      "          ...,\n",
      "          [-51.3174, -47.6784, -46.9831,  ..., -50.6825, -49.8886, -49.5048],\n",
      "          [-51.6961, -49.0685, -48.9114,  ..., -49.4049, -49.1464, -50.9212],\n",
      "          [-50.2888, -48.5087, -49.5262,  ..., -49.4060, -50.3186, -50.6697]]],\n",
      "\n",
      "\n",
      "        [[[-10.5740,  -6.6337,  -8.5231,  ...,  -8.6571,  -5.7712,  -7.2641],\n",
      "          [-13.8897, -10.3217, -13.4287,  ..., -16.9600, -11.8110,  -9.2367],\n",
      "          [-23.7448, -22.1353, -25.4149,  ..., -25.1986, -20.3145, -14.5135],\n",
      "          ...,\n",
      "          [-56.6444, -52.8006, -52.6621,  ..., -51.8420, -53.6470, -55.4209],\n",
      "          [-55.7708, -51.4955, -51.6007,  ..., -51.9611, -51.7362, -53.4997],\n",
      "          [-55.3219, -52.4044, -52.4623,  ..., -52.5349, -53.7143, -56.9817]]],\n",
      "\n",
      "\n",
      "        [[[ -5.3598,  -3.5870,  -7.7213,  ...,  -2.1239,  -7.6019, -16.7891],\n",
      "          [ -5.8658,  -5.3685,  -7.8181,  ...,  -4.0615,  -8.9067, -14.8545],\n",
      "          [-11.5583, -15.3547, -19.3934,  ..., -16.7265, -17.2696, -18.3079],\n",
      "          ...,\n",
      "          [-47.5734, -45.8095, -45.9924,  ..., -44.0620, -45.6469, -47.2745],\n",
      "          [-48.5098, -45.7572, -45.2733,  ..., -44.6914, -46.3110, -48.8676],\n",
      "          [-49.0852, -46.0152, -45.1482,  ..., -44.7064, -45.7651, -47.9350]]]]), tensor([0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0])]\n",
      "[tensor([[[[-16.5098, -13.6158, -13.7698,  ..., -20.1823, -15.1784, -14.9491],\n",
      "          [-17.1146, -14.5767, -15.2056,  ..., -17.9235, -14.7208, -14.5118],\n",
      "          [-20.5487, -19.4128, -19.8824,  ..., -25.1827, -23.9422, -20.0301],\n",
      "          ...,\n",
      "          [-51.9878, -48.7872, -49.3824,  ..., -49.1425, -48.0484, -49.6893],\n",
      "          [-51.2758, -49.8633, -49.9142,  ..., -50.0475, -49.9551, -51.1813],\n",
      "          [-53.1391, -51.0403, -50.3494,  ..., -51.4081, -50.0263, -50.0482]]],\n",
      "\n",
      "\n",
      "        [[[-10.7208,  -5.1715,  -4.3676,  ..., -10.5834, -11.5595, -16.9046],\n",
      "          [-12.3766,  -8.8231, -10.9925,  ..., -15.4747, -12.9223, -19.2970],\n",
      "          [-18.7908, -21.4462, -20.5267,  ..., -22.6840, -21.4934, -24.3930],\n",
      "          ...,\n",
      "          [-49.9995, -48.0103, -48.4120,  ..., -49.7643, -49.8806, -51.6831],\n",
      "          [-47.4270, -47.3056, -48.4698,  ..., -49.4439, -47.8779, -49.5320],\n",
      "          [-51.3528, -48.1071, -48.6567,  ..., -48.5554, -48.1139, -51.5024]]],\n",
      "\n",
      "\n",
      "        [[[-15.0478, -13.8001, -14.4621,  ..., -15.5620, -12.5570, -13.9192],\n",
      "          [-16.9501, -15.3223, -15.4388,  ..., -23.5943, -17.3096, -17.4727],\n",
      "          [-21.4123, -20.9109, -20.8366,  ..., -28.2529, -30.6608, -29.5175],\n",
      "          ...,\n",
      "          [-51.7909, -49.2375, -49.9399,  ..., -50.1581, -49.0799, -51.5343],\n",
      "          [-50.2857, -49.8086, -50.5261,  ..., -49.6846, -49.2241, -50.3883],\n",
      "          [-55.8301, -51.5755, -50.2552,  ..., -49.5259, -50.5020, -52.1422]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -7.5071,  -3.8854,  -4.2999,  ...,  -9.5368,  -5.0302,  -8.2657],\n",
      "          [ -6.8737,  -3.2673,  -4.4442,  ...,  -7.8864,  -4.6115,  -6.8085],\n",
      "          [-12.2169, -13.6799, -16.4138,  ..., -11.7323,  -9.3301, -12.1456],\n",
      "          ...,\n",
      "          [-53.6855, -49.2084, -48.6956,  ..., -47.9869, -48.6832, -50.5034],\n",
      "          [-52.8633, -50.2232, -48.7245,  ..., -48.7317, -48.8106, -49.9419],\n",
      "          [-51.5715, -49.3451, -48.4451,  ..., -50.2108, -50.0642, -52.4181]]],\n",
      "\n",
      "\n",
      "        [[[-11.8320,  -9.3900, -12.8467,  ...,  -8.0388, -12.1001, -16.2452],\n",
      "          [-14.0154, -11.1234, -13.2705,  ..., -10.9791, -21.3799, -25.7574],\n",
      "          [-21.1259, -20.0579, -16.5633,  ..., -17.7590, -18.4349, -24.7722],\n",
      "          ...,\n",
      "          [-48.7344, -46.6707, -47.3893,  ..., -47.9304, -47.0027, -49.1107],\n",
      "          [-50.8510, -47.1817, -45.4753,  ..., -47.5742, -47.8928, -49.5717],\n",
      "          [-51.1758, -47.2426, -46.3059,  ..., -46.3051, -46.9690, -50.1339]]],\n",
      "\n",
      "\n",
      "        [[[-14.4391,  -9.1209, -13.9443,  ...,   0.0000,  -2.8345, -10.3333],\n",
      "          [-15.8548, -12.0871, -15.2193,  ...,  -4.8612,  -9.4798, -14.0009],\n",
      "          [-24.0867, -24.5031, -22.1925,  ..., -19.7124, -24.7431, -22.2317],\n",
      "          ...,\n",
      "          [-51.8401, -49.6562, -49.8052,  ..., -50.2163, -49.5208, -51.2952],\n",
      "          [-51.6299, -48.7858, -48.9311,  ..., -48.2765, -49.9220, -50.6108],\n",
      "          [-51.8833, -49.2698, -50.0158,  ..., -48.9768, -50.1476, -53.0972]]]]), tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1])]\n",
      "[tensor([[[[-12.9459, -10.7339, -10.5763,  ..., -20.9138, -20.2874, -14.5386],\n",
      "          [-16.2831, -17.0857, -17.3435,  ..., -20.9503, -15.2757, -11.8472],\n",
      "          [-19.1016, -23.3032, -27.8499,  ..., -24.8851, -16.8646, -13.7081],\n",
      "          ...,\n",
      "          [-56.1595, -54.5195, -52.6238,  ..., -53.5836, -51.8603, -54.6450],\n",
      "          [-55.6095, -52.5743, -51.9246,  ..., -53.2095, -52.6188, -55.5935],\n",
      "          [-56.4487, -52.2921, -53.7554,  ..., -52.4024, -51.2213, -51.8921]]],\n",
      "\n",
      "\n",
      "        [[[-18.0209, -11.7379, -10.2200,  ...,  -4.2470,   0.0000,  -3.4826],\n",
      "          [-23.1801, -15.6190, -14.9000,  ...,  -7.3462,  -2.9329,  -4.3133],\n",
      "          [-33.2646, -23.7604, -21.9551,  ..., -20.5872, -16.4038, -11.7417],\n",
      "          ...,\n",
      "          [-56.7785, -52.5463, -51.7002,  ..., -53.8370, -52.9018, -53.2154],\n",
      "          [-56.1939, -54.8628, -54.4604,  ..., -52.7387, -52.6176, -52.2500],\n",
      "          [-54.6674, -52.6126, -53.7326,  ..., -52.3661, -52.9609, -54.0416]]],\n",
      "\n",
      "\n",
      "        [[[-18.3027, -15.4641,  -9.5809,  ..., -11.0653, -12.1972, -19.5427],\n",
      "          [-19.2963, -18.3188, -13.0030,  ..., -15.4253, -15.2683, -24.6046],\n",
      "          [-20.2961, -20.8818, -20.8779,  ..., -24.6880, -25.6998, -30.8342],\n",
      "          ...,\n",
      "          [-48.0807, -45.6483, -45.3463,  ..., -47.3056, -47.6561, -47.9204],\n",
      "          [-47.8975, -44.5405, -43.8399,  ..., -47.5982, -47.1712, -48.2320],\n",
      "          [-48.5111, -45.4942, -44.9434,  ..., -46.1690, -44.6446, -46.2503]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.3386,  -8.1295,  -9.4182,  ...,  -3.5372,  -6.9823, -12.3089],\n",
      "          [-14.2323, -10.6343, -11.0549,  ...,  -6.1847, -12.1914, -14.8063],\n",
      "          [-23.5425, -23.3458, -19.9860,  ..., -17.2117, -20.5783, -20.5997],\n",
      "          ...,\n",
      "          [-49.5552, -46.5474, -46.3638,  ..., -47.1317, -46.2887, -47.9489],\n",
      "          [-50.2128, -46.6963, -46.5049,  ..., -46.7846, -48.3372, -50.4113],\n",
      "          [-49.7589, -48.1748, -49.3193,  ..., -48.4582, -49.2449, -50.2379]]],\n",
      "\n",
      "\n",
      "        [[[-11.0291,  -5.0556,  -7.3908,  ...,  -5.4382,  -8.5189, -14.6596],\n",
      "          [-11.8465,  -8.6335,  -9.1775,  ..., -10.5531, -13.6293, -21.6308],\n",
      "          [-17.3718, -17.8354, -16.5804,  ..., -19.8602, -21.2210, -25.3905],\n",
      "          ...,\n",
      "          [-50.1780, -48.1141, -49.1871,  ..., -47.1003, -47.3462, -50.3536],\n",
      "          [-49.9736, -48.0062, -49.3661,  ..., -47.9526, -48.1708, -51.8342],\n",
      "          [-52.2147, -48.4390, -48.6952,  ..., -48.9274, -48.7183, -51.3020]]],\n",
      "\n",
      "\n",
      "        [[[-12.6869,  -6.1255,  -5.5152,  ...,  -5.7381,  -3.4278,  -6.2596],\n",
      "          [-13.6166, -11.1559,  -8.7832,  ..., -11.3911,  -7.8598, -11.0899],\n",
      "          [-18.3389, -18.4038, -21.8603,  ..., -21.9691, -21.5309, -24.5514],\n",
      "          ...,\n",
      "          [-53.4539, -51.1406, -50.9320,  ..., -51.7844, -51.3928, -51.3885],\n",
      "          [-55.7355, -52.1812, -51.9173,  ..., -51.1953, -51.1556, -51.4325],\n",
      "          [-55.7891, -53.1854, -52.2578,  ..., -50.8765, -51.2024, -53.7012]]]]), tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])]\n",
      "[tensor([[[[ -5.1685,  -3.5431,  -6.1680,  ...,  -0.0917,  -0.7231,  -5.5518],\n",
      "          [ -7.6702,  -7.7361, -11.8104,  ...,  -6.2485,  -5.7362,  -8.8374],\n",
      "          [-13.8354, -15.0222, -20.2270,  ..., -22.6714, -23.3922, -22.0796],\n",
      "          ...,\n",
      "          [-55.2056, -52.8139, -52.3971,  ..., -52.7700, -53.1397, -54.7791],\n",
      "          [-55.8079, -52.0751, -50.6632,  ..., -52.3088, -52.0392, -54.6527],\n",
      "          [-56.1405, -53.2581, -52.3736,  ..., -53.7071, -53.6263, -53.4978]]],\n",
      "\n",
      "\n",
      "        [[[-10.6643,  -7.3887,  -8.8921,  ...,  -8.2710,  -7.0803, -11.5905],\n",
      "          [-10.7584,  -8.7772,  -8.7842,  ..., -12.7270,  -8.9024, -12.9026],\n",
      "          [-16.5672, -21.2453, -18.7724,  ..., -17.3295, -18.4741, -22.8398],\n",
      "          ...,\n",
      "          [-53.2704, -50.3550, -51.5633,  ..., -50.3345, -51.2440, -53.5748],\n",
      "          [-51.9836, -50.0980, -50.9822,  ..., -50.7501, -52.0841, -52.2893],\n",
      "          [-52.8884, -51.2494, -51.7744,  ..., -50.7838, -51.9005, -53.4901]]],\n",
      "\n",
      "\n",
      "        [[[-12.4899, -12.6390, -18.3412,  ..., -11.5354, -11.1510, -11.5272],\n",
      "          [-10.6332, -11.0089, -16.0313,  ..., -11.6983, -10.5265, -11.8239],\n",
      "          [-14.1030, -14.8124, -21.2318,  ..., -15.8251, -16.3481, -18.2146],\n",
      "          ...,\n",
      "          [-52.3472, -50.5478, -50.0083,  ..., -51.3235, -50.5600, -52.0638],\n",
      "          [-54.1867, -51.5227, -51.9898,  ..., -53.0278, -52.5103, -52.9369],\n",
      "          [-53.4603, -51.6214, -52.9473,  ..., -52.4769, -51.4700, -52.2444]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-18.7897, -15.7237, -19.1669,  ...,  -2.5864,  -3.4854,  -8.3363],\n",
      "          [-17.5980, -15.9615, -24.4952,  ..., -10.9740,  -9.5510, -10.4342],\n",
      "          [-23.2868, -20.0114, -26.7704,  ..., -31.7439, -22.8537, -20.2259],\n",
      "          ...,\n",
      "          [-55.7549, -51.1689, -50.3053,  ..., -50.8378, -50.6562, -53.0983],\n",
      "          [-54.3370, -50.7302, -50.5244,  ..., -51.5256, -51.2671, -51.4067],\n",
      "          [-55.3706, -51.2870, -50.2594,  ..., -52.2861, -51.2770, -52.1787]]],\n",
      "\n",
      "\n",
      "        [[[-19.4503, -11.6368,  -6.7816,  ..., -12.0678,  -8.9254,  -9.2904],\n",
      "          [-14.8976,  -8.0731,  -6.4716,  ..., -15.7901, -11.9013, -12.1636],\n",
      "          [-17.3328, -15.8321, -17.5205,  ..., -22.3996, -16.8316, -18.6882],\n",
      "          ...,\n",
      "          [-55.9450, -52.5807, -53.6123,  ..., -52.4918, -53.1196, -56.1903],\n",
      "          [-56.1926, -52.4201, -52.3664,  ..., -52.7488, -52.3760, -53.7092],\n",
      "          [-56.5493, -52.8165, -52.9666,  ..., -53.1975, -52.5657, -54.5543]]],\n",
      "\n",
      "\n",
      "        [[[ -8.2463,  -1.5153,  -0.3417,  ...,  -0.0767,  -0.2532,  -5.6081],\n",
      "          [ -7.9649,  -2.4761,  -3.8179,  ...,  -1.0361,  -2.4826,  -7.4762],\n",
      "          [-15.5043, -13.3370, -16.3814,  ..., -13.8375, -16.0605, -16.8942],\n",
      "          ...,\n",
      "          [-52.0576, -47.6453, -47.5434,  ..., -50.1476, -49.5708, -50.5257],\n",
      "          [-52.1544, -48.6912, -47.6840,  ..., -50.1298, -51.6062, -52.9518],\n",
      "          [-53.5745, -50.4228, -49.4765,  ..., -49.7564, -49.9691, -51.0382]]]]), tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0])]\n",
      "[tensor([[[[-11.7756,  -7.0410,  -4.9498,  ...,  -9.3433,  -6.6749,  -8.1286],\n",
      "          [-16.8265, -12.4159, -10.2116,  ...,  -8.9402,  -7.7014,  -9.2996],\n",
      "          [-22.2347, -21.5294, -20.6842,  ..., -16.5950, -21.3083, -17.7230],\n",
      "          ...,\n",
      "          [-52.1803, -50.2204, -50.7931,  ..., -50.7613, -50.6474, -51.4796],\n",
      "          [-53.6427, -51.5287, -50.7069,  ..., -49.1984, -50.5256, -53.1105],\n",
      "          [-53.3888, -50.0538, -50.9244,  ..., -50.5473, -49.6493, -52.5006]]],\n",
      "\n",
      "\n",
      "        [[[-16.8677, -10.9837, -11.5365,  ..., -17.7769, -14.8101, -12.9792],\n",
      "          [-16.3892, -12.8971, -14.8058,  ..., -26.5489, -17.9043, -13.9401],\n",
      "          [-21.4324, -22.9268, -26.4240,  ..., -31.6903, -24.6109, -19.1836],\n",
      "          ...,\n",
      "          [-55.8700, -52.3636, -51.3638,  ..., -50.5106, -52.0963, -54.2482],\n",
      "          [-56.1806, -52.7200, -51.4017,  ..., -50.6342, -51.1227, -53.4283],\n",
      "          [-57.3869, -54.4889, -53.0539,  ..., -54.0687, -52.3150, -53.6756]]],\n",
      "\n",
      "\n",
      "        [[[-11.7163,  -4.6254,  -3.2696,  ..., -16.9017, -12.0346, -14.7881],\n",
      "          [-12.1810,  -7.0967,  -6.9876,  ..., -15.8202, -15.7874, -15.3310],\n",
      "          [-20.1109, -21.1059, -22.1745,  ..., -18.4897, -20.9831, -20.7972],\n",
      "          ...,\n",
      "          [-50.0040, -47.9352, -48.0505,  ..., -48.1633, -48.3408, -50.5797],\n",
      "          [-52.1636, -49.2911, -48.9361,  ..., -48.9829, -48.4587, -51.9963],\n",
      "          [-53.8949, -50.1011, -49.6775,  ..., -49.2414, -48.3503, -52.0036]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -8.0873,  -7.3582,  -7.8443,  ..., -12.2081, -11.0819,  -8.1737],\n",
      "          [-10.2855, -11.8433, -10.3012,  ...,  -9.5623,  -9.5996,  -8.4761],\n",
      "          [-16.7114, -16.3081, -19.1141,  ..., -15.3856, -15.3966, -14.3635],\n",
      "          ...,\n",
      "          [-52.9925, -51.6669, -51.2964,  ..., -47.6690, -50.3343, -54.7010],\n",
      "          [-53.0450, -50.2613, -51.2696,  ..., -49.3092, -50.2960, -51.7941],\n",
      "          [-51.0952, -48.8961, -50.2779,  ..., -48.1650, -49.5840, -52.3887]]],\n",
      "\n",
      "\n",
      "        [[[-11.7221,  -7.5009,  -4.9032,  ...,  -3.8887,  -2.3518,  -5.2582],\n",
      "          [-12.1687,  -6.4206,  -4.1923,  ...,  -3.6549,  -2.2777,  -4.3293],\n",
      "          [-19.7003, -17.7530, -17.0349,  ..., -15.9735, -14.7695, -11.0209],\n",
      "          ...,\n",
      "          [-55.3763, -53.5250, -53.1544,  ..., -53.0976, -53.6414, -54.5680],\n",
      "          [-57.2011, -54.6884, -53.9950,  ..., -53.2046, -54.7418, -55.1734],\n",
      "          [-54.8278, -52.9933, -53.7695,  ..., -55.1222, -55.4178, -56.0121]]],\n",
      "\n",
      "\n",
      "        [[[-32.0508, -18.6434, -15.1491,  ..., -23.5368, -24.9932, -32.0979],\n",
      "          [-31.0583, -20.0940, -18.5767,  ..., -30.2197, -28.5712, -33.5006],\n",
      "          [-35.3113, -28.8498, -30.7482,  ..., -34.2117, -27.9173, -28.0230],\n",
      "          ...,\n",
      "          [-58.8011, -56.6923, -58.5047,  ..., -56.8365, -55.2544, -56.6119],\n",
      "          [-59.9491, -56.5991, -56.6075,  ..., -57.2557, -57.4822, -59.0407],\n",
      "          [-60.0381, -57.1882, -55.2488,  ..., -54.3049, -55.9977, -60.8532]]]]), tensor([0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1])]\n",
      "[tensor([[[[-13.8820, -13.2763, -12.7538,  ...,  -5.6196,  -4.1067,  -8.6514],\n",
      "          [-15.5819, -19.0227, -19.7076,  ...,  -8.1158,  -7.6211, -10.1307],\n",
      "          [-18.5374, -20.9645, -31.7378,  ..., -14.6175, -18.0286, -17.5111],\n",
      "          ...,\n",
      "          [-51.7487, -49.4922, -50.8934,  ..., -48.3644, -49.7760, -52.1333],\n",
      "          [-51.9308, -50.1141, -51.3312,  ..., -50.5186, -50.3585, -52.3874],\n",
      "          [-53.7617, -50.5438, -50.3975,  ..., -50.3885, -49.3604, -51.6796]]],\n",
      "\n",
      "\n",
      "        [[[ -3.6491,  -0.1169,  -1.2708,  ..., -15.0683, -18.6120, -16.5309],\n",
      "          [ -7.5189,  -4.7812,  -6.0383,  ..., -12.9051, -12.8131, -14.1332],\n",
      "          [-17.1251, -19.8379, -17.7177,  ..., -18.6443, -15.8214, -17.1822],\n",
      "          ...,\n",
      "          [-53.1104, -50.6421, -50.9671,  ..., -49.0212, -50.9348, -53.4743],\n",
      "          [-54.4481, -52.0334, -51.3920,  ..., -50.2045, -51.1214, -52.6923],\n",
      "          [-53.0755, -51.1130, -49.9918,  ..., -50.5614, -50.6246, -53.7614]]],\n",
      "\n",
      "\n",
      "        [[[ -9.7955,  -5.9862,  -3.8906,  ...,  -1.4620,  -6.8214, -12.6527],\n",
      "          [ -8.9254,  -3.9711,  -3.1762,  ...,  -1.2694,  -3.6564,  -9.0598],\n",
      "          [-14.6580, -14.2811, -15.4592,  ..., -13.5096, -13.4330, -13.1754],\n",
      "          ...,\n",
      "          [-55.6674, -53.4809, -53.3736,  ..., -53.4829, -54.8861, -55.5131],\n",
      "          [-56.9255, -55.2635, -54.5886,  ..., -53.6918, -53.9781, -54.3855],\n",
      "          [-56.1894, -53.2439, -53.3132,  ..., -54.0230, -53.9033, -54.7176]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -9.3630,  -8.0156, -10.7116,  ..., -15.6980, -18.4390, -22.9805],\n",
      "          [-11.0363, -10.8332, -16.3648,  ..., -12.0238, -11.7764, -16.9739],\n",
      "          [-17.6310, -19.5291, -27.1900,  ..., -18.5102, -14.0359, -19.7002],\n",
      "          ...,\n",
      "          [-56.1942, -53.0955, -53.3711,  ..., -53.7066, -53.6759, -55.7073],\n",
      "          [-55.1096, -52.2083, -52.4010,  ..., -52.3425, -51.5793, -54.9182],\n",
      "          [-55.2412, -52.8344, -52.3349,  ..., -54.3277, -52.6744, -54.7175]]],\n",
      "\n",
      "\n",
      "        [[[-16.5507, -16.8092, -13.3030,  ..., -11.8545,  -7.5122,  -7.1141],\n",
      "          [-17.8905, -15.7555, -15.3671,  ..., -12.9508,  -8.6334,  -8.8057],\n",
      "          [-22.0580, -20.2114, -21.9231,  ..., -21.1280, -17.4335, -16.1876],\n",
      "          ...,\n",
      "          [-51.2254, -49.3412, -48.4575,  ..., -48.8502, -49.8611, -52.1791],\n",
      "          [-51.9451, -48.5081, -48.4278,  ..., -48.6097, -48.3876, -50.1398],\n",
      "          [-52.1920, -49.4794, -48.2586,  ..., -48.9832, -49.5116, -51.7586]]],\n",
      "\n",
      "\n",
      "        [[[-12.6704, -10.0989, -15.7285,  ...,  -1.1067,  -4.9090, -11.6635],\n",
      "          [-17.0735, -12.7654, -14.1774,  ...,  -4.9070,  -9.1263, -17.1113],\n",
      "          [-24.4590, -19.2597, -19.7641,  ..., -18.5482, -19.4238, -18.5840],\n",
      "          ...,\n",
      "          [-61.6435, -58.9187, -57.5728,  ..., -59.3153, -58.2450, -59.3043],\n",
      "          [-60.0850, -57.6033, -56.7001,  ..., -58.3688, -58.7643, -59.3651],\n",
      "          [-62.3474, -59.6540, -58.1206,  ..., -57.3825, -57.4624, -59.3069]]]]), tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0])]\n",
      "[tensor([[[[ -7.6809,  -1.3894,  -6.1454,  ...,  -3.2551,  -6.2737, -16.9419],\n",
      "          [ -8.9156,  -3.4992,  -4.9761,  ...,  -5.3517,  -9.1741, -21.1846],\n",
      "          [-18.6063, -13.1490, -12.8090,  ..., -17.3216, -20.5329, -24.9092],\n",
      "          ...,\n",
      "          [-46.4100, -42.4945, -41.8615,  ..., -41.1409, -42.9757, -43.2790],\n",
      "          [-46.7894, -42.9631, -42.8739,  ..., -42.9658, -42.4366, -46.0061],\n",
      "          [-46.6880, -43.2702, -43.5808,  ..., -42.4506, -41.8991, -46.7900]]],\n",
      "\n",
      "\n",
      "        [[[-10.9027,  -5.9879,  -4.8815,  ..., -12.9866, -12.6573, -23.0787],\n",
      "          [-11.0216, -12.6848, -10.1498,  ..., -14.9163, -13.8779, -19.4198],\n",
      "          [-14.9135, -17.6198, -21.9165,  ..., -25.8100, -23.9186, -22.0997],\n",
      "          ...,\n",
      "          [-54.8032, -52.6899, -51.4362,  ..., -49.7228, -49.5046, -52.7644],\n",
      "          [-54.9945, -53.0867, -51.7927,  ..., -52.5484, -52.0616, -53.3008],\n",
      "          [-52.5169, -51.2426, -52.4969,  ..., -52.0333, -51.2828, -52.8398]]],\n",
      "\n",
      "\n",
      "        [[[-15.9130,  -9.9528,  -7.5890,  ..., -11.2977, -10.1811, -12.3607],\n",
      "          [-21.2572, -14.8245, -11.5313,  ..., -16.5643, -16.8365, -18.4382],\n",
      "          [-33.1820, -24.2761, -21.9110,  ..., -27.6454, -28.7181, -27.4541],\n",
      "          ...,\n",
      "          [-50.6144, -49.4790, -49.2020,  ..., -49.9200, -50.9647, -52.2441],\n",
      "          [-52.9786, -50.4453, -50.5858,  ..., -49.9498, -49.8033, -51.3987],\n",
      "          [-53.1406, -51.3434, -51.0862,  ..., -49.2642, -49.5327, -49.3084]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -6.2205,  -3.8830,  -4.9260,  ...,  -3.4583,  -2.2113,  -4.2974],\n",
      "          [ -6.9878,  -3.6763,  -4.0112,  ...,  -3.6516,  -2.7743,  -4.7081],\n",
      "          [-14.9627, -15.9165, -17.0534,  ..., -17.2712, -15.9078, -12.9416],\n",
      "          ...,\n",
      "          [-55.6110, -51.7466, -50.3878,  ..., -52.5192, -50.9247, -53.7009],\n",
      "          [-53.5899, -49.8057, -50.3230,  ..., -52.8653, -52.6432, -55.3551],\n",
      "          [-55.4416, -52.3089, -51.4771,  ..., -51.5620, -51.0621, -52.7299]]],\n",
      "\n",
      "\n",
      "        [[[-18.3339,  -9.2998,  -4.6474,  ..., -12.3196, -14.5386, -20.0846],\n",
      "          [-20.7360, -15.5852,  -7.0846,  ..., -14.6952, -17.1643, -24.0331],\n",
      "          [-26.5389, -24.6012, -16.0612,  ..., -22.2092, -19.4099, -23.9425],\n",
      "          ...,\n",
      "          [-51.2855, -47.6523, -48.5198,  ..., -48.6568, -48.5462, -50.3284],\n",
      "          [-52.5481, -49.4531, -48.6133,  ..., -48.4802, -48.6068, -50.3791],\n",
      "          [-52.2420, -49.7171, -48.2370,  ..., -49.4797, -50.1228, -51.8326]]],\n",
      "\n",
      "\n",
      "        [[[-12.6616,  -8.2074,  -9.9863,  ...,  -9.5144, -17.3313, -22.6666],\n",
      "          [-15.6575, -12.6969, -15.0423,  ..., -11.6336, -14.0662, -18.8411],\n",
      "          [-19.4713, -17.0566, -17.6623,  ..., -18.6267, -19.1972, -20.3666],\n",
      "          ...,\n",
      "          [-50.4674, -48.8755, -48.1325,  ..., -48.3828, -48.9122, -51.1367],\n",
      "          [-51.4188, -49.2578, -49.7904,  ..., -48.0029, -47.9695, -50.3255],\n",
      "          [-52.1345, -49.0089, -48.0940,  ..., -48.2453, -48.6368, -51.7287]]]]), tensor([0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0])]\n",
      "[tensor([[[[-12.3534,  -8.1414,  -7.3962,  ...,  -9.6710, -10.2073, -18.5057],\n",
      "          [-15.8491, -12.5674, -10.7024,  ..., -13.2207, -11.3987, -18.4529],\n",
      "          [-24.6950, -25.3183, -25.8794,  ..., -25.2772, -20.0603, -21.6492],\n",
      "          ...,\n",
      "          [-58.5614, -54.2405, -53.9698,  ..., -55.7635, -55.6912, -56.3000],\n",
      "          [-57.0635, -54.4432, -55.9435,  ..., -54.1819, -54.7409, -55.6478],\n",
      "          [-57.2229, -55.7335, -56.3952,  ..., -56.5256, -54.9140, -55.9728]]],\n",
      "\n",
      "\n",
      "        [[[ -4.0662,  -0.3494,   0.0000,  ...,  -4.6714,  -3.9676,  -8.6064],\n",
      "          [-10.3888,  -7.2953,  -5.8475,  ...,  -9.4470,  -8.2664, -10.5236],\n",
      "          [-17.5188, -18.0142, -23.6312,  ..., -20.8997, -20.2381, -17.0905],\n",
      "          ...,\n",
      "          [-54.4361, -50.9694, -49.5850,  ..., -50.9147, -48.4651, -49.2708],\n",
      "          [-53.5730, -49.8567, -50.6208,  ..., -51.8278, -50.4198, -52.0098],\n",
      "          [-53.8774, -52.0039, -51.2027,  ..., -49.0434, -48.4871, -52.2826]]],\n",
      "\n",
      "\n",
      "        [[[ -6.0855,  -4.9794,  -8.9611,  ...,  -4.5734,  -8.1216, -14.2574],\n",
      "          [ -8.3703,  -7.9510, -12.9993,  ...,  -3.3616,  -4.6402, -10.8244],\n",
      "          [-15.2722, -17.3643, -18.1749,  ..., -13.3375, -12.6844, -15.5775],\n",
      "          ...,\n",
      "          [-53.7831, -50.6899, -50.5273,  ..., -49.9324, -49.5276, -51.8852],\n",
      "          [-54.1276, -53.2184, -51.3571,  ..., -50.0235, -49.4541, -51.1497],\n",
      "          [-52.8796, -50.6453, -50.6585,  ..., -50.6192, -50.4637, -52.1600]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.5110,  -7.9269,  -7.1359,  ...,  -6.5687,  -8.4930, -13.5501],\n",
      "          [-16.0248, -13.7008, -10.5023,  ...,  -9.8067, -12.3579, -14.6271],\n",
      "          [-23.0445, -20.5140, -20.6409,  ..., -22.6591, -21.4507, -22.0410],\n",
      "          ...,\n",
      "          [-54.8558, -53.1715, -52.6942,  ..., -55.3365, -54.3472, -55.8967],\n",
      "          [-55.5346, -53.1642, -52.5521,  ..., -53.4395, -53.8366, -55.6236],\n",
      "          [-56.6218, -53.3334, -55.0011,  ..., -53.3813, -52.2190, -54.2354]]],\n",
      "\n",
      "\n",
      "        [[[-21.5801, -15.6315, -14.7686,  ..., -19.2304, -22.4431, -26.7380],\n",
      "          [-26.2056, -20.6170, -16.6030,  ..., -16.2064, -18.8988, -23.0298],\n",
      "          [-33.2804, -28.7255, -21.4495,  ..., -24.0527, -27.0809, -27.6899],\n",
      "          ...,\n",
      "          [-55.4699, -52.1332, -50.2111,  ..., -51.3910, -51.0190, -54.0519],\n",
      "          [-54.2748, -50.5112, -50.0293,  ..., -52.0322, -52.3634, -54.5737],\n",
      "          [-53.5809, -51.2456, -51.6310,  ..., -51.4344, -51.5829, -53.4043]]],\n",
      "\n",
      "\n",
      "        [[[ -9.9556,  -8.0223, -15.5049,  ...,  -5.8669,  -7.9880, -15.8333],\n",
      "          [ -7.7237,  -6.1376, -10.2059,  ...,  -5.8948, -10.3746, -19.1705],\n",
      "          [-11.4615, -14.8107, -14.7004,  ..., -17.7533, -22.1156, -32.2179],\n",
      "          ...,\n",
      "          [-51.2957, -49.0700, -49.1583,  ..., -48.1738, -49.3872, -52.2161],\n",
      "          [-50.7348, -48.1175, -49.4220,  ..., -47.8958, -48.5351, -49.4556],\n",
      "          [-50.5864, -48.8926, -49.5004,  ..., -48.6794, -49.1842, -52.3914]]]]), tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0])]\n",
      "[tensor([[[[-17.3370, -13.6840, -18.9090,  ...,  -6.2777,  -8.6486, -16.0327],\n",
      "          [-22.4095, -18.8803, -17.4200,  ..., -10.2325, -13.0265, -21.1505],\n",
      "          [-28.2006, -22.0807, -20.6433,  ..., -18.2779, -23.1035, -28.7418],\n",
      "          ...,\n",
      "          [-58.2493, -54.7077, -52.7674,  ..., -55.4682, -53.3706, -53.8794],\n",
      "          [-56.9645, -54.1312, -52.3820,  ..., -53.6517, -52.9824, -54.0226],\n",
      "          [-58.1695, -54.5925, -53.9564,  ..., -52.4616, -52.3464, -54.8691]]],\n",
      "\n",
      "\n",
      "        [[[ -8.0931,  -3.0809,  -2.1194,  ...,  -2.4892,  -3.2072,  -5.9954],\n",
      "          [ -8.8219,  -3.6177,  -2.6965,  ...,  -2.7955,  -3.2077,  -5.1771],\n",
      "          [-16.2112, -16.0135, -16.6433,  ..., -16.2770, -15.9546, -12.2362],\n",
      "          ...,\n",
      "          [-54.1955, -53.2327, -54.2320,  ..., -53.0093, -53.6045, -54.3664],\n",
      "          [-55.6548, -53.5421, -54.4195,  ..., -52.1077, -52.6243, -54.1062],\n",
      "          [-58.7440, -54.3559, -54.2793,  ..., -52.4463, -52.1186, -54.6892]]],\n",
      "\n",
      "\n",
      "        [[[ -9.6498,  -6.2075,  -4.5347,  ...,  -3.5316,  -4.4289,  -4.4301],\n",
      "          [ -9.5448,  -5.8848,  -5.0769,  ...,  -2.5754,  -3.3229,  -4.6227],\n",
      "          [-15.3968, -16.7912, -18.0456,  ..., -14.1376, -15.4660, -11.7303],\n",
      "          ...,\n",
      "          [-54.1135, -51.7630, -51.7465,  ..., -51.6635, -52.8606, -52.8051],\n",
      "          [-53.7857, -51.8269, -51.9632,  ..., -53.6480, -53.6472, -54.0929],\n",
      "          [-55.9510, -54.0242, -53.8441,  ..., -52.1160, -53.5992, -55.9835]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-19.3030, -20.0919, -14.3340,  ...,  -1.1654,  -4.4234, -15.1536],\n",
      "          [-17.3505, -16.7345, -13.2978,  ...,  -1.8424,  -3.4892, -11.1512],\n",
      "          [-21.5774, -23.9938, -20.7966,  ..., -10.2834, -12.9977, -13.8153],\n",
      "          ...,\n",
      "          [-53.1820, -51.2893, -52.1281,  ..., -50.9769, -50.3367, -52.9549],\n",
      "          [-55.8379, -51.9040, -52.0206,  ..., -50.9986, -51.2125, -53.2668],\n",
      "          [-55.7550, -52.6171, -52.5296,  ..., -52.2303, -52.8020, -53.9154]]],\n",
      "\n",
      "\n",
      "        [[[-11.1603,  -5.8698,  -5.5590,  ..., -11.9730, -12.3221, -11.9913],\n",
      "          [-12.4443,  -8.4158,  -7.2249,  ..., -15.0613, -12.1208, -13.6823],\n",
      "          [-21.6478, -22.9541, -19.5704,  ..., -17.1054, -19.1276, -21.0368],\n",
      "          ...,\n",
      "          [-47.0859, -46.2030, -46.4313,  ..., -44.2340, -44.1578, -46.9369],\n",
      "          [-48.9116, -46.0197, -45.4827,  ..., -44.7112, -45.0200, -47.0736],\n",
      "          [-50.2629, -46.8827, -46.5767,  ..., -45.6073, -46.9797, -48.5544]]],\n",
      "\n",
      "\n",
      "        [[[ -8.9465,  -4.9386,  -3.4910,  ...,  -8.8267,  -6.6299, -10.4541],\n",
      "          [-11.3466,  -9.8318,  -8.1840,  ..., -11.4609,  -7.0067, -10.0628],\n",
      "          [-18.8256, -24.1063, -22.3295,  ..., -17.7201, -17.6753, -18.2109],\n",
      "          ...,\n",
      "          [-56.3092, -54.5021, -54.6962,  ..., -54.3815, -55.0944, -58.3650],\n",
      "          [-57.5449, -54.3026, -53.5777,  ..., -55.1495, -55.4923, -57.5995],\n",
      "          [-56.4856, -56.0001, -56.5582,  ..., -55.7848, -55.2925, -56.0462]]]]), tensor([1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "        0])]\n",
      "[tensor([[[[-1.3163e+01, -1.3713e+01, -5.7044e+00,  ..., -1.2634e+01,\n",
      "           -1.5390e+01, -1.5345e+01],\n",
      "          [-1.2363e+01, -1.0146e+01, -7.4118e+00,  ..., -1.5231e+01,\n",
      "           -2.1727e+01, -1.8272e+01],\n",
      "          [-1.7476e+01, -1.6215e+01, -1.7197e+01,  ..., -2.2400e+01,\n",
      "           -2.5497e+01, -2.2533e+01],\n",
      "          ...,\n",
      "          [-5.1182e+01, -4.7666e+01, -4.9066e+01,  ..., -4.9475e+01,\n",
      "           -4.9563e+01, -5.2183e+01],\n",
      "          [-5.2512e+01, -5.0168e+01, -5.0191e+01,  ..., -5.0816e+01,\n",
      "           -5.0405e+01, -5.3730e+01],\n",
      "          [-5.1582e+01, -5.0124e+01, -5.0477e+01,  ..., -4.9791e+01,\n",
      "           -4.8661e+01, -5.0672e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8231e+01, -1.5682e+01, -1.6320e+01,  ..., -1.0946e+01,\n",
      "           -1.6421e+01, -2.0916e+01],\n",
      "          [-2.1584e+01, -2.1924e+01, -1.9308e+01,  ..., -1.6133e+01,\n",
      "           -2.4725e+01, -2.7363e+01],\n",
      "          [-2.5565e+01, -2.4838e+01, -2.4402e+01,  ..., -2.5382e+01,\n",
      "           -2.8689e+01, -3.0411e+01],\n",
      "          ...,\n",
      "          [-5.5260e+01, -5.1811e+01, -5.1724e+01,  ..., -5.4572e+01,\n",
      "           -5.2932e+01, -5.4526e+01],\n",
      "          [-5.2874e+01, -5.1235e+01, -5.1454e+01,  ..., -5.2265e+01,\n",
      "           -5.3131e+01, -5.6713e+01],\n",
      "          [-5.5489e+01, -5.3212e+01, -5.2562e+01,  ..., -5.1594e+01,\n",
      "           -5.2086e+01, -5.4104e+01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1001e+01, -1.1171e+01, -5.3095e+00,  ..., -1.7959e+00,\n",
      "           -8.4892e-01, -4.4087e+00],\n",
      "          [-1.6136e+01, -8.5612e+00, -6.8571e+00,  ..., -4.9754e+00,\n",
      "           -1.9684e+00, -5.6396e+00],\n",
      "          [-1.9678e+01, -1.6660e+01, -1.9172e+01,  ..., -1.8701e+01,\n",
      "           -1.3089e+01, -1.4169e+01],\n",
      "          ...,\n",
      "          [-5.3229e+01, -5.2300e+01, -5.2039e+01,  ..., -5.1505e+01,\n",
      "           -5.0635e+01, -5.2131e+01],\n",
      "          [-5.2583e+01, -5.1240e+01, -5.1056e+01,  ..., -5.1894e+01,\n",
      "           -5.0664e+01, -5.1814e+01],\n",
      "          [-5.2456e+01, -5.0066e+01, -5.1281e+01,  ..., -5.1113e+01,\n",
      "           -5.1398e+01, -5.3474e+01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.7889e+00, -5.3173e-02,  0.0000e+00,  ..., -1.3146e+01,\n",
      "           -1.3671e+01, -1.9899e+01],\n",
      "          [-9.5718e+00, -9.7293e+00, -8.9567e+00,  ..., -1.0821e+01,\n",
      "           -1.3538e+01, -2.3663e+01],\n",
      "          [-1.7641e+01, -1.7799e+01, -2.0182e+01,  ..., -1.7725e+01,\n",
      "           -2.0284e+01, -2.8764e+01],\n",
      "          ...,\n",
      "          [-4.6298e+01, -4.3867e+01, -4.4462e+01,  ..., -4.2813e+01,\n",
      "           -4.3264e+01, -4.6480e+01],\n",
      "          [-4.7597e+01, -4.4798e+01, -4.6027e+01,  ..., -4.4467e+01,\n",
      "           -4.4975e+01, -4.6983e+01],\n",
      "          [-4.6886e+01, -4.2917e+01, -4.3735e+01,  ..., -4.4047e+01,\n",
      "           -4.4016e+01, -4.7508e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9714e+01, -1.4077e+01, -1.0484e+01,  ..., -9.4866e+00,\n",
      "           -1.0080e+01, -1.4313e+01],\n",
      "          [-2.1948e+01, -1.4893e+01, -1.1055e+01,  ..., -1.3739e+01,\n",
      "           -1.2502e+01, -1.8532e+01],\n",
      "          [-2.1884e+01, -2.0928e+01, -1.5884e+01,  ..., -2.1130e+01,\n",
      "           -1.9600e+01, -2.5277e+01],\n",
      "          ...,\n",
      "          [-5.3528e+01, -5.1130e+01, -5.1114e+01,  ..., -4.9709e+01,\n",
      "           -5.0251e+01, -5.3770e+01],\n",
      "          [-5.5577e+01, -5.1963e+01, -5.0338e+01,  ..., -4.9454e+01,\n",
      "           -5.0415e+01, -5.4143e+01],\n",
      "          [-5.5766e+01, -5.1828e+01, -5.1872e+01,  ..., -5.2364e+01,\n",
      "           -5.4275e+01, -5.4615e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0949e+01, -8.2982e+00, -9.4104e+00,  ..., -8.3833e+00,\n",
      "           -1.0680e+01, -1.7655e+01],\n",
      "          [-1.4225e+01, -1.3354e+01, -1.2044e+01,  ..., -1.1007e+01,\n",
      "           -1.4488e+01, -2.0791e+01],\n",
      "          [-2.1753e+01, -2.3312e+01, -2.4889e+01,  ..., -2.6160e+01,\n",
      "           -2.6580e+01, -3.0275e+01],\n",
      "          ...,\n",
      "          [-5.5445e+01, -5.1929e+01, -5.1407e+01,  ..., -5.1096e+01,\n",
      "           -5.0680e+01, -5.1394e+01],\n",
      "          [-5.6412e+01, -5.3327e+01, -5.2589e+01,  ..., -5.1193e+01,\n",
      "           -5.1988e+01, -5.4647e+01],\n",
      "          [-5.4574e+01, -5.2384e+01, -5.2588e+01,  ..., -5.1052e+01,\n",
      "           -5.2922e+01, -5.4676e+01]]]]), tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0])]\n",
      "[tensor([[[[-10.5757,  -3.9565,  -2.4490,  ..., -14.0344,  -9.8667,  -8.6727],\n",
      "          [-11.0136,  -6.4531,  -5.1831,  ..., -15.6522, -15.9574, -11.5940],\n",
      "          [-16.8577, -18.9107, -17.7916,  ..., -25.2219, -21.9087, -16.2473],\n",
      "          ...,\n",
      "          [-49.0824, -47.5911, -48.4652,  ..., -47.4768, -46.8074, -49.4357],\n",
      "          [-50.9669, -46.5640, -47.5060,  ..., -47.9900, -48.4327, -50.0647],\n",
      "          [-50.7123, -46.7355, -48.1979,  ..., -49.1863, -48.1227, -50.5570]]],\n",
      "\n",
      "\n",
      "        [[[ -5.2120,  -4.1334,  -4.2097,  ...,  -3.1277,  -4.9027,  -9.8809],\n",
      "          [ -5.6036,  -2.7944,  -3.4257,  ...,  -1.8790,  -2.7097,  -7.4012],\n",
      "          [-12.0036, -13.3965, -15.7236,  ..., -13.7522, -12.8860, -12.6874],\n",
      "          ...,\n",
      "          [-55.8372, -55.1540, -55.6561,  ..., -54.8882, -53.8076, -53.9245],\n",
      "          [-57.1962, -55.5976, -54.3309,  ..., -53.6039, -53.9144, -54.7926],\n",
      "          [-57.5957, -53.3097, -53.5559,  ..., -52.3026, -52.0629, -55.3671]]],\n",
      "\n",
      "\n",
      "        [[[-10.9055,  -8.4470,  -7.5049,  ...,  -7.8123,  -8.2866,  -8.0311],\n",
      "          [-11.2018, -12.1854, -13.8080,  ...,  -8.2462,  -6.4423,  -8.3171],\n",
      "          [-16.2980, -16.6967, -25.5274,  ..., -18.9832, -15.7927, -17.1252],\n",
      "          ...,\n",
      "          [-47.6100, -45.3317, -44.1492,  ..., -43.8832, -44.8364, -47.1210],\n",
      "          [-46.9981, -43.2093, -44.3806,  ..., -44.0768, -44.4132, -46.8178],\n",
      "          [-47.9968, -46.1935, -45.9198,  ..., -44.9125, -44.4910, -47.1867]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-21.2481, -13.2318, -11.4360,  ..., -15.2457, -15.5091, -14.6598],\n",
      "          [-17.2403, -12.1630, -12.5750,  ..., -13.9417, -12.8999, -13.9763],\n",
      "          [-21.7108, -21.8343, -25.2063,  ..., -23.5583, -21.1637, -18.0900],\n",
      "          ...,\n",
      "          [-57.6918, -54.9767, -55.4636,  ..., -55.7728, -55.3717, -57.3948],\n",
      "          [-56.7882, -55.5966, -55.6308,  ..., -56.3670, -58.5222, -60.3500],\n",
      "          [-56.5126, -56.1400, -57.2627,  ..., -55.5291, -55.8905, -58.4184]]],\n",
      "\n",
      "\n",
      "        [[[ -8.8491,  -3.4978,  -2.1545,  ...,  -1.4982,  -2.7293,  -5.5224],\n",
      "          [-10.6318,  -8.1585,  -9.1547,  ...,  -6.2677,  -6.8292,  -7.6696],\n",
      "          [-17.5509, -18.6270, -23.1745,  ..., -18.0806, -17.0130, -17.8795],\n",
      "          ...,\n",
      "          [-55.0710, -53.1003, -52.7147,  ..., -54.3135, -54.2095, -54.4146],\n",
      "          [-56.1594, -53.1380, -52.6578,  ..., -54.8881, -52.9731, -53.5724],\n",
      "          [-57.9322, -53.9722, -51.9583,  ..., -54.1590, -52.9439, -53.9007]]],\n",
      "\n",
      "\n",
      "        [[[-16.7492, -12.9213, -15.4992,  ..., -12.9660, -18.1481, -28.5464],\n",
      "          [-16.1996, -16.6247, -23.7688,  ..., -17.7725, -19.2445, -21.1943],\n",
      "          [-21.6059, -22.9027, -25.0755,  ..., -29.1831, -24.5935, -21.2665],\n",
      "          ...,\n",
      "          [-59.5307, -55.9166, -53.8853,  ..., -52.0816, -53.1255, -55.9003],\n",
      "          [-56.8013, -54.8264, -54.2567,  ..., -51.6883, -52.1367, -53.6113],\n",
      "          [-54.8412, -54.4343, -53.4510,  ..., -52.3981, -52.6179, -53.7668]]]]), tensor([0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        1])]\n",
      "[tensor([[[[ -4.5473,  -6.2138,  -8.2985,  ...,  -9.9810,  -7.5181,  -8.0491],\n",
      "          [ -4.6183,  -6.6108,  -7.8492,  ...,  -9.0374, -12.7874, -10.7625],\n",
      "          [ -7.9839,  -7.1070, -11.3627,  ...,  -8.2434, -12.9951, -14.6108],\n",
      "          ...,\n",
      "          [-53.3331, -49.3938, -48.5414,  ..., -50.9687, -50.4058, -52.9669],\n",
      "          [-53.4087, -50.9847, -49.7883,  ..., -51.6659, -51.4237, -50.6602],\n",
      "          [-53.9578, -51.2299, -50.1041,  ..., -48.0495, -49.1640, -52.8801]]],\n",
      "\n",
      "\n",
      "        [[[-29.0853, -25.9006, -20.9731,  ...,  -4.6901,  -3.4193,  -6.6621],\n",
      "          [-31.8727, -30.8039, -26.8090,  ...,  -9.3810,  -8.3873, -10.8362],\n",
      "          [-34.7868, -31.7465, -26.1857,  ..., -22.7420, -23.9624, -23.2167],\n",
      "          ...,\n",
      "          [-56.9019, -54.4784, -53.9953,  ..., -51.4284, -52.9841, -54.8922],\n",
      "          [-55.0232, -53.2602, -52.1002,  ..., -51.9545, -52.1367, -54.1389],\n",
      "          [-57.8918, -54.3597, -53.4134,  ..., -53.0290, -53.1905, -53.7613]]],\n",
      "\n",
      "\n",
      "        [[[-12.3970, -12.6769, -11.6861,  ...,  -8.7590,  -8.7376, -15.7222],\n",
      "          [-13.7573, -12.4105, -11.5589,  ..., -10.1950,  -9.7541, -16.6158],\n",
      "          [-21.0281, -21.3274, -19.8277,  ..., -20.4875, -20.1054, -26.3162],\n",
      "          ...,\n",
      "          [-58.3173, -55.6905, -55.1446,  ..., -56.4763, -55.9175, -57.1586],\n",
      "          [-57.4746, -55.1483, -55.9968,  ..., -54.8604, -56.6697, -57.0417],\n",
      "          [-58.5717, -55.8531, -55.7319,  ..., -56.2001, -56.9702, -58.9404]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-13.5728, -14.9611, -20.2619,  ...,  -5.9169,  -4.7809,  -8.8456],\n",
      "          [-12.5747, -13.8058, -19.0077,  ...,  -9.9999,  -9.2723, -10.9084],\n",
      "          [-15.6077, -18.4661, -21.2161,  ..., -25.4814, -20.5172, -17.7988],\n",
      "          ...,\n",
      "          [-55.8372, -53.0905, -52.1294,  ..., -51.2333, -52.2833, -55.3700],\n",
      "          [-55.6846, -53.1335, -53.1861,  ..., -53.7703, -52.5696, -56.3729],\n",
      "          [-55.9756, -53.4670, -53.9101,  ..., -54.4707, -52.9915, -54.3717]]],\n",
      "\n",
      "\n",
      "        [[[-19.8387, -19.1716, -19.8422,  ..., -13.1208, -14.9518, -16.8472],\n",
      "          [-18.7445, -16.9057, -18.9242,  ..., -11.5250, -16.7029, -16.0062],\n",
      "          [-22.2301, -20.9569, -23.2562,  ..., -18.8113, -18.8529, -21.0423],\n",
      "          ...,\n",
      "          [-51.6377, -48.9324, -49.3959,  ..., -49.5261, -49.0410, -50.5903],\n",
      "          [-52.5942, -48.7486, -48.6424,  ..., -50.0788, -49.2967, -50.9648],\n",
      "          [-52.7858, -49.8041, -49.2364,  ..., -49.7302, -49.9798, -51.4836]]],\n",
      "\n",
      "\n",
      "        [[[-11.1326, -10.5856, -14.7633,  ..., -14.8453, -12.1551, -15.0998],\n",
      "          [-12.4634, -11.9332, -16.5080,  ..., -15.3169, -13.5214, -16.0434],\n",
      "          [-18.5694, -22.5046, -23.3326,  ..., -27.7116, -25.4419, -23.5093],\n",
      "          ...,\n",
      "          [-62.1397, -58.9528, -59.2467,  ..., -59.4400, -59.5343, -62.5773],\n",
      "          [-60.5881, -59.8082, -60.4605,  ..., -61.3787, -59.6531, -60.5962],\n",
      "          [-61.0361, -58.9775, -59.5100,  ..., -59.5443, -59.5720, -60.2610]]]]), tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[-14.5727,  -9.6321,  -9.2103,  ..., -11.8275, -12.9413, -14.7009],\n",
      "          [-14.8433, -10.5649, -10.4794,  ..., -11.4483, -14.5512, -22.0689],\n",
      "          [-19.2211, -19.8117, -23.7096,  ..., -19.3841, -21.9057, -22.2750],\n",
      "          ...,\n",
      "          [-48.0494, -45.3691, -45.0387,  ..., -44.0265, -44.6877, -46.3299],\n",
      "          [-47.9073, -45.6596, -44.2975,  ..., -43.3746, -44.3873, -46.3455],\n",
      "          [-46.8101, -43.1942, -42.5134,  ..., -44.2990, -44.3076, -46.7911]]],\n",
      "\n",
      "\n",
      "        [[[-11.4160,  -7.3010,  -6.6249,  ...,  -7.3409,  -7.4026,  -7.1805],\n",
      "          [-14.4316,  -9.6936,  -9.6551,  ..., -10.6789, -12.1702,  -8.9309],\n",
      "          [-23.1466, -21.0663, -21.5290,  ..., -16.4595, -22.0419, -14.9949],\n",
      "          ...,\n",
      "          [-53.4368, -51.5554, -52.7034,  ..., -53.0157, -51.8218, -53.0765],\n",
      "          [-55.1234, -52.2997, -52.0330,  ..., -52.9236, -53.6745, -53.7170],\n",
      "          [-55.4410, -52.7464, -54.5536,  ..., -52.0832, -51.6558, -53.0386]]],\n",
      "\n",
      "\n",
      "        [[[-25.4292, -21.1790, -22.2339,  ...,  -5.7871,  -9.1459, -14.4599],\n",
      "          [-26.4267, -23.9548, -24.4095,  ...,  -9.5116, -14.7796, -18.1322],\n",
      "          [-33.1059, -28.9126, -29.1085,  ..., -24.1106, -23.1945, -24.7255],\n",
      "          ...,\n",
      "          [-51.1722, -47.9533, -48.7014,  ..., -50.8125, -51.2782, -53.2235],\n",
      "          [-50.1713, -49.4649, -49.1165,  ..., -52.0051, -51.0308, -51.5985],\n",
      "          [-52.8469, -51.0000, -48.9094,  ..., -51.7971, -51.5983, -53.4973]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-10.5673,  -3.9909,  -2.2397,  ...,  -5.5005,  -9.2543, -11.1301],\n",
      "          [-12.1509, -11.3756,  -8.1727,  ...,  -9.4391, -16.0497, -16.9221],\n",
      "          [-18.5598, -21.9601, -23.0297,  ..., -23.3890, -22.1037, -25.7802],\n",
      "          ...,\n",
      "          [-52.5944, -51.0127, -51.3107,  ..., -49.6637, -48.0445, -49.6687],\n",
      "          [-52.9727, -50.3655, -51.2536,  ..., -50.5060, -49.5551, -51.8140],\n",
      "          [-51.6009, -49.8333, -50.5489,  ..., -49.9480, -49.9710, -53.0863]]],\n",
      "\n",
      "\n",
      "        [[[-31.1283, -19.7714, -13.0959,  ..., -15.0967, -13.8639, -12.3390],\n",
      "          [-28.8814, -18.6744, -14.8699,  ..., -15.0312, -14.5804, -12.8169],\n",
      "          [-27.4124, -22.4962, -26.7199,  ..., -21.2707, -22.0196, -19.5442],\n",
      "          ...,\n",
      "          [-56.3981, -53.3566, -54.6137,  ..., -54.7959, -55.6958, -57.0505],\n",
      "          [-60.1292, -54.9629, -54.1229,  ..., -53.5637, -53.8974, -56.5261],\n",
      "          [-59.2950, -54.1326, -54.6737,  ..., -53.2280, -54.1052, -56.9463]]],\n",
      "\n",
      "\n",
      "        [[[-15.2821, -11.3767, -11.9845,  ...,  -8.2670,  -8.7736, -12.1539],\n",
      "          [-16.1250, -13.5754, -12.0899,  ...,  -9.9776, -11.9258, -13.2226],\n",
      "          [-21.2551, -22.1299, -22.0504,  ..., -23.9481, -23.7623, -18.9937],\n",
      "          ...,\n",
      "          [-52.6190, -49.9110, -49.1751,  ..., -49.4075, -48.4457, -50.3696],\n",
      "          [-54.6232, -51.2046, -49.7113,  ..., -51.4984, -49.5948, -50.0063],\n",
      "          [-53.9702, -50.4028, -50.4095,  ..., -50.6015, -49.4070, -52.4006]]]]), tensor([1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[-20.4516, -17.9941, -20.7322,  ..., -10.1277,  -9.5659, -13.3434],\n",
      "          [-19.9730, -19.4323, -24.4138,  ..., -12.8505, -15.7333, -17.6391],\n",
      "          [-24.7819, -27.8253, -29.0989,  ..., -25.7507, -26.0385, -24.3234],\n",
      "          ...,\n",
      "          [-61.4442, -56.9441, -57.8352,  ..., -59.6203, -58.7586, -60.7551],\n",
      "          [-63.3090, -58.8948, -57.7879,  ..., -58.1593, -57.8995, -59.4014],\n",
      "          [-63.7417, -58.9781, -58.3609,  ..., -58.3074, -59.4399, -61.0138]]],\n",
      "\n",
      "\n",
      "        [[[-16.6691,  -6.9946,  -4.2131,  ...,  -4.6266,  -8.2105, -20.6552],\n",
      "          [-18.8094, -14.4730, -11.0312,  ...,  -8.4841, -11.0249, -22.1196],\n",
      "          [-30.1462, -28.0029, -26.0084,  ..., -21.5683, -20.1793, -19.5037],\n",
      "          ...,\n",
      "          [-56.2467, -52.7388, -52.5563,  ..., -53.2897, -53.3861, -55.1204],\n",
      "          [-56.1644, -53.2781, -54.2015,  ..., -55.0455, -55.1568, -57.1638],\n",
      "          [-56.9713, -53.0619, -52.9821,  ..., -55.6448, -54.6392, -57.0169]]],\n",
      "\n",
      "\n",
      "        [[[-18.9631, -13.8646,  -6.3394,  ...,  -5.7576,  -8.7145,  -9.8001],\n",
      "          [-14.4478,  -9.7717,  -6.0515,  ...,  -5.1902,  -6.5360,  -9.6219],\n",
      "          [-15.2846, -12.2192, -13.8214,  ..., -16.2318, -13.9726, -16.0866],\n",
      "          ...,\n",
      "          [-55.2470, -51.1208, -50.1670,  ..., -53.1796, -51.7913, -52.6755],\n",
      "          [-54.4827, -51.3380, -49.9832,  ..., -52.8669, -53.0000, -54.9691],\n",
      "          [-55.3948, -52.0201, -50.5608,  ..., -52.0717, -52.1901, -55.3488]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -7.9592,  -3.1344,  -2.6511,  ..., -10.3558, -11.6797, -17.3033],\n",
      "          [ -9.0071,  -7.6488, -11.3487,  ..., -11.8102,  -9.2244, -13.1895],\n",
      "          [-14.0929, -17.4014, -23.1372,  ..., -15.3419, -17.5167, -15.7416],\n",
      "          ...,\n",
      "          [-50.5680, -45.4783, -44.7638,  ..., -46.7668, -43.6946, -46.2976],\n",
      "          [-49.7016, -48.4203, -47.4780,  ..., -46.1984, -46.1178, -48.5836],\n",
      "          [-49.5079, -47.1403, -47.2599,  ..., -47.6474, -47.2906, -49.3603]]],\n",
      "\n",
      "\n",
      "        [[[-19.5398, -10.2152,  -8.2142,  ...,  -5.7538, -13.2875, -14.3327],\n",
      "          [-18.2087, -10.3713,  -9.4515,  ...,  -3.6821,  -9.0942, -14.3417],\n",
      "          [-25.1122, -20.6830, -19.5156,  ..., -10.5679, -16.3520, -18.6934],\n",
      "          ...,\n",
      "          [-54.8693, -52.6403, -53.0187,  ..., -53.9944, -51.9241, -53.2146],\n",
      "          [-55.0803, -53.3021, -52.8280,  ..., -52.2696, -52.6950, -55.4110],\n",
      "          [-56.9314, -52.7392, -52.0397,  ..., -52.4353, -52.6939, -54.9656]]],\n",
      "\n",
      "\n",
      "        [[[-21.1655,  -9.2806,  -5.2622,  ...,  -8.8647, -11.1282, -18.5056],\n",
      "          [-20.0558,  -9.4534,  -6.5965,  ..., -11.7341, -10.9992, -17.6177],\n",
      "          [-21.2958, -18.4667, -19.6582,  ..., -23.4726, -20.1104, -22.3423],\n",
      "          ...,\n",
      "          [-52.6853, -51.5193, -50.5851,  ..., -51.7641, -51.5040, -55.3226],\n",
      "          [-54.2208, -51.7189, -51.3510,  ..., -51.1839, -50.5015, -51.5194],\n",
      "          [-55.2196, -51.3944, -51.7383,  ..., -52.0318, -51.2384, -52.3445]]]]), tensor([0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[-24.0151, -14.0741,  -8.4813,  ...,  -7.1553,  -3.5366,  -4.7332],\n",
      "          [-23.5508, -12.4591,  -8.8935,  ..., -10.3823,  -6.3858,  -7.1951],\n",
      "          [-25.5836, -19.2200, -21.9387,  ..., -21.8384, -20.6047, -16.8313],\n",
      "          ...,\n",
      "          [-51.8312, -50.7193, -52.3980,  ..., -52.6845, -52.2245, -53.4746],\n",
      "          [-54.0043, -51.1681, -50.4154,  ..., -51.9934, -52.3931, -54.9598],\n",
      "          [-53.2392, -50.3139, -50.2935,  ..., -53.3171, -52.3102, -54.1964]]],\n",
      "\n",
      "\n",
      "        [[[ -6.1380,   0.0000,  -2.7168,  ..., -12.1368, -10.0503, -11.5785],\n",
      "          [ -6.2788,  -3.2301,  -6.3150,  ..., -10.3615, -11.0651, -13.5633],\n",
      "          [-13.6251, -15.8973, -17.5655,  ..., -20.3949, -22.2687, -22.6195],\n",
      "          ...,\n",
      "          [-51.9228, -51.6819, -54.1421,  ..., -51.6485, -50.9753, -53.2437],\n",
      "          [-52.7215, -51.4035, -51.8770,  ..., -55.0120, -55.5797, -56.5155],\n",
      "          [-54.9164, -52.4614, -52.8216,  ..., -53.7601, -53.2088, -53.1660]]],\n",
      "\n",
      "\n",
      "        [[[-42.9951, -36.3205, -36.3536,  ..., -48.3439, -42.3000, -41.3858],\n",
      "          [-43.3959, -39.5435, -39.7030,  ..., -49.3582, -46.7161, -47.5142],\n",
      "          [-50.4178, -53.0831, -55.0694,  ..., -57.7504, -54.0611, -50.6898],\n",
      "          ...,\n",
      "          [-80.0000, -79.2811, -80.0000,  ..., -79.9852, -79.7417, -80.0000],\n",
      "          [-80.0000, -80.0000, -80.0000,  ..., -79.3143, -79.0314, -80.0000],\n",
      "          [-80.0000, -79.0932, -79.6483,  ..., -79.6318, -79.4915, -80.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.7691, -12.9450,  -5.3312,  ..., -15.4166,  -9.5626,  -8.5781],\n",
      "          [-15.8101, -11.6237,  -6.9632,  ..., -18.2089, -12.4391, -10.7572],\n",
      "          [-20.8231, -16.4172, -15.3844,  ..., -20.1217, -24.1861, -17.7948],\n",
      "          ...,\n",
      "          [-47.6799, -43.9780, -42.7015,  ..., -42.8832, -45.8906, -47.8539],\n",
      "          [-45.3930, -43.2284, -43.3101,  ..., -42.7987, -44.2289, -46.8842],\n",
      "          [-45.2104, -43.1165, -44.7029,  ..., -43.2037, -42.8307, -45.3306]]],\n",
      "\n",
      "\n",
      "        [[[-12.8657, -11.2482, -13.4724,  ..., -10.0661, -11.7544,  -9.9558],\n",
      "          [-13.8016, -14.9496, -17.2188,  ..., -10.6228, -14.6726, -11.0705],\n",
      "          [-19.8329, -19.9795, -24.5743,  ..., -20.7737, -17.6161, -15.3557],\n",
      "          ...,\n",
      "          [-55.4961, -52.9254, -53.6704,  ..., -52.3865, -52.6815, -55.8604],\n",
      "          [-56.1053, -53.6912, -53.0935,  ..., -52.2997, -52.0639, -53.5094],\n",
      "          [-56.6315, -53.5775, -52.6498,  ..., -53.7087, -53.7046, -55.0886]]],\n",
      "\n",
      "\n",
      "        [[[-10.9037,  -9.6316, -15.9832,  ...,  -8.0860, -11.3804, -17.6645],\n",
      "          [-14.0838, -12.3146, -16.5750,  ..., -14.8592, -16.9757, -25.1795],\n",
      "          [-23.0597, -23.9344, -26.1906,  ..., -24.4917, -25.9262, -30.6096],\n",
      "          ...,\n",
      "          [-54.3032, -51.4389, -51.8348,  ..., -50.4987, -51.0670, -53.0224],\n",
      "          [-53.3753, -51.9854, -52.5193,  ..., -52.5263, -52.4781, -53.4447],\n",
      "          [-54.4793, -52.6034, -51.8446,  ..., -52.5953, -52.8672, -54.7190]]]]), tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[ -8.7493,  -4.5807,  -6.4738,  ..., -15.9647, -14.0820, -12.0870],\n",
      "          [-12.3815, -10.5802, -14.8960,  ..., -12.7258, -10.9269, -12.2491],\n",
      "          [-19.4824, -23.7299, -29.5765,  ..., -21.6016, -19.3830, -17.2908],\n",
      "          ...,\n",
      "          [-52.9048, -50.6366, -49.7437,  ..., -49.7154, -49.2230, -51.2233],\n",
      "          [-52.8697, -49.8926, -49.1587,  ..., -48.3543, -49.6159, -51.7414],\n",
      "          [-52.8566, -50.6728, -49.1883,  ..., -49.3658, -49.1887, -51.0989]]],\n",
      "\n",
      "\n",
      "        [[[ -7.6943,  -5.9382,  -7.4032,  ...,  -8.1046,  -6.6941,  -8.8680],\n",
      "          [-10.2469, -11.4874, -12.8954,  ..., -13.6241,  -9.5865, -11.0633],\n",
      "          [-16.2723, -19.8872, -23.0262,  ..., -26.5111, -22.3468, -21.9607],\n",
      "          ...,\n",
      "          [-54.4179, -52.9635, -53.7995,  ..., -54.1535, -54.6889, -56.2902],\n",
      "          [-55.2268, -52.4172, -53.1265,  ..., -54.1609, -53.8873, -56.5630],\n",
      "          [-56.8721, -53.6757, -53.8824,  ..., -52.9600, -53.5689, -56.0322]]],\n",
      "\n",
      "\n",
      "        [[[-21.2722, -15.7363,  -8.0751,  ...,  -7.4133,  -8.0877, -13.2537],\n",
      "          [-20.5599, -18.8401, -11.2284,  ..., -14.0391, -12.3484, -17.6471],\n",
      "          [-25.1204, -22.4697, -24.0603,  ..., -17.8006, -16.6104, -21.9891],\n",
      "          ...,\n",
      "          [-53.8747, -49.7312, -48.8353,  ..., -50.6623, -50.2794, -51.2271],\n",
      "          [-53.6322, -49.5831, -49.3631,  ..., -50.9076, -51.1527, -51.0633],\n",
      "          [-51.1943, -48.3772, -47.9430,  ..., -51.9853, -50.8899, -51.1673]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-20.3959, -16.9312,  -8.0731,  ...,  -4.7936, -11.8573, -10.2112],\n",
      "          [-19.3135, -13.2479,  -6.8360,  ...,  -4.4044,  -8.8201,  -9.5876],\n",
      "          [-21.3031, -17.6341, -14.4458,  ..., -12.8848, -15.2223, -13.6971],\n",
      "          ...,\n",
      "          [-51.9537, -48.4511, -47.5545,  ..., -47.8985, -46.5046, -47.7934],\n",
      "          [-52.2264, -48.3000, -47.6907,  ..., -45.9011, -46.9553, -50.1222],\n",
      "          [-52.2821, -48.0322, -48.4575,  ..., -46.2426, -46.7295, -50.8456]]],\n",
      "\n",
      "\n",
      "        [[[-12.5628,  -8.1854,  -7.5131,  ...,  -1.9018,  -2.7220,  -7.7348],\n",
      "          [-12.8445,  -8.3350,  -7.3685,  ...,  -5.0801,  -5.7026,  -8.7274],\n",
      "          [-18.6842, -20.4696, -18.0192,  ..., -18.9351, -18.2657, -18.4970],\n",
      "          ...,\n",
      "          [-53.3269, -52.5081, -53.6013,  ..., -52.3845, -53.6357, -55.7000],\n",
      "          [-55.8092, -53.5823, -53.8144,  ..., -51.1757, -51.5666, -53.6472],\n",
      "          [-56.6887, -53.7506, -53.7992,  ..., -50.3366, -51.5614, -52.8527]]],\n",
      "\n",
      "\n",
      "        [[[-13.8973,  -7.7259,  -5.2067,  ...,  -3.8277,  -7.8463, -10.4925],\n",
      "          [-16.4069, -15.3037,  -8.7685,  ...,  -8.0257, -12.5607, -11.9184],\n",
      "          [-19.6523, -18.2227, -19.9249,  ..., -21.0571, -15.6680, -14.9900],\n",
      "          ...,\n",
      "          [-54.9636, -52.6137, -52.2102,  ..., -51.4800, -52.3609, -53.2149],\n",
      "          [-53.9044, -51.6077, -52.3988,  ..., -53.3218, -53.4893, -53.3324],\n",
      "          [-53.8415, -52.4827, -53.0353,  ..., -54.9332, -53.2509, -52.9774]]]]), tensor([1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ラベルの指定\n",
    "t_df = Dataset.shNum\n",
    "\n",
    "# テンソル形式に変換\n",
    "df_tenosor = torch.tensor(df, dtype=torch.float32)\n",
    "df_tenosor = torch.unsqueeze(df_tenosor, 1)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "print(df_tenosor.size())\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset = torch.utils.data.TensorDataset(df_tenosor, label_tensor)\n",
    "\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 50%　: 25% : 25%\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 25\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DyMN(\n",
      "  (layers): ModuleList(\n",
      "    (0): DY_Block(\n",
      "      (exp_conv): DynamicWrapper(\n",
      "        (module): Identity()\n",
      "      )\n",
      "      (exp_norm): Identity()\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Identity()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (1): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=256, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (3): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (4-5): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=480, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (6): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=960, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(40, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=800, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (8-9): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=736, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (10): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=1920, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (11): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (12): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (13-14): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=3840, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (in_c): ConvNormActivation(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (out_c): ConvNormActivation(\n",
      "    (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=960, out_features=1280, bias=True)\n",
      "    (3): Hardswish()\n",
      "    (4): Dropout(p=0.2, inplace=True)\n",
      "    (5): Linear(in_features=1280, out_features=527, bias=True)\n",
      "  )\n",
      ")\n",
      "DyMN(\n",
      "  (layers): ModuleList(\n",
      "    (0): DY_Block(\n",
      "      (exp_conv): DynamicWrapper(\n",
      "        (module): Identity()\n",
      "      )\n",
      "      (exp_norm): Identity()\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Identity()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (1): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=256, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (3): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (4-5): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=480, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (6): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=960, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(40, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=800, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (8-9): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=736, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (10): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=1920, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (11): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (12): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (13-14): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=3840, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (in_c): ConvNormActivation(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (out_c): ConvNormActivation(\n",
      "    (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=960, out_features=1280, bias=True)\n",
      "    (3): Hardswish()\n",
      "    (4): Dropout(p=0.2, inplace=True)\n",
      "    (5): Linear(in_features=1280, out_features=527, bias=True)\n",
      "    (6): Linear(in_features=527, out_features=176, bias=True)\n",
      "    (7): Linear(in_features=176, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/ops/misc.py:120: UserWarning: Don't use ConvNormActivation directly, please use Conv2dNormActivation and Conv3dNormActivation instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# modelのインポート\n",
    "from models.dymn.model import get_model as get_dymn\n",
    "model = get_dymn(pretrained_name=\"dymn10_as\")\n",
    "\n",
    "#パラメータの更新を許可\n",
    "for param in model.parameters():\n",
    "    param.requires_gred = True\n",
    "\n",
    "\n",
    "# print(model.classifier)\n",
    "\n",
    "# 出力層の最後だけ変更\n",
    "# model.classifier[5] = torch.nn.Linear(1280,2)\n",
    "model.classifier= nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(output_size=1),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    nn.Linear(in_features=960, out_features=1280, bias=True),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=527, bias=True),\n",
    "    nn.Linear(in_features=527, out_features=176, bias=True),  # 新しい層\n",
    "    nn.Linear(in_features=176, out_features=2, bias=True)  # 新しい層\n",
    "\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch [1/150], Train Loss: 0.6765, Validation Loss: 1.8418\n",
      "Epoch [2/150], Train Loss: 0.6678, Validation Loss: 1.1562\n",
      "Epoch [3/150], Train Loss: 0.6637, Validation Loss: 1.0149\n",
      "Epoch [4/150], Train Loss: 0.6535, Validation Loss: 1.0807\n",
      "Epoch [5/150], Train Loss: 0.6110, Validation Loss: 1.8472\n",
      "Epoch [6/150], Train Loss: 0.3521, Validation Loss: 2.3821\n",
      "Epoch [7/150], Train Loss: 0.1891, Validation Loss: 1.8072\n",
      "Epoch [8/150], Train Loss: 0.1459, Validation Loss: 0.5117\n",
      "Epoch [9/150], Train Loss: 0.0800, Validation Loss: 0.5584\n",
      "Epoch [10/150], Train Loss: 0.0721, Validation Loss: 0.3421\n",
      "Epoch [11/150], Train Loss: 0.0823, Validation Loss: 0.2542\n",
      "Epoch [12/150], Train Loss: 0.0376, Validation Loss: 0.0954\n",
      "Epoch [13/150], Train Loss: 0.0335, Validation Loss: 0.2482\n",
      "Epoch [14/150], Train Loss: 0.0346, Validation Loss: 0.1764\n",
      "Epoch [15/150], Train Loss: 0.0466, Validation Loss: 0.1255\n",
      "Epoch [16/150], Train Loss: 0.1040, Validation Loss: 1.4723\n",
      "Epoch [17/150], Train Loss: 0.0199, Validation Loss: 0.9510\n",
      "Epoch [18/150], Train Loss: 0.0098, Validation Loss: 0.1019\n",
      "Epoch [19/150], Train Loss: 0.0026, Validation Loss: 0.0743\n",
      "Epoch [20/150], Train Loss: 0.0066, Validation Loss: 0.3728\n",
      "Epoch [21/150], Train Loss: 0.0158, Validation Loss: 0.2923\n",
      "Epoch [22/150], Train Loss: 0.0072, Validation Loss: 0.1304\n",
      "Epoch [23/150], Train Loss: 0.0126, Validation Loss: 0.0602\n",
      "Epoch [24/150], Train Loss: 0.0035, Validation Loss: 0.0828\n",
      "Epoch [25/150], Train Loss: 0.0027, Validation Loss: 0.0669\n",
      "Epoch [26/150], Train Loss: 0.0012, Validation Loss: 0.0728\n",
      "Epoch [27/150], Train Loss: 0.0006, Validation Loss: 0.0624\n",
      "Epoch [28/150], Train Loss: 0.0004, Validation Loss: 0.0590\n",
      "Epoch [29/150], Train Loss: 0.0030, Validation Loss: 0.0848\n",
      "Epoch [30/150], Train Loss: 0.0107, Validation Loss: 1.2608\n",
      "Epoch [31/150], Train Loss: 0.0082, Validation Loss: 0.2438\n",
      "Epoch [32/150], Train Loss: 0.0024, Validation Loss: 0.0509\n",
      "Epoch [33/150], Train Loss: 0.0004, Validation Loss: 0.0491\n",
      "Epoch [34/150], Train Loss: 0.0006, Validation Loss: 0.0577\n",
      "Epoch [35/150], Train Loss: 0.0004, Validation Loss: 0.0569\n",
      "Epoch [36/150], Train Loss: 0.0004, Validation Loss: 0.0618\n",
      "Epoch [37/150], Train Loss: 0.0010, Validation Loss: 0.0528\n",
      "Epoch [38/150], Train Loss: 0.0163, Validation Loss: 0.5978\n",
      "Epoch [39/150], Train Loss: 0.0296, Validation Loss: 0.1140\n",
      "Epoch [40/150], Train Loss: 0.0027, Validation Loss: 0.1784\n",
      "Epoch [41/150], Train Loss: 0.0130, Validation Loss: 0.1905\n",
      "Epoch [42/150], Train Loss: 0.0007, Validation Loss: 0.1332\n",
      "Epoch [43/150], Train Loss: 0.0397, Validation Loss: 0.8034\n",
      "Epoch [44/150], Train Loss: 0.0011, Validation Loss: 0.4557\n",
      "Epoch [45/150], Train Loss: 0.0023, Validation Loss: 0.2992\n",
      "Epoch [46/150], Train Loss: 0.0037, Validation Loss: 0.3266\n",
      "Epoch [47/150], Train Loss: 0.0055, Validation Loss: 0.0787\n",
      "Epoch [48/150], Train Loss: 0.0038, Validation Loss: 0.1746\n",
      "Epoch [49/150], Train Loss: 0.0004, Validation Loss: 0.1155\n",
      "Epoch [50/150], Train Loss: 0.0008, Validation Loss: 0.0785\n",
      "Epoch [51/150], Train Loss: 0.0048, Validation Loss: 0.0360\n",
      "Epoch [52/150], Train Loss: 0.0005, Validation Loss: 0.0345\n",
      "Epoch [53/150], Train Loss: 0.0006, Validation Loss: 0.0353\n",
      "Epoch [54/150], Train Loss: 0.0004, Validation Loss: 0.0369\n",
      "Epoch [55/150], Train Loss: 0.0022, Validation Loss: 0.0567\n",
      "Epoch [56/150], Train Loss: 0.0209, Validation Loss: 0.0892\n",
      "Epoch [57/150], Train Loss: 0.0034, Validation Loss: 0.0582\n",
      "Epoch [58/150], Train Loss: 0.0003, Validation Loss: 0.0502\n",
      "Epoch [59/150], Train Loss: 0.0008, Validation Loss: 0.0447\n",
      "Epoch [60/150], Train Loss: 0.0018, Validation Loss: 0.0464\n",
      "Epoch [61/150], Train Loss: 0.0005, Validation Loss: 0.0522\n",
      "Epoch [62/150], Train Loss: 0.0006, Validation Loss: 0.0631\n",
      "Epoch [63/150], Train Loss: 0.0005, Validation Loss: 0.0641\n",
      "Epoch [64/150], Train Loss: 0.0002, Validation Loss: 0.0636\n",
      "Epoch [65/150], Train Loss: 0.0003, Validation Loss: 0.0569\n",
      "Epoch [66/150], Train Loss: 0.0039, Validation Loss: 0.2992\n",
      "Epoch [67/150], Train Loss: 0.0006, Validation Loss: 0.2812\n",
      "Epoch [68/150], Train Loss: 0.0021, Validation Loss: 0.3806\n",
      "Epoch [69/150], Train Loss: 0.0004, Validation Loss: 0.2976\n",
      "Epoch [70/150], Train Loss: 0.0011, Validation Loss: 0.2022\n",
      "Epoch [71/150], Train Loss: 0.0006, Validation Loss: 0.1486\n",
      "Epoch [72/150], Train Loss: 0.0002, Validation Loss: 0.1262\n",
      "Epoch [73/150], Train Loss: 0.0001, Validation Loss: 0.1042\n",
      "Epoch [74/150], Train Loss: 0.0001, Validation Loss: 0.0875\n",
      "Epoch [75/150], Train Loss: 0.0001, Validation Loss: 0.0726\n",
      "Epoch [76/150], Train Loss: 0.0030, Validation Loss: 0.2183\n",
      "Epoch [77/150], Train Loss: 0.0023, Validation Loss: 0.0561\n",
      "Epoch [78/150], Train Loss: 0.0002, Validation Loss: 0.0562\n",
      "Epoch [79/150], Train Loss: 0.0001, Validation Loss: 0.0586\n",
      "Epoch [80/150], Train Loss: 0.0000, Validation Loss: 0.0599\n",
      "Epoch [81/150], Train Loss: 0.0004, Validation Loss: 0.0542\n",
      "Epoch [82/150], Train Loss: 0.0013, Validation Loss: 0.0645\n",
      "Epoch [83/150], Train Loss: 0.0006, Validation Loss: 0.0747\n",
      "Epoch [84/150], Train Loss: 0.0001, Validation Loss: 0.0725\n",
      "Epoch [85/150], Train Loss: 0.0000, Validation Loss: 0.0723\n",
      "Epoch [86/150], Train Loss: 0.0002, Validation Loss: 0.0687\n",
      "Epoch [87/150], Train Loss: 0.0001, Validation Loss: 0.0680\n",
      "Epoch [88/150], Train Loss: 0.0207, Validation Loss: 0.4087\n",
      "Epoch [89/150], Train Loss: 0.0016, Validation Loss: 0.7047\n",
      "Epoch [90/150], Train Loss: 0.0007, Validation Loss: 0.5606\n",
      "Epoch [91/150], Train Loss: 0.0005, Validation Loss: 0.3952\n",
      "Epoch [92/150], Train Loss: 0.0004, Validation Loss: 0.1620\n",
      "Epoch [93/150], Train Loss: 0.0002, Validation Loss: 0.1210\n",
      "Epoch [94/150], Train Loss: 0.0003, Validation Loss: 0.1178\n",
      "Epoch [95/150], Train Loss: 0.0005, Validation Loss: 0.1019\n",
      "Epoch [96/150], Train Loss: 0.0005, Validation Loss: 0.0947\n",
      "Epoch [97/150], Train Loss: 0.0004, Validation Loss: 0.0829\n",
      "Epoch [98/150], Train Loss: 0.0002, Validation Loss: 0.0546\n",
      "Epoch [99/150], Train Loss: 0.0004, Validation Loss: 0.0527\n",
      "Epoch [100/150], Train Loss: 0.0003, Validation Loss: 0.0511\n",
      "Epoch [101/150], Train Loss: 0.0000, Validation Loss: 0.0493\n",
      "Epoch [102/150], Train Loss: 0.0001, Validation Loss: 0.0487\n",
      "Epoch [103/150], Train Loss: 0.0007, Validation Loss: 0.0715\n",
      "Epoch [104/150], Train Loss: 0.0002, Validation Loss: 0.0697\n",
      "Epoch [105/150], Train Loss: 0.0005, Validation Loss: 0.0594\n",
      "Epoch [106/150], Train Loss: 0.0001, Validation Loss: 0.0698\n",
      "Epoch [107/150], Train Loss: 0.0003, Validation Loss: 0.0591\n",
      "Epoch [108/150], Train Loss: 0.0005, Validation Loss: 0.0586\n",
      "Epoch [109/150], Train Loss: 0.0003, Validation Loss: 0.0598\n",
      "Epoch [110/150], Train Loss: 0.0002, Validation Loss: 0.0554\n",
      "Epoch [111/150], Train Loss: 0.0001, Validation Loss: 0.0512\n",
      "Epoch [112/150], Train Loss: 0.0007, Validation Loss: 0.0798\n",
      "Epoch [113/150], Train Loss: 0.0001, Validation Loss: 0.0779\n",
      "Epoch [114/150], Train Loss: 0.0008, Validation Loss: 0.1244\n",
      "Epoch [115/150], Train Loss: 0.0001, Validation Loss: 0.1079\n",
      "Epoch [116/150], Train Loss: 0.0001, Validation Loss: 0.1001\n",
      "Epoch [117/150], Train Loss: 0.0001, Validation Loss: 0.0956\n",
      "Epoch [118/150], Train Loss: 0.0000, Validation Loss: 0.0899\n",
      "Epoch [119/150], Train Loss: 0.0001, Validation Loss: 0.0835\n",
      "Epoch [120/150], Train Loss: 0.0001, Validation Loss: 0.0777\n",
      "Epoch [121/150], Train Loss: 0.0002, Validation Loss: 0.0710\n",
      "Epoch [122/150], Train Loss: 0.0003, Validation Loss: 0.0673\n",
      "Epoch [123/150], Train Loss: 0.0001, Validation Loss: 0.0640\n",
      "Epoch [124/150], Train Loss: 0.0006, Validation Loss: 0.0438\n",
      "Epoch [125/150], Train Loss: 0.0001, Validation Loss: 0.0424\n",
      "Epoch [126/150], Train Loss: 0.0001, Validation Loss: 0.0423\n",
      "Epoch [127/150], Train Loss: 0.0001, Validation Loss: 0.0434\n",
      "Epoch [128/150], Train Loss: 0.0009, Validation Loss: 0.0337\n",
      "Epoch [129/150], Train Loss: 0.0001, Validation Loss: 0.0347\n",
      "Epoch [130/150], Train Loss: 0.0001, Validation Loss: 0.0366\n",
      "Epoch [131/150], Train Loss: 0.0090, Validation Loss: 0.0794\n",
      "Epoch [132/150], Train Loss: 0.0090, Validation Loss: 0.3010\n",
      "Epoch [133/150], Train Loss: 0.0005, Validation Loss: 0.1737\n",
      "Epoch [134/150], Train Loss: 0.0064, Validation Loss: 0.6483\n",
      "Epoch [135/150], Train Loss: 0.0033, Validation Loss: 0.5267\n",
      "Epoch [136/150], Train Loss: 0.0003, Validation Loss: 0.3722\n",
      "Epoch [137/150], Train Loss: 0.0003, Validation Loss: 0.2482\n",
      "Epoch [138/150], Train Loss: 0.0001, Validation Loss: 0.2005\n",
      "Epoch [139/150], Train Loss: 0.0001, Validation Loss: 0.1670\n",
      "Epoch [140/150], Train Loss: 0.0001, Validation Loss: 0.1326\n",
      "Epoch [141/150], Train Loss: 0.0002, Validation Loss: 0.1178\n",
      "Epoch [142/150], Train Loss: 0.0000, Validation Loss: 0.1008\n",
      "Epoch [143/150], Train Loss: 0.0001, Validation Loss: 0.0840\n",
      "Epoch [144/150], Train Loss: 0.0000, Validation Loss: 0.0750\n",
      "Epoch [145/150], Train Loss: 0.0001, Validation Loss: 0.0645\n",
      "Epoch [146/150], Train Loss: 0.0001, Validation Loss: 0.0591\n",
      "Epoch [147/150], Train Loss: 0.0002, Validation Loss: 0.0398\n",
      "Epoch [148/150], Train Loss: 0.0008, Validation Loss: 0.0435\n",
      "Epoch [149/150], Train Loss: 0.0004, Validation Loss: 0.0569\n",
      "Epoch [150/150], Train Loss: 0.0003, Validation Loss: 0.0474\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# エポックの数\n",
    "max_epoch = 150\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net1 = model.cuda()\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "  \n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net1.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net1.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y = net1(x)\n",
    "        loss = criterion(y[0], t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net1.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "  \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net1(x)\n",
    "            loss = criterion(y[0], t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "shModel_trained = net1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "def ShowTrainLoss(train_losses,val_losses,save):\n",
    "    # 日本時間のタイムゾーンを取得\n",
    "    jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "    # 現在の日本時間を取得\n",
    "    now = datetime.now(jst)\n",
    "\n",
    "    # 時刻を指定された形式の文字列に変換\n",
    "    time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # 学習曲線の可視化\n",
    "\n",
    "    title = 'Training and Validation Losses Soft-hard'\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0,5)\n",
    "    plt.legend()\n",
    "    if save == True:\n",
    "        plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "ShowTrainLoss(train_losses,val_losses,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.2%\n",
      "Accuracy: 98.5%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9855)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y[0], dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            # x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net1(x)\n",
    "            \n",
    "            y_label = torch.argmax(y[0], dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.dymn.model import get_model as get_dymn\n",
    "# dymn10 = get_dymn(pretrained_name=\"dymn10_as\")\n",
    "\n",
    "# DataLoder(df,Dataset.matNum,25)\n",
    "# FineTune(dymn10,5,1280,6)\n",
    "# print(dymn10)\n",
    "# TrainVall(dymn10,train_loader,val_loader,8)\n",
    "\n",
    "# ShowTrainLoss(train_losses,val_losses,False)\n",
    "# calc_acc(FineTune.net,val_loader)\n",
    "# calc_acc(net,test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### material 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1050, 1, 128, 130])\n",
      "525 262 263\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fdd2643e230>\n",
      "[tensor([[[[-15.7372, -12.7907, -12.2806,  ..., -16.2258, -12.1957, -14.6959],\n",
      "          [-15.7418, -11.8346, -11.9373,  ..., -12.7932, -11.7111, -12.4843],\n",
      "          [-22.5785, -21.3953, -21.5793,  ..., -20.6679, -21.5296, -17.3727],\n",
      "          ...,\n",
      "          [-58.1976, -55.0280, -55.0888,  ..., -53.4471, -52.7718, -53.7474],\n",
      "          [-56.4661, -53.7698, -54.6103,  ..., -54.0908, -53.9045, -56.2288],\n",
      "          [-57.3117, -54.9557, -55.6911,  ..., -54.7845, -54.3604, -56.0656]]],\n",
      "\n",
      "\n",
      "        [[[ -5.8755,  -1.3352,   0.0000,  ...,  -8.2323,  -7.3307,  -8.7717],\n",
      "          [ -7.0860,  -4.6320,  -2.7805,  ...,  -6.8078,  -5.4152,  -6.6856],\n",
      "          [-14.4937, -18.4999, -18.0805,  ..., -15.1023, -14.4274, -11.6789],\n",
      "          ...,\n",
      "          [-50.1694, -46.3330, -44.8377,  ..., -47.9001, -46.6421, -47.7369],\n",
      "          [-49.2638, -46.9567, -46.7122,  ..., -46.9204, -46.5079, -49.3187],\n",
      "          [-46.9555, -45.9099, -47.1923,  ..., -47.8846, -48.9719, -50.9079]]],\n",
      "\n",
      "\n",
      "        [[[-14.0626, -12.4793, -12.4311,  ...,  -6.8308,  -6.2901, -10.4582],\n",
      "          [-18.8385, -19.3206, -16.3264,  ...,  -9.3470,  -9.8862, -12.6103],\n",
      "          [-26.0905, -30.3457, -25.2675,  ..., -20.0117, -23.9119, -21.9449],\n",
      "          ...,\n",
      "          [-53.3047, -52.0847, -53.4519,  ..., -52.4061, -53.3940, -56.5739],\n",
      "          [-58.1525, -54.5277, -52.5746,  ..., -53.0982, -53.9163, -56.1266],\n",
      "          [-55.2106, -52.8737, -53.1973,  ..., -52.8028, -52.4231, -54.3603]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -9.9831,  -7.1871, -11.7807,  ..., -11.2343,  -9.8302, -13.3886],\n",
      "          [-11.8676,  -9.5992, -15.2492,  ..., -12.9284, -12.4264, -17.9736],\n",
      "          [-19.0413, -18.4740, -26.9585,  ..., -21.7851, -23.7197, -26.1367],\n",
      "          ...,\n",
      "          [-53.6593, -52.2464, -51.7386,  ..., -51.2787, -51.4993, -56.2754],\n",
      "          [-55.0183, -52.9384, -52.6564,  ..., -51.3566, -51.8909, -54.7269],\n",
      "          [-56.5075, -52.0982, -52.3580,  ..., -51.7871, -52.0791, -53.2282]]],\n",
      "\n",
      "\n",
      "        [[[-17.2652, -11.0746,  -9.8907,  ...,  -0.6295,   0.0000,  -3.5875],\n",
      "          [-18.6370, -15.4748, -16.1502,  ...,  -6.1369,  -3.3467,  -4.0424],\n",
      "          [-28.6770, -30.6238, -34.6265,  ..., -19.3636, -16.2683, -12.0035],\n",
      "          ...,\n",
      "          [-56.7433, -54.9483, -56.3357,  ..., -56.7504, -55.6961, -54.8034],\n",
      "          [-59.7806, -56.2284, -55.0864,  ..., -54.5428, -54.2212, -54.7591],\n",
      "          [-60.2414, -56.0917, -55.5884,  ..., -56.2427, -55.2146, -53.6850]]],\n",
      "\n",
      "\n",
      "        [[[ -9.3511,  -5.2951,  -9.8728,  ..., -10.9083,  -9.2532, -11.2135],\n",
      "          [ -8.2031,  -6.5688, -12.9695,  ..., -10.1815, -11.6199, -10.9543],\n",
      "          [-13.0035, -13.6482, -18.5944,  ..., -16.5582, -14.2727, -13.9899],\n",
      "          ...,\n",
      "          [-45.4077, -44.2285, -46.0337,  ..., -45.8847, -45.8283, -47.6377],\n",
      "          [-47.8298, -45.4274, -44.8245,  ..., -45.7963, -45.1360, -47.9109],\n",
      "          [-46.2646, -44.5052, -46.9336,  ..., -47.0090, -46.8320, -47.4182]]]]), tensor([5, 0, 4, 5, 0, 1, 1, 3, 0, 2, 0, 5, 2, 5, 5, 5, 0, 0, 0, 1, 2, 2, 3, 4,\n",
      "        2])]\n",
      "[tensor([[[[ -6.0762,  -3.5017,  -3.3377,  ...,  -4.1093,  -2.1572,  -5.0010],\n",
      "          [ -8.7918,  -7.3907,  -5.0249,  ...,  -8.1448,  -4.9479,  -9.1982],\n",
      "          [ -9.1813,  -6.6263, -11.7422,  ...,  -8.8395, -12.1046, -19.2009],\n",
      "          ...,\n",
      "          [-52.7497, -48.8865, -48.6537,  ..., -51.1285, -49.8177, -50.1686],\n",
      "          [-50.9880, -48.3031, -49.1782,  ..., -49.3246, -50.4652, -51.6474],\n",
      "          [-53.7844, -50.3416, -49.3829,  ..., -49.5337, -51.0771, -51.4142]]],\n",
      "\n",
      "\n",
      "        [[[-23.0836, -17.6527, -16.0622,  ..., -10.6483, -10.1918, -12.0575],\n",
      "          [-23.1806, -22.3402, -18.6569,  ..., -13.4887, -13.7516, -13.3281],\n",
      "          [-26.3015, -25.4151, -28.7933,  ..., -27.0607, -24.7454, -19.3046],\n",
      "          ...,\n",
      "          [-66.6998, -62.6790, -60.6387,  ..., -61.7790, -61.7823, -62.4379],\n",
      "          [-63.1558, -60.9635, -61.3787,  ..., -63.1781, -63.1277, -62.9624],\n",
      "          [-64.4473, -63.1082, -63.1545,  ..., -62.6057, -62.2202, -63.7380]]],\n",
      "\n",
      "\n",
      "        [[[-19.4677, -13.8089, -14.6049,  ..., -10.6197,  -9.1130, -14.6017],\n",
      "          [-26.8576, -22.7456, -24.1618,  ..., -10.5441, -12.6558, -19.9263],\n",
      "          [-35.0707, -34.8668, -34.4597,  ..., -19.6834, -21.1026, -24.3130],\n",
      "          ...,\n",
      "          [-57.2477, -53.7524, -52.4263,  ..., -53.7950, -53.9968, -55.4982],\n",
      "          [-55.1792, -53.1644, -54.2603,  ..., -52.6724, -53.1959, -54.9959],\n",
      "          [-54.3971, -52.5030, -52.5609,  ..., -53.9797, -53.4432, -55.9142]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -6.2664,  -2.9890,  -5.2798,  ...,  -5.7535,  -4.7177,  -6.9648],\n",
      "          [ -7.5614,  -3.9616,  -7.6979,  ...,  -7.0264,  -8.9588, -11.5580],\n",
      "          [-15.4290, -14.8272, -17.7061,  ..., -19.6478, -22.2260, -23.2930],\n",
      "          ...,\n",
      "          [-51.9192, -50.1242, -49.7132,  ..., -47.8093, -47.7594, -49.0973],\n",
      "          [-52.1852, -48.6977, -48.1595,  ..., -47.4365, -47.7249, -49.1994],\n",
      "          [-51.3106, -48.8156, -48.8151,  ..., -47.7161, -48.4147, -50.3677]]],\n",
      "\n",
      "\n",
      "        [[[-12.9531,  -8.4623, -10.9949,  ..., -13.9743, -12.5583, -12.9040],\n",
      "          [-12.9575,  -9.1291,  -9.6971,  ..., -12.4427, -10.5136, -12.3491],\n",
      "          [-18.2892, -20.0374, -20.3422,  ..., -16.5155, -15.7638, -17.3400],\n",
      "          ...,\n",
      "          [-54.6013, -51.4329, -50.6813,  ..., -50.8779, -51.4110, -53.4678],\n",
      "          [-52.1137, -49.6309, -49.8039,  ..., -51.3086, -50.1676, -51.5474],\n",
      "          [-52.6111, -51.0972, -51.9317,  ..., -52.1191, -50.8958, -52.4753]]],\n",
      "\n",
      "\n",
      "        [[[-25.9034, -21.9119, -14.0451,  ...,  -5.3250,  -9.2805, -16.3978],\n",
      "          [-19.3675, -13.7969, -12.1835,  ...,  -7.1418,  -7.7071, -15.4302],\n",
      "          [-19.0328, -17.3201, -16.0753,  ..., -17.0908, -13.7243, -22.8432],\n",
      "          ...,\n",
      "          [-48.0925, -46.5962, -46.7822,  ..., -47.8841, -46.8159, -47.6297],\n",
      "          [-47.8132, -45.3680, -44.6936,  ..., -46.3455, -46.1164, -49.3973],\n",
      "          [-49.8005, -47.0284, -47.1830,  ..., -46.4303, -46.3429, -48.1432]]]]), tensor([0, 4, 3, 0, 2, 5, 0, 1, 3, 0, 0, 0, 0, 0, 0, 4, 0, 1, 3, 4, 3, 0, 1, 0,\n",
      "        2])]\n",
      "[tensor([[[[-10.0279,  -7.8579, -11.8001,  ..., -12.3195,  -7.2473,  -9.8667],\n",
      "          [-10.8272,  -8.6687, -14.2134,  ..., -12.5902,  -6.6770,  -8.9679],\n",
      "          [-17.5238, -18.0341, -23.8566,  ..., -20.1754, -14.4655, -14.4317],\n",
      "          ...,\n",
      "          [-53.8049, -51.9219, -53.2467,  ..., -50.7193, -51.2442, -53.0188],\n",
      "          [-54.4185, -52.8468, -53.4759,  ..., -52.1240, -51.0827, -54.4927],\n",
      "          [-55.8065, -52.5886, -52.4451,  ..., -53.5472, -51.6183, -53.5764]]],\n",
      "\n",
      "\n",
      "        [[[-10.7324,  -4.6517,  -3.8478,  ...,  -8.2309, -14.8002, -18.0520],\n",
      "          [-11.8236,  -6.3387,  -9.1619,  ..., -12.2978, -17.8332, -16.8948],\n",
      "          [-21.9459, -15.6345, -17.6357,  ..., -23.1039, -19.1691, -19.0841],\n",
      "          ...,\n",
      "          [-53.8330, -49.2684, -48.2273,  ..., -48.3188, -49.0298, -52.3784],\n",
      "          [-53.0411, -49.3866, -48.0516,  ..., -49.6745, -49.0690, -51.8535],\n",
      "          [-53.7364, -49.5175, -48.6195,  ..., -50.3162, -49.5507, -49.6395]]],\n",
      "\n",
      "\n",
      "        [[[ -7.1616,  -0.9457,   0.0000,  ...,  -5.7713,  -8.1283, -18.2104],\n",
      "          [ -7.6271,  -3.1601,  -2.3634,  ...,  -8.6473,  -7.9879, -13.6696],\n",
      "          [-13.9333, -14.6354, -14.1242,  ..., -19.9669, -18.1613, -17.1388],\n",
      "          ...,\n",
      "          [-54.6771, -51.6242, -50.7401,  ..., -50.1866, -50.7028, -51.4649],\n",
      "          [-54.6167, -51.3566, -50.3548,  ..., -51.2736, -51.6761, -52.4059],\n",
      "          [-52.7593, -50.6332, -51.0717,  ..., -49.3423, -51.7091, -53.6027]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -8.3681,  -5.1823,  -7.4577,  ...,  -3.7348,  -2.5485,  -6.6958],\n",
      "          [ -8.0277,  -4.9073,  -4.9623,  ...,  -4.2416,  -4.8608,  -9.5555],\n",
      "          [-13.0840, -13.7098, -12.8687,  ..., -17.7461, -19.1325, -21.0760],\n",
      "          ...,\n",
      "          [-50.0689, -46.2291, -45.4716,  ..., -46.8236, -47.4431, -49.0650],\n",
      "          [-50.4353, -47.2231, -45.5502,  ..., -46.8992, -46.7623, -48.7872],\n",
      "          [-48.1989, -46.7950, -47.2719,  ..., -46.1326, -46.5750, -47.0558]]],\n",
      "\n",
      "\n",
      "        [[[-24.0054, -16.5717, -12.2069,  ..., -10.8894, -11.0717, -14.5653],\n",
      "          [-26.5346, -21.9115, -16.5898,  ..., -15.5828, -16.0140, -14.1760],\n",
      "          [-30.1219, -23.5671, -23.9182,  ..., -19.3224, -19.7878, -16.0493],\n",
      "          ...,\n",
      "          [-55.0039, -50.1655, -47.9797,  ..., -48.1771, -49.0459, -50.6193],\n",
      "          [-50.9413, -48.6363, -49.1542,  ..., -50.7510, -50.4623, -51.4882],\n",
      "          [-51.2350, -50.3329, -50.0501,  ..., -51.2576, -50.9684, -51.8375]]],\n",
      "\n",
      "\n",
      "        [[[ -9.2767,  -5.4631,  -1.6625,  ..., -10.1021,  -7.4068,  -9.1599],\n",
      "          [ -7.2520,  -3.3959,  -2.4361,  ...,  -7.8024,  -6.9836,  -7.6628],\n",
      "          [-12.1627, -14.2867, -15.8049,  ..., -17.6147, -16.5750, -12.0232],\n",
      "          ...,\n",
      "          [-56.9290, -53.3854, -53.6736,  ..., -53.6213, -53.0371, -55.1418],\n",
      "          [-55.0039, -54.3032, -54.7474,  ..., -54.4607, -53.4741, -54.6051],\n",
      "          [-55.0830, -54.0245, -54.1530,  ..., -54.0167, -54.1413, -55.7217]]]]), tensor([2, 2, 1, 2, 2, 3, 3, 1, 0, 2, 1, 3, 5, 5, 2, 2, 5, 3, 0, 5, 0, 4, 5, 4,\n",
      "        5])]\n",
      "[tensor([[[[ -8.9003,  -5.6950,  -8.4137,  ...,  -7.9397, -14.6901, -13.7975],\n",
      "          [ -7.0621,  -4.2965,  -5.2679,  ...,  -6.8257, -10.7655, -12.5228],\n",
      "          [-12.1692, -14.2089, -16.3282,  ..., -14.7645, -16.9071, -14.4980],\n",
      "          ...,\n",
      "          [-51.3359, -48.0489, -47.7460,  ..., -48.3099, -47.7784, -49.3869],\n",
      "          [-49.6297, -48.2010, -48.3301,  ..., -48.2575, -48.2402, -50.6874],\n",
      "          [-50.8940, -48.3321, -48.8617,  ..., -48.8092, -48.8599, -50.0928]]],\n",
      "\n",
      "\n",
      "        [[[-17.7462, -15.1062, -26.7662,  ...,  -8.3707, -11.2060, -17.8887],\n",
      "          [-19.8870, -15.9270, -17.0375,  ..., -11.2934, -13.8616, -16.8674],\n",
      "          [-27.6479, -24.2454, -21.9514,  ..., -25.1244, -26.2341, -22.6001],\n",
      "          ...,\n",
      "          [-61.9573, -58.3460, -58.4538,  ..., -57.4640, -59.4890, -60.6936],\n",
      "          [-60.5880, -58.2899, -57.2648,  ..., -59.2312, -58.1507, -59.4468],\n",
      "          [-59.8953, -57.4230, -57.5208,  ..., -58.3148, -57.9805, -58.8456]]],\n",
      "\n",
      "\n",
      "        [[[-13.5176, -11.6368,  -8.7873,  ..., -17.7489, -16.9146, -20.3726],\n",
      "          [-16.1134, -14.8937, -12.4694,  ..., -18.9430, -14.6921, -16.7794],\n",
      "          [-22.4209, -19.2131, -22.1324,  ..., -22.3883, -22.1521, -21.7480],\n",
      "          ...,\n",
      "          [-51.0376, -48.7682, -49.6154,  ..., -49.2334, -49.2060, -50.9532],\n",
      "          [-54.0740, -50.1427, -49.8437,  ..., -49.6026, -50.2182, -51.0737],\n",
      "          [-50.7706, -48.5343, -48.9691,  ..., -50.4240, -50.7928, -52.9936]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-15.8294, -11.2537, -10.9465,  ..., -11.9487, -14.0252, -14.7746],\n",
      "          [-17.5562, -16.3954, -18.2899,  ..., -14.2846, -11.2523, -12.0967],\n",
      "          [-25.0954, -28.1919, -22.7930,  ..., -19.2034, -19.1958, -15.9922],\n",
      "          ...,\n",
      "          [-50.6322, -49.0325, -47.4819,  ..., -48.4302, -47.1102, -48.7352],\n",
      "          [-51.8628, -47.9553, -48.7344,  ..., -49.1368, -49.6521, -51.7342],\n",
      "          [-51.8983, -47.6698, -48.2550,  ..., -47.4888, -47.7807, -50.4829]]],\n",
      "\n",
      "\n",
      "        [[[-14.3831, -12.1354, -12.6169,  ..., -15.8074, -16.5729, -17.3791],\n",
      "          [-18.5885, -19.1402, -17.1982,  ..., -10.2863, -16.8677, -18.6861],\n",
      "          [-22.7160, -21.8464, -18.4663,  ..., -16.2206, -17.2931, -20.8829],\n",
      "          ...,\n",
      "          [-53.3006, -49.5118, -47.8410,  ..., -48.6413, -49.1530, -49.6687],\n",
      "          [-51.7591, -49.3027, -49.3969,  ..., -48.9461, -49.3949, -50.4807],\n",
      "          [-51.4795, -50.4085, -50.9016,  ..., -50.5438, -49.8652, -51.7285]]],\n",
      "\n",
      "\n",
      "        [[[-11.6841, -10.6428, -10.8915,  ...,  -1.7235,  -4.8453, -10.9071],\n",
      "          [-13.1581, -10.0602, -10.0689,  ...,  -3.7508,  -5.8531, -10.0624],\n",
      "          [-19.0680, -19.6948, -21.7907,  ..., -19.0947, -19.8550, -18.1728],\n",
      "          ...,\n",
      "          [-56.3883, -55.2090, -55.1556,  ..., -54.6343, -55.5138, -58.5798],\n",
      "          [-57.3524, -55.6003, -55.8850,  ..., -54.4737, -53.9710, -56.3188],\n",
      "          [-56.3898, -54.3298, -55.1854,  ..., -54.6399, -55.4026, -57.7112]]]]), tensor([5, 4, 0, 5, 4, 2, 2, 2, 0, 0, 4, 2, 1, 4, 4, 0, 5, 2, 4, 0, 5, 0, 2, 0,\n",
      "        3])]\n",
      "[tensor([[[[ -9.1439,  -6.3815,  -8.6553,  ...,  -9.9656, -15.8904, -22.7964],\n",
      "          [-12.4257, -10.7954, -15.2085,  ..., -11.7822, -20.2603, -23.9475],\n",
      "          [-20.7228, -24.3895, -28.4178,  ..., -24.0787, -26.8945, -27.7306],\n",
      "          ...,\n",
      "          [-50.6917, -48.3092, -48.8301,  ..., -50.6481, -49.7191, -51.0505],\n",
      "          [-51.6069, -48.9763, -49.3845,  ..., -50.7629, -50.2760, -51.0789],\n",
      "          [-52.5421, -50.3477, -51.9593,  ..., -49.8749, -50.1946, -52.2247]]],\n",
      "\n",
      "\n",
      "        [[[-12.8183,  -8.8736,  -9.9669,  ...,  -0.9775,  -1.1875,  -3.4887],\n",
      "          [-17.7811, -14.6838, -12.9425,  ...,  -5.8998,  -5.5387,  -6.5439],\n",
      "          [-26.6312, -26.0636, -23.6724,  ..., -25.0167, -22.3263, -16.4586],\n",
      "          ...,\n",
      "          [-58.4294, -54.7695, -54.3107,  ..., -55.4369, -54.4335, -56.1671],\n",
      "          [-59.0020, -54.6001, -54.8849,  ..., -52.7717, -53.4871, -55.4511],\n",
      "          [-58.0232, -54.3704, -54.5316,  ..., -54.1423, -53.6740, -55.1368]]],\n",
      "\n",
      "\n",
      "        [[[-15.6181, -17.4919, -20.0049,  ..., -11.2635, -18.8130, -19.6856],\n",
      "          [-17.4799, -19.6151, -21.3630,  ..., -11.9547, -16.5333, -17.9439],\n",
      "          [-23.0230, -26.7643, -25.9644,  ..., -21.4136, -18.9200, -21.3353],\n",
      "          ...,\n",
      "          [-57.8216, -55.8503, -55.6969,  ..., -53.9801, -54.6264, -56.9200],\n",
      "          [-59.3948, -56.9479, -56.4685,  ..., -53.6779, -54.0244, -55.7368],\n",
      "          [-57.8211, -55.0197, -55.2547,  ..., -55.0715, -54.6728, -57.3392]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-19.3755, -15.8834, -19.4765,  ..., -15.2986, -18.9731, -28.3482],\n",
      "          [-18.2080, -16.1983, -15.6329,  ..., -20.2465, -22.4688, -29.8424],\n",
      "          [-22.2617, -25.5475, -24.1155,  ..., -31.1005, -25.8298, -27.9543],\n",
      "          ...,\n",
      "          [-59.2608, -56.9048, -56.1722,  ..., -54.8316, -56.1192, -58.8295],\n",
      "          [-58.3115, -55.2242, -55.7536,  ..., -55.2191, -55.8394, -58.2460],\n",
      "          [-58.3019, -55.6733, -56.1740,  ..., -56.5903, -55.3230, -55.6876]]],\n",
      "\n",
      "\n",
      "        [[[-20.7064, -12.7469, -10.5713,  ...,  -5.6322, -11.0249, -23.3230],\n",
      "          [-23.0129, -15.8259, -15.6464,  ...,  -9.6322, -13.9740, -25.6630],\n",
      "          [-32.3584, -28.0187, -26.3400,  ..., -21.2980, -21.1598, -23.0218],\n",
      "          ...,\n",
      "          [-58.6716, -54.6895, -55.8372,  ..., -56.8688, -56.7343, -59.0497],\n",
      "          [-58.0728, -55.9267, -56.6812,  ..., -55.3060, -55.7754, -58.9926],\n",
      "          [-57.1548, -55.0041, -56.1730,  ..., -55.2742, -56.0316, -58.6850]]],\n",
      "\n",
      "\n",
      "        [[[-17.7484,  -7.8096,  -5.0597,  ...,  -7.1552, -10.3615, -15.7479],\n",
      "          [-24.1250, -11.6381,  -9.1836,  ..., -10.0575, -14.9263, -20.7033],\n",
      "          [-24.6713, -22.2962, -22.8559,  ..., -17.8255, -21.8843, -28.1199],\n",
      "          ...,\n",
      "          [-52.9812, -49.4930, -49.4893,  ..., -47.8044, -48.4419, -50.2379],\n",
      "          [-51.8783, -48.7094, -48.4333,  ..., -49.4847, -48.6194, -51.0819],\n",
      "          [-51.4531, -49.4110, -49.6053,  ..., -48.9175, -49.1056, -51.0907]]]]), tensor([3, 0, 1, 4, 3, 2, 1, 4, 5, 4, 5, 5, 0, 0, 0, 0, 3, 0, 5, 3, 1, 0, 4, 0,\n",
      "        0])]\n",
      "[tensor([[[[-17.0427, -14.9856, -19.9267,  ...,  -5.5589,  -7.6223,  -9.4907],\n",
      "          [-18.2477, -14.8280, -17.3509,  ...,  -6.7090, -12.1974, -12.1394],\n",
      "          [-26.8981, -25.3371, -20.1127,  ..., -16.3102, -16.0153, -16.4981],\n",
      "          ...,\n",
      "          [-53.9200, -51.8853, -52.4520,  ..., -53.6749, -51.8540, -53.6749],\n",
      "          [-55.1911, -52.7323, -53.3232,  ..., -54.3976, -54.8286, -56.5963],\n",
      "          [-54.7715, -52.9818, -53.6572,  ..., -53.8595, -53.5804, -54.8806]]],\n",
      "\n",
      "\n",
      "        [[[-10.5205, -12.1467, -11.9641,  ..., -11.1011,  -7.8841, -10.2488],\n",
      "          [-10.7204, -10.2712, -14.8051,  ..., -17.4890, -10.1350,  -9.9657],\n",
      "          [-15.4316, -14.7884, -19.3225,  ..., -20.4244, -19.5974, -16.2358],\n",
      "          ...,\n",
      "          [-48.4588, -47.1349, -46.9040,  ..., -47.7909, -47.2344, -49.7415],\n",
      "          [-50.3802, -47.2370, -45.4467,  ..., -47.3579, -46.4145, -48.9298],\n",
      "          [-51.0459, -48.2725, -48.0139,  ..., -46.4444, -47.2485, -48.7807]]],\n",
      "\n",
      "\n",
      "        [[[-11.1962,  -5.1562,  -3.9529,  ..., -13.7877, -13.9695, -18.9762],\n",
      "          [-11.6165, -10.5394, -10.5728,  ..., -20.3477, -17.0996, -21.1129],\n",
      "          [-17.8774, -21.0547, -26.0836,  ..., -28.4353, -27.5213, -30.6109],\n",
      "          ...,\n",
      "          [-55.0200, -53.2546, -53.1739,  ..., -54.1681, -53.8253, -56.4622],\n",
      "          [-57.6203, -53.9981, -53.5916,  ..., -53.0469, -53.1876, -55.7428],\n",
      "          [-58.0921, -53.5759, -52.9358,  ..., -54.2606, -55.0854, -56.0155]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-13.0929,  -8.1490,  -6.0740,  ...,  -9.0175,  -8.1026, -11.2404],\n",
      "          [-10.8897,  -6.2664,  -5.4600,  ..., -10.1410, -10.2522, -13.9232],\n",
      "          [-16.1681, -14.1593, -16.3334,  ..., -17.0501, -17.4465, -21.9007],\n",
      "          ...,\n",
      "          [-51.3174, -47.6784, -46.9831,  ..., -50.6825, -49.8886, -49.5048],\n",
      "          [-51.6961, -49.0685, -48.9114,  ..., -49.4049, -49.1464, -50.9212],\n",
      "          [-50.2888, -48.5087, -49.5262,  ..., -49.4060, -50.3186, -50.6697]]],\n",
      "\n",
      "\n",
      "        [[[-10.5740,  -6.6337,  -8.5231,  ...,  -8.6571,  -5.7712,  -7.2641],\n",
      "          [-13.8897, -10.3217, -13.4287,  ..., -16.9600, -11.8110,  -9.2367],\n",
      "          [-23.7448, -22.1353, -25.4149,  ..., -25.1986, -20.3145, -14.5135],\n",
      "          ...,\n",
      "          [-56.6444, -52.8006, -52.6621,  ..., -51.8420, -53.6470, -55.4209],\n",
      "          [-55.7708, -51.4955, -51.6007,  ..., -51.9611, -51.7362, -53.4997],\n",
      "          [-55.3219, -52.4044, -52.4623,  ..., -52.5349, -53.7143, -56.9817]]],\n",
      "\n",
      "\n",
      "        [[[ -5.3598,  -3.5870,  -7.7213,  ...,  -2.1239,  -7.6019, -16.7891],\n",
      "          [ -5.8658,  -5.3685,  -7.8181,  ...,  -4.0615,  -8.9067, -14.8545],\n",
      "          [-11.5583, -15.3547, -19.3934,  ..., -16.7265, -17.2696, -18.3079],\n",
      "          ...,\n",
      "          [-47.5734, -45.8095, -45.9924,  ..., -44.0620, -45.6469, -47.2745],\n",
      "          [-48.5098, -45.7572, -45.2733,  ..., -44.6914, -46.3110, -48.8676],\n",
      "          [-49.0852, -46.0152, -45.1482,  ..., -44.7064, -45.7651, -47.9350]]]]), tensor([1, 0, 3, 5, 0, 2, 1, 3, 2, 4, 1, 0, 5, 4, 5, 5, 4, 3, 4, 3, 0, 2, 4, 3,\n",
      "        2])]\n",
      "[tensor([[[[-16.5098, -13.6158, -13.7698,  ..., -20.1823, -15.1784, -14.9491],\n",
      "          [-17.1146, -14.5767, -15.2056,  ..., -17.9235, -14.7208, -14.5118],\n",
      "          [-20.5487, -19.4128, -19.8824,  ..., -25.1827, -23.9422, -20.0301],\n",
      "          ...,\n",
      "          [-51.9878, -48.7872, -49.3824,  ..., -49.1425, -48.0484, -49.6893],\n",
      "          [-51.2758, -49.8633, -49.9142,  ..., -50.0475, -49.9551, -51.1813],\n",
      "          [-53.1391, -51.0403, -50.3494,  ..., -51.4081, -50.0263, -50.0482]]],\n",
      "\n",
      "\n",
      "        [[[-10.7208,  -5.1715,  -4.3676,  ..., -10.5834, -11.5595, -16.9046],\n",
      "          [-12.3766,  -8.8231, -10.9925,  ..., -15.4747, -12.9223, -19.2970],\n",
      "          [-18.7908, -21.4462, -20.5267,  ..., -22.6840, -21.4934, -24.3930],\n",
      "          ...,\n",
      "          [-49.9995, -48.0103, -48.4120,  ..., -49.7643, -49.8806, -51.6831],\n",
      "          [-47.4270, -47.3056, -48.4698,  ..., -49.4439, -47.8779, -49.5320],\n",
      "          [-51.3528, -48.1071, -48.6567,  ..., -48.5554, -48.1139, -51.5024]]],\n",
      "\n",
      "\n",
      "        [[[-15.0478, -13.8001, -14.4621,  ..., -15.5620, -12.5570, -13.9192],\n",
      "          [-16.9501, -15.3223, -15.4388,  ..., -23.5943, -17.3096, -17.4727],\n",
      "          [-21.4123, -20.9109, -20.8366,  ..., -28.2529, -30.6608, -29.5175],\n",
      "          ...,\n",
      "          [-51.7909, -49.2375, -49.9399,  ..., -50.1581, -49.0799, -51.5343],\n",
      "          [-50.2857, -49.8086, -50.5261,  ..., -49.6846, -49.2241, -50.3883],\n",
      "          [-55.8301, -51.5755, -50.2552,  ..., -49.5259, -50.5020, -52.1422]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -7.5071,  -3.8854,  -4.2999,  ...,  -9.5368,  -5.0302,  -8.2657],\n",
      "          [ -6.8737,  -3.2673,  -4.4442,  ...,  -7.8864,  -4.6115,  -6.8085],\n",
      "          [-12.2169, -13.6799, -16.4138,  ..., -11.7323,  -9.3301, -12.1456],\n",
      "          ...,\n",
      "          [-53.6855, -49.2084, -48.6956,  ..., -47.9869, -48.6832, -50.5034],\n",
      "          [-52.8633, -50.2232, -48.7245,  ..., -48.7317, -48.8106, -49.9419],\n",
      "          [-51.5715, -49.3451, -48.4451,  ..., -50.2108, -50.0642, -52.4181]]],\n",
      "\n",
      "\n",
      "        [[[-11.8320,  -9.3900, -12.8467,  ...,  -8.0388, -12.1001, -16.2452],\n",
      "          [-14.0154, -11.1234, -13.2705,  ..., -10.9791, -21.3799, -25.7574],\n",
      "          [-21.1259, -20.0579, -16.5633,  ..., -17.7590, -18.4349, -24.7722],\n",
      "          ...,\n",
      "          [-48.7344, -46.6707, -47.3893,  ..., -47.9304, -47.0027, -49.1107],\n",
      "          [-50.8510, -47.1817, -45.4753,  ..., -47.5742, -47.8928, -49.5717],\n",
      "          [-51.1758, -47.2426, -46.3059,  ..., -46.3051, -46.9690, -50.1339]]],\n",
      "\n",
      "\n",
      "        [[[-14.4391,  -9.1209, -13.9443,  ...,   0.0000,  -2.8345, -10.3333],\n",
      "          [-15.8548, -12.0871, -15.2193,  ...,  -4.8612,  -9.4798, -14.0009],\n",
      "          [-24.0867, -24.5031, -22.1925,  ..., -19.7124, -24.7431, -22.2317],\n",
      "          ...,\n",
      "          [-51.8401, -49.6562, -49.8052,  ..., -50.2163, -49.5208, -51.2952],\n",
      "          [-51.6299, -48.7858, -48.9311,  ..., -48.2765, -49.9220, -50.6108],\n",
      "          [-51.8833, -49.2698, -50.0158,  ..., -48.9768, -50.1476, -53.0972]]]]), tensor([4, 0, 3, 5, 5, 3, 0, 2, 4, 1, 3, 1, 4, 3, 2, 1, 1, 0, 4, 5, 4, 0, 5, 0,\n",
      "        5])]\n",
      "[tensor([[[[-12.9459, -10.7339, -10.5763,  ..., -20.9138, -20.2874, -14.5386],\n",
      "          [-16.2831, -17.0857, -17.3435,  ..., -20.9503, -15.2757, -11.8472],\n",
      "          [-19.1016, -23.3032, -27.8499,  ..., -24.8851, -16.8646, -13.7081],\n",
      "          ...,\n",
      "          [-56.1595, -54.5195, -52.6238,  ..., -53.5836, -51.8603, -54.6450],\n",
      "          [-55.6095, -52.5743, -51.9246,  ..., -53.2095, -52.6188, -55.5935],\n",
      "          [-56.4487, -52.2921, -53.7554,  ..., -52.4024, -51.2213, -51.8921]]],\n",
      "\n",
      "\n",
      "        [[[-18.0209, -11.7379, -10.2200,  ...,  -4.2470,   0.0000,  -3.4826],\n",
      "          [-23.1801, -15.6190, -14.9000,  ...,  -7.3462,  -2.9329,  -4.3133],\n",
      "          [-33.2646, -23.7604, -21.9551,  ..., -20.5872, -16.4038, -11.7417],\n",
      "          ...,\n",
      "          [-56.7785, -52.5463, -51.7002,  ..., -53.8370, -52.9018, -53.2154],\n",
      "          [-56.1939, -54.8628, -54.4604,  ..., -52.7387, -52.6176, -52.2500],\n",
      "          [-54.6674, -52.6126, -53.7326,  ..., -52.3661, -52.9609, -54.0416]]],\n",
      "\n",
      "\n",
      "        [[[-18.3027, -15.4641,  -9.5809,  ..., -11.0653, -12.1972, -19.5427],\n",
      "          [-19.2963, -18.3188, -13.0030,  ..., -15.4253, -15.2683, -24.6046],\n",
      "          [-20.2961, -20.8818, -20.8779,  ..., -24.6880, -25.6998, -30.8342],\n",
      "          ...,\n",
      "          [-48.0807, -45.6483, -45.3463,  ..., -47.3056, -47.6561, -47.9204],\n",
      "          [-47.8975, -44.5405, -43.8399,  ..., -47.5982, -47.1712, -48.2320],\n",
      "          [-48.5111, -45.4942, -44.9434,  ..., -46.1690, -44.6446, -46.2503]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.3386,  -8.1295,  -9.4182,  ...,  -3.5372,  -6.9823, -12.3089],\n",
      "          [-14.2323, -10.6343, -11.0549,  ...,  -6.1847, -12.1914, -14.8063],\n",
      "          [-23.5425, -23.3458, -19.9860,  ..., -17.2117, -20.5783, -20.5997],\n",
      "          ...,\n",
      "          [-49.5552, -46.5474, -46.3638,  ..., -47.1317, -46.2887, -47.9489],\n",
      "          [-50.2128, -46.6963, -46.5049,  ..., -46.7846, -48.3372, -50.4113],\n",
      "          [-49.7589, -48.1748, -49.3193,  ..., -48.4582, -49.2449, -50.2379]]],\n",
      "\n",
      "\n",
      "        [[[-11.0291,  -5.0556,  -7.3908,  ...,  -5.4382,  -8.5189, -14.6596],\n",
      "          [-11.8465,  -8.6335,  -9.1775,  ..., -10.5531, -13.6293, -21.6308],\n",
      "          [-17.3718, -17.8354, -16.5804,  ..., -19.8602, -21.2210, -25.3905],\n",
      "          ...,\n",
      "          [-50.1780, -48.1141, -49.1871,  ..., -47.1003, -47.3462, -50.3536],\n",
      "          [-49.9736, -48.0062, -49.3661,  ..., -47.9526, -48.1708, -51.8342],\n",
      "          [-52.2147, -48.4390, -48.6952,  ..., -48.9274, -48.7183, -51.3020]]],\n",
      "\n",
      "\n",
      "        [[[-12.6869,  -6.1255,  -5.5152,  ...,  -5.7381,  -3.4278,  -6.2596],\n",
      "          [-13.6166, -11.1559,  -8.7832,  ..., -11.3911,  -7.8598, -11.0899],\n",
      "          [-18.3389, -18.4038, -21.8603,  ..., -21.9691, -21.5309, -24.5514],\n",
      "          ...,\n",
      "          [-53.4539, -51.1406, -50.9320,  ..., -51.7844, -51.3928, -51.3885],\n",
      "          [-55.7355, -52.1812, -51.9173,  ..., -51.1953, -51.1556, -51.4325],\n",
      "          [-55.7891, -53.1854, -52.2578,  ..., -50.8765, -51.2024, -53.7012]]]]), tensor([0, 1, 2, 0, 2, 3, 0, 0, 3, 4, 5, 4, 0, 3, 2, 1, 3, 2, 2, 0, 0, 0, 2, 1,\n",
      "        1])]\n",
      "[tensor([[[[ -5.1685,  -3.5431,  -6.1680,  ...,  -0.0917,  -0.7231,  -5.5518],\n",
      "          [ -7.6702,  -7.7361, -11.8104,  ...,  -6.2485,  -5.7362,  -8.8374],\n",
      "          [-13.8354, -15.0222, -20.2270,  ..., -22.6714, -23.3922, -22.0796],\n",
      "          ...,\n",
      "          [-55.2056, -52.8139, -52.3971,  ..., -52.7700, -53.1397, -54.7791],\n",
      "          [-55.8079, -52.0751, -50.6632,  ..., -52.3088, -52.0392, -54.6527],\n",
      "          [-56.1405, -53.2581, -52.3736,  ..., -53.7071, -53.6263, -53.4978]]],\n",
      "\n",
      "\n",
      "        [[[-10.6643,  -7.3887,  -8.8921,  ...,  -8.2710,  -7.0803, -11.5905],\n",
      "          [-10.7584,  -8.7772,  -8.7842,  ..., -12.7270,  -8.9024, -12.9026],\n",
      "          [-16.5672, -21.2453, -18.7724,  ..., -17.3295, -18.4741, -22.8398],\n",
      "          ...,\n",
      "          [-53.2704, -50.3550, -51.5633,  ..., -50.3345, -51.2440, -53.5748],\n",
      "          [-51.9836, -50.0980, -50.9822,  ..., -50.7501, -52.0841, -52.2893],\n",
      "          [-52.8884, -51.2494, -51.7744,  ..., -50.7838, -51.9005, -53.4901]]],\n",
      "\n",
      "\n",
      "        [[[-12.4899, -12.6390, -18.3412,  ..., -11.5354, -11.1510, -11.5272],\n",
      "          [-10.6332, -11.0089, -16.0313,  ..., -11.6983, -10.5265, -11.8239],\n",
      "          [-14.1030, -14.8124, -21.2318,  ..., -15.8251, -16.3481, -18.2146],\n",
      "          ...,\n",
      "          [-52.3472, -50.5478, -50.0083,  ..., -51.3235, -50.5600, -52.0638],\n",
      "          [-54.1867, -51.5227, -51.9898,  ..., -53.0278, -52.5103, -52.9369],\n",
      "          [-53.4603, -51.6214, -52.9473,  ..., -52.4769, -51.4700, -52.2444]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-18.7897, -15.7237, -19.1669,  ...,  -2.5864,  -3.4854,  -8.3363],\n",
      "          [-17.5980, -15.9615, -24.4952,  ..., -10.9740,  -9.5510, -10.4342],\n",
      "          [-23.2868, -20.0114, -26.7704,  ..., -31.7439, -22.8537, -20.2259],\n",
      "          ...,\n",
      "          [-55.7549, -51.1689, -50.3053,  ..., -50.8378, -50.6562, -53.0983],\n",
      "          [-54.3370, -50.7302, -50.5244,  ..., -51.5256, -51.2671, -51.4067],\n",
      "          [-55.3706, -51.2870, -50.2594,  ..., -52.2861, -51.2770, -52.1787]]],\n",
      "\n",
      "\n",
      "        [[[-19.4503, -11.6368,  -6.7816,  ..., -12.0678,  -8.9254,  -9.2904],\n",
      "          [-14.8976,  -8.0731,  -6.4716,  ..., -15.7901, -11.9013, -12.1636],\n",
      "          [-17.3328, -15.8321, -17.5205,  ..., -22.3996, -16.8316, -18.6882],\n",
      "          ...,\n",
      "          [-55.9450, -52.5807, -53.6123,  ..., -52.4918, -53.1196, -56.1903],\n",
      "          [-56.1926, -52.4201, -52.3664,  ..., -52.7488, -52.3760, -53.7092],\n",
      "          [-56.5493, -52.8165, -52.9666,  ..., -53.1975, -52.5657, -54.5543]]],\n",
      "\n",
      "\n",
      "        [[[ -8.2463,  -1.5153,  -0.3417,  ...,  -0.0767,  -0.2532,  -5.6081],\n",
      "          [ -7.9649,  -2.4761,  -3.8179,  ...,  -1.0361,  -2.4826,  -7.4762],\n",
      "          [-15.5043, -13.3370, -16.3814,  ..., -13.8375, -16.0605, -16.8942],\n",
      "          ...,\n",
      "          [-52.0576, -47.6453, -47.5434,  ..., -50.1476, -49.5708, -50.5257],\n",
      "          [-52.1544, -48.6912, -47.6840,  ..., -50.1298, -51.6062, -52.9518],\n",
      "          [-53.5745, -50.4228, -49.4765,  ..., -49.7564, -49.9691, -51.0382]]]]), tensor([0, 2, 0, 3, 2, 3, 2, 1, 1, 3, 2, 3, 5, 5, 5, 2, 4, 0, 4, 3, 0, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[-11.7756,  -7.0410,  -4.9498,  ...,  -9.3433,  -6.6749,  -8.1286],\n",
      "          [-16.8265, -12.4159, -10.2116,  ...,  -8.9402,  -7.7014,  -9.2996],\n",
      "          [-22.2347, -21.5294, -20.6842,  ..., -16.5950, -21.3083, -17.7230],\n",
      "          ...,\n",
      "          [-52.1803, -50.2204, -50.7931,  ..., -50.7613, -50.6474, -51.4796],\n",
      "          [-53.6427, -51.5287, -50.7069,  ..., -49.1984, -50.5256, -53.1105],\n",
      "          [-53.3888, -50.0538, -50.9244,  ..., -50.5473, -49.6493, -52.5006]]],\n",
      "\n",
      "\n",
      "        [[[-16.8677, -10.9837, -11.5365,  ..., -17.7769, -14.8101, -12.9792],\n",
      "          [-16.3892, -12.8971, -14.8058,  ..., -26.5489, -17.9043, -13.9401],\n",
      "          [-21.4324, -22.9268, -26.4240,  ..., -31.6903, -24.6109, -19.1836],\n",
      "          ...,\n",
      "          [-55.8700, -52.3636, -51.3638,  ..., -50.5106, -52.0963, -54.2482],\n",
      "          [-56.1806, -52.7200, -51.4017,  ..., -50.6342, -51.1227, -53.4283],\n",
      "          [-57.3869, -54.4889, -53.0539,  ..., -54.0687, -52.3150, -53.6756]]],\n",
      "\n",
      "\n",
      "        [[[-11.7163,  -4.6254,  -3.2696,  ..., -16.9017, -12.0346, -14.7881],\n",
      "          [-12.1810,  -7.0967,  -6.9876,  ..., -15.8202, -15.7874, -15.3310],\n",
      "          [-20.1109, -21.1059, -22.1745,  ..., -18.4897, -20.9831, -20.7972],\n",
      "          ...,\n",
      "          [-50.0040, -47.9352, -48.0505,  ..., -48.1633, -48.3408, -50.5797],\n",
      "          [-52.1636, -49.2911, -48.9361,  ..., -48.9829, -48.4587, -51.9963],\n",
      "          [-53.8949, -50.1011, -49.6775,  ..., -49.2414, -48.3503, -52.0036]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -8.0873,  -7.3582,  -7.8443,  ..., -12.2081, -11.0819,  -8.1737],\n",
      "          [-10.2855, -11.8433, -10.3012,  ...,  -9.5623,  -9.5996,  -8.4761],\n",
      "          [-16.7114, -16.3081, -19.1141,  ..., -15.3856, -15.3966, -14.3635],\n",
      "          ...,\n",
      "          [-52.9925, -51.6669, -51.2964,  ..., -47.6690, -50.3343, -54.7010],\n",
      "          [-53.0450, -50.2613, -51.2696,  ..., -49.3092, -50.2960, -51.7941],\n",
      "          [-51.0952, -48.8961, -50.2779,  ..., -48.1650, -49.5840, -52.3887]]],\n",
      "\n",
      "\n",
      "        [[[-11.7221,  -7.5009,  -4.9032,  ...,  -3.8887,  -2.3518,  -5.2582],\n",
      "          [-12.1687,  -6.4206,  -4.1923,  ...,  -3.6549,  -2.2777,  -4.3293],\n",
      "          [-19.7003, -17.7530, -17.0349,  ..., -15.9735, -14.7695, -11.0209],\n",
      "          ...,\n",
      "          [-55.3763, -53.5250, -53.1544,  ..., -53.0976, -53.6414, -54.5680],\n",
      "          [-57.2011, -54.6884, -53.9950,  ..., -53.2046, -54.7418, -55.1734],\n",
      "          [-54.8278, -52.9933, -53.7695,  ..., -55.1222, -55.4178, -56.0121]]],\n",
      "\n",
      "\n",
      "        [[[-32.0508, -18.6434, -15.1491,  ..., -23.5368, -24.9932, -32.0979],\n",
      "          [-31.0583, -20.0940, -18.5767,  ..., -30.2197, -28.5712, -33.5006],\n",
      "          [-35.3113, -28.8498, -30.7482,  ..., -34.2117, -27.9173, -28.0230],\n",
      "          ...,\n",
      "          [-58.8011, -56.6923, -58.5047,  ..., -56.8365, -55.2544, -56.6119],\n",
      "          [-59.9491, -56.5991, -56.6075,  ..., -57.2557, -57.4822, -59.0407],\n",
      "          [-60.0381, -57.1882, -55.2488,  ..., -54.3049, -55.9977, -60.8532]]]]), tensor([0, 4, 0, 3, 0, 2, 4, 4, 0, 1, 0, 0, 1, 5, 5, 0, 3, 4, 4, 4, 0, 3, 0, 3,\n",
      "        4])]\n",
      "[tensor([[[[-13.8820, -13.2763, -12.7538,  ...,  -5.6196,  -4.1067,  -8.6514],\n",
      "          [-15.5819, -19.0227, -19.7076,  ...,  -8.1158,  -7.6211, -10.1307],\n",
      "          [-18.5374, -20.9645, -31.7378,  ..., -14.6175, -18.0286, -17.5111],\n",
      "          ...,\n",
      "          [-51.7487, -49.4922, -50.8934,  ..., -48.3644, -49.7760, -52.1333],\n",
      "          [-51.9308, -50.1141, -51.3312,  ..., -50.5186, -50.3585, -52.3874],\n",
      "          [-53.7617, -50.5438, -50.3975,  ..., -50.3885, -49.3604, -51.6796]]],\n",
      "\n",
      "\n",
      "        [[[ -3.6491,  -0.1169,  -1.2708,  ..., -15.0683, -18.6120, -16.5309],\n",
      "          [ -7.5189,  -4.7812,  -6.0383,  ..., -12.9051, -12.8131, -14.1332],\n",
      "          [-17.1251, -19.8379, -17.7177,  ..., -18.6443, -15.8214, -17.1822],\n",
      "          ...,\n",
      "          [-53.1104, -50.6421, -50.9671,  ..., -49.0212, -50.9348, -53.4743],\n",
      "          [-54.4481, -52.0334, -51.3920,  ..., -50.2045, -51.1214, -52.6923],\n",
      "          [-53.0755, -51.1130, -49.9918,  ..., -50.5614, -50.6246, -53.7614]]],\n",
      "\n",
      "\n",
      "        [[[ -9.7955,  -5.9862,  -3.8906,  ...,  -1.4620,  -6.8214, -12.6527],\n",
      "          [ -8.9254,  -3.9711,  -3.1762,  ...,  -1.2694,  -3.6564,  -9.0598],\n",
      "          [-14.6580, -14.2811, -15.4592,  ..., -13.5096, -13.4330, -13.1754],\n",
      "          ...,\n",
      "          [-55.6674, -53.4809, -53.3736,  ..., -53.4829, -54.8861, -55.5131],\n",
      "          [-56.9255, -55.2635, -54.5886,  ..., -53.6918, -53.9781, -54.3855],\n",
      "          [-56.1894, -53.2439, -53.3132,  ..., -54.0230, -53.9033, -54.7176]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -9.3630,  -8.0156, -10.7116,  ..., -15.6980, -18.4390, -22.9805],\n",
      "          [-11.0363, -10.8332, -16.3648,  ..., -12.0238, -11.7764, -16.9739],\n",
      "          [-17.6310, -19.5291, -27.1900,  ..., -18.5102, -14.0359, -19.7002],\n",
      "          ...,\n",
      "          [-56.1942, -53.0955, -53.3711,  ..., -53.7066, -53.6759, -55.7073],\n",
      "          [-55.1096, -52.2083, -52.4010,  ..., -52.3425, -51.5793, -54.9182],\n",
      "          [-55.2412, -52.8344, -52.3349,  ..., -54.3277, -52.6744, -54.7175]]],\n",
      "\n",
      "\n",
      "        [[[-16.5507, -16.8092, -13.3030,  ..., -11.8545,  -7.5122,  -7.1141],\n",
      "          [-17.8905, -15.7555, -15.3671,  ..., -12.9508,  -8.6334,  -8.8057],\n",
      "          [-22.0580, -20.2114, -21.9231,  ..., -21.1280, -17.4335, -16.1876],\n",
      "          ...,\n",
      "          [-51.2254, -49.3412, -48.4575,  ..., -48.8502, -49.8611, -52.1791],\n",
      "          [-51.9451, -48.5081, -48.4278,  ..., -48.6097, -48.3876, -50.1398],\n",
      "          [-52.1920, -49.4794, -48.2586,  ..., -48.9832, -49.5116, -51.7586]]],\n",
      "\n",
      "\n",
      "        [[[-12.6704, -10.0989, -15.7285,  ...,  -1.1067,  -4.9090, -11.6635],\n",
      "          [-17.0735, -12.7654, -14.1774,  ...,  -4.9070,  -9.1263, -17.1113],\n",
      "          [-24.4590, -19.2597, -19.7641,  ..., -18.5482, -19.4238, -18.5840],\n",
      "          ...,\n",
      "          [-61.6435, -58.9187, -57.5728,  ..., -59.3153, -58.2450, -59.3043],\n",
      "          [-60.0850, -57.6033, -56.7001,  ..., -58.3688, -58.7643, -59.3651],\n",
      "          [-62.3474, -59.6540, -58.1206,  ..., -57.3825, -57.4624, -59.3069]]]]), tensor([0, 0, 3, 0, 2, 0, 3, 1, 0, 3, 4, 0, 2, 2, 5, 0, 4, 0, 1, 2, 5, 5, 0, 1,\n",
      "        1])]\n",
      "[tensor([[[[ -7.6809,  -1.3894,  -6.1454,  ...,  -3.2551,  -6.2737, -16.9419],\n",
      "          [ -8.9156,  -3.4992,  -4.9761,  ...,  -5.3517,  -9.1741, -21.1846],\n",
      "          [-18.6063, -13.1490, -12.8090,  ..., -17.3216, -20.5329, -24.9092],\n",
      "          ...,\n",
      "          [-46.4100, -42.4945, -41.8615,  ..., -41.1409, -42.9757, -43.2790],\n",
      "          [-46.7894, -42.9631, -42.8739,  ..., -42.9658, -42.4366, -46.0061],\n",
      "          [-46.6880, -43.2702, -43.5808,  ..., -42.4506, -41.8991, -46.7900]]],\n",
      "\n",
      "\n",
      "        [[[-10.9027,  -5.9879,  -4.8815,  ..., -12.9866, -12.6573, -23.0787],\n",
      "          [-11.0216, -12.6848, -10.1498,  ..., -14.9163, -13.8779, -19.4198],\n",
      "          [-14.9135, -17.6198, -21.9165,  ..., -25.8100, -23.9186, -22.0997],\n",
      "          ...,\n",
      "          [-54.8032, -52.6899, -51.4362,  ..., -49.7228, -49.5046, -52.7644],\n",
      "          [-54.9945, -53.0867, -51.7927,  ..., -52.5484, -52.0616, -53.3008],\n",
      "          [-52.5169, -51.2426, -52.4969,  ..., -52.0333, -51.2828, -52.8398]]],\n",
      "\n",
      "\n",
      "        [[[-15.9130,  -9.9528,  -7.5890,  ..., -11.2977, -10.1811, -12.3607],\n",
      "          [-21.2572, -14.8245, -11.5313,  ..., -16.5643, -16.8365, -18.4382],\n",
      "          [-33.1820, -24.2761, -21.9110,  ..., -27.6454, -28.7181, -27.4541],\n",
      "          ...,\n",
      "          [-50.6144, -49.4790, -49.2020,  ..., -49.9200, -50.9647, -52.2441],\n",
      "          [-52.9786, -50.4453, -50.5858,  ..., -49.9498, -49.8033, -51.3987],\n",
      "          [-53.1406, -51.3434, -51.0862,  ..., -49.2642, -49.5327, -49.3084]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -6.2205,  -3.8830,  -4.9260,  ...,  -3.4583,  -2.2113,  -4.2974],\n",
      "          [ -6.9878,  -3.6763,  -4.0112,  ...,  -3.6516,  -2.7743,  -4.7081],\n",
      "          [-14.9627, -15.9165, -17.0534,  ..., -17.2712, -15.9078, -12.9416],\n",
      "          ...,\n",
      "          [-55.6110, -51.7466, -50.3878,  ..., -52.5192, -50.9247, -53.7009],\n",
      "          [-53.5899, -49.8057, -50.3230,  ..., -52.8653, -52.6432, -55.3551],\n",
      "          [-55.4416, -52.3089, -51.4771,  ..., -51.5620, -51.0621, -52.7299]]],\n",
      "\n",
      "\n",
      "        [[[-18.3339,  -9.2998,  -4.6474,  ..., -12.3196, -14.5386, -20.0846],\n",
      "          [-20.7360, -15.5852,  -7.0846,  ..., -14.6952, -17.1643, -24.0331],\n",
      "          [-26.5389, -24.6012, -16.0612,  ..., -22.2092, -19.4099, -23.9425],\n",
      "          ...,\n",
      "          [-51.2855, -47.6523, -48.5198,  ..., -48.6568, -48.5462, -50.3284],\n",
      "          [-52.5481, -49.4531, -48.6133,  ..., -48.4802, -48.6068, -50.3791],\n",
      "          [-52.2420, -49.7171, -48.2370,  ..., -49.4797, -50.1228, -51.8326]]],\n",
      "\n",
      "\n",
      "        [[[-12.6616,  -8.2074,  -9.9863,  ...,  -9.5144, -17.3313, -22.6666],\n",
      "          [-15.6575, -12.6969, -15.0423,  ..., -11.6336, -14.0662, -18.8411],\n",
      "          [-19.4713, -17.0566, -17.6623,  ..., -18.6267, -19.1972, -20.3666],\n",
      "          ...,\n",
      "          [-50.4674, -48.8755, -48.1325,  ..., -48.3828, -48.9122, -51.1367],\n",
      "          [-51.4188, -49.2578, -49.7904,  ..., -48.0029, -47.9695, -50.3255],\n",
      "          [-52.1345, -49.0089, -48.0940,  ..., -48.2453, -48.6368, -51.7287]]]]), tensor([2, 4, 0, 0, 0, 4, 5, 0, 3, 0, 5, 0, 2, 0, 0, 3, 0, 2, 0, 0, 5, 0, 3, 1,\n",
      "        0])]\n",
      "[tensor([[[[-12.3534,  -8.1414,  -7.3962,  ...,  -9.6710, -10.2073, -18.5057],\n",
      "          [-15.8491, -12.5674, -10.7024,  ..., -13.2207, -11.3987, -18.4529],\n",
      "          [-24.6950, -25.3183, -25.8794,  ..., -25.2772, -20.0603, -21.6492],\n",
      "          ...,\n",
      "          [-58.5614, -54.2405, -53.9698,  ..., -55.7635, -55.6912, -56.3000],\n",
      "          [-57.0635, -54.4432, -55.9435,  ..., -54.1819, -54.7409, -55.6478],\n",
      "          [-57.2229, -55.7335, -56.3952,  ..., -56.5256, -54.9140, -55.9728]]],\n",
      "\n",
      "\n",
      "        [[[ -4.0662,  -0.3494,   0.0000,  ...,  -4.6714,  -3.9676,  -8.6064],\n",
      "          [-10.3888,  -7.2953,  -5.8475,  ...,  -9.4470,  -8.2664, -10.5236],\n",
      "          [-17.5188, -18.0142, -23.6312,  ..., -20.8997, -20.2381, -17.0905],\n",
      "          ...,\n",
      "          [-54.4361, -50.9694, -49.5850,  ..., -50.9147, -48.4651, -49.2708],\n",
      "          [-53.5730, -49.8567, -50.6208,  ..., -51.8278, -50.4198, -52.0098],\n",
      "          [-53.8774, -52.0039, -51.2027,  ..., -49.0434, -48.4871, -52.2826]]],\n",
      "\n",
      "\n",
      "        [[[ -6.0855,  -4.9794,  -8.9611,  ...,  -4.5734,  -8.1216, -14.2574],\n",
      "          [ -8.3703,  -7.9510, -12.9993,  ...,  -3.3616,  -4.6402, -10.8244],\n",
      "          [-15.2722, -17.3643, -18.1749,  ..., -13.3375, -12.6844, -15.5775],\n",
      "          ...,\n",
      "          [-53.7831, -50.6899, -50.5273,  ..., -49.9324, -49.5276, -51.8852],\n",
      "          [-54.1276, -53.2184, -51.3571,  ..., -50.0235, -49.4541, -51.1497],\n",
      "          [-52.8796, -50.6453, -50.6585,  ..., -50.6192, -50.4637, -52.1600]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.5110,  -7.9269,  -7.1359,  ...,  -6.5687,  -8.4930, -13.5501],\n",
      "          [-16.0248, -13.7008, -10.5023,  ...,  -9.8067, -12.3579, -14.6271],\n",
      "          [-23.0445, -20.5140, -20.6409,  ..., -22.6591, -21.4507, -22.0410],\n",
      "          ...,\n",
      "          [-54.8558, -53.1715, -52.6942,  ..., -55.3365, -54.3472, -55.8967],\n",
      "          [-55.5346, -53.1642, -52.5521,  ..., -53.4395, -53.8366, -55.6236],\n",
      "          [-56.6218, -53.3334, -55.0011,  ..., -53.3813, -52.2190, -54.2354]]],\n",
      "\n",
      "\n",
      "        [[[-21.5801, -15.6315, -14.7686,  ..., -19.2304, -22.4431, -26.7380],\n",
      "          [-26.2056, -20.6170, -16.6030,  ..., -16.2064, -18.8988, -23.0298],\n",
      "          [-33.2804, -28.7255, -21.4495,  ..., -24.0527, -27.0809, -27.6899],\n",
      "          ...,\n",
      "          [-55.4699, -52.1332, -50.2111,  ..., -51.3910, -51.0190, -54.0519],\n",
      "          [-54.2748, -50.5112, -50.0293,  ..., -52.0322, -52.3634, -54.5737],\n",
      "          [-53.5809, -51.2456, -51.6310,  ..., -51.4344, -51.5829, -53.4043]]],\n",
      "\n",
      "\n",
      "        [[[ -9.9556,  -8.0223, -15.5049,  ...,  -5.8669,  -7.9880, -15.8333],\n",
      "          [ -7.7237,  -6.1376, -10.2059,  ...,  -5.8948, -10.3746, -19.1705],\n",
      "          [-11.4615, -14.8107, -14.7004,  ..., -17.7533, -22.1156, -32.2179],\n",
      "          ...,\n",
      "          [-51.2957, -49.0700, -49.1583,  ..., -48.1738, -49.3872, -52.2161],\n",
      "          [-50.7348, -48.1175, -49.4220,  ..., -47.8958, -48.5351, -49.4556],\n",
      "          [-50.5864, -48.8926, -49.5004,  ..., -48.6794, -49.1842, -52.3914]]]]), tensor([0, 0, 1, 2, 3, 0, 0, 2, 0, 1, 0, 4, 1, 0, 2, 4, 4, 0, 3, 1, 2, 0, 1, 3,\n",
      "        1])]\n",
      "[tensor([[[[-17.3370, -13.6840, -18.9090,  ...,  -6.2777,  -8.6486, -16.0327],\n",
      "          [-22.4095, -18.8803, -17.4200,  ..., -10.2325, -13.0265, -21.1505],\n",
      "          [-28.2006, -22.0807, -20.6433,  ..., -18.2779, -23.1035, -28.7418],\n",
      "          ...,\n",
      "          [-58.2493, -54.7077, -52.7674,  ..., -55.4682, -53.3706, -53.8794],\n",
      "          [-56.9645, -54.1312, -52.3820,  ..., -53.6517, -52.9824, -54.0226],\n",
      "          [-58.1695, -54.5925, -53.9564,  ..., -52.4616, -52.3464, -54.8691]]],\n",
      "\n",
      "\n",
      "        [[[ -8.0931,  -3.0809,  -2.1194,  ...,  -2.4892,  -3.2072,  -5.9954],\n",
      "          [ -8.8219,  -3.6177,  -2.6965,  ...,  -2.7955,  -3.2077,  -5.1771],\n",
      "          [-16.2112, -16.0135, -16.6433,  ..., -16.2770, -15.9546, -12.2362],\n",
      "          ...,\n",
      "          [-54.1955, -53.2327, -54.2320,  ..., -53.0093, -53.6045, -54.3664],\n",
      "          [-55.6548, -53.5421, -54.4195,  ..., -52.1077, -52.6243, -54.1062],\n",
      "          [-58.7440, -54.3559, -54.2793,  ..., -52.4463, -52.1186, -54.6892]]],\n",
      "\n",
      "\n",
      "        [[[ -9.6498,  -6.2075,  -4.5347,  ...,  -3.5316,  -4.4289,  -4.4301],\n",
      "          [ -9.5448,  -5.8848,  -5.0769,  ...,  -2.5754,  -3.3229,  -4.6227],\n",
      "          [-15.3968, -16.7912, -18.0456,  ..., -14.1376, -15.4660, -11.7303],\n",
      "          ...,\n",
      "          [-54.1135, -51.7630, -51.7465,  ..., -51.6635, -52.8606, -52.8051],\n",
      "          [-53.7857, -51.8269, -51.9632,  ..., -53.6480, -53.6472, -54.0929],\n",
      "          [-55.9510, -54.0242, -53.8441,  ..., -52.1160, -53.5992, -55.9835]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-19.3030, -20.0919, -14.3340,  ...,  -1.1654,  -4.4234, -15.1536],\n",
      "          [-17.3505, -16.7345, -13.2978,  ...,  -1.8424,  -3.4892, -11.1512],\n",
      "          [-21.5774, -23.9938, -20.7966,  ..., -10.2834, -12.9977, -13.8153],\n",
      "          ...,\n",
      "          [-53.1820, -51.2893, -52.1281,  ..., -50.9769, -50.3367, -52.9549],\n",
      "          [-55.8379, -51.9040, -52.0206,  ..., -50.9986, -51.2125, -53.2668],\n",
      "          [-55.7550, -52.6171, -52.5296,  ..., -52.2303, -52.8020, -53.9154]]],\n",
      "\n",
      "\n",
      "        [[[-11.1603,  -5.8698,  -5.5590,  ..., -11.9730, -12.3221, -11.9913],\n",
      "          [-12.4443,  -8.4158,  -7.2249,  ..., -15.0613, -12.1208, -13.6823],\n",
      "          [-21.6478, -22.9541, -19.5704,  ..., -17.1054, -19.1276, -21.0368],\n",
      "          ...,\n",
      "          [-47.0859, -46.2030, -46.4313,  ..., -44.2340, -44.1578, -46.9369],\n",
      "          [-48.9116, -46.0197, -45.4827,  ..., -44.7112, -45.0200, -47.0736],\n",
      "          [-50.2629, -46.8827, -46.5767,  ..., -45.6073, -46.9797, -48.5544]]],\n",
      "\n",
      "\n",
      "        [[[ -8.9465,  -4.9386,  -3.4910,  ...,  -8.8267,  -6.6299, -10.4541],\n",
      "          [-11.3466,  -9.8318,  -8.1840,  ..., -11.4609,  -7.0067, -10.0628],\n",
      "          [-18.8256, -24.1063, -22.3295,  ..., -17.7201, -17.6753, -18.2109],\n",
      "          ...,\n",
      "          [-56.3092, -54.5021, -54.6962,  ..., -54.3815, -55.0944, -58.3650],\n",
      "          [-57.5449, -54.3026, -53.5777,  ..., -55.1495, -55.4923, -57.5995],\n",
      "          [-56.4856, -56.0001, -56.5582,  ..., -55.7848, -55.2925, -56.0462]]]]), tensor([4, 3, 5, 3, 0, 1, 4, 4, 0, 1, 5, 5, 2, 3, 0, 2, 2, 0, 5, 3, 1, 4, 5, 0,\n",
      "        1])]\n",
      "[tensor([[[[-1.3163e+01, -1.3713e+01, -5.7044e+00,  ..., -1.2634e+01,\n",
      "           -1.5390e+01, -1.5345e+01],\n",
      "          [-1.2363e+01, -1.0146e+01, -7.4118e+00,  ..., -1.5231e+01,\n",
      "           -2.1727e+01, -1.8272e+01],\n",
      "          [-1.7476e+01, -1.6215e+01, -1.7197e+01,  ..., -2.2400e+01,\n",
      "           -2.5497e+01, -2.2533e+01],\n",
      "          ...,\n",
      "          [-5.1182e+01, -4.7666e+01, -4.9066e+01,  ..., -4.9475e+01,\n",
      "           -4.9563e+01, -5.2183e+01],\n",
      "          [-5.2512e+01, -5.0168e+01, -5.0191e+01,  ..., -5.0816e+01,\n",
      "           -5.0405e+01, -5.3730e+01],\n",
      "          [-5.1582e+01, -5.0124e+01, -5.0477e+01,  ..., -4.9791e+01,\n",
      "           -4.8661e+01, -5.0672e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8231e+01, -1.5682e+01, -1.6320e+01,  ..., -1.0946e+01,\n",
      "           -1.6421e+01, -2.0916e+01],\n",
      "          [-2.1584e+01, -2.1924e+01, -1.9308e+01,  ..., -1.6133e+01,\n",
      "           -2.4725e+01, -2.7363e+01],\n",
      "          [-2.5565e+01, -2.4838e+01, -2.4402e+01,  ..., -2.5382e+01,\n",
      "           -2.8689e+01, -3.0411e+01],\n",
      "          ...,\n",
      "          [-5.5260e+01, -5.1811e+01, -5.1724e+01,  ..., -5.4572e+01,\n",
      "           -5.2932e+01, -5.4526e+01],\n",
      "          [-5.2874e+01, -5.1235e+01, -5.1454e+01,  ..., -5.2265e+01,\n",
      "           -5.3131e+01, -5.6713e+01],\n",
      "          [-5.5489e+01, -5.3212e+01, -5.2562e+01,  ..., -5.1594e+01,\n",
      "           -5.2086e+01, -5.4104e+01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1001e+01, -1.1171e+01, -5.3095e+00,  ..., -1.7959e+00,\n",
      "           -8.4892e-01, -4.4087e+00],\n",
      "          [-1.6136e+01, -8.5612e+00, -6.8571e+00,  ..., -4.9754e+00,\n",
      "           -1.9684e+00, -5.6396e+00],\n",
      "          [-1.9678e+01, -1.6660e+01, -1.9172e+01,  ..., -1.8701e+01,\n",
      "           -1.3089e+01, -1.4169e+01],\n",
      "          ...,\n",
      "          [-5.3229e+01, -5.2300e+01, -5.2039e+01,  ..., -5.1505e+01,\n",
      "           -5.0635e+01, -5.2131e+01],\n",
      "          [-5.2583e+01, -5.1240e+01, -5.1056e+01,  ..., -5.1894e+01,\n",
      "           -5.0664e+01, -5.1814e+01],\n",
      "          [-5.2456e+01, -5.0066e+01, -5.1281e+01,  ..., -5.1113e+01,\n",
      "           -5.1398e+01, -5.3474e+01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.7889e+00, -5.3173e-02,  0.0000e+00,  ..., -1.3146e+01,\n",
      "           -1.3671e+01, -1.9899e+01],\n",
      "          [-9.5718e+00, -9.7293e+00, -8.9567e+00,  ..., -1.0821e+01,\n",
      "           -1.3538e+01, -2.3663e+01],\n",
      "          [-1.7641e+01, -1.7799e+01, -2.0182e+01,  ..., -1.7725e+01,\n",
      "           -2.0284e+01, -2.8764e+01],\n",
      "          ...,\n",
      "          [-4.6298e+01, -4.3867e+01, -4.4462e+01,  ..., -4.2813e+01,\n",
      "           -4.3264e+01, -4.6480e+01],\n",
      "          [-4.7597e+01, -4.4798e+01, -4.6027e+01,  ..., -4.4467e+01,\n",
      "           -4.4975e+01, -4.6983e+01],\n",
      "          [-4.6886e+01, -4.2917e+01, -4.3735e+01,  ..., -4.4047e+01,\n",
      "           -4.4016e+01, -4.7508e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9714e+01, -1.4077e+01, -1.0484e+01,  ..., -9.4866e+00,\n",
      "           -1.0080e+01, -1.4313e+01],\n",
      "          [-2.1948e+01, -1.4893e+01, -1.1055e+01,  ..., -1.3739e+01,\n",
      "           -1.2502e+01, -1.8532e+01],\n",
      "          [-2.1884e+01, -2.0928e+01, -1.5884e+01,  ..., -2.1130e+01,\n",
      "           -1.9600e+01, -2.5277e+01],\n",
      "          ...,\n",
      "          [-5.3528e+01, -5.1130e+01, -5.1114e+01,  ..., -4.9709e+01,\n",
      "           -5.0251e+01, -5.3770e+01],\n",
      "          [-5.5577e+01, -5.1963e+01, -5.0338e+01,  ..., -4.9454e+01,\n",
      "           -5.0415e+01, -5.4143e+01],\n",
      "          [-5.5766e+01, -5.1828e+01, -5.1872e+01,  ..., -5.2364e+01,\n",
      "           -5.4275e+01, -5.4615e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0949e+01, -8.2982e+00, -9.4104e+00,  ..., -8.3833e+00,\n",
      "           -1.0680e+01, -1.7655e+01],\n",
      "          [-1.4225e+01, -1.3354e+01, -1.2044e+01,  ..., -1.1007e+01,\n",
      "           -1.4488e+01, -2.0791e+01],\n",
      "          [-2.1753e+01, -2.3312e+01, -2.4889e+01,  ..., -2.6160e+01,\n",
      "           -2.6580e+01, -3.0275e+01],\n",
      "          ...,\n",
      "          [-5.5445e+01, -5.1929e+01, -5.1407e+01,  ..., -5.1096e+01,\n",
      "           -5.0680e+01, -5.1394e+01],\n",
      "          [-5.6412e+01, -5.3327e+01, -5.2589e+01,  ..., -5.1193e+01,\n",
      "           -5.1988e+01, -5.4647e+01],\n",
      "          [-5.4574e+01, -5.2384e+01, -5.2588e+01,  ..., -5.1052e+01,\n",
      "           -5.2922e+01, -5.4676e+01]]]]), tensor([2, 4, 0, 4, 2, 3, 1, 4, 2, 5, 4, 0, 0, 3, 3, 5, 4, 4, 1, 3, 3, 4, 2, 0,\n",
      "        2])]\n",
      "[tensor([[[[-10.5757,  -3.9565,  -2.4490,  ..., -14.0344,  -9.8667,  -8.6727],\n",
      "          [-11.0136,  -6.4531,  -5.1831,  ..., -15.6522, -15.9574, -11.5940],\n",
      "          [-16.8577, -18.9107, -17.7916,  ..., -25.2219, -21.9087, -16.2473],\n",
      "          ...,\n",
      "          [-49.0824, -47.5911, -48.4652,  ..., -47.4768, -46.8074, -49.4357],\n",
      "          [-50.9669, -46.5640, -47.5060,  ..., -47.9900, -48.4327, -50.0647],\n",
      "          [-50.7123, -46.7355, -48.1979,  ..., -49.1863, -48.1227, -50.5570]]],\n",
      "\n",
      "\n",
      "        [[[ -5.2120,  -4.1334,  -4.2097,  ...,  -3.1277,  -4.9027,  -9.8809],\n",
      "          [ -5.6036,  -2.7944,  -3.4257,  ...,  -1.8790,  -2.7097,  -7.4012],\n",
      "          [-12.0036, -13.3965, -15.7236,  ..., -13.7522, -12.8860, -12.6874],\n",
      "          ...,\n",
      "          [-55.8372, -55.1540, -55.6561,  ..., -54.8882, -53.8076, -53.9245],\n",
      "          [-57.1962, -55.5976, -54.3309,  ..., -53.6039, -53.9144, -54.7926],\n",
      "          [-57.5957, -53.3097, -53.5559,  ..., -52.3026, -52.0629, -55.3671]]],\n",
      "\n",
      "\n",
      "        [[[-10.9055,  -8.4470,  -7.5049,  ...,  -7.8123,  -8.2866,  -8.0311],\n",
      "          [-11.2018, -12.1854, -13.8080,  ...,  -8.2462,  -6.4423,  -8.3171],\n",
      "          [-16.2980, -16.6967, -25.5274,  ..., -18.9832, -15.7927, -17.1252],\n",
      "          ...,\n",
      "          [-47.6100, -45.3317, -44.1492,  ..., -43.8832, -44.8364, -47.1210],\n",
      "          [-46.9981, -43.2093, -44.3806,  ..., -44.0768, -44.4132, -46.8178],\n",
      "          [-47.9968, -46.1935, -45.9198,  ..., -44.9125, -44.4910, -47.1867]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-21.2481, -13.2318, -11.4360,  ..., -15.2457, -15.5091, -14.6598],\n",
      "          [-17.2403, -12.1630, -12.5750,  ..., -13.9417, -12.8999, -13.9763],\n",
      "          [-21.7108, -21.8343, -25.2063,  ..., -23.5583, -21.1637, -18.0900],\n",
      "          ...,\n",
      "          [-57.6918, -54.9767, -55.4636,  ..., -55.7728, -55.3717, -57.3948],\n",
      "          [-56.7882, -55.5966, -55.6308,  ..., -56.3670, -58.5222, -60.3500],\n",
      "          [-56.5126, -56.1400, -57.2627,  ..., -55.5291, -55.8905, -58.4184]]],\n",
      "\n",
      "\n",
      "        [[[ -8.8491,  -3.4978,  -2.1545,  ...,  -1.4982,  -2.7293,  -5.5224],\n",
      "          [-10.6318,  -8.1585,  -9.1547,  ...,  -6.2677,  -6.8292,  -7.6696],\n",
      "          [-17.5509, -18.6270, -23.1745,  ..., -18.0806, -17.0130, -17.8795],\n",
      "          ...,\n",
      "          [-55.0710, -53.1003, -52.7147,  ..., -54.3135, -54.2095, -54.4146],\n",
      "          [-56.1594, -53.1380, -52.6578,  ..., -54.8881, -52.9731, -53.5724],\n",
      "          [-57.9322, -53.9722, -51.9583,  ..., -54.1590, -52.9439, -53.9007]]],\n",
      "\n",
      "\n",
      "        [[[-16.7492, -12.9213, -15.4992,  ..., -12.9660, -18.1481, -28.5464],\n",
      "          [-16.1996, -16.6247, -23.7688,  ..., -17.7725, -19.2445, -21.1943],\n",
      "          [-21.6059, -22.9027, -25.0755,  ..., -29.1831, -24.5935, -21.2665],\n",
      "          ...,\n",
      "          [-59.5307, -55.9166, -53.8853,  ..., -52.0816, -53.1255, -55.9003],\n",
      "          [-56.8013, -54.8264, -54.2567,  ..., -51.6883, -52.1367, -53.6113],\n",
      "          [-54.8412, -54.4343, -53.4510,  ..., -52.3981, -52.6179, -53.7668]]]]), tensor([0, 3, 2, 1, 4, 5, 2, 3, 1, 4, 0, 0, 5, 0, 0, 0, 0, 5, 1, 1, 4, 2, 5, 1,\n",
      "        4])]\n",
      "[tensor([[[[ -4.5473,  -6.2138,  -8.2985,  ...,  -9.9810,  -7.5181,  -8.0491],\n",
      "          [ -4.6183,  -6.6108,  -7.8492,  ...,  -9.0374, -12.7874, -10.7625],\n",
      "          [ -7.9839,  -7.1070, -11.3627,  ...,  -8.2434, -12.9951, -14.6108],\n",
      "          ...,\n",
      "          [-53.3331, -49.3938, -48.5414,  ..., -50.9687, -50.4058, -52.9669],\n",
      "          [-53.4087, -50.9847, -49.7883,  ..., -51.6659, -51.4237, -50.6602],\n",
      "          [-53.9578, -51.2299, -50.1041,  ..., -48.0495, -49.1640, -52.8801]]],\n",
      "\n",
      "\n",
      "        [[[-29.0853, -25.9006, -20.9731,  ...,  -4.6901,  -3.4193,  -6.6621],\n",
      "          [-31.8727, -30.8039, -26.8090,  ...,  -9.3810,  -8.3873, -10.8362],\n",
      "          [-34.7868, -31.7465, -26.1857,  ..., -22.7420, -23.9624, -23.2167],\n",
      "          ...,\n",
      "          [-56.9019, -54.4784, -53.9953,  ..., -51.4284, -52.9841, -54.8922],\n",
      "          [-55.0232, -53.2602, -52.1002,  ..., -51.9545, -52.1367, -54.1389],\n",
      "          [-57.8918, -54.3597, -53.4134,  ..., -53.0290, -53.1905, -53.7613]]],\n",
      "\n",
      "\n",
      "        [[[-12.3970, -12.6769, -11.6861,  ...,  -8.7590,  -8.7376, -15.7222],\n",
      "          [-13.7573, -12.4105, -11.5589,  ..., -10.1950,  -9.7541, -16.6158],\n",
      "          [-21.0281, -21.3274, -19.8277,  ..., -20.4875, -20.1054, -26.3162],\n",
      "          ...,\n",
      "          [-58.3173, -55.6905, -55.1446,  ..., -56.4763, -55.9175, -57.1586],\n",
      "          [-57.4746, -55.1483, -55.9968,  ..., -54.8604, -56.6697, -57.0417],\n",
      "          [-58.5717, -55.8531, -55.7319,  ..., -56.2001, -56.9702, -58.9404]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-13.5728, -14.9611, -20.2619,  ...,  -5.9169,  -4.7809,  -8.8456],\n",
      "          [-12.5747, -13.8058, -19.0077,  ...,  -9.9999,  -9.2723, -10.9084],\n",
      "          [-15.6077, -18.4661, -21.2161,  ..., -25.4814, -20.5172, -17.7988],\n",
      "          ...,\n",
      "          [-55.8372, -53.0905, -52.1294,  ..., -51.2333, -52.2833, -55.3700],\n",
      "          [-55.6846, -53.1335, -53.1861,  ..., -53.7703, -52.5696, -56.3729],\n",
      "          [-55.9756, -53.4670, -53.9101,  ..., -54.4707, -52.9915, -54.3717]]],\n",
      "\n",
      "\n",
      "        [[[-19.8387, -19.1716, -19.8422,  ..., -13.1208, -14.9518, -16.8472],\n",
      "          [-18.7445, -16.9057, -18.9242,  ..., -11.5250, -16.7029, -16.0062],\n",
      "          [-22.2301, -20.9569, -23.2562,  ..., -18.8113, -18.8529, -21.0423],\n",
      "          ...,\n",
      "          [-51.6377, -48.9324, -49.3959,  ..., -49.5261, -49.0410, -50.5903],\n",
      "          [-52.5942, -48.7486, -48.6424,  ..., -50.0788, -49.2967, -50.9648],\n",
      "          [-52.7858, -49.8041, -49.2364,  ..., -49.7302, -49.9798, -51.4836]]],\n",
      "\n",
      "\n",
      "        [[[-11.1326, -10.5856, -14.7633,  ..., -14.8453, -12.1551, -15.0998],\n",
      "          [-12.4634, -11.9332, -16.5080,  ..., -15.3169, -13.5214, -16.0434],\n",
      "          [-18.5694, -22.5046, -23.3326,  ..., -27.7116, -25.4419, -23.5093],\n",
      "          ...,\n",
      "          [-62.1397, -58.9528, -59.2467,  ..., -59.4400, -59.5343, -62.5773],\n",
      "          [-60.5881, -59.8082, -60.4605,  ..., -61.3787, -59.6531, -60.5962],\n",
      "          [-61.0361, -58.9775, -59.5100,  ..., -59.5443, -59.5720, -60.2610]]]]), tensor([0, 2, 2, 5, 1, 0, 1, 2, 4, 0, 2, 0, 5, 5, 1, 2, 0, 0, 0, 1, 2, 1, 0, 2,\n",
      "        5])]\n",
      "[tensor([[[[-14.5727,  -9.6321,  -9.2103,  ..., -11.8275, -12.9413, -14.7009],\n",
      "          [-14.8433, -10.5649, -10.4794,  ..., -11.4483, -14.5512, -22.0689],\n",
      "          [-19.2211, -19.8117, -23.7096,  ..., -19.3841, -21.9057, -22.2750],\n",
      "          ...,\n",
      "          [-48.0494, -45.3691, -45.0387,  ..., -44.0265, -44.6877, -46.3299],\n",
      "          [-47.9073, -45.6596, -44.2975,  ..., -43.3746, -44.3873, -46.3455],\n",
      "          [-46.8101, -43.1942, -42.5134,  ..., -44.2990, -44.3076, -46.7911]]],\n",
      "\n",
      "\n",
      "        [[[-11.4160,  -7.3010,  -6.6249,  ...,  -7.3409,  -7.4026,  -7.1805],\n",
      "          [-14.4316,  -9.6936,  -9.6551,  ..., -10.6789, -12.1702,  -8.9309],\n",
      "          [-23.1466, -21.0663, -21.5290,  ..., -16.4595, -22.0419, -14.9949],\n",
      "          ...,\n",
      "          [-53.4368, -51.5554, -52.7034,  ..., -53.0157, -51.8218, -53.0765],\n",
      "          [-55.1234, -52.2997, -52.0330,  ..., -52.9236, -53.6745, -53.7170],\n",
      "          [-55.4410, -52.7464, -54.5536,  ..., -52.0832, -51.6558, -53.0386]]],\n",
      "\n",
      "\n",
      "        [[[-25.4292, -21.1790, -22.2339,  ...,  -5.7871,  -9.1459, -14.4599],\n",
      "          [-26.4267, -23.9548, -24.4095,  ...,  -9.5116, -14.7796, -18.1322],\n",
      "          [-33.1059, -28.9126, -29.1085,  ..., -24.1106, -23.1945, -24.7255],\n",
      "          ...,\n",
      "          [-51.1722, -47.9533, -48.7014,  ..., -50.8125, -51.2782, -53.2235],\n",
      "          [-50.1713, -49.4649, -49.1165,  ..., -52.0051, -51.0308, -51.5985],\n",
      "          [-52.8469, -51.0000, -48.9094,  ..., -51.7971, -51.5983, -53.4973]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-10.5673,  -3.9909,  -2.2397,  ...,  -5.5005,  -9.2543, -11.1301],\n",
      "          [-12.1509, -11.3756,  -8.1727,  ...,  -9.4391, -16.0497, -16.9221],\n",
      "          [-18.5598, -21.9601, -23.0297,  ..., -23.3890, -22.1037, -25.7802],\n",
      "          ...,\n",
      "          [-52.5944, -51.0127, -51.3107,  ..., -49.6637, -48.0445, -49.6687],\n",
      "          [-52.9727, -50.3655, -51.2536,  ..., -50.5060, -49.5551, -51.8140],\n",
      "          [-51.6009, -49.8333, -50.5489,  ..., -49.9480, -49.9710, -53.0863]]],\n",
      "\n",
      "\n",
      "        [[[-31.1283, -19.7714, -13.0959,  ..., -15.0967, -13.8639, -12.3390],\n",
      "          [-28.8814, -18.6744, -14.8699,  ..., -15.0312, -14.5804, -12.8169],\n",
      "          [-27.4124, -22.4962, -26.7199,  ..., -21.2707, -22.0196, -19.5442],\n",
      "          ...,\n",
      "          [-56.3981, -53.3566, -54.6137,  ..., -54.7959, -55.6958, -57.0505],\n",
      "          [-60.1292, -54.9629, -54.1229,  ..., -53.5637, -53.8974, -56.5261],\n",
      "          [-59.2950, -54.1326, -54.6737,  ..., -53.2280, -54.1052, -56.9463]]],\n",
      "\n",
      "\n",
      "        [[[-15.2821, -11.3767, -11.9845,  ...,  -8.2670,  -8.7736, -12.1539],\n",
      "          [-16.1250, -13.5754, -12.0899,  ...,  -9.9776, -11.9258, -13.2226],\n",
      "          [-21.2551, -22.1299, -22.0504,  ..., -23.9481, -23.7623, -18.9937],\n",
      "          ...,\n",
      "          [-52.6190, -49.9110, -49.1751,  ..., -49.4075, -48.4457, -50.3696],\n",
      "          [-54.6232, -51.2046, -49.7113,  ..., -51.4984, -49.5948, -50.0063],\n",
      "          [-53.9702, -50.4028, -50.4095,  ..., -50.6015, -49.4070, -52.4006]]]]), tensor([4, 1, 3, 1, 0, 4, 0, 1, 0, 0, 0, 0, 1, 0, 5, 3, 0, 2, 1, 4, 5, 0, 0, 0,\n",
      "        3])]\n",
      "[tensor([[[[-20.4516, -17.9941, -20.7322,  ..., -10.1277,  -9.5659, -13.3434],\n",
      "          [-19.9730, -19.4323, -24.4138,  ..., -12.8505, -15.7333, -17.6391],\n",
      "          [-24.7819, -27.8253, -29.0989,  ..., -25.7507, -26.0385, -24.3234],\n",
      "          ...,\n",
      "          [-61.4442, -56.9441, -57.8352,  ..., -59.6203, -58.7586, -60.7551],\n",
      "          [-63.3090, -58.8948, -57.7879,  ..., -58.1593, -57.8995, -59.4014],\n",
      "          [-63.7417, -58.9781, -58.3609,  ..., -58.3074, -59.4399, -61.0138]]],\n",
      "\n",
      "\n",
      "        [[[-16.6691,  -6.9946,  -4.2131,  ...,  -4.6266,  -8.2105, -20.6552],\n",
      "          [-18.8094, -14.4730, -11.0312,  ...,  -8.4841, -11.0249, -22.1196],\n",
      "          [-30.1462, -28.0029, -26.0084,  ..., -21.5683, -20.1793, -19.5037],\n",
      "          ...,\n",
      "          [-56.2467, -52.7388, -52.5563,  ..., -53.2897, -53.3861, -55.1204],\n",
      "          [-56.1644, -53.2781, -54.2015,  ..., -55.0455, -55.1568, -57.1638],\n",
      "          [-56.9713, -53.0619, -52.9821,  ..., -55.6448, -54.6392, -57.0169]]],\n",
      "\n",
      "\n",
      "        [[[-18.9631, -13.8646,  -6.3394,  ...,  -5.7576,  -8.7145,  -9.8001],\n",
      "          [-14.4478,  -9.7717,  -6.0515,  ...,  -5.1902,  -6.5360,  -9.6219],\n",
      "          [-15.2846, -12.2192, -13.8214,  ..., -16.2318, -13.9726, -16.0866],\n",
      "          ...,\n",
      "          [-55.2470, -51.1208, -50.1670,  ..., -53.1796, -51.7913, -52.6755],\n",
      "          [-54.4827, -51.3380, -49.9832,  ..., -52.8669, -53.0000, -54.9691],\n",
      "          [-55.3948, -52.0201, -50.5608,  ..., -52.0717, -52.1901, -55.3488]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -7.9592,  -3.1344,  -2.6511,  ..., -10.3558, -11.6797, -17.3033],\n",
      "          [ -9.0071,  -7.6488, -11.3487,  ..., -11.8102,  -9.2244, -13.1895],\n",
      "          [-14.0929, -17.4014, -23.1372,  ..., -15.3419, -17.5167, -15.7416],\n",
      "          ...,\n",
      "          [-50.5680, -45.4783, -44.7638,  ..., -46.7668, -43.6946, -46.2976],\n",
      "          [-49.7016, -48.4203, -47.4780,  ..., -46.1984, -46.1178, -48.5836],\n",
      "          [-49.5079, -47.1403, -47.2599,  ..., -47.6474, -47.2906, -49.3603]]],\n",
      "\n",
      "\n",
      "        [[[-19.5398, -10.2152,  -8.2142,  ...,  -5.7538, -13.2875, -14.3327],\n",
      "          [-18.2087, -10.3713,  -9.4515,  ...,  -3.6821,  -9.0942, -14.3417],\n",
      "          [-25.1122, -20.6830, -19.5156,  ..., -10.5679, -16.3520, -18.6934],\n",
      "          ...,\n",
      "          [-54.8693, -52.6403, -53.0187,  ..., -53.9944, -51.9241, -53.2146],\n",
      "          [-55.0803, -53.3021, -52.8280,  ..., -52.2696, -52.6950, -55.4110],\n",
      "          [-56.9314, -52.7392, -52.0397,  ..., -52.4353, -52.6939, -54.9656]]],\n",
      "\n",
      "\n",
      "        [[[-21.1655,  -9.2806,  -5.2622,  ...,  -8.8647, -11.1282, -18.5056],\n",
      "          [-20.0558,  -9.4534,  -6.5965,  ..., -11.7341, -10.9992, -17.6177],\n",
      "          [-21.2958, -18.4667, -19.6582,  ..., -23.4726, -20.1104, -22.3423],\n",
      "          ...,\n",
      "          [-52.6853, -51.5193, -50.5851,  ..., -51.7641, -51.5040, -55.3226],\n",
      "          [-54.2208, -51.7189, -51.3510,  ..., -51.1839, -50.5015, -51.5194],\n",
      "          [-55.2196, -51.3944, -51.7383,  ..., -52.0318, -51.2384, -52.3445]]]]), tensor([1, 4, 2, 1, 5, 0, 3, 3, 0, 4, 0, 4, 1, 5, 0, 2, 0, 2, 0, 1, 0, 1, 0, 1,\n",
      "        5])]\n",
      "[tensor([[[[-24.0151, -14.0741,  -8.4813,  ...,  -7.1553,  -3.5366,  -4.7332],\n",
      "          [-23.5508, -12.4591,  -8.8935,  ..., -10.3823,  -6.3858,  -7.1951],\n",
      "          [-25.5836, -19.2200, -21.9387,  ..., -21.8384, -20.6047, -16.8313],\n",
      "          ...,\n",
      "          [-51.8312, -50.7193, -52.3980,  ..., -52.6845, -52.2245, -53.4746],\n",
      "          [-54.0043, -51.1681, -50.4154,  ..., -51.9934, -52.3931, -54.9598],\n",
      "          [-53.2392, -50.3139, -50.2935,  ..., -53.3171, -52.3102, -54.1964]]],\n",
      "\n",
      "\n",
      "        [[[ -6.1380,   0.0000,  -2.7168,  ..., -12.1368, -10.0503, -11.5785],\n",
      "          [ -6.2788,  -3.2301,  -6.3150,  ..., -10.3615, -11.0651, -13.5633],\n",
      "          [-13.6251, -15.8973, -17.5655,  ..., -20.3949, -22.2687, -22.6195],\n",
      "          ...,\n",
      "          [-51.9228, -51.6819, -54.1421,  ..., -51.6485, -50.9753, -53.2437],\n",
      "          [-52.7215, -51.4035, -51.8770,  ..., -55.0120, -55.5797, -56.5155],\n",
      "          [-54.9164, -52.4614, -52.8216,  ..., -53.7601, -53.2088, -53.1660]]],\n",
      "\n",
      "\n",
      "        [[[-42.9951, -36.3205, -36.3536,  ..., -48.3439, -42.3000, -41.3858],\n",
      "          [-43.3959, -39.5435, -39.7030,  ..., -49.3582, -46.7161, -47.5142],\n",
      "          [-50.4178, -53.0831, -55.0694,  ..., -57.7504, -54.0611, -50.6898],\n",
      "          ...,\n",
      "          [-80.0000, -79.2811, -80.0000,  ..., -79.9852, -79.7417, -80.0000],\n",
      "          [-80.0000, -80.0000, -80.0000,  ..., -79.3143, -79.0314, -80.0000],\n",
      "          [-80.0000, -79.0932, -79.6483,  ..., -79.6318, -79.4915, -80.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.7691, -12.9450,  -5.3312,  ..., -15.4166,  -9.5626,  -8.5781],\n",
      "          [-15.8101, -11.6237,  -6.9632,  ..., -18.2089, -12.4391, -10.7572],\n",
      "          [-20.8231, -16.4172, -15.3844,  ..., -20.1217, -24.1861, -17.7948],\n",
      "          ...,\n",
      "          [-47.6799, -43.9780, -42.7015,  ..., -42.8832, -45.8906, -47.8539],\n",
      "          [-45.3930, -43.2284, -43.3101,  ..., -42.7987, -44.2289, -46.8842],\n",
      "          [-45.2104, -43.1165, -44.7029,  ..., -43.2037, -42.8307, -45.3306]]],\n",
      "\n",
      "\n",
      "        [[[-12.8657, -11.2482, -13.4724,  ..., -10.0661, -11.7544,  -9.9558],\n",
      "          [-13.8016, -14.9496, -17.2188,  ..., -10.6228, -14.6726, -11.0705],\n",
      "          [-19.8329, -19.9795, -24.5743,  ..., -20.7737, -17.6161, -15.3557],\n",
      "          ...,\n",
      "          [-55.4961, -52.9254, -53.6704,  ..., -52.3865, -52.6815, -55.8604],\n",
      "          [-56.1053, -53.6912, -53.0935,  ..., -52.2997, -52.0639, -53.5094],\n",
      "          [-56.6315, -53.5775, -52.6498,  ..., -53.7087, -53.7046, -55.0886]]],\n",
      "\n",
      "\n",
      "        [[[-10.9037,  -9.6316, -15.9832,  ...,  -8.0860, -11.3804, -17.6645],\n",
      "          [-14.0838, -12.3146, -16.5750,  ..., -14.8592, -16.9757, -25.1795],\n",
      "          [-23.0597, -23.9344, -26.1906,  ..., -24.4917, -25.9262, -30.6096],\n",
      "          ...,\n",
      "          [-54.3032, -51.4389, -51.8348,  ..., -50.4987, -51.0670, -53.0224],\n",
      "          [-53.3753, -51.9854, -52.5193,  ..., -52.5263, -52.4781, -53.4447],\n",
      "          [-54.4793, -52.6034, -51.8446,  ..., -52.5953, -52.8672, -54.7190]]]]), tensor([0, 5, 4, 5, 1, 0, 1, 1, 0, 0, 5, 0, 1, 0, 5, 0, 2, 1, 0, 0, 1, 0, 2, 1,\n",
      "        4])]\n",
      "[tensor([[[[ -8.7493,  -4.5807,  -6.4738,  ..., -15.9647, -14.0820, -12.0870],\n",
      "          [-12.3815, -10.5802, -14.8960,  ..., -12.7258, -10.9269, -12.2491],\n",
      "          [-19.4824, -23.7299, -29.5765,  ..., -21.6016, -19.3830, -17.2908],\n",
      "          ...,\n",
      "          [-52.9048, -50.6366, -49.7437,  ..., -49.7154, -49.2230, -51.2233],\n",
      "          [-52.8697, -49.8926, -49.1587,  ..., -48.3543, -49.6159, -51.7414],\n",
      "          [-52.8566, -50.6728, -49.1883,  ..., -49.3658, -49.1887, -51.0989]]],\n",
      "\n",
      "\n",
      "        [[[ -7.6943,  -5.9382,  -7.4032,  ...,  -8.1046,  -6.6941,  -8.8680],\n",
      "          [-10.2469, -11.4874, -12.8954,  ..., -13.6241,  -9.5865, -11.0633],\n",
      "          [-16.2723, -19.8872, -23.0262,  ..., -26.5111, -22.3468, -21.9607],\n",
      "          ...,\n",
      "          [-54.4179, -52.9635, -53.7995,  ..., -54.1535, -54.6889, -56.2902],\n",
      "          [-55.2268, -52.4172, -53.1265,  ..., -54.1609, -53.8873, -56.5630],\n",
      "          [-56.8721, -53.6757, -53.8824,  ..., -52.9600, -53.5689, -56.0322]]],\n",
      "\n",
      "\n",
      "        [[[-21.2722, -15.7363,  -8.0751,  ...,  -7.4133,  -8.0877, -13.2537],\n",
      "          [-20.5599, -18.8401, -11.2284,  ..., -14.0391, -12.3484, -17.6471],\n",
      "          [-25.1204, -22.4697, -24.0603,  ..., -17.8006, -16.6104, -21.9891],\n",
      "          ...,\n",
      "          [-53.8747, -49.7312, -48.8353,  ..., -50.6623, -50.2794, -51.2271],\n",
      "          [-53.6322, -49.5831, -49.3631,  ..., -50.9076, -51.1527, -51.0633],\n",
      "          [-51.1943, -48.3772, -47.9430,  ..., -51.9853, -50.8899, -51.1673]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-20.3959, -16.9312,  -8.0731,  ...,  -4.7936, -11.8573, -10.2112],\n",
      "          [-19.3135, -13.2479,  -6.8360,  ...,  -4.4044,  -8.8201,  -9.5876],\n",
      "          [-21.3031, -17.6341, -14.4458,  ..., -12.8848, -15.2223, -13.6971],\n",
      "          ...,\n",
      "          [-51.9537, -48.4511, -47.5545,  ..., -47.8985, -46.5046, -47.7934],\n",
      "          [-52.2264, -48.3000, -47.6907,  ..., -45.9011, -46.9553, -50.1222],\n",
      "          [-52.2821, -48.0322, -48.4575,  ..., -46.2426, -46.7295, -50.8456]]],\n",
      "\n",
      "\n",
      "        [[[-12.5628,  -8.1854,  -7.5131,  ...,  -1.9018,  -2.7220,  -7.7348],\n",
      "          [-12.8445,  -8.3350,  -7.3685,  ...,  -5.0801,  -5.7026,  -8.7274],\n",
      "          [-18.6842, -20.4696, -18.0192,  ..., -18.9351, -18.2657, -18.4970],\n",
      "          ...,\n",
      "          [-53.3269, -52.5081, -53.6013,  ..., -52.3845, -53.6357, -55.7000],\n",
      "          [-55.8092, -53.5823, -53.8144,  ..., -51.1757, -51.5666, -53.6472],\n",
      "          [-56.6887, -53.7506, -53.7992,  ..., -50.3366, -51.5614, -52.8527]]],\n",
      "\n",
      "\n",
      "        [[[-13.8973,  -7.7259,  -5.2067,  ...,  -3.8277,  -7.8463, -10.4925],\n",
      "          [-16.4069, -15.3037,  -8.7685,  ...,  -8.0257, -12.5607, -11.9184],\n",
      "          [-19.6523, -18.2227, -19.9249,  ..., -21.0571, -15.6680, -14.9900],\n",
      "          ...,\n",
      "          [-54.9636, -52.6137, -52.2102,  ..., -51.4800, -52.3609, -53.2149],\n",
      "          [-53.9044, -51.6077, -52.3988,  ..., -53.3218, -53.4893, -53.3324],\n",
      "          [-53.8415, -52.4827, -53.0353,  ..., -54.9332, -53.2509, -52.9774]]]]), tensor([3, 2, 2, 2, 3, 3, 0, 4, 2, 0, 5, 2, 4, 0, 5, 0, 2, 4, 1, 5, 4, 1, 1, 3,\n",
      "        1])]\n"
     ]
    }
   ],
   "source": [
    "# ラベルの指定\n",
    "t_df = Dataset.matNum\n",
    "\n",
    "# テンソル形式に変換\n",
    "df_tenosor = torch.tensor(df, dtype=torch.float32)\n",
    "df_tenosor = torch.unsqueeze(df_tenosor, 1)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "print(df_tenosor.size())\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset = torch.utils.data.TensorDataset(df_tenosor, label_tensor)\n",
    "\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 50%　: 25% : 25%\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 25\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "# summary(net,(1,128,130))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DyMN(\n",
      "  (layers): ModuleList(\n",
      "    (0): DY_Block(\n",
      "      (exp_conv): DynamicWrapper(\n",
      "        (module): Identity()\n",
      "      )\n",
      "      (exp_norm): Identity()\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Identity()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (1): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=256, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (3): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (4-5): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=480, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (6): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=960, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(40, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=800, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (8-9): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=736, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (10): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=1920, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (11): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (12): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (13-14): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=3840, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (in_c): ConvNormActivation(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (out_c): ConvNormActivation(\n",
      "    (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=960, out_features=1280, bias=True)\n",
      "    (3): Hardswish()\n",
      "    (4): Dropout(p=0.2, inplace=True)\n",
      "    (5): Linear(in_features=1280, out_features=527, bias=True)\n",
      "    (6): Linear(in_features=527, out_features=176, bias=True)\n",
      "    (7): Linear(in_features=176, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "matModel = shModel_trained\n",
    "\n",
    "#パラメータの更新を許可\n",
    "for param in matModel.parameters():\n",
    "    param.requires_gred = True\n",
    "\n",
    "\n",
    "# print(model.classifier)\n",
    "\n",
    "# 出力層の最後だけ変更\n",
    "# model.classifier[5] = torch.nn.Linear(1280,2)\n",
    "matModel.classifier= nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(output_size=1),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    nn.Linear(in_features=960, out_features=1280, bias=True),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=527, bias=True),\n",
    "    nn.Linear(in_features=527, out_features=176, bias=True),  # 新しい層\n",
    "    nn.Linear(in_features=176, out_features=6, bias=True)  # 新しい層\n",
    "\n",
    ")\n",
    "print(matModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch [1/150], Train Loss: 1.7325, Validation Loss: 1.6908\n",
      "Epoch [2/150], Train Loss: 1.4973, Validation Loss: 1.3193\n",
      "Epoch [3/150], Train Loss: 1.1405, Validation Loss: 1.2691\n",
      "Epoch [4/150], Train Loss: 1.0787, Validation Loss: 1.0992\n",
      "Epoch [5/150], Train Loss: 1.0313, Validation Loss: 1.0988\n",
      "Epoch [6/150], Train Loss: 1.0314, Validation Loss: 1.0946\n",
      "Epoch [7/150], Train Loss: 1.0013, Validation Loss: 1.0504\n",
      "Epoch [8/150], Train Loss: 0.9693, Validation Loss: 1.0888\n",
      "Epoch [9/150], Train Loss: 0.8751, Validation Loss: 1.1483\n",
      "Epoch [10/150], Train Loss: 0.8533, Validation Loss: 1.0492\n",
      "Epoch [11/150], Train Loss: 0.8248, Validation Loss: 1.1300\n",
      "Epoch [12/150], Train Loss: 0.7323, Validation Loss: 1.1513\n",
      "Epoch [13/150], Train Loss: 0.6837, Validation Loss: 1.6790\n",
      "Epoch [14/150], Train Loss: 0.7350, Validation Loss: 1.3011\n",
      "Epoch [15/150], Train Loss: 0.6743, Validation Loss: 1.3724\n",
      "Epoch [16/150], Train Loss: 0.7063, Validation Loss: 1.0009\n",
      "Epoch [17/150], Train Loss: 0.5774, Validation Loss: 1.5418\n",
      "Epoch [18/150], Train Loss: 0.4704, Validation Loss: 1.3414\n",
      "Epoch [19/150], Train Loss: 0.5066, Validation Loss: 1.6461\n",
      "Epoch [20/150], Train Loss: 0.5569, Validation Loss: 3.0876\n",
      "Epoch [21/150], Train Loss: 0.4335, Validation Loss: 2.4419\n",
      "Epoch [22/150], Train Loss: 0.4823, Validation Loss: 1.1676\n",
      "Epoch [23/150], Train Loss: 0.3849, Validation Loss: 1.3934\n",
      "Epoch [24/150], Train Loss: 0.3745, Validation Loss: 1.4781\n",
      "Epoch [25/150], Train Loss: 0.2996, Validation Loss: 3.2529\n",
      "Epoch [26/150], Train Loss: 0.3371, Validation Loss: 1.8742\n",
      "Epoch [27/150], Train Loss: 0.2410, Validation Loss: 2.0865\n",
      "Epoch [28/150], Train Loss: 0.0878, Validation Loss: 1.3944\n",
      "Epoch [29/150], Train Loss: 0.0993, Validation Loss: 2.0525\n",
      "Epoch [30/150], Train Loss: 0.0773, Validation Loss: 1.0443\n",
      "Epoch [31/150], Train Loss: 0.3882, Validation Loss: 1.9071\n",
      "Epoch [32/150], Train Loss: 0.2302, Validation Loss: 1.9409\n",
      "Epoch [33/150], Train Loss: 0.1788, Validation Loss: 1.4767\n",
      "Epoch [34/150], Train Loss: 0.1004, Validation Loss: 0.8239\n",
      "Epoch [35/150], Train Loss: 0.0498, Validation Loss: 1.5251\n",
      "Epoch [36/150], Train Loss: 0.0750, Validation Loss: 0.8668\n",
      "Epoch [37/150], Train Loss: 0.2092, Validation Loss: 2.0867\n",
      "Epoch [38/150], Train Loss: 0.2632, Validation Loss: 1.6576\n",
      "Epoch [39/150], Train Loss: 0.0739, Validation Loss: 1.6883\n",
      "Epoch [40/150], Train Loss: 0.0438, Validation Loss: 2.7997\n",
      "Epoch [41/150], Train Loss: 0.0348, Validation Loss: 0.9556\n",
      "Epoch [42/150], Train Loss: 0.0177, Validation Loss: 0.4816\n",
      "Epoch [43/150], Train Loss: 0.0366, Validation Loss: 1.8397\n",
      "Epoch [44/150], Train Loss: 0.0641, Validation Loss: 0.8723\n",
      "Epoch [45/150], Train Loss: 0.0170, Validation Loss: 1.3535\n",
      "Epoch [46/150], Train Loss: 0.0153, Validation Loss: 0.9207\n",
      "Epoch [47/150], Train Loss: 0.0608, Validation Loss: 1.8561\n",
      "Epoch [48/150], Train Loss: 0.1866, Validation Loss: 5.0236\n",
      "Epoch [49/150], Train Loss: 0.1200, Validation Loss: 1.9400\n",
      "Epoch [50/150], Train Loss: 0.0468, Validation Loss: 1.5115\n",
      "Epoch [51/150], Train Loss: 0.0204, Validation Loss: 0.8493\n",
      "Epoch [52/150], Train Loss: 0.0200, Validation Loss: 0.6568\n",
      "Epoch [53/150], Train Loss: 0.0061, Validation Loss: 0.6351\n",
      "Epoch [54/150], Train Loss: 0.0141, Validation Loss: 0.7752\n",
      "Epoch [55/150], Train Loss: 0.0137, Validation Loss: 0.7452\n",
      "Epoch [56/150], Train Loss: 0.0860, Validation Loss: 2.7268\n",
      "Epoch [57/150], Train Loss: 0.1615, Validation Loss: 3.4991\n",
      "Epoch [58/150], Train Loss: 0.0545, Validation Loss: 1.1607\n",
      "Epoch [59/150], Train Loss: 0.0625, Validation Loss: 1.5496\n",
      "Epoch [60/150], Train Loss: 0.0468, Validation Loss: 0.9180\n",
      "Epoch [61/150], Train Loss: 0.0137, Validation Loss: 0.6128\n",
      "Epoch [62/150], Train Loss: 0.0097, Validation Loss: 0.5172\n",
      "Epoch [63/150], Train Loss: 0.0078, Validation Loss: 0.5056\n",
      "Epoch [64/150], Train Loss: 0.0294, Validation Loss: 2.9304\n",
      "Epoch [65/150], Train Loss: 0.0887, Validation Loss: 1.2856\n",
      "Epoch [66/150], Train Loss: 0.1092, Validation Loss: 6.5510\n",
      "Epoch [67/150], Train Loss: 0.0307, Validation Loss: 1.0901\n",
      "Epoch [68/150], Train Loss: 0.0257, Validation Loss: 1.5844\n",
      "Epoch [69/150], Train Loss: 0.0281, Validation Loss: 2.0136\n",
      "Epoch [70/150], Train Loss: 0.0392, Validation Loss: 3.9959\n",
      "Epoch [71/150], Train Loss: 0.0171, Validation Loss: 1.3742\n",
      "Epoch [72/150], Train Loss: 0.0180, Validation Loss: 0.8450\n",
      "Epoch [73/150], Train Loss: 0.0335, Validation Loss: 1.0816\n",
      "Epoch [74/150], Train Loss: 0.0087, Validation Loss: 0.7733\n",
      "Epoch [75/150], Train Loss: 0.0040, Validation Loss: 0.7381\n",
      "Epoch [76/150], Train Loss: 0.0109, Validation Loss: 0.9391\n",
      "Epoch [77/150], Train Loss: 0.0026, Validation Loss: 0.6629\n",
      "Epoch [78/150], Train Loss: 0.0028, Validation Loss: 0.6030\n",
      "Epoch [79/150], Train Loss: 0.0014, Validation Loss: 0.5946\n",
      "Epoch [80/150], Train Loss: 0.0020, Validation Loss: 0.6045\n",
      "Epoch [81/150], Train Loss: 0.0013, Validation Loss: 0.6174\n",
      "Epoch [82/150], Train Loss: 0.0109, Validation Loss: 0.6811\n",
      "Epoch [83/150], Train Loss: 0.0021, Validation Loss: 0.6309\n",
      "Epoch [84/150], Train Loss: 0.0055, Validation Loss: 0.6500\n",
      "Epoch [85/150], Train Loss: 0.0009, Validation Loss: 0.5825\n",
      "Epoch [86/150], Train Loss: 0.0015, Validation Loss: 0.5667\n",
      "Epoch [87/150], Train Loss: 0.0016, Validation Loss: 0.6083\n",
      "Epoch [88/150], Train Loss: 0.0804, Validation Loss: 2.3739\n",
      "Epoch [89/150], Train Loss: 0.0453, Validation Loss: 2.1802\n",
      "Epoch [90/150], Train Loss: 0.0323, Validation Loss: 1.7380\n",
      "Epoch [91/150], Train Loss: 0.0782, Validation Loss: 2.1151\n",
      "Epoch [92/150], Train Loss: 0.0226, Validation Loss: 1.0927\n",
      "Epoch [93/150], Train Loss: 0.0038, Validation Loss: 0.9433\n",
      "Epoch [94/150], Train Loss: 0.0719, Validation Loss: 1.8065\n",
      "Epoch [95/150], Train Loss: 0.0500, Validation Loss: 2.2149\n",
      "Epoch [96/150], Train Loss: 0.0221, Validation Loss: 0.8969\n",
      "Epoch [97/150], Train Loss: 0.0136, Validation Loss: 1.0186\n",
      "Epoch [98/150], Train Loss: 0.0054, Validation Loss: 1.1174\n",
      "Epoch [99/150], Train Loss: 0.0043, Validation Loss: 0.9690\n",
      "Epoch [100/150], Train Loss: 0.0157, Validation Loss: 1.0975\n",
      "Epoch [101/150], Train Loss: 0.0267, Validation Loss: 0.8678\n",
      "Epoch [102/150], Train Loss: 0.0036, Validation Loss: 0.6837\n",
      "Epoch [103/150], Train Loss: 0.0103, Validation Loss: 0.9341\n",
      "Epoch [104/150], Train Loss: 0.0103, Validation Loss: 1.9173\n",
      "Epoch [105/150], Train Loss: 0.0170, Validation Loss: 1.1267\n",
      "Epoch [106/150], Train Loss: 0.0045, Validation Loss: 0.8232\n",
      "Epoch [107/150], Train Loss: 0.0109, Validation Loss: 1.1393\n",
      "Epoch [108/150], Train Loss: 0.0185, Validation Loss: 1.7460\n",
      "Epoch [109/150], Train Loss: 0.0090, Validation Loss: 0.8823\n",
      "Epoch [110/150], Train Loss: 0.0054, Validation Loss: 0.7790\n",
      "Epoch [111/150], Train Loss: 0.0099, Validation Loss: 0.7839\n",
      "Epoch [112/150], Train Loss: 0.0055, Validation Loss: 0.8940\n",
      "Epoch [113/150], Train Loss: 0.0017, Validation Loss: 0.6640\n",
      "Epoch [114/150], Train Loss: 0.0009, Validation Loss: 0.7752\n",
      "Epoch [115/150], Train Loss: 0.0075, Validation Loss: 1.1327\n",
      "Epoch [116/150], Train Loss: 0.0013, Validation Loss: 0.7116\n",
      "Epoch [117/150], Train Loss: 0.0020, Validation Loss: 1.0141\n",
      "Epoch [118/150], Train Loss: 0.0014, Validation Loss: 0.6568\n",
      "Epoch [119/150], Train Loss: 0.0022, Validation Loss: 0.7609\n",
      "Epoch [120/150], Train Loss: 0.0013, Validation Loss: 0.7035\n",
      "Epoch [121/150], Train Loss: 0.0008, Validation Loss: 0.6499\n",
      "Epoch [122/150], Train Loss: 0.0008, Validation Loss: 0.6273\n",
      "Epoch [123/150], Train Loss: 0.0012, Validation Loss: 0.6515\n",
      "Epoch [124/150], Train Loss: 0.0005, Validation Loss: 0.6298\n",
      "Epoch [125/150], Train Loss: 0.0005, Validation Loss: 0.6019\n",
      "Epoch [126/150], Train Loss: 0.0023, Validation Loss: 0.7657\n",
      "Epoch [127/150], Train Loss: 0.0015, Validation Loss: 0.6735\n",
      "Epoch [128/150], Train Loss: 0.0007, Validation Loss: 0.6695\n",
      "Epoch [129/150], Train Loss: 0.0069, Validation Loss: 0.8107\n",
      "Epoch [130/150], Train Loss: 0.0018, Validation Loss: 0.6093\n",
      "Epoch [131/150], Train Loss: 0.0077, Validation Loss: 0.9346\n",
      "Epoch [132/150], Train Loss: 0.0009, Validation Loss: 0.8350\n",
      "Epoch [133/150], Train Loss: 0.0004, Validation Loss: 0.7603\n",
      "Epoch [134/150], Train Loss: 0.0124, Validation Loss: 0.7614\n",
      "Epoch [135/150], Train Loss: 0.0079, Validation Loss: 0.6538\n",
      "Epoch [136/150], Train Loss: 0.0008, Validation Loss: 0.6102\n",
      "Epoch [137/150], Train Loss: 0.0010, Validation Loss: 0.6209\n",
      "Epoch [138/150], Train Loss: 0.0013, Validation Loss: 0.5697\n",
      "Epoch [139/150], Train Loss: 0.0430, Validation Loss: 1.3619\n",
      "Epoch [140/150], Train Loss: 0.0058, Validation Loss: 1.0811\n",
      "Epoch [141/150], Train Loss: 0.0011, Validation Loss: 0.7738\n",
      "Epoch [142/150], Train Loss: 0.0009, Validation Loss: 0.7193\n",
      "Epoch [143/150], Train Loss: 0.0005, Validation Loss: 0.6879\n",
      "Epoch [144/150], Train Loss: 0.0004, Validation Loss: 0.6721\n",
      "Epoch [145/150], Train Loss: 0.0011, Validation Loss: 0.6175\n",
      "Epoch [146/150], Train Loss: 0.0005, Validation Loss: 0.6351\n",
      "Epoch [147/150], Train Loss: 0.0005, Validation Loss: 0.6450\n",
      "Epoch [148/150], Train Loss: 0.0010, Validation Loss: 0.7424\n",
      "Epoch [149/150], Train Loss: 0.0007, Validation Loss: 0.7620\n",
      "Epoch [150/150], Train Loss: 0.0004, Validation Loss: 0.7167\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# エポックの数\n",
    "max_epoch = 150\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net2 = matModel.cuda()\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "  \n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net2.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net2.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y = net2(x)\n",
    "        loss = criterion(y[0], t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net2.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "  \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net2(x)\n",
    "            loss = criterion(y[0], t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "\n",
    "matModel_trained = net2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "def ShowTrainLoss(train_losses,val_losses,save):\n",
    "    # 日本時間のタイムゾーンを取得\n",
    "    jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "    # 現在の日本時間を取得\n",
    "    now = datetime.now(jst)\n",
    "\n",
    "    # 時刻を指定された形式の文字列に変換\n",
    "    time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # 学習曲線の可視化\n",
    "\n",
    "    title = 'Training and Validation Losses Material'\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0,5)\n",
    "    plt.legend()\n",
    "    if save == True:\n",
    "        plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "ShowTrainLoss(train_losses,val_losses,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.3%\n",
      "Accuracy: 84.5%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8448)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y[0], dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            # x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net2(x)\n",
    "            \n",
    "            y_label = torch.argmax(y[0], dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### object 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1050, 1, 128, 130])\n",
      "525 262 263\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fdd2010edd0>\n",
      "[tensor([[[[-15.7372, -12.7907, -12.2806,  ..., -16.2258, -12.1957, -14.6959],\n",
      "          [-15.7418, -11.8346, -11.9373,  ..., -12.7932, -11.7111, -12.4843],\n",
      "          [-22.5785, -21.3953, -21.5793,  ..., -20.6679, -21.5296, -17.3727],\n",
      "          ...,\n",
      "          [-58.1976, -55.0280, -55.0888,  ..., -53.4471, -52.7718, -53.7474],\n",
      "          [-56.4661, -53.7698, -54.6103,  ..., -54.0908, -53.9045, -56.2288],\n",
      "          [-57.3117, -54.9557, -55.6911,  ..., -54.7845, -54.3604, -56.0656]]],\n",
      "\n",
      "\n",
      "        [[[ -5.8755,  -1.3352,   0.0000,  ...,  -8.2323,  -7.3307,  -8.7717],\n",
      "          [ -7.0860,  -4.6320,  -2.7805,  ...,  -6.8078,  -5.4152,  -6.6856],\n",
      "          [-14.4937, -18.4999, -18.0805,  ..., -15.1023, -14.4274, -11.6789],\n",
      "          ...,\n",
      "          [-50.1694, -46.3330, -44.8377,  ..., -47.9001, -46.6421, -47.7369],\n",
      "          [-49.2638, -46.9567, -46.7122,  ..., -46.9204, -46.5079, -49.3187],\n",
      "          [-46.9555, -45.9099, -47.1923,  ..., -47.8846, -48.9719, -50.9079]]],\n",
      "\n",
      "\n",
      "        [[[-14.0626, -12.4793, -12.4311,  ...,  -6.8308,  -6.2901, -10.4582],\n",
      "          [-18.8385, -19.3206, -16.3264,  ...,  -9.3470,  -9.8862, -12.6103],\n",
      "          [-26.0905, -30.3457, -25.2675,  ..., -20.0117, -23.9119, -21.9449],\n",
      "          ...,\n",
      "          [-53.3047, -52.0847, -53.4519,  ..., -52.4061, -53.3940, -56.5739],\n",
      "          [-58.1525, -54.5277, -52.5746,  ..., -53.0982, -53.9163, -56.1266],\n",
      "          [-55.2106, -52.8737, -53.1973,  ..., -52.8028, -52.4231, -54.3603]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -9.9831,  -7.1871, -11.7807,  ..., -11.2343,  -9.8302, -13.3886],\n",
      "          [-11.8676,  -9.5992, -15.2492,  ..., -12.9284, -12.4264, -17.9736],\n",
      "          [-19.0413, -18.4740, -26.9585,  ..., -21.7851, -23.7197, -26.1367],\n",
      "          ...,\n",
      "          [-53.6593, -52.2464, -51.7386,  ..., -51.2787, -51.4993, -56.2754],\n",
      "          [-55.0183, -52.9384, -52.6564,  ..., -51.3566, -51.8909, -54.7269],\n",
      "          [-56.5075, -52.0982, -52.3580,  ..., -51.7871, -52.0791, -53.2282]]],\n",
      "\n",
      "\n",
      "        [[[-17.2652, -11.0746,  -9.8907,  ...,  -0.6295,   0.0000,  -3.5875],\n",
      "          [-18.6370, -15.4748, -16.1502,  ...,  -6.1369,  -3.3467,  -4.0424],\n",
      "          [-28.6770, -30.6238, -34.6265,  ..., -19.3636, -16.2683, -12.0035],\n",
      "          ...,\n",
      "          [-56.7433, -54.9483, -56.3357,  ..., -56.7504, -55.6961, -54.8034],\n",
      "          [-59.7806, -56.2284, -55.0864,  ..., -54.5428, -54.2212, -54.7591],\n",
      "          [-60.2414, -56.0917, -55.5884,  ..., -56.2427, -55.2146, -53.6850]]],\n",
      "\n",
      "\n",
      "        [[[ -9.3511,  -5.2951,  -9.8728,  ..., -10.9083,  -9.2532, -11.2135],\n",
      "          [ -8.2031,  -6.5688, -12.9695,  ..., -10.1815, -11.6199, -10.9543],\n",
      "          [-13.0035, -13.6482, -18.5944,  ..., -16.5582, -14.2727, -13.9899],\n",
      "          ...,\n",
      "          [-45.4077, -44.2285, -46.0337,  ..., -45.8847, -45.8283, -47.6377],\n",
      "          [-47.8298, -45.4274, -44.8245,  ..., -45.7963, -45.1360, -47.9109],\n",
      "          [-46.2646, -44.5052, -46.9336,  ..., -47.0090, -46.8320, -47.4182]]]]), tensor([19,  4, 16, 18,  2,  7,  6, 13,  5, 11,  2, 18, 10, 18, 19, 18,  0,  0,\n",
      "         1,  6,  9,  9, 12, 17, 10])]\n",
      "[tensor([[[[ -6.0762,  -3.5017,  -3.3377,  ...,  -4.1093,  -2.1572,  -5.0010],\n",
      "          [ -8.7918,  -7.3907,  -5.0249,  ...,  -8.1448,  -4.9479,  -9.1982],\n",
      "          [ -9.1813,  -6.6263, -11.7422,  ...,  -8.8395, -12.1046, -19.2009],\n",
      "          ...,\n",
      "          [-52.7497, -48.8865, -48.6537,  ..., -51.1285, -49.8177, -50.1686],\n",
      "          [-50.9880, -48.3031, -49.1782,  ..., -49.3246, -50.4652, -51.6474],\n",
      "          [-53.7844, -50.3416, -49.3829,  ..., -49.5337, -51.0771, -51.4142]]],\n",
      "\n",
      "\n",
      "        [[[-23.0836, -17.6527, -16.0622,  ..., -10.6483, -10.1918, -12.0575],\n",
      "          [-23.1806, -22.3402, -18.6569,  ..., -13.4887, -13.7516, -13.3281],\n",
      "          [-26.3015, -25.4151, -28.7933,  ..., -27.0607, -24.7454, -19.3046],\n",
      "          ...,\n",
      "          [-66.6998, -62.6790, -60.6387,  ..., -61.7790, -61.7823, -62.4379],\n",
      "          [-63.1558, -60.9635, -61.3787,  ..., -63.1781, -63.1277, -62.9624],\n",
      "          [-64.4473, -63.1082, -63.1545,  ..., -62.6057, -62.2202, -63.7380]]],\n",
      "\n",
      "\n",
      "        [[[-19.4677, -13.8089, -14.6049,  ..., -10.6197,  -9.1130, -14.6017],\n",
      "          [-26.8576, -22.7456, -24.1618,  ..., -10.5441, -12.6558, -19.9263],\n",
      "          [-35.0707, -34.8668, -34.4597,  ..., -19.6834, -21.1026, -24.3130],\n",
      "          ...,\n",
      "          [-57.2477, -53.7524, -52.4263,  ..., -53.7950, -53.9968, -55.4982],\n",
      "          [-55.1792, -53.1644, -54.2603,  ..., -52.6724, -53.1959, -54.9959],\n",
      "          [-54.3971, -52.5030, -52.5609,  ..., -53.9797, -53.4432, -55.9142]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -6.2664,  -2.9890,  -5.2798,  ...,  -5.7535,  -4.7177,  -6.9648],\n",
      "          [ -7.5614,  -3.9616,  -7.6979,  ...,  -7.0264,  -8.9588, -11.5580],\n",
      "          [-15.4290, -14.8272, -17.7061,  ..., -19.6478, -22.2260, -23.2930],\n",
      "          ...,\n",
      "          [-51.9192, -50.1242, -49.7132,  ..., -47.8093, -47.7594, -49.0973],\n",
      "          [-52.1852, -48.6977, -48.1595,  ..., -47.4365, -47.7249, -49.1994],\n",
      "          [-51.3106, -48.8156, -48.8151,  ..., -47.7161, -48.4147, -50.3677]]],\n",
      "\n",
      "\n",
      "        [[[-12.9531,  -8.4623, -10.9949,  ..., -13.9743, -12.5583, -12.9040],\n",
      "          [-12.9575,  -9.1291,  -9.6971,  ..., -12.4427, -10.5136, -12.3491],\n",
      "          [-18.2892, -20.0374, -20.3422,  ..., -16.5155, -15.7638, -17.3400],\n",
      "          ...,\n",
      "          [-54.6013, -51.4329, -50.6813,  ..., -50.8779, -51.4110, -53.4678],\n",
      "          [-52.1137, -49.6309, -49.8039,  ..., -51.3086, -50.1676, -51.5474],\n",
      "          [-52.6111, -51.0972, -51.9317,  ..., -52.1191, -50.8958, -52.4753]]],\n",
      "\n",
      "\n",
      "        [[[-25.9034, -21.9119, -14.0451,  ...,  -5.3250,  -9.2805, -16.3978],\n",
      "          [-19.3675, -13.7969, -12.1835,  ...,  -7.1418,  -7.7071, -15.4302],\n",
      "          [-19.0328, -17.3201, -16.0753,  ..., -17.0908, -13.7243, -22.8432],\n",
      "          ...,\n",
      "          [-48.0925, -46.5962, -46.7822,  ..., -47.8841, -46.8159, -47.6297],\n",
      "          [-47.8132, -45.3680, -44.6936,  ..., -46.3455, -46.1164, -49.3973],\n",
      "          [-49.8005, -47.0284, -47.1830,  ..., -46.4303, -46.3429, -48.1432]]]]), tensor([ 0, 17, 13,  2, 10, 19,  5,  7, 13,  5,  0,  2,  0,  1,  5, 15,  2,  6,\n",
      "        12, 17, 12,  3,  6,  5, 10])]\n",
      "[tensor([[[[-10.0279,  -7.8579, -11.8001,  ..., -12.3195,  -7.2473,  -9.8667],\n",
      "          [-10.8272,  -8.6687, -14.2134,  ..., -12.5902,  -6.6770,  -8.9679],\n",
      "          [-17.5238, -18.0341, -23.8566,  ..., -20.1754, -14.4655, -14.4317],\n",
      "          ...,\n",
      "          [-53.8049, -51.9219, -53.2467,  ..., -50.7193, -51.2442, -53.0188],\n",
      "          [-54.4185, -52.8468, -53.4759,  ..., -52.1240, -51.0827, -54.4927],\n",
      "          [-55.8065, -52.5886, -52.4451,  ..., -53.5472, -51.6183, -53.5764]]],\n",
      "\n",
      "\n",
      "        [[[-10.7324,  -4.6517,  -3.8478,  ...,  -8.2309, -14.8002, -18.0520],\n",
      "          [-11.8236,  -6.3387,  -9.1619,  ..., -12.2978, -17.8332, -16.8948],\n",
      "          [-21.9459, -15.6345, -17.6357,  ..., -23.1039, -19.1691, -19.0841],\n",
      "          ...,\n",
      "          [-53.8330, -49.2684, -48.2273,  ..., -48.3188, -49.0298, -52.3784],\n",
      "          [-53.0411, -49.3866, -48.0516,  ..., -49.6745, -49.0690, -51.8535],\n",
      "          [-53.7364, -49.5175, -48.6195,  ..., -50.3162, -49.5507, -49.6395]]],\n",
      "\n",
      "\n",
      "        [[[ -7.1616,  -0.9457,   0.0000,  ...,  -5.7713,  -8.1283, -18.2104],\n",
      "          [ -7.6271,  -3.1601,  -2.3634,  ...,  -8.6473,  -7.9879, -13.6696],\n",
      "          [-13.9333, -14.6354, -14.1242,  ..., -19.9669, -18.1613, -17.1388],\n",
      "          ...,\n",
      "          [-54.6771, -51.6242, -50.7401,  ..., -50.1866, -50.7028, -51.4649],\n",
      "          [-54.6167, -51.3566, -50.3548,  ..., -51.2736, -51.6761, -52.4059],\n",
      "          [-52.7593, -50.6332, -51.0717,  ..., -49.3423, -51.7091, -53.6027]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -8.3681,  -5.1823,  -7.4577,  ...,  -3.7348,  -2.5485,  -6.6958],\n",
      "          [ -8.0277,  -4.9073,  -4.9623,  ...,  -4.2416,  -4.8608,  -9.5555],\n",
      "          [-13.0840, -13.7098, -12.8687,  ..., -17.7461, -19.1325, -21.0760],\n",
      "          ...,\n",
      "          [-50.0689, -46.2291, -45.4716,  ..., -46.8236, -47.4431, -49.0650],\n",
      "          [-50.4353, -47.2231, -45.5502,  ..., -46.8992, -46.7623, -48.7872],\n",
      "          [-48.1989, -46.7950, -47.2719,  ..., -46.1326, -46.5750, -47.0558]]],\n",
      "\n",
      "\n",
      "        [[[-24.0054, -16.5717, -12.2069,  ..., -10.8894, -11.0717, -14.5653],\n",
      "          [-26.5346, -21.9115, -16.5898,  ..., -15.5828, -16.0140, -14.1760],\n",
      "          [-30.1219, -23.5671, -23.9182,  ..., -19.3224, -19.7878, -16.0493],\n",
      "          ...,\n",
      "          [-55.0039, -50.1655, -47.9797,  ..., -48.1771, -49.0459, -50.6193],\n",
      "          [-50.9413, -48.6363, -49.1542,  ..., -50.7510, -50.4623, -51.4882],\n",
      "          [-51.2350, -50.3329, -50.0501,  ..., -51.2576, -50.9684, -51.8375]]],\n",
      "\n",
      "\n",
      "        [[[ -9.2767,  -5.4631,  -1.6625,  ..., -10.1021,  -7.4068,  -9.1599],\n",
      "          [ -7.2520,  -3.3959,  -2.4361,  ...,  -7.8024,  -6.9836,  -7.6628],\n",
      "          [-12.1627, -14.2867, -15.8049,  ..., -17.6147, -16.5750, -12.0232],\n",
      "          ...,\n",
      "          [-56.9290, -53.3854, -53.6736,  ..., -53.6213, -53.0371, -55.1418],\n",
      "          [-55.0039, -54.3032, -54.7474,  ..., -54.4607, -53.4741, -54.6051],\n",
      "          [-55.0830, -54.0245, -54.1530,  ..., -54.0167, -54.1413, -55.7217]]]]), tensor([ 9,  9,  7,  9, 10, 14, 14,  6,  4, 11,  7, 14, 19, 18, 10, 10, 19, 12,\n",
      "         5, 19,  0, 17, 20, 15, 18])]\n",
      "[tensor([[[[ -8.9003,  -5.6950,  -8.4137,  ...,  -7.9397, -14.6901, -13.7975],\n",
      "          [ -7.0621,  -4.2965,  -5.2679,  ...,  -6.8257, -10.7655, -12.5228],\n",
      "          [-12.1692, -14.2089, -16.3282,  ..., -14.7645, -16.9071, -14.4980],\n",
      "          ...,\n",
      "          [-51.3359, -48.0489, -47.7460,  ..., -48.3099, -47.7784, -49.3869],\n",
      "          [-49.6297, -48.2010, -48.3301,  ..., -48.2575, -48.2402, -50.6874],\n",
      "          [-50.8940, -48.3321, -48.8617,  ..., -48.8092, -48.8599, -50.0928]]],\n",
      "\n",
      "\n",
      "        [[[-17.7462, -15.1062, -26.7662,  ...,  -8.3707, -11.2060, -17.8887],\n",
      "          [-19.8870, -15.9270, -17.0375,  ..., -11.2934, -13.8616, -16.8674],\n",
      "          [-27.6479, -24.2454, -21.9514,  ..., -25.1244, -26.2341, -22.6001],\n",
      "          ...,\n",
      "          [-61.9573, -58.3460, -58.4538,  ..., -57.4640, -59.4890, -60.6936],\n",
      "          [-60.5880, -58.2899, -57.2648,  ..., -59.2312, -58.1507, -59.4468],\n",
      "          [-59.8953, -57.4230, -57.5208,  ..., -58.3148, -57.9805, -58.8456]]],\n",
      "\n",
      "\n",
      "        [[[-13.5176, -11.6368,  -8.7873,  ..., -17.7489, -16.9146, -20.3726],\n",
      "          [-16.1134, -14.8937, -12.4694,  ..., -18.9430, -14.6921, -16.7794],\n",
      "          [-22.4209, -19.2131, -22.1324,  ..., -22.3883, -22.1521, -21.7480],\n",
      "          ...,\n",
      "          [-51.0376, -48.7682, -49.6154,  ..., -49.2334, -49.2060, -50.9532],\n",
      "          [-54.0740, -50.1427, -49.8437,  ..., -49.6026, -50.2182, -51.0737],\n",
      "          [-50.7706, -48.5343, -48.9691,  ..., -50.4240, -50.7928, -52.9936]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-15.8294, -11.2537, -10.9465,  ..., -11.9487, -14.0252, -14.7746],\n",
      "          [-17.5562, -16.3954, -18.2899,  ..., -14.2846, -11.2523, -12.0967],\n",
      "          [-25.0954, -28.1919, -22.7930,  ..., -19.2034, -19.1958, -15.9922],\n",
      "          ...,\n",
      "          [-50.6322, -49.0325, -47.4819,  ..., -48.4302, -47.1102, -48.7352],\n",
      "          [-51.8628, -47.9553, -48.7344,  ..., -49.1368, -49.6521, -51.7342],\n",
      "          [-51.8983, -47.6698, -48.2550,  ..., -47.4888, -47.7807, -50.4829]]],\n",
      "\n",
      "\n",
      "        [[[-14.3831, -12.1354, -12.6169,  ..., -15.8074, -16.5729, -17.3791],\n",
      "          [-18.5885, -19.1402, -17.1982,  ..., -10.2863, -16.8677, -18.6861],\n",
      "          [-22.7160, -21.8464, -18.4663,  ..., -16.2206, -17.2931, -20.8829],\n",
      "          ...,\n",
      "          [-53.3006, -49.5118, -47.8410,  ..., -48.6413, -49.1530, -49.6687],\n",
      "          [-51.7591, -49.3027, -49.3969,  ..., -48.9461, -49.3949, -50.4807],\n",
      "          [-51.4795, -50.4085, -50.9016,  ..., -50.5438, -49.8652, -51.7285]]],\n",
      "\n",
      "\n",
      "        [[[-11.6841, -10.6428, -10.8915,  ...,  -1.7235,  -4.8453, -10.9071],\n",
      "          [-13.1581, -10.0602, -10.0689,  ...,  -3.7508,  -5.8531, -10.0624],\n",
      "          [-19.0680, -19.6948, -21.7907,  ..., -19.0947, -19.8550, -18.1728],\n",
      "          ...,\n",
      "          [-56.3883, -55.2090, -55.1556,  ..., -54.6343, -55.5138, -58.5798],\n",
      "          [-57.3524, -55.6003, -55.8850,  ..., -54.4737, -53.9710, -56.3188],\n",
      "          [-56.3898, -54.3298, -55.1854,  ..., -54.6399, -55.4026, -57.7112]]]]), tensor([20, 15,  4, 20, 17, 11,  9,  9,  0,  2, 15, 10,  8, 16, 16,  3, 18, 10,\n",
      "        17,  2, 20,  3, 10,  4, 14])]\n",
      "[tensor([[[[ -9.1439,  -6.3815,  -8.6553,  ...,  -9.9656, -15.8904, -22.7964],\n",
      "          [-12.4257, -10.7954, -15.2085,  ..., -11.7822, -20.2603, -23.9475],\n",
      "          [-20.7228, -24.3895, -28.4178,  ..., -24.0787, -26.8945, -27.7306],\n",
      "          ...,\n",
      "          [-50.6917, -48.3092, -48.8301,  ..., -50.6481, -49.7191, -51.0505],\n",
      "          [-51.6069, -48.9763, -49.3845,  ..., -50.7629, -50.2760, -51.0789],\n",
      "          [-52.5421, -50.3477, -51.9593,  ..., -49.8749, -50.1946, -52.2247]]],\n",
      "\n",
      "\n",
      "        [[[-12.8183,  -8.8736,  -9.9669,  ...,  -0.9775,  -1.1875,  -3.4887],\n",
      "          [-17.7811, -14.6838, -12.9425,  ...,  -5.8998,  -5.5387,  -6.5439],\n",
      "          [-26.6312, -26.0636, -23.6724,  ..., -25.0167, -22.3263, -16.4586],\n",
      "          ...,\n",
      "          [-58.4294, -54.7695, -54.3107,  ..., -55.4369, -54.4335, -56.1671],\n",
      "          [-59.0020, -54.6001, -54.8849,  ..., -52.7717, -53.4871, -55.4511],\n",
      "          [-58.0232, -54.3704, -54.5316,  ..., -54.1423, -53.6740, -55.1368]]],\n",
      "\n",
      "\n",
      "        [[[-15.6181, -17.4919, -20.0049,  ..., -11.2635, -18.8130, -19.6856],\n",
      "          [-17.4799, -19.6151, -21.3630,  ..., -11.9547, -16.5333, -17.9439],\n",
      "          [-23.0230, -26.7643, -25.9644,  ..., -21.4136, -18.9200, -21.3353],\n",
      "          ...,\n",
      "          [-57.8216, -55.8503, -55.6969,  ..., -53.9801, -54.6264, -56.9200],\n",
      "          [-59.3948, -56.9479, -56.4685,  ..., -53.6779, -54.0244, -55.7368],\n",
      "          [-57.8211, -55.0197, -55.2547,  ..., -55.0715, -54.6728, -57.3392]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-19.3755, -15.8834, -19.4765,  ..., -15.2986, -18.9731, -28.3482],\n",
      "          [-18.2080, -16.1983, -15.6329,  ..., -20.2465, -22.4688, -29.8424],\n",
      "          [-22.2617, -25.5475, -24.1155,  ..., -31.1005, -25.8298, -27.9543],\n",
      "          ...,\n",
      "          [-59.2608, -56.9048, -56.1722,  ..., -54.8316, -56.1192, -58.8295],\n",
      "          [-58.3115, -55.2242, -55.7536,  ..., -55.2191, -55.8394, -58.2460],\n",
      "          [-58.3019, -55.6733, -56.1740,  ..., -56.5903, -55.3230, -55.6876]]],\n",
      "\n",
      "\n",
      "        [[[-20.7064, -12.7469, -10.5713,  ...,  -5.6322, -11.0249, -23.3230],\n",
      "          [-23.0129, -15.8259, -15.6464,  ...,  -9.6322, -13.9740, -25.6630],\n",
      "          [-32.3584, -28.0187, -26.3400,  ..., -21.2980, -21.1598, -23.0218],\n",
      "          ...,\n",
      "          [-58.6716, -54.6895, -55.8372,  ..., -56.8688, -56.7343, -59.0497],\n",
      "          [-58.0728, -55.9267, -56.6812,  ..., -55.3060, -55.7754, -58.9926],\n",
      "          [-57.1548, -55.0041, -56.1730,  ..., -55.2742, -56.0316, -58.6850]]],\n",
      "\n",
      "\n",
      "        [[[-17.7484,  -7.8096,  -5.0597,  ...,  -7.1552, -10.3615, -15.7479],\n",
      "          [-24.1250, -11.6381,  -9.1836,  ..., -10.0575, -14.9263, -20.7033],\n",
      "          [-24.6713, -22.2962, -22.8559,  ..., -17.8255, -21.8843, -28.1199],\n",
      "          ...,\n",
      "          [-52.9812, -49.4930, -49.4893,  ..., -47.8044, -48.4419, -50.2379],\n",
      "          [-51.8783, -48.7094, -48.4333,  ..., -49.4847, -48.6194, -51.0819],\n",
      "          [-51.4531, -49.4110, -49.6053,  ..., -48.9175, -49.1056, -51.0907]]]]), tensor([12,  0,  7, 16, 14,  9,  8, 15, 18, 16, 18, 18,  4,  4,  4,  0, 13,  1,\n",
      "        18, 14,  7,  2, 17,  5,  3])]\n",
      "[tensor([[[[-17.0427, -14.9856, -19.9267,  ...,  -5.5589,  -7.6223,  -9.4907],\n",
      "          [-18.2477, -14.8280, -17.3509,  ...,  -6.7090, -12.1974, -12.1394],\n",
      "          [-26.8981, -25.3371, -20.1127,  ..., -16.3102, -16.0153, -16.4981],\n",
      "          ...,\n",
      "          [-53.9200, -51.8853, -52.4520,  ..., -53.6749, -51.8540, -53.6749],\n",
      "          [-55.1911, -52.7323, -53.3232,  ..., -54.3976, -54.8286, -56.5963],\n",
      "          [-54.7715, -52.9818, -53.6572,  ..., -53.8595, -53.5804, -54.8806]]],\n",
      "\n",
      "\n",
      "        [[[-10.5205, -12.1467, -11.9641,  ..., -11.1011,  -7.8841, -10.2488],\n",
      "          [-10.7204, -10.2712, -14.8051,  ..., -17.4890, -10.1350,  -9.9657],\n",
      "          [-15.4316, -14.7884, -19.3225,  ..., -20.4244, -19.5974, -16.2358],\n",
      "          ...,\n",
      "          [-48.4588, -47.1349, -46.9040,  ..., -47.7909, -47.2344, -49.7415],\n",
      "          [-50.3802, -47.2370, -45.4467,  ..., -47.3579, -46.4145, -48.9298],\n",
      "          [-51.0459, -48.2725, -48.0139,  ..., -46.4444, -47.2485, -48.7807]]],\n",
      "\n",
      "\n",
      "        [[[-11.1962,  -5.1562,  -3.9529,  ..., -13.7877, -13.9695, -18.9762],\n",
      "          [-11.6165, -10.5394, -10.5728,  ..., -20.3477, -17.0996, -21.1129],\n",
      "          [-17.8774, -21.0547, -26.0836,  ..., -28.4353, -27.5213, -30.6109],\n",
      "          ...,\n",
      "          [-55.0200, -53.2546, -53.1739,  ..., -54.1681, -53.8253, -56.4622],\n",
      "          [-57.6203, -53.9981, -53.5916,  ..., -53.0469, -53.1876, -55.7428],\n",
      "          [-58.0921, -53.5759, -52.9358,  ..., -54.2606, -55.0854, -56.0155]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-13.0929,  -8.1490,  -6.0740,  ...,  -9.0175,  -8.1026, -11.2404],\n",
      "          [-10.8897,  -6.2664,  -5.4600,  ..., -10.1410, -10.2522, -13.9232],\n",
      "          [-16.1681, -14.1593, -16.3334,  ..., -17.0501, -17.4465, -21.9007],\n",
      "          ...,\n",
      "          [-51.3174, -47.6784, -46.9831,  ..., -50.6825, -49.8886, -49.5048],\n",
      "          [-51.6961, -49.0685, -48.9114,  ..., -49.4049, -49.1464, -50.9212],\n",
      "          [-50.2888, -48.5087, -49.5262,  ..., -49.4060, -50.3186, -50.6697]]],\n",
      "\n",
      "\n",
      "        [[[-10.5740,  -6.6337,  -8.5231,  ...,  -8.6571,  -5.7712,  -7.2641],\n",
      "          [-13.8897, -10.3217, -13.4287,  ..., -16.9600, -11.8110,  -9.2367],\n",
      "          [-23.7448, -22.1353, -25.4149,  ..., -25.1986, -20.3145, -14.5135],\n",
      "          ...,\n",
      "          [-56.6444, -52.8006, -52.6621,  ..., -51.8420, -53.6470, -55.4209],\n",
      "          [-55.7708, -51.4955, -51.6007,  ..., -51.9611, -51.7362, -53.4997],\n",
      "          [-55.3219, -52.4044, -52.4623,  ..., -52.5349, -53.7143, -56.9817]]],\n",
      "\n",
      "\n",
      "        [[[ -5.3598,  -3.5870,  -7.7213,  ...,  -2.1239,  -7.6019, -16.7891],\n",
      "          [ -5.8658,  -5.3685,  -7.8181,  ...,  -4.0615,  -8.9067, -14.8545],\n",
      "          [-11.5583, -15.3547, -19.3934,  ..., -16.7265, -17.2696, -18.3079],\n",
      "          ...,\n",
      "          [-47.5734, -45.8095, -45.9924,  ..., -44.0620, -45.6469, -47.2745],\n",
      "          [-48.5098, -45.7572, -45.2733,  ..., -44.6914, -46.3110, -48.8676],\n",
      "          [-49.0852, -46.0152, -45.1482,  ..., -44.7064, -45.7651, -47.9350]]]]), tensor([ 7,  4, 13, 20,  5,  9,  7, 14,  9, 17,  7,  2, 19, 15, 19, 18, 17, 12,\n",
      "        17, 13,  1,  9, 15, 13, 10])]\n",
      "[tensor([[[[-16.5098, -13.6158, -13.7698,  ..., -20.1823, -15.1784, -14.9491],\n",
      "          [-17.1146, -14.5767, -15.2056,  ..., -17.9235, -14.7208, -14.5118],\n",
      "          [-20.5487, -19.4128, -19.8824,  ..., -25.1827, -23.9422, -20.0301],\n",
      "          ...,\n",
      "          [-51.9878, -48.7872, -49.3824,  ..., -49.1425, -48.0484, -49.6893],\n",
      "          [-51.2758, -49.8633, -49.9142,  ..., -50.0475, -49.9551, -51.1813],\n",
      "          [-53.1391, -51.0403, -50.3494,  ..., -51.4081, -50.0263, -50.0482]]],\n",
      "\n",
      "\n",
      "        [[[-10.7208,  -5.1715,  -4.3676,  ..., -10.5834, -11.5595, -16.9046],\n",
      "          [-12.3766,  -8.8231, -10.9925,  ..., -15.4747, -12.9223, -19.2970],\n",
      "          [-18.7908, -21.4462, -20.5267,  ..., -22.6840, -21.4934, -24.3930],\n",
      "          ...,\n",
      "          [-49.9995, -48.0103, -48.4120,  ..., -49.7643, -49.8806, -51.6831],\n",
      "          [-47.4270, -47.3056, -48.4698,  ..., -49.4439, -47.8779, -49.5320],\n",
      "          [-51.3528, -48.1071, -48.6567,  ..., -48.5554, -48.1139, -51.5024]]],\n",
      "\n",
      "\n",
      "        [[[-15.0478, -13.8001, -14.4621,  ..., -15.5620, -12.5570, -13.9192],\n",
      "          [-16.9501, -15.3223, -15.4388,  ..., -23.5943, -17.3096, -17.4727],\n",
      "          [-21.4123, -20.9109, -20.8366,  ..., -28.2529, -30.6608, -29.5175],\n",
      "          ...,\n",
      "          [-51.7909, -49.2375, -49.9399,  ..., -50.1581, -49.0799, -51.5343],\n",
      "          [-50.2857, -49.8086, -50.5261,  ..., -49.6846, -49.2241, -50.3883],\n",
      "          [-55.8301, -51.5755, -50.2552,  ..., -49.5259, -50.5020, -52.1422]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -7.5071,  -3.8854,  -4.2999,  ...,  -9.5368,  -5.0302,  -8.2657],\n",
      "          [ -6.8737,  -3.2673,  -4.4442,  ...,  -7.8864,  -4.6115,  -6.8085],\n",
      "          [-12.2169, -13.6799, -16.4138,  ..., -11.7323,  -9.3301, -12.1456],\n",
      "          ...,\n",
      "          [-53.6855, -49.2084, -48.6956,  ..., -47.9869, -48.6832, -50.5034],\n",
      "          [-52.8633, -50.2232, -48.7245,  ..., -48.7317, -48.8106, -49.9419],\n",
      "          [-51.5715, -49.3451, -48.4451,  ..., -50.2108, -50.0642, -52.4181]]],\n",
      "\n",
      "\n",
      "        [[[-11.8320,  -9.3900, -12.8467,  ...,  -8.0388, -12.1001, -16.2452],\n",
      "          [-14.0154, -11.1234, -13.2705,  ..., -10.9791, -21.3799, -25.7574],\n",
      "          [-21.1259, -20.0579, -16.5633,  ..., -17.7590, -18.4349, -24.7722],\n",
      "          ...,\n",
      "          [-48.7344, -46.6707, -47.3893,  ..., -47.9304, -47.0027, -49.1107],\n",
      "          [-50.8510, -47.1817, -45.4753,  ..., -47.5742, -47.8928, -49.5717],\n",
      "          [-51.1758, -47.2426, -46.3059,  ..., -46.3051, -46.9690, -50.1339]]],\n",
      "\n",
      "\n",
      "        [[[-14.4391,  -9.1209, -13.9443,  ...,   0.0000,  -2.8345, -10.3333],\n",
      "          [-15.8548, -12.0871, -15.2193,  ...,  -4.8612,  -9.4798, -14.0009],\n",
      "          [-24.0867, -24.5031, -22.1925,  ..., -19.7124, -24.7431, -22.2317],\n",
      "          ...,\n",
      "          [-51.8401, -49.6562, -49.8052,  ..., -50.2163, -49.5208, -51.2952],\n",
      "          [-51.6299, -48.7858, -48.9311,  ..., -48.2765, -49.9220, -50.6108],\n",
      "          [-51.8833, -49.2698, -50.0158,  ..., -48.9768, -50.1476, -53.0972]]]]), tensor([15,  5, 13, 19, 19, 14,  1, 10, 16,  8, 14,  7, 15, 12, 11,  6,  8,  2,\n",
      "        15, 18, 17,  2, 20,  4, 18])]\n",
      "[tensor([[[[-12.9459, -10.7339, -10.5763,  ..., -20.9138, -20.2874, -14.5386],\n",
      "          [-16.2831, -17.0857, -17.3435,  ..., -20.9503, -15.2757, -11.8472],\n",
      "          [-19.1016, -23.3032, -27.8499,  ..., -24.8851, -16.8646, -13.7081],\n",
      "          ...,\n",
      "          [-56.1595, -54.5195, -52.6238,  ..., -53.5836, -51.8603, -54.6450],\n",
      "          [-55.6095, -52.5743, -51.9246,  ..., -53.2095, -52.6188, -55.5935],\n",
      "          [-56.4487, -52.2921, -53.7554,  ..., -52.4024, -51.2213, -51.8921]]],\n",
      "\n",
      "\n",
      "        [[[-18.0209, -11.7379, -10.2200,  ...,  -4.2470,   0.0000,  -3.4826],\n",
      "          [-23.1801, -15.6190, -14.9000,  ...,  -7.3462,  -2.9329,  -4.3133],\n",
      "          [-33.2646, -23.7604, -21.9551,  ..., -20.5872, -16.4038, -11.7417],\n",
      "          ...,\n",
      "          [-56.7785, -52.5463, -51.7002,  ..., -53.8370, -52.9018, -53.2154],\n",
      "          [-56.1939, -54.8628, -54.4604,  ..., -52.7387, -52.6176, -52.2500],\n",
      "          [-54.6674, -52.6126, -53.7326,  ..., -52.3661, -52.9609, -54.0416]]],\n",
      "\n",
      "\n",
      "        [[[-18.3027, -15.4641,  -9.5809,  ..., -11.0653, -12.1972, -19.5427],\n",
      "          [-19.2963, -18.3188, -13.0030,  ..., -15.4253, -15.2683, -24.6046],\n",
      "          [-20.2961, -20.8818, -20.8779,  ..., -24.6880, -25.6998, -30.8342],\n",
      "          ...,\n",
      "          [-48.0807, -45.6483, -45.3463,  ..., -47.3056, -47.6561, -47.9204],\n",
      "          [-47.8975, -44.5405, -43.8399,  ..., -47.5982, -47.1712, -48.2320],\n",
      "          [-48.5111, -45.4942, -44.9434,  ..., -46.1690, -44.6446, -46.2503]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.3386,  -8.1295,  -9.4182,  ...,  -3.5372,  -6.9823, -12.3089],\n",
      "          [-14.2323, -10.6343, -11.0549,  ...,  -6.1847, -12.1914, -14.8063],\n",
      "          [-23.5425, -23.3458, -19.9860,  ..., -17.2117, -20.5783, -20.5997],\n",
      "          ...,\n",
      "          [-49.5552, -46.5474, -46.3638,  ..., -47.1317, -46.2887, -47.9489],\n",
      "          [-50.2128, -46.6963, -46.5049,  ..., -46.7846, -48.3372, -50.4113],\n",
      "          [-49.7589, -48.1748, -49.3193,  ..., -48.4582, -49.2449, -50.2379]]],\n",
      "\n",
      "\n",
      "        [[[-11.0291,  -5.0556,  -7.3908,  ...,  -5.4382,  -8.5189, -14.6596],\n",
      "          [-11.8465,  -8.6335,  -9.1775,  ..., -10.5531, -13.6293, -21.6308],\n",
      "          [-17.3718, -17.8354, -16.5804,  ..., -19.8602, -21.2210, -25.3905],\n",
      "          ...,\n",
      "          [-50.1780, -48.1141, -49.1871,  ..., -47.1003, -47.3462, -50.3536],\n",
      "          [-49.9736, -48.0062, -49.3661,  ..., -47.9526, -48.1708, -51.8342],\n",
      "          [-52.2147, -48.4390, -48.6952,  ..., -48.9274, -48.7183, -51.3020]]],\n",
      "\n",
      "\n",
      "        [[[-12.6869,  -6.1255,  -5.5152,  ...,  -5.7381,  -3.4278,  -6.2596],\n",
      "          [-13.6166, -11.1559,  -8.7832,  ..., -11.3911,  -7.8598, -11.0899],\n",
      "          [-18.3389, -18.4038, -21.8603,  ..., -21.9691, -21.5309, -24.5514],\n",
      "          ...,\n",
      "          [-53.4539, -51.1406, -50.9320,  ..., -51.7844, -51.3928, -51.3885],\n",
      "          [-55.7355, -52.1812, -51.9173,  ..., -51.1953, -51.1556, -51.4325],\n",
      "          [-55.7891, -53.1854, -52.2578,  ..., -50.8765, -51.2024, -53.7012]]]]), tensor([ 2,  7, 11,  3, 11, 12,  1,  3, 13, 15, 19, 16,  1, 14, 11,  6, 12,  9,\n",
      "        10,  5,  1,  0, 10,  6,  6])]\n",
      "[tensor([[[[ -5.1685,  -3.5431,  -6.1680,  ...,  -0.0917,  -0.7231,  -5.5518],\n",
      "          [ -7.6702,  -7.7361, -11.8104,  ...,  -6.2485,  -5.7362,  -8.8374],\n",
      "          [-13.8354, -15.0222, -20.2270,  ..., -22.6714, -23.3922, -22.0796],\n",
      "          ...,\n",
      "          [-55.2056, -52.8139, -52.3971,  ..., -52.7700, -53.1397, -54.7791],\n",
      "          [-55.8079, -52.0751, -50.6632,  ..., -52.3088, -52.0392, -54.6527],\n",
      "          [-56.1405, -53.2581, -52.3736,  ..., -53.7071, -53.6263, -53.4978]]],\n",
      "\n",
      "\n",
      "        [[[-10.6643,  -7.3887,  -8.8921,  ...,  -8.2710,  -7.0803, -11.5905],\n",
      "          [-10.7584,  -8.7772,  -8.7842,  ..., -12.7270,  -8.9024, -12.9026],\n",
      "          [-16.5672, -21.2453, -18.7724,  ..., -17.3295, -18.4741, -22.8398],\n",
      "          ...,\n",
      "          [-53.2704, -50.3550, -51.5633,  ..., -50.3345, -51.2440, -53.5748],\n",
      "          [-51.9836, -50.0980, -50.9822,  ..., -50.7501, -52.0841, -52.2893],\n",
      "          [-52.8884, -51.2494, -51.7744,  ..., -50.7838, -51.9005, -53.4901]]],\n",
      "\n",
      "\n",
      "        [[[-12.4899, -12.6390, -18.3412,  ..., -11.5354, -11.1510, -11.5272],\n",
      "          [-10.6332, -11.0089, -16.0313,  ..., -11.6983, -10.5265, -11.8239],\n",
      "          [-14.1030, -14.8124, -21.2318,  ..., -15.8251, -16.3481, -18.2146],\n",
      "          ...,\n",
      "          [-52.3472, -50.5478, -50.0083,  ..., -51.3235, -50.5600, -52.0638],\n",
      "          [-54.1867, -51.5227, -51.9898,  ..., -53.0278, -52.5103, -52.9369],\n",
      "          [-53.4603, -51.6214, -52.9473,  ..., -52.4769, -51.4700, -52.2444]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-18.7897, -15.7237, -19.1669,  ...,  -2.5864,  -3.4854,  -8.3363],\n",
      "          [-17.5980, -15.9615, -24.4952,  ..., -10.9740,  -9.5510, -10.4342],\n",
      "          [-23.2868, -20.0114, -26.7704,  ..., -31.7439, -22.8537, -20.2259],\n",
      "          ...,\n",
      "          [-55.7549, -51.1689, -50.3053,  ..., -50.8378, -50.6562, -53.0983],\n",
      "          [-54.3370, -50.7302, -50.5244,  ..., -51.5256, -51.2671, -51.4067],\n",
      "          [-55.3706, -51.2870, -50.2594,  ..., -52.2861, -51.2770, -52.1787]]],\n",
      "\n",
      "\n",
      "        [[[-19.4503, -11.6368,  -6.7816,  ..., -12.0678,  -8.9254,  -9.2904],\n",
      "          [-14.8976,  -8.0731,  -6.4716,  ..., -15.7901, -11.9013, -12.1636],\n",
      "          [-17.3328, -15.8321, -17.5205,  ..., -22.3996, -16.8316, -18.6882],\n",
      "          ...,\n",
      "          [-55.9450, -52.5807, -53.6123,  ..., -52.4918, -53.1196, -56.1903],\n",
      "          [-56.1926, -52.4201, -52.3664,  ..., -52.7488, -52.3760, -53.7092],\n",
      "          [-56.5493, -52.8165, -52.9666,  ..., -53.1975, -52.5657, -54.5543]]],\n",
      "\n",
      "\n",
      "        [[[ -8.2463,  -1.5153,  -0.3417,  ...,  -0.0767,  -0.2532,  -5.6081],\n",
      "          [ -7.9649,  -2.4761,  -3.8179,  ...,  -1.0361,  -2.4826,  -7.4762],\n",
      "          [-15.5043, -13.3370, -16.3814,  ..., -13.8375, -16.0605, -16.8942],\n",
      "          ...,\n",
      "          [-52.0576, -47.6453, -47.5434,  ..., -50.1476, -49.5708, -50.5257],\n",
      "          [-52.1544, -48.6912, -47.6840,  ..., -50.1298, -51.6062, -52.9518],\n",
      "          [-53.5745, -50.4228, -49.4765,  ..., -49.7564, -49.9691, -51.0382]]]]), tensor([ 2,  9,  1, 13, 11, 13, 10,  6,  8, 14, 10, 12, 20, 18, 19,  9, 16,  0,\n",
      "        17, 14,  5,  2,  4,  2,  7])]\n",
      "[tensor([[[[-11.7756,  -7.0410,  -4.9498,  ...,  -9.3433,  -6.6749,  -8.1286],\n",
      "          [-16.8265, -12.4159, -10.2116,  ...,  -8.9402,  -7.7014,  -9.2996],\n",
      "          [-22.2347, -21.5294, -20.6842,  ..., -16.5950, -21.3083, -17.7230],\n",
      "          ...,\n",
      "          [-52.1803, -50.2204, -50.7931,  ..., -50.7613, -50.6474, -51.4796],\n",
      "          [-53.6427, -51.5287, -50.7069,  ..., -49.1984, -50.5256, -53.1105],\n",
      "          [-53.3888, -50.0538, -50.9244,  ..., -50.5473, -49.6493, -52.5006]]],\n",
      "\n",
      "\n",
      "        [[[-16.8677, -10.9837, -11.5365,  ..., -17.7769, -14.8101, -12.9792],\n",
      "          [-16.3892, -12.8971, -14.8058,  ..., -26.5489, -17.9043, -13.9401],\n",
      "          [-21.4324, -22.9268, -26.4240,  ..., -31.6903, -24.6109, -19.1836],\n",
      "          ...,\n",
      "          [-55.8700, -52.3636, -51.3638,  ..., -50.5106, -52.0963, -54.2482],\n",
      "          [-56.1806, -52.7200, -51.4017,  ..., -50.6342, -51.1227, -53.4283],\n",
      "          [-57.3869, -54.4889, -53.0539,  ..., -54.0687, -52.3150, -53.6756]]],\n",
      "\n",
      "\n",
      "        [[[-11.7163,  -4.6254,  -3.2696,  ..., -16.9017, -12.0346, -14.7881],\n",
      "          [-12.1810,  -7.0967,  -6.9876,  ..., -15.8202, -15.7874, -15.3310],\n",
      "          [-20.1109, -21.1059, -22.1745,  ..., -18.4897, -20.9831, -20.7972],\n",
      "          ...,\n",
      "          [-50.0040, -47.9352, -48.0505,  ..., -48.1633, -48.3408, -50.5797],\n",
      "          [-52.1636, -49.2911, -48.9361,  ..., -48.9829, -48.4587, -51.9963],\n",
      "          [-53.8949, -50.1011, -49.6775,  ..., -49.2414, -48.3503, -52.0036]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -8.0873,  -7.3582,  -7.8443,  ..., -12.2081, -11.0819,  -8.1737],\n",
      "          [-10.2855, -11.8433, -10.3012,  ...,  -9.5623,  -9.5996,  -8.4761],\n",
      "          [-16.7114, -16.3081, -19.1141,  ..., -15.3856, -15.3966, -14.3635],\n",
      "          ...,\n",
      "          [-52.9925, -51.6669, -51.2964,  ..., -47.6690, -50.3343, -54.7010],\n",
      "          [-53.0450, -50.2613, -51.2696,  ..., -49.3092, -50.2960, -51.7941],\n",
      "          [-51.0952, -48.8961, -50.2779,  ..., -48.1650, -49.5840, -52.3887]]],\n",
      "\n",
      "\n",
      "        [[[-11.7221,  -7.5009,  -4.9032,  ...,  -3.8887,  -2.3518,  -5.2582],\n",
      "          [-12.1687,  -6.4206,  -4.1923,  ...,  -3.6549,  -2.2777,  -4.3293],\n",
      "          [-19.7003, -17.7530, -17.0349,  ..., -15.9735, -14.7695, -11.0209],\n",
      "          ...,\n",
      "          [-55.3763, -53.5250, -53.1544,  ..., -53.0976, -53.6414, -54.5680],\n",
      "          [-57.2011, -54.6884, -53.9950,  ..., -53.2046, -54.7418, -55.1734],\n",
      "          [-54.8278, -52.9933, -53.7695,  ..., -55.1222, -55.4178, -56.0121]]],\n",
      "\n",
      "\n",
      "        [[[-32.0508, -18.6434, -15.1491,  ..., -23.5368, -24.9932, -32.0979],\n",
      "          [-31.0583, -20.0940, -18.5767,  ..., -30.2197, -28.5712, -33.5006],\n",
      "          [-35.3113, -28.8498, -30.7482,  ..., -34.2117, -27.9173, -28.0230],\n",
      "          ...,\n",
      "          [-58.8011, -56.6923, -58.5047,  ..., -56.8365, -55.2544, -56.6119],\n",
      "          [-59.9491, -56.5991, -56.6075,  ..., -57.2557, -57.4822, -59.0407],\n",
      "          [-60.0381, -57.1882, -55.2488,  ..., -54.3049, -55.9977, -60.8532]]]]), tensor([ 0, 16,  4, 12,  3, 10, 16, 17,  4,  7,  4,  2,  6, 18, 20,  1, 12, 16,\n",
      "        16, 17,  4, 14,  1, 14, 17])]\n",
      "[tensor([[[[-13.8820, -13.2763, -12.7538,  ...,  -5.6196,  -4.1067,  -8.6514],\n",
      "          [-15.5819, -19.0227, -19.7076,  ...,  -8.1158,  -7.6211, -10.1307],\n",
      "          [-18.5374, -20.9645, -31.7378,  ..., -14.6175, -18.0286, -17.5111],\n",
      "          ...,\n",
      "          [-51.7487, -49.4922, -50.8934,  ..., -48.3644, -49.7760, -52.1333],\n",
      "          [-51.9308, -50.1141, -51.3312,  ..., -50.5186, -50.3585, -52.3874],\n",
      "          [-53.7617, -50.5438, -50.3975,  ..., -50.3885, -49.3604, -51.6796]]],\n",
      "\n",
      "\n",
      "        [[[ -3.6491,  -0.1169,  -1.2708,  ..., -15.0683, -18.6120, -16.5309],\n",
      "          [ -7.5189,  -4.7812,  -6.0383,  ..., -12.9051, -12.8131, -14.1332],\n",
      "          [-17.1251, -19.8379, -17.7177,  ..., -18.6443, -15.8214, -17.1822],\n",
      "          ...,\n",
      "          [-53.1104, -50.6421, -50.9671,  ..., -49.0212, -50.9348, -53.4743],\n",
      "          [-54.4481, -52.0334, -51.3920,  ..., -50.2045, -51.1214, -52.6923],\n",
      "          [-53.0755, -51.1130, -49.9918,  ..., -50.5614, -50.6246, -53.7614]]],\n",
      "\n",
      "\n",
      "        [[[ -9.7955,  -5.9862,  -3.8906,  ...,  -1.4620,  -6.8214, -12.6527],\n",
      "          [ -8.9254,  -3.9711,  -3.1762,  ...,  -1.2694,  -3.6564,  -9.0598],\n",
      "          [-14.6580, -14.2811, -15.4592,  ..., -13.5096, -13.4330, -13.1754],\n",
      "          ...,\n",
      "          [-55.6674, -53.4809, -53.3736,  ..., -53.4829, -54.8861, -55.5131],\n",
      "          [-56.9255, -55.2635, -54.5886,  ..., -53.6918, -53.9781, -54.3855],\n",
      "          [-56.1894, -53.2439, -53.3132,  ..., -54.0230, -53.9033, -54.7176]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -9.3630,  -8.0156, -10.7116,  ..., -15.6980, -18.4390, -22.9805],\n",
      "          [-11.0363, -10.8332, -16.3648,  ..., -12.0238, -11.7764, -16.9739],\n",
      "          [-17.6310, -19.5291, -27.1900,  ..., -18.5102, -14.0359, -19.7002],\n",
      "          ...,\n",
      "          [-56.1942, -53.0955, -53.3711,  ..., -53.7066, -53.6759, -55.7073],\n",
      "          [-55.1096, -52.2083, -52.4010,  ..., -52.3425, -51.5793, -54.9182],\n",
      "          [-55.2412, -52.8344, -52.3349,  ..., -54.3277, -52.6744, -54.7175]]],\n",
      "\n",
      "\n",
      "        [[[-16.5507, -16.8092, -13.3030,  ..., -11.8545,  -7.5122,  -7.1141],\n",
      "          [-17.8905, -15.7555, -15.3671,  ..., -12.9508,  -8.6334,  -8.8057],\n",
      "          [-22.0580, -20.2114, -21.9231,  ..., -21.1280, -17.4335, -16.1876],\n",
      "          ...,\n",
      "          [-51.2254, -49.3412, -48.4575,  ..., -48.8502, -49.8611, -52.1791],\n",
      "          [-51.9451, -48.5081, -48.4278,  ..., -48.6097, -48.3876, -50.1398],\n",
      "          [-52.1920, -49.4794, -48.2586,  ..., -48.9832, -49.5116, -51.7586]]],\n",
      "\n",
      "\n",
      "        [[[-12.6704, -10.0989, -15.7285,  ...,  -1.1067,  -4.9090, -11.6635],\n",
      "          [-17.0735, -12.7654, -14.1774,  ...,  -4.9070,  -9.1263, -17.1113],\n",
      "          [-24.4590, -19.2597, -19.7641,  ..., -18.5482, -19.4238, -18.5840],\n",
      "          ...,\n",
      "          [-61.6435, -58.9187, -57.5728,  ..., -59.3153, -58.2450, -59.3043],\n",
      "          [-60.0850, -57.6033, -56.7001,  ..., -58.3688, -58.7643, -59.3651],\n",
      "          [-62.3474, -59.6540, -58.1206,  ..., -57.3825, -57.4624, -59.3069]]]]), tensor([ 1,  3, 14,  3,  9,  4, 14,  8,  1, 12, 15,  0, 10, 11, 20,  0, 15,  3,\n",
      "         7, 10, 18, 18,  0,  8,  8])]\n",
      "[tensor([[[[ -7.6809,  -1.3894,  -6.1454,  ...,  -3.2551,  -6.2737, -16.9419],\n",
      "          [ -8.9156,  -3.4992,  -4.9761,  ...,  -5.3517,  -9.1741, -21.1846],\n",
      "          [-18.6063, -13.1490, -12.8090,  ..., -17.3216, -20.5329, -24.9092],\n",
      "          ...,\n",
      "          [-46.4100, -42.4945, -41.8615,  ..., -41.1409, -42.9757, -43.2790],\n",
      "          [-46.7894, -42.9631, -42.8739,  ..., -42.9658, -42.4366, -46.0061],\n",
      "          [-46.6880, -43.2702, -43.5808,  ..., -42.4506, -41.8991, -46.7900]]],\n",
      "\n",
      "\n",
      "        [[[-10.9027,  -5.9879,  -4.8815,  ..., -12.9866, -12.6573, -23.0787],\n",
      "          [-11.0216, -12.6848, -10.1498,  ..., -14.9163, -13.8779, -19.4198],\n",
      "          [-14.9135, -17.6198, -21.9165,  ..., -25.8100, -23.9186, -22.0997],\n",
      "          ...,\n",
      "          [-54.8032, -52.6899, -51.4362,  ..., -49.7228, -49.5046, -52.7644],\n",
      "          [-54.9945, -53.0867, -51.7927,  ..., -52.5484, -52.0616, -53.3008],\n",
      "          [-52.5169, -51.2426, -52.4969,  ..., -52.0333, -51.2828, -52.8398]]],\n",
      "\n",
      "\n",
      "        [[[-15.9130,  -9.9528,  -7.5890,  ..., -11.2977, -10.1811, -12.3607],\n",
      "          [-21.2572, -14.8245, -11.5313,  ..., -16.5643, -16.8365, -18.4382],\n",
      "          [-33.1820, -24.2761, -21.9110,  ..., -27.6454, -28.7181, -27.4541],\n",
      "          ...,\n",
      "          [-50.6144, -49.4790, -49.2020,  ..., -49.9200, -50.9647, -52.2441],\n",
      "          [-52.9786, -50.4453, -50.5858,  ..., -49.9498, -49.8033, -51.3987],\n",
      "          [-53.1406, -51.3434, -51.0862,  ..., -49.2642, -49.5327, -49.3084]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -6.2205,  -3.8830,  -4.9260,  ...,  -3.4583,  -2.2113,  -4.2974],\n",
      "          [ -6.9878,  -3.6763,  -4.0112,  ...,  -3.6516,  -2.7743,  -4.7081],\n",
      "          [-14.9627, -15.9165, -17.0534,  ..., -17.2712, -15.9078, -12.9416],\n",
      "          ...,\n",
      "          [-55.6110, -51.7466, -50.3878,  ..., -52.5192, -50.9247, -53.7009],\n",
      "          [-53.5899, -49.8057, -50.3230,  ..., -52.8653, -52.6432, -55.3551],\n",
      "          [-55.4416, -52.3089, -51.4771,  ..., -51.5620, -51.0621, -52.7299]]],\n",
      "\n",
      "\n",
      "        [[[-18.3339,  -9.2998,  -4.6474,  ..., -12.3196, -14.5386, -20.0846],\n",
      "          [-20.7360, -15.5852,  -7.0846,  ..., -14.6952, -17.1643, -24.0331],\n",
      "          [-26.5389, -24.6012, -16.0612,  ..., -22.2092, -19.4099, -23.9425],\n",
      "          ...,\n",
      "          [-51.2855, -47.6523, -48.5198,  ..., -48.6568, -48.5462, -50.3284],\n",
      "          [-52.5481, -49.4531, -48.6133,  ..., -48.4802, -48.6068, -50.3791],\n",
      "          [-52.2420, -49.7171, -48.2370,  ..., -49.4797, -50.1228, -51.8326]]],\n",
      "\n",
      "\n",
      "        [[[-12.6616,  -8.2074,  -9.9863,  ...,  -9.5144, -17.3313, -22.6666],\n",
      "          [-15.6575, -12.6969, -15.0423,  ..., -11.6336, -14.0662, -18.8411],\n",
      "          [-19.4713, -17.0566, -17.6623,  ..., -18.6267, -19.1972, -20.3666],\n",
      "          ...,\n",
      "          [-50.4674, -48.8755, -48.1325,  ..., -48.3828, -48.9122, -51.1367],\n",
      "          [-51.4188, -49.2578, -49.7904,  ..., -48.0029, -47.9695, -50.3255],\n",
      "          [-52.1345, -49.0089, -48.0940,  ..., -48.2453, -48.6368, -51.7287]]]]), tensor([11, 16,  1,  1,  0, 15, 20,  4, 13,  1, 19,  3, 10,  1,  4, 12,  2,  9,\n",
      "         0,  5, 20,  3, 14,  6,  3])]\n",
      "[tensor([[[[-12.3534,  -8.1414,  -7.3962,  ...,  -9.6710, -10.2073, -18.5057],\n",
      "          [-15.8491, -12.5674, -10.7024,  ..., -13.2207, -11.3987, -18.4529],\n",
      "          [-24.6950, -25.3183, -25.8794,  ..., -25.2772, -20.0603, -21.6492],\n",
      "          ...,\n",
      "          [-58.5614, -54.2405, -53.9698,  ..., -55.7635, -55.6912, -56.3000],\n",
      "          [-57.0635, -54.4432, -55.9435,  ..., -54.1819, -54.7409, -55.6478],\n",
      "          [-57.2229, -55.7335, -56.3952,  ..., -56.5256, -54.9140, -55.9728]]],\n",
      "\n",
      "\n",
      "        [[[ -4.0662,  -0.3494,   0.0000,  ...,  -4.6714,  -3.9676,  -8.6064],\n",
      "          [-10.3888,  -7.2953,  -5.8475,  ...,  -9.4470,  -8.2664, -10.5236],\n",
      "          [-17.5188, -18.0142, -23.6312,  ..., -20.8997, -20.2381, -17.0905],\n",
      "          ...,\n",
      "          [-54.4361, -50.9694, -49.5850,  ..., -50.9147, -48.4651, -49.2708],\n",
      "          [-53.5730, -49.8567, -50.6208,  ..., -51.8278, -50.4198, -52.0098],\n",
      "          [-53.8774, -52.0039, -51.2027,  ..., -49.0434, -48.4871, -52.2826]]],\n",
      "\n",
      "\n",
      "        [[[ -6.0855,  -4.9794,  -8.9611,  ...,  -4.5734,  -8.1216, -14.2574],\n",
      "          [ -8.3703,  -7.9510, -12.9993,  ...,  -3.3616,  -4.6402, -10.8244],\n",
      "          [-15.2722, -17.3643, -18.1749,  ..., -13.3375, -12.6844, -15.5775],\n",
      "          ...,\n",
      "          [-53.7831, -50.6899, -50.5273,  ..., -49.9324, -49.5276, -51.8852],\n",
      "          [-54.1276, -53.2184, -51.3571,  ..., -50.0235, -49.4541, -51.1497],\n",
      "          [-52.8796, -50.6453, -50.6585,  ..., -50.6192, -50.4637, -52.1600]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.5110,  -7.9269,  -7.1359,  ...,  -6.5687,  -8.4930, -13.5501],\n",
      "          [-16.0248, -13.7008, -10.5023,  ...,  -9.8067, -12.3579, -14.6271],\n",
      "          [-23.0445, -20.5140, -20.6409,  ..., -22.6591, -21.4507, -22.0410],\n",
      "          ...,\n",
      "          [-54.8558, -53.1715, -52.6942,  ..., -55.3365, -54.3472, -55.8967],\n",
      "          [-55.5346, -53.1642, -52.5521,  ..., -53.4395, -53.8366, -55.6236],\n",
      "          [-56.6218, -53.3334, -55.0011,  ..., -53.3813, -52.2190, -54.2354]]],\n",
      "\n",
      "\n",
      "        [[[-21.5801, -15.6315, -14.7686,  ..., -19.2304, -22.4431, -26.7380],\n",
      "          [-26.2056, -20.6170, -16.6030,  ..., -16.2064, -18.8988, -23.0298],\n",
      "          [-33.2804, -28.7255, -21.4495,  ..., -24.0527, -27.0809, -27.6899],\n",
      "          ...,\n",
      "          [-55.4699, -52.1332, -50.2111,  ..., -51.3910, -51.0190, -54.0519],\n",
      "          [-54.2748, -50.5112, -50.0293,  ..., -52.0322, -52.3634, -54.5737],\n",
      "          [-53.5809, -51.2456, -51.6310,  ..., -51.4344, -51.5829, -53.4043]]],\n",
      "\n",
      "\n",
      "        [[[ -9.9556,  -8.0223, -15.5049,  ...,  -5.8669,  -7.9880, -15.8333],\n",
      "          [ -7.7237,  -6.1376, -10.2059,  ...,  -5.8948, -10.3746, -19.1705],\n",
      "          [-11.4615, -14.8107, -14.7004,  ..., -17.7533, -22.1156, -32.2179],\n",
      "          ...,\n",
      "          [-51.2957, -49.0700, -49.1583,  ..., -48.1738, -49.3872, -52.2161],\n",
      "          [-50.7348, -48.1175, -49.4220,  ..., -47.8958, -48.5351, -49.4556],\n",
      "          [-50.5864, -48.8926, -49.5004,  ..., -48.6794, -49.1842, -52.3914]]]]), tensor([ 4,  0,  8,  9, 12,  3,  3,  9,  0,  6,  3, 17,  6,  5, 11, 16, 15,  4,\n",
      "        12,  8,  9,  5,  6, 13,  8])]\n",
      "[tensor([[[[-17.3370, -13.6840, -18.9090,  ...,  -6.2777,  -8.6486, -16.0327],\n",
      "          [-22.4095, -18.8803, -17.4200,  ..., -10.2325, -13.0265, -21.1505],\n",
      "          [-28.2006, -22.0807, -20.6433,  ..., -18.2779, -23.1035, -28.7418],\n",
      "          ...,\n",
      "          [-58.2493, -54.7077, -52.7674,  ..., -55.4682, -53.3706, -53.8794],\n",
      "          [-56.9645, -54.1312, -52.3820,  ..., -53.6517, -52.9824, -54.0226],\n",
      "          [-58.1695, -54.5925, -53.9564,  ..., -52.4616, -52.3464, -54.8691]]],\n",
      "\n",
      "\n",
      "        [[[ -8.0931,  -3.0809,  -2.1194,  ...,  -2.4892,  -3.2072,  -5.9954],\n",
      "          [ -8.8219,  -3.6177,  -2.6965,  ...,  -2.7955,  -3.2077,  -5.1771],\n",
      "          [-16.2112, -16.0135, -16.6433,  ..., -16.2770, -15.9546, -12.2362],\n",
      "          ...,\n",
      "          [-54.1955, -53.2327, -54.2320,  ..., -53.0093, -53.6045, -54.3664],\n",
      "          [-55.6548, -53.5421, -54.4195,  ..., -52.1077, -52.6243, -54.1062],\n",
      "          [-58.7440, -54.3559, -54.2793,  ..., -52.4463, -52.1186, -54.6892]]],\n",
      "\n",
      "\n",
      "        [[[ -9.6498,  -6.2075,  -4.5347,  ...,  -3.5316,  -4.4289,  -4.4301],\n",
      "          [ -9.5448,  -5.8848,  -5.0769,  ...,  -2.5754,  -3.3229,  -4.6227],\n",
      "          [-15.3968, -16.7912, -18.0456,  ..., -14.1376, -15.4660, -11.7303],\n",
      "          ...,\n",
      "          [-54.1135, -51.7630, -51.7465,  ..., -51.6635, -52.8606, -52.8051],\n",
      "          [-53.7857, -51.8269, -51.9632,  ..., -53.6480, -53.6472, -54.0929],\n",
      "          [-55.9510, -54.0242, -53.8441,  ..., -52.1160, -53.5992, -55.9835]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-19.3030, -20.0919, -14.3340,  ...,  -1.1654,  -4.4234, -15.1536],\n",
      "          [-17.3505, -16.7345, -13.2978,  ...,  -1.8424,  -3.4892, -11.1512],\n",
      "          [-21.5774, -23.9938, -20.7966,  ..., -10.2834, -12.9977, -13.8153],\n",
      "          ...,\n",
      "          [-53.1820, -51.2893, -52.1281,  ..., -50.9769, -50.3367, -52.9549],\n",
      "          [-55.8379, -51.9040, -52.0206,  ..., -50.9986, -51.2125, -53.2668],\n",
      "          [-55.7550, -52.6171, -52.5296,  ..., -52.2303, -52.8020, -53.9154]]],\n",
      "\n",
      "\n",
      "        [[[-11.1603,  -5.8698,  -5.5590,  ..., -11.9730, -12.3221, -11.9913],\n",
      "          [-12.4443,  -8.4158,  -7.2249,  ..., -15.0613, -12.1208, -13.6823],\n",
      "          [-21.6478, -22.9541, -19.5704,  ..., -17.1054, -19.1276, -21.0368],\n",
      "          ...,\n",
      "          [-47.0859, -46.2030, -46.4313,  ..., -44.2340, -44.1578, -46.9369],\n",
      "          [-48.9116, -46.0197, -45.4827,  ..., -44.7112, -45.0200, -47.0736],\n",
      "          [-50.2629, -46.8827, -46.5767,  ..., -45.6073, -46.9797, -48.5544]]],\n",
      "\n",
      "\n",
      "        [[[ -8.9465,  -4.9386,  -3.4910,  ...,  -8.8267,  -6.6299, -10.4541],\n",
      "          [-11.3466,  -9.8318,  -8.1840,  ..., -11.4609,  -7.0067, -10.0628],\n",
      "          [-18.8256, -24.1063, -22.3295,  ..., -17.7201, -17.6753, -18.2109],\n",
      "          ...,\n",
      "          [-56.3092, -54.5021, -54.6962,  ..., -54.3815, -55.0944, -58.3650],\n",
      "          [-57.5449, -54.3026, -53.5777,  ..., -55.1495, -55.4923, -57.5995],\n",
      "          [-56.4856, -56.0001, -56.5582,  ..., -55.7848, -55.2925, -56.0462]]]]), tensor([15, 14, 18, 12,  4,  7, 17, 16,  2,  6, 19, 19, 11, 14,  2, 11,  9,  5,\n",
      "        19, 12,  7, 15, 19,  4,  8])]\n",
      "[tensor([[[[-1.3163e+01, -1.3713e+01, -5.7044e+00,  ..., -1.2634e+01,\n",
      "           -1.5390e+01, -1.5345e+01],\n",
      "          [-1.2363e+01, -1.0146e+01, -7.4118e+00,  ..., -1.5231e+01,\n",
      "           -2.1727e+01, -1.8272e+01],\n",
      "          [-1.7476e+01, -1.6215e+01, -1.7197e+01,  ..., -2.2400e+01,\n",
      "           -2.5497e+01, -2.2533e+01],\n",
      "          ...,\n",
      "          [-5.1182e+01, -4.7666e+01, -4.9066e+01,  ..., -4.9475e+01,\n",
      "           -4.9563e+01, -5.2183e+01],\n",
      "          [-5.2512e+01, -5.0168e+01, -5.0191e+01,  ..., -5.0816e+01,\n",
      "           -5.0405e+01, -5.3730e+01],\n",
      "          [-5.1582e+01, -5.0124e+01, -5.0477e+01,  ..., -4.9791e+01,\n",
      "           -4.8661e+01, -5.0672e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8231e+01, -1.5682e+01, -1.6320e+01,  ..., -1.0946e+01,\n",
      "           -1.6421e+01, -2.0916e+01],\n",
      "          [-2.1584e+01, -2.1924e+01, -1.9308e+01,  ..., -1.6133e+01,\n",
      "           -2.4725e+01, -2.7363e+01],\n",
      "          [-2.5565e+01, -2.4838e+01, -2.4402e+01,  ..., -2.5382e+01,\n",
      "           -2.8689e+01, -3.0411e+01],\n",
      "          ...,\n",
      "          [-5.5260e+01, -5.1811e+01, -5.1724e+01,  ..., -5.4572e+01,\n",
      "           -5.2932e+01, -5.4526e+01],\n",
      "          [-5.2874e+01, -5.1235e+01, -5.1454e+01,  ..., -5.2265e+01,\n",
      "           -5.3131e+01, -5.6713e+01],\n",
      "          [-5.5489e+01, -5.3212e+01, -5.2562e+01,  ..., -5.1594e+01,\n",
      "           -5.2086e+01, -5.4104e+01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1001e+01, -1.1171e+01, -5.3095e+00,  ..., -1.7959e+00,\n",
      "           -8.4892e-01, -4.4087e+00],\n",
      "          [-1.6136e+01, -8.5612e+00, -6.8571e+00,  ..., -4.9754e+00,\n",
      "           -1.9684e+00, -5.6396e+00],\n",
      "          [-1.9678e+01, -1.6660e+01, -1.9172e+01,  ..., -1.8701e+01,\n",
      "           -1.3089e+01, -1.4169e+01],\n",
      "          ...,\n",
      "          [-5.3229e+01, -5.2300e+01, -5.2039e+01,  ..., -5.1505e+01,\n",
      "           -5.0635e+01, -5.2131e+01],\n",
      "          [-5.2583e+01, -5.1240e+01, -5.1056e+01,  ..., -5.1894e+01,\n",
      "           -5.0664e+01, -5.1814e+01],\n",
      "          [-5.2456e+01, -5.0066e+01, -5.1281e+01,  ..., -5.1113e+01,\n",
      "           -5.1398e+01, -5.3474e+01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.7889e+00, -5.3173e-02,  0.0000e+00,  ..., -1.3146e+01,\n",
      "           -1.3671e+01, -1.9899e+01],\n",
      "          [-9.5718e+00, -9.7293e+00, -8.9567e+00,  ..., -1.0821e+01,\n",
      "           -1.3538e+01, -2.3663e+01],\n",
      "          [-1.7641e+01, -1.7799e+01, -2.0182e+01,  ..., -1.7725e+01,\n",
      "           -2.0284e+01, -2.8764e+01],\n",
      "          ...,\n",
      "          [-4.6298e+01, -4.3867e+01, -4.4462e+01,  ..., -4.2813e+01,\n",
      "           -4.3264e+01, -4.6480e+01],\n",
      "          [-4.7597e+01, -4.4798e+01, -4.6027e+01,  ..., -4.4467e+01,\n",
      "           -4.4975e+01, -4.6983e+01],\n",
      "          [-4.6886e+01, -4.2917e+01, -4.3735e+01,  ..., -4.4047e+01,\n",
      "           -4.4016e+01, -4.7508e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9714e+01, -1.4077e+01, -1.0484e+01,  ..., -9.4866e+00,\n",
      "           -1.0080e+01, -1.4313e+01],\n",
      "          [-2.1948e+01, -1.4893e+01, -1.1055e+01,  ..., -1.3739e+01,\n",
      "           -1.2502e+01, -1.8532e+01],\n",
      "          [-2.1884e+01, -2.0928e+01, -1.5884e+01,  ..., -2.1130e+01,\n",
      "           -1.9600e+01, -2.5277e+01],\n",
      "          ...,\n",
      "          [-5.3528e+01, -5.1130e+01, -5.1114e+01,  ..., -4.9709e+01,\n",
      "           -5.0251e+01, -5.3770e+01],\n",
      "          [-5.5577e+01, -5.1963e+01, -5.0338e+01,  ..., -4.9454e+01,\n",
      "           -5.0415e+01, -5.4143e+01],\n",
      "          [-5.5766e+01, -5.1828e+01, -5.1872e+01,  ..., -5.2364e+01,\n",
      "           -5.4275e+01, -5.4615e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0949e+01, -8.2982e+00, -9.4104e+00,  ..., -8.3833e+00,\n",
      "           -1.0680e+01, -1.7655e+01],\n",
      "          [-1.4225e+01, -1.3354e+01, -1.2044e+01,  ..., -1.1007e+01,\n",
      "           -1.4488e+01, -2.0791e+01],\n",
      "          [-2.1753e+01, -2.3312e+01, -2.4889e+01,  ..., -2.6160e+01,\n",
      "           -2.6580e+01, -3.0275e+01],\n",
      "          ...,\n",
      "          [-5.5445e+01, -5.1929e+01, -5.1407e+01,  ..., -5.1096e+01,\n",
      "           -5.0680e+01, -5.1394e+01],\n",
      "          [-5.6412e+01, -5.3327e+01, -5.2589e+01,  ..., -5.1193e+01,\n",
      "           -5.1988e+01, -5.4647e+01],\n",
      "          [-5.4574e+01, -5.2384e+01, -5.2588e+01,  ..., -5.1052e+01,\n",
      "           -5.2922e+01, -5.4676e+01]]]]), tensor([11, 16,  2, 15, 10, 13,  6, 15, 11, 18, 16,  5,  4, 12, 12, 20, 17, 17,\n",
      "         6, 14, 13, 17, 11,  1,  9])]\n",
      "[tensor([[[[-10.5757,  -3.9565,  -2.4490,  ..., -14.0344,  -9.8667,  -8.6727],\n",
      "          [-11.0136,  -6.4531,  -5.1831,  ..., -15.6522, -15.9574, -11.5940],\n",
      "          [-16.8577, -18.9107, -17.7916,  ..., -25.2219, -21.9087, -16.2473],\n",
      "          ...,\n",
      "          [-49.0824, -47.5911, -48.4652,  ..., -47.4768, -46.8074, -49.4357],\n",
      "          [-50.9669, -46.5640, -47.5060,  ..., -47.9900, -48.4327, -50.0647],\n",
      "          [-50.7123, -46.7355, -48.1979,  ..., -49.1863, -48.1227, -50.5570]]],\n",
      "\n",
      "\n",
      "        [[[ -5.2120,  -4.1334,  -4.2097,  ...,  -3.1277,  -4.9027,  -9.8809],\n",
      "          [ -5.6036,  -2.7944,  -3.4257,  ...,  -1.8790,  -2.7097,  -7.4012],\n",
      "          [-12.0036, -13.3965, -15.7236,  ..., -13.7522, -12.8860, -12.6874],\n",
      "          ...,\n",
      "          [-55.8372, -55.1540, -55.6561,  ..., -54.8882, -53.8076, -53.9245],\n",
      "          [-57.1962, -55.5976, -54.3309,  ..., -53.6039, -53.9144, -54.7926],\n",
      "          [-57.5957, -53.3097, -53.5559,  ..., -52.3026, -52.0629, -55.3671]]],\n",
      "\n",
      "\n",
      "        [[[-10.9055,  -8.4470,  -7.5049,  ...,  -7.8123,  -8.2866,  -8.0311],\n",
      "          [-11.2018, -12.1854, -13.8080,  ...,  -8.2462,  -6.4423,  -8.3171],\n",
      "          [-16.2980, -16.6967, -25.5274,  ..., -18.9832, -15.7927, -17.1252],\n",
      "          ...,\n",
      "          [-47.6100, -45.3317, -44.1492,  ..., -43.8832, -44.8364, -47.1210],\n",
      "          [-46.9981, -43.2093, -44.3806,  ..., -44.0768, -44.4132, -46.8178],\n",
      "          [-47.9968, -46.1935, -45.9198,  ..., -44.9125, -44.4910, -47.1867]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-21.2481, -13.2318, -11.4360,  ..., -15.2457, -15.5091, -14.6598],\n",
      "          [-17.2403, -12.1630, -12.5750,  ..., -13.9417, -12.8999, -13.9763],\n",
      "          [-21.7108, -21.8343, -25.2063,  ..., -23.5583, -21.1637, -18.0900],\n",
      "          ...,\n",
      "          [-57.6918, -54.9767, -55.4636,  ..., -55.7728, -55.3717, -57.3948],\n",
      "          [-56.7882, -55.5966, -55.6308,  ..., -56.3670, -58.5222, -60.3500],\n",
      "          [-56.5126, -56.1400, -57.2627,  ..., -55.5291, -55.8905, -58.4184]]],\n",
      "\n",
      "\n",
      "        [[[ -8.8491,  -3.4978,  -2.1545,  ...,  -1.4982,  -2.7293,  -5.5224],\n",
      "          [-10.6318,  -8.1585,  -9.1547,  ...,  -6.2677,  -6.8292,  -7.6696],\n",
      "          [-17.5509, -18.6270, -23.1745,  ..., -18.0806, -17.0130, -17.8795],\n",
      "          ...,\n",
      "          [-55.0710, -53.1003, -52.7147,  ..., -54.3135, -54.2095, -54.4146],\n",
      "          [-56.1594, -53.1380, -52.6578,  ..., -54.8881, -52.9731, -53.5724],\n",
      "          [-57.9322, -53.9722, -51.9583,  ..., -54.1590, -52.9439, -53.9007]]],\n",
      "\n",
      "\n",
      "        [[[-16.7492, -12.9213, -15.4992,  ..., -12.9660, -18.1481, -28.5464],\n",
      "          [-16.1996, -16.6247, -23.7688,  ..., -17.7725, -19.2445, -21.1943],\n",
      "          [-21.6059, -22.9027, -25.0755,  ..., -29.1831, -24.5935, -21.2665],\n",
      "          ...,\n",
      "          [-59.5307, -55.9166, -53.8853,  ..., -52.0816, -53.1255, -55.9003],\n",
      "          [-56.8013, -54.8264, -54.2567,  ..., -51.6883, -52.1367, -53.6113],\n",
      "          [-54.8412, -54.4343, -53.4510,  ..., -52.3981, -52.6179, -53.7668]]]]), tensor([ 4, 14, 10,  6, 17, 20, 11, 12,  7, 15,  5,  1, 19,  2,  1,  1,  0, 20,\n",
      "         7,  7, 15, 10, 20,  8, 16])]\n",
      "[tensor([[[[ -4.5473,  -6.2138,  -8.2985,  ...,  -9.9810,  -7.5181,  -8.0491],\n",
      "          [ -4.6183,  -6.6108,  -7.8492,  ...,  -9.0374, -12.7874, -10.7625],\n",
      "          [ -7.9839,  -7.1070, -11.3627,  ...,  -8.2434, -12.9951, -14.6108],\n",
      "          ...,\n",
      "          [-53.3331, -49.3938, -48.5414,  ..., -50.9687, -50.4058, -52.9669],\n",
      "          [-53.4087, -50.9847, -49.7883,  ..., -51.6659, -51.4237, -50.6602],\n",
      "          [-53.9578, -51.2299, -50.1041,  ..., -48.0495, -49.1640, -52.8801]]],\n",
      "\n",
      "\n",
      "        [[[-29.0853, -25.9006, -20.9731,  ...,  -4.6901,  -3.4193,  -6.6621],\n",
      "          [-31.8727, -30.8039, -26.8090,  ...,  -9.3810,  -8.3873, -10.8362],\n",
      "          [-34.7868, -31.7465, -26.1857,  ..., -22.7420, -23.9624, -23.2167],\n",
      "          ...,\n",
      "          [-56.9019, -54.4784, -53.9953,  ..., -51.4284, -52.9841, -54.8922],\n",
      "          [-55.0232, -53.2602, -52.1002,  ..., -51.9545, -52.1367, -54.1389],\n",
      "          [-57.8918, -54.3597, -53.4134,  ..., -53.0290, -53.1905, -53.7613]]],\n",
      "\n",
      "\n",
      "        [[[-12.3970, -12.6769, -11.6861,  ...,  -8.7590,  -8.7376, -15.7222],\n",
      "          [-13.7573, -12.4105, -11.5589,  ..., -10.1950,  -9.7541, -16.6158],\n",
      "          [-21.0281, -21.3274, -19.8277,  ..., -20.4875, -20.1054, -26.3162],\n",
      "          ...,\n",
      "          [-58.3173, -55.6905, -55.1446,  ..., -56.4763, -55.9175, -57.1586],\n",
      "          [-57.4746, -55.1483, -55.9968,  ..., -54.8604, -56.6697, -57.0417],\n",
      "          [-58.5717, -55.8531, -55.7319,  ..., -56.2001, -56.9702, -58.9404]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-13.5728, -14.9611, -20.2619,  ...,  -5.9169,  -4.7809,  -8.8456],\n",
      "          [-12.5747, -13.8058, -19.0077,  ...,  -9.9999,  -9.2723, -10.9084],\n",
      "          [-15.6077, -18.4661, -21.2161,  ..., -25.4814, -20.5172, -17.7988],\n",
      "          ...,\n",
      "          [-55.8372, -53.0905, -52.1294,  ..., -51.2333, -52.2833, -55.3700],\n",
      "          [-55.6846, -53.1335, -53.1861,  ..., -53.7703, -52.5696, -56.3729],\n",
      "          [-55.9756, -53.4670, -53.9101,  ..., -54.4707, -52.9915, -54.3717]]],\n",
      "\n",
      "\n",
      "        [[[-19.8387, -19.1716, -19.8422,  ..., -13.1208, -14.9518, -16.8472],\n",
      "          [-18.7445, -16.9057, -18.9242,  ..., -11.5250, -16.7029, -16.0062],\n",
      "          [-22.2301, -20.9569, -23.2562,  ..., -18.8113, -18.8529, -21.0423],\n",
      "          ...,\n",
      "          [-51.6377, -48.9324, -49.3959,  ..., -49.5261, -49.0410, -50.5903],\n",
      "          [-52.5942, -48.7486, -48.6424,  ..., -50.0788, -49.2967, -50.9648],\n",
      "          [-52.7858, -49.8041, -49.2364,  ..., -49.7302, -49.9798, -51.4836]]],\n",
      "\n",
      "\n",
      "        [[[-11.1326, -10.5856, -14.7633,  ..., -14.8453, -12.1551, -15.0998],\n",
      "          [-12.4634, -11.9332, -16.5080,  ..., -15.3169, -13.5214, -16.0434],\n",
      "          [-18.5694, -22.5046, -23.3326,  ..., -27.7116, -25.4419, -23.5093],\n",
      "          ...,\n",
      "          [-62.1397, -58.9528, -59.2467,  ..., -59.4400, -59.5343, -62.5773],\n",
      "          [-60.5881, -59.8082, -60.4605,  ..., -61.3787, -59.6531, -60.5962],\n",
      "          [-61.0361, -58.9775, -59.5100,  ..., -59.5443, -59.5720, -60.2610]]]]), tensor([ 3,  9, 11, 20,  7,  2,  6, 11, 17,  4,  9,  5, 18, 19,  8, 11,  0,  1,\n",
      "         3,  6, 11,  7,  0,  9, 18])]\n",
      "[tensor([[[[-14.5727,  -9.6321,  -9.2103,  ..., -11.8275, -12.9413, -14.7009],\n",
      "          [-14.8433, -10.5649, -10.4794,  ..., -11.4483, -14.5512, -22.0689],\n",
      "          [-19.2211, -19.8117, -23.7096,  ..., -19.3841, -21.9057, -22.2750],\n",
      "          ...,\n",
      "          [-48.0494, -45.3691, -45.0387,  ..., -44.0265, -44.6877, -46.3299],\n",
      "          [-47.9073, -45.6596, -44.2975,  ..., -43.3746, -44.3873, -46.3455],\n",
      "          [-46.8101, -43.1942, -42.5134,  ..., -44.2990, -44.3076, -46.7911]]],\n",
      "\n",
      "\n",
      "        [[[-11.4160,  -7.3010,  -6.6249,  ...,  -7.3409,  -7.4026,  -7.1805],\n",
      "          [-14.4316,  -9.6936,  -9.6551,  ..., -10.6789, -12.1702,  -8.9309],\n",
      "          [-23.1466, -21.0663, -21.5290,  ..., -16.4595, -22.0419, -14.9949],\n",
      "          ...,\n",
      "          [-53.4368, -51.5554, -52.7034,  ..., -53.0157, -51.8218, -53.0765],\n",
      "          [-55.1234, -52.2997, -52.0330,  ..., -52.9236, -53.6745, -53.7170],\n",
      "          [-55.4410, -52.7464, -54.5536,  ..., -52.0832, -51.6558, -53.0386]]],\n",
      "\n",
      "\n",
      "        [[[-25.4292, -21.1790, -22.2339,  ...,  -5.7871,  -9.1459, -14.4599],\n",
      "          [-26.4267, -23.9548, -24.4095,  ...,  -9.5116, -14.7796, -18.1322],\n",
      "          [-33.1059, -28.9126, -29.1085,  ..., -24.1106, -23.1945, -24.7255],\n",
      "          ...,\n",
      "          [-51.1722, -47.9533, -48.7014,  ..., -50.8125, -51.2782, -53.2235],\n",
      "          [-50.1713, -49.4649, -49.1165,  ..., -52.0051, -51.0308, -51.5985],\n",
      "          [-52.8469, -51.0000, -48.9094,  ..., -51.7971, -51.5983, -53.4973]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-10.5673,  -3.9909,  -2.2397,  ...,  -5.5005,  -9.2543, -11.1301],\n",
      "          [-12.1509, -11.3756,  -8.1727,  ...,  -9.4391, -16.0497, -16.9221],\n",
      "          [-18.5598, -21.9601, -23.0297,  ..., -23.3890, -22.1037, -25.7802],\n",
      "          ...,\n",
      "          [-52.5944, -51.0127, -51.3107,  ..., -49.6637, -48.0445, -49.6687],\n",
      "          [-52.9727, -50.3655, -51.2536,  ..., -50.5060, -49.5551, -51.8140],\n",
      "          [-51.6009, -49.8333, -50.5489,  ..., -49.9480, -49.9710, -53.0863]]],\n",
      "\n",
      "\n",
      "        [[[-31.1283, -19.7714, -13.0959,  ..., -15.0967, -13.8639, -12.3390],\n",
      "          [-28.8814, -18.6744, -14.8699,  ..., -15.0312, -14.5804, -12.8169],\n",
      "          [-27.4124, -22.4962, -26.7199,  ..., -21.2707, -22.0196, -19.5442],\n",
      "          ...,\n",
      "          [-56.3981, -53.3566, -54.6137,  ..., -54.7959, -55.6958, -57.0505],\n",
      "          [-60.1292, -54.9629, -54.1229,  ..., -53.5637, -53.8974, -56.5261],\n",
      "          [-59.2950, -54.1326, -54.6737,  ..., -53.2280, -54.1052, -56.9463]]],\n",
      "\n",
      "\n",
      "        [[[-15.2821, -11.3767, -11.9845,  ...,  -8.2670,  -8.7736, -12.1539],\n",
      "          [-16.1250, -13.5754, -12.0899,  ...,  -9.9776, -11.9258, -13.2226],\n",
      "          [-21.2551, -22.1299, -22.0504,  ..., -23.9481, -23.7623, -18.9937],\n",
      "          ...,\n",
      "          [-52.6190, -49.9110, -49.1751,  ..., -49.4075, -48.4457, -50.3696],\n",
      "          [-54.6232, -51.2046, -49.7113,  ..., -51.4984, -49.5948, -50.0063],\n",
      "          [-53.9702, -50.4028, -50.4095,  ..., -50.6015, -49.4070, -52.4006]]]]), tensor([16,  7, 13,  7,  5, 17,  0,  6,  3,  2,  0,  1,  7,  1, 18, 14,  2,  9,\n",
      "         6, 16, 18,  2,  5,  3, 12])]\n",
      "[tensor([[[[-20.4516, -17.9941, -20.7322,  ..., -10.1277,  -9.5659, -13.3434],\n",
      "          [-19.9730, -19.4323, -24.4138,  ..., -12.8505, -15.7333, -17.6391],\n",
      "          [-24.7819, -27.8253, -29.0989,  ..., -25.7507, -26.0385, -24.3234],\n",
      "          ...,\n",
      "          [-61.4442, -56.9441, -57.8352,  ..., -59.6203, -58.7586, -60.7551],\n",
      "          [-63.3090, -58.8948, -57.7879,  ..., -58.1593, -57.8995, -59.4014],\n",
      "          [-63.7417, -58.9781, -58.3609,  ..., -58.3074, -59.4399, -61.0138]]],\n",
      "\n",
      "\n",
      "        [[[-16.6691,  -6.9946,  -4.2131,  ...,  -4.6266,  -8.2105, -20.6552],\n",
      "          [-18.8094, -14.4730, -11.0312,  ...,  -8.4841, -11.0249, -22.1196],\n",
      "          [-30.1462, -28.0029, -26.0084,  ..., -21.5683, -20.1793, -19.5037],\n",
      "          ...,\n",
      "          [-56.2467, -52.7388, -52.5563,  ..., -53.2897, -53.3861, -55.1204],\n",
      "          [-56.1644, -53.2781, -54.2015,  ..., -55.0455, -55.1568, -57.1638],\n",
      "          [-56.9713, -53.0619, -52.9821,  ..., -55.6448, -54.6392, -57.0169]]],\n",
      "\n",
      "\n",
      "        [[[-18.9631, -13.8646,  -6.3394,  ...,  -5.7576,  -8.7145,  -9.8001],\n",
      "          [-14.4478,  -9.7717,  -6.0515,  ...,  -5.1902,  -6.5360,  -9.6219],\n",
      "          [-15.2846, -12.2192, -13.8214,  ..., -16.2318, -13.9726, -16.0866],\n",
      "          ...,\n",
      "          [-55.2470, -51.1208, -50.1670,  ..., -53.1796, -51.7913, -52.6755],\n",
      "          [-54.4827, -51.3380, -49.9832,  ..., -52.8669, -53.0000, -54.9691],\n",
      "          [-55.3948, -52.0201, -50.5608,  ..., -52.0717, -52.1901, -55.3488]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -7.9592,  -3.1344,  -2.6511,  ..., -10.3558, -11.6797, -17.3033],\n",
      "          [ -9.0071,  -7.6488, -11.3487,  ..., -11.8102,  -9.2244, -13.1895],\n",
      "          [-14.0929, -17.4014, -23.1372,  ..., -15.3419, -17.5167, -15.7416],\n",
      "          ...,\n",
      "          [-50.5680, -45.4783, -44.7638,  ..., -46.7668, -43.6946, -46.2976],\n",
      "          [-49.7016, -48.4203, -47.4780,  ..., -46.1984, -46.1178, -48.5836],\n",
      "          [-49.5079, -47.1403, -47.2599,  ..., -47.6474, -47.2906, -49.3603]]],\n",
      "\n",
      "\n",
      "        [[[-19.5398, -10.2152,  -8.2142,  ...,  -5.7538, -13.2875, -14.3327],\n",
      "          [-18.2087, -10.3713,  -9.4515,  ...,  -3.6821,  -9.0942, -14.3417],\n",
      "          [-25.1122, -20.6830, -19.5156,  ..., -10.5679, -16.3520, -18.6934],\n",
      "          ...,\n",
      "          [-54.8693, -52.6403, -53.0187,  ..., -53.9944, -51.9241, -53.2146],\n",
      "          [-55.0803, -53.3021, -52.8280,  ..., -52.2696, -52.6950, -55.4110],\n",
      "          [-56.9314, -52.7392, -52.0397,  ..., -52.4353, -52.6939, -54.9656]]],\n",
      "\n",
      "\n",
      "        [[[-21.1655,  -9.2806,  -5.2622,  ...,  -8.8647, -11.1282, -18.5056],\n",
      "          [-20.0558,  -9.4534,  -6.5965,  ..., -11.7341, -10.9992, -17.6177],\n",
      "          [-21.2958, -18.4667, -19.6582,  ..., -23.4726, -20.1104, -22.3423],\n",
      "          ...,\n",
      "          [-52.6853, -51.5193, -50.5851,  ..., -51.7641, -51.5040, -55.3226],\n",
      "          [-54.2208, -51.7189, -51.3510,  ..., -51.1839, -50.5015, -51.5194],\n",
      "          [-55.2196, -51.3944, -51.7383,  ..., -52.0318, -51.2384, -52.3445]]]]), tensor([ 6, 17, 11,  8, 18,  1, 14, 13,  2, 16,  0, 15,  7, 18,  2,  9,  1, 10,\n",
      "         3,  6,  4,  6,  5,  8, 19])]\n",
      "[tensor([[[[-24.0151, -14.0741,  -8.4813,  ...,  -7.1553,  -3.5366,  -4.7332],\n",
      "          [-23.5508, -12.4591,  -8.8935,  ..., -10.3823,  -6.3858,  -7.1951],\n",
      "          [-25.5836, -19.2200, -21.9387,  ..., -21.8384, -20.6047, -16.8313],\n",
      "          ...,\n",
      "          [-51.8312, -50.7193, -52.3980,  ..., -52.6845, -52.2245, -53.4746],\n",
      "          [-54.0043, -51.1681, -50.4154,  ..., -51.9934, -52.3931, -54.9598],\n",
      "          [-53.2392, -50.3139, -50.2935,  ..., -53.3171, -52.3102, -54.1964]]],\n",
      "\n",
      "\n",
      "        [[[ -6.1380,   0.0000,  -2.7168,  ..., -12.1368, -10.0503, -11.5785],\n",
      "          [ -6.2788,  -3.2301,  -6.3150,  ..., -10.3615, -11.0651, -13.5633],\n",
      "          [-13.6251, -15.8973, -17.5655,  ..., -20.3949, -22.2687, -22.6195],\n",
      "          ...,\n",
      "          [-51.9228, -51.6819, -54.1421,  ..., -51.6485, -50.9753, -53.2437],\n",
      "          [-52.7215, -51.4035, -51.8770,  ..., -55.0120, -55.5797, -56.5155],\n",
      "          [-54.9164, -52.4614, -52.8216,  ..., -53.7601, -53.2088, -53.1660]]],\n",
      "\n",
      "\n",
      "        [[[-42.9951, -36.3205, -36.3536,  ..., -48.3439, -42.3000, -41.3858],\n",
      "          [-43.3959, -39.5435, -39.7030,  ..., -49.3582, -46.7161, -47.5142],\n",
      "          [-50.4178, -53.0831, -55.0694,  ..., -57.7504, -54.0611, -50.6898],\n",
      "          ...,\n",
      "          [-80.0000, -79.2811, -80.0000,  ..., -79.9852, -79.7417, -80.0000],\n",
      "          [-80.0000, -80.0000, -80.0000,  ..., -79.3143, -79.0314, -80.0000],\n",
      "          [-80.0000, -79.0932, -79.6483,  ..., -79.6318, -79.4915, -80.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.7691, -12.9450,  -5.3312,  ..., -15.4166,  -9.5626,  -8.5781],\n",
      "          [-15.8101, -11.6237,  -6.9632,  ..., -18.2089, -12.4391, -10.7572],\n",
      "          [-20.8231, -16.4172, -15.3844,  ..., -20.1217, -24.1861, -17.7948],\n",
      "          ...,\n",
      "          [-47.6799, -43.9780, -42.7015,  ..., -42.8832, -45.8906, -47.8539],\n",
      "          [-45.3930, -43.2284, -43.3101,  ..., -42.7987, -44.2289, -46.8842],\n",
      "          [-45.2104, -43.1165, -44.7029,  ..., -43.2037, -42.8307, -45.3306]]],\n",
      "\n",
      "\n",
      "        [[[-12.8657, -11.2482, -13.4724,  ..., -10.0661, -11.7544,  -9.9558],\n",
      "          [-13.8016, -14.9496, -17.2188,  ..., -10.6228, -14.6726, -11.0705],\n",
      "          [-19.8329, -19.9795, -24.5743,  ..., -20.7737, -17.6161, -15.3557],\n",
      "          ...,\n",
      "          [-55.4961, -52.9254, -53.6704,  ..., -52.3865, -52.6815, -55.8604],\n",
      "          [-56.1053, -53.6912, -53.0935,  ..., -52.2997, -52.0639, -53.5094],\n",
      "          [-56.6315, -53.5775, -52.6498,  ..., -53.7087, -53.7046, -55.0886]]],\n",
      "\n",
      "\n",
      "        [[[-10.9037,  -9.6316, -15.9832,  ...,  -8.0860, -11.3804, -17.6645],\n",
      "          [-14.0838, -12.3146, -16.5750,  ..., -14.8592, -16.9757, -25.1795],\n",
      "          [-23.0597, -23.9344, -26.1906,  ..., -24.4917, -25.9262, -30.6096],\n",
      "          ...,\n",
      "          [-54.3032, -51.4389, -51.8348,  ..., -50.4987, -51.0670, -53.0224],\n",
      "          [-53.3753, -51.9854, -52.5193,  ..., -52.5263, -52.4781, -53.4447],\n",
      "          [-54.4793, -52.6034, -51.8446,  ..., -52.5953, -52.8672, -54.7190]]]]), tensor([ 3, 20, 16, 20,  6,  2,  6,  8,  4,  4, 20,  5,  6,  5, 18,  3,  9,  6,\n",
      "         5,  0,  7,  3, 10,  8, 17])]\n",
      "[tensor([[[[ -8.7493,  -4.5807,  -6.4738,  ..., -15.9647, -14.0820, -12.0870],\n",
      "          [-12.3815, -10.5802, -14.8960,  ..., -12.7258, -10.9269, -12.2491],\n",
      "          [-19.4824, -23.7299, -29.5765,  ..., -21.6016, -19.3830, -17.2908],\n",
      "          ...,\n",
      "          [-52.9048, -50.6366, -49.7437,  ..., -49.7154, -49.2230, -51.2233],\n",
      "          [-52.8697, -49.8926, -49.1587,  ..., -48.3543, -49.6159, -51.7414],\n",
      "          [-52.8566, -50.6728, -49.1883,  ..., -49.3658, -49.1887, -51.0989]]],\n",
      "\n",
      "\n",
      "        [[[ -7.6943,  -5.9382,  -7.4032,  ...,  -8.1046,  -6.6941,  -8.8680],\n",
      "          [-10.2469, -11.4874, -12.8954,  ..., -13.6241,  -9.5865, -11.0633],\n",
      "          [-16.2723, -19.8872, -23.0262,  ..., -26.5111, -22.3468, -21.9607],\n",
      "          ...,\n",
      "          [-54.4179, -52.9635, -53.7995,  ..., -54.1535, -54.6889, -56.2902],\n",
      "          [-55.2268, -52.4172, -53.1265,  ..., -54.1609, -53.8873, -56.5630],\n",
      "          [-56.8721, -53.6757, -53.8824,  ..., -52.9600, -53.5689, -56.0322]]],\n",
      "\n",
      "\n",
      "        [[[-21.2722, -15.7363,  -8.0751,  ...,  -7.4133,  -8.0877, -13.2537],\n",
      "          [-20.5599, -18.8401, -11.2284,  ..., -14.0391, -12.3484, -17.6471],\n",
      "          [-25.1204, -22.4697, -24.0603,  ..., -17.8006, -16.6104, -21.9891],\n",
      "          ...,\n",
      "          [-53.8747, -49.7312, -48.8353,  ..., -50.6623, -50.2794, -51.2271],\n",
      "          [-53.6322, -49.5831, -49.3631,  ..., -50.9076, -51.1527, -51.0633],\n",
      "          [-51.1943, -48.3772, -47.9430,  ..., -51.9853, -50.8899, -51.1673]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-20.3959, -16.9312,  -8.0731,  ...,  -4.7936, -11.8573, -10.2112],\n",
      "          [-19.3135, -13.2479,  -6.8360,  ...,  -4.4044,  -8.8201,  -9.5876],\n",
      "          [-21.3031, -17.6341, -14.4458,  ..., -12.8848, -15.2223, -13.6971],\n",
      "          ...,\n",
      "          [-51.9537, -48.4511, -47.5545,  ..., -47.8985, -46.5046, -47.7934],\n",
      "          [-52.2264, -48.3000, -47.6907,  ..., -45.9011, -46.9553, -50.1222],\n",
      "          [-52.2821, -48.0322, -48.4575,  ..., -46.2426, -46.7295, -50.8456]]],\n",
      "\n",
      "\n",
      "        [[[-12.5628,  -8.1854,  -7.5131,  ...,  -1.9018,  -2.7220,  -7.7348],\n",
      "          [-12.8445,  -8.3350,  -7.3685,  ...,  -5.0801,  -5.7026,  -8.7274],\n",
      "          [-18.6842, -20.4696, -18.0192,  ..., -18.9351, -18.2657, -18.4970],\n",
      "          ...,\n",
      "          [-53.3269, -52.5081, -53.6013,  ..., -52.3845, -53.6357, -55.7000],\n",
      "          [-55.8092, -53.5823, -53.8144,  ..., -51.1757, -51.5666, -53.6472],\n",
      "          [-56.6887, -53.7506, -53.7992,  ..., -50.3366, -51.5614, -52.8527]]],\n",
      "\n",
      "\n",
      "        [[[-13.8973,  -7.7259,  -5.2067,  ...,  -3.8277,  -7.8463, -10.4925],\n",
      "          [-16.4069, -15.3037,  -8.7685,  ...,  -8.0257, -12.5607, -11.9184],\n",
      "          [-19.6523, -18.2227, -19.9249,  ..., -21.0571, -15.6680, -14.9900],\n",
      "          ...,\n",
      "          [-54.9636, -52.6137, -52.2102,  ..., -51.4800, -52.3609, -53.2149],\n",
      "          [-53.9044, -51.6077, -52.3988,  ..., -53.3218, -53.4893, -53.3324],\n",
      "          [-53.8415, -52.4827, -53.0353,  ..., -54.9332, -53.2509, -52.9774]]]]), tensor([12,  9, 10,  9, 12, 13,  4, 15,  9,  4, 20, 10, 17,  3, 18,  3, 11, 15,\n",
      "         6, 18, 17,  8,  6, 14,  8])]\n"
     ]
    }
   ],
   "source": [
    "# ラベルの指定\n",
    "t_df = Dataset.objectNum\n",
    "\n",
    "# テンソル形式に変換\n",
    "df_tenosor = torch.tensor(df, dtype=torch.float32)\n",
    "df_tenosor = torch.unsqueeze(df_tenosor, 1)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "print(df_tenosor.size())\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset = torch.utils.data.TensorDataset(df_tenosor, label_tensor)\n",
    "\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 50%　: 25% : 25%\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 25\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DyMN(\n",
      "  (layers): ModuleList(\n",
      "    (0): DY_Block(\n",
      "      (exp_conv): DynamicWrapper(\n",
      "        (module): Identity()\n",
      "      )\n",
      "      (exp_norm): Identity()\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Identity()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (1): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=256, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (3): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (4-5): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=480, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (6): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=960, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(40, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=800, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (8-9): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=736, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (10): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=1920, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (11): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (12): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (13-14): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=3840, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (in_c): ConvNormActivation(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (out_c): ConvNormActivation(\n",
      "    (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=960, out_features=1280, bias=True)\n",
      "    (3): Hardswish()\n",
      "    (4): Dropout(p=0.2, inplace=True)\n",
      "    (5): Linear(in_features=1280, out_features=527, bias=True)\n",
      "    (6): Linear(in_features=527, out_features=176, bias=True)\n",
      "    (7): Linear(in_features=176, out_features=21, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "objModel = matModel_trained\n",
    "\n",
    "#パラメータの更新を許可\n",
    "for param in objModel.parameters():\n",
    "    param.requires_gred = True\n",
    "\n",
    "\n",
    "# print(model.classifier)\n",
    "\n",
    "# 出力層の最後だけ変更\n",
    "# model.classifier[5] = torch.nn.Linear(1280,2)\n",
    "objModel.classifier= nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(output_size=1),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    nn.Linear(in_features=960, out_features=1280, bias=True),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=527, bias=True),\n",
    "    nn.Linear(in_features=527, out_features=176, bias=True),  # 新しい層\n",
    "    nn.Linear(in_features=176, out_features=21, bias=True)  # 新しい層\n",
    "\n",
    ")\n",
    "print(objModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch [1/150], Train Loss: 3.0278, Validation Loss: 3.0198\n",
      "Epoch [2/150], Train Loss: 2.9709, Validation Loss: 2.9448\n",
      "Epoch [3/150], Train Loss: 2.7689, Validation Loss: 2.5568\n",
      "Epoch [4/150], Train Loss: 2.2522, Validation Loss: 2.2272\n",
      "Epoch [5/150], Train Loss: 1.8530, Validation Loss: 1.9331\n",
      "Epoch [6/150], Train Loss: 1.6220, Validation Loss: 1.8476\n",
      "Epoch [7/150], Train Loss: 1.5508, Validation Loss: 1.8055\n",
      "Epoch [8/150], Train Loss: 1.4792, Validation Loss: 1.8295\n",
      "Epoch [9/150], Train Loss: 1.4718, Validation Loss: 1.8003\n",
      "Epoch [10/150], Train Loss: 1.3980, Validation Loss: 1.9794\n",
      "Epoch [11/150], Train Loss: 1.4398, Validation Loss: 1.8589\n",
      "Epoch [12/150], Train Loss: 1.3370, Validation Loss: 2.0071\n",
      "Epoch [13/150], Train Loss: 1.2999, Validation Loss: 1.9319\n",
      "Epoch [14/150], Train Loss: 1.2895, Validation Loss: 2.1634\n",
      "Epoch [15/150], Train Loss: 1.2648, Validation Loss: 1.7984\n",
      "Epoch [16/150], Train Loss: 1.3273, Validation Loss: 1.7300\n",
      "Epoch [17/150], Train Loss: 1.2490, Validation Loss: 1.8213\n",
      "Epoch [18/150], Train Loss: 1.1954, Validation Loss: 1.9198\n",
      "Epoch [19/150], Train Loss: 1.1936, Validation Loss: 1.7403\n",
      "Epoch [20/150], Train Loss: 1.1470, Validation Loss: 1.7801\n",
      "Epoch [21/150], Train Loss: 1.1251, Validation Loss: 1.8757\n",
      "Epoch [22/150], Train Loss: 1.0837, Validation Loss: 2.7736\n",
      "Epoch [23/150], Train Loss: 1.0377, Validation Loss: 1.9531\n",
      "Epoch [24/150], Train Loss: 1.0706, Validation Loss: 1.5934\n",
      "Epoch [25/150], Train Loss: 0.9900, Validation Loss: 2.1507\n",
      "Epoch [26/150], Train Loss: 0.8562, Validation Loss: 1.5338\n",
      "Epoch [27/150], Train Loss: 0.8643, Validation Loss: 1.4638\n",
      "Epoch [28/150], Train Loss: 0.7574, Validation Loss: 1.7654\n",
      "Epoch [29/150], Train Loss: 0.7974, Validation Loss: 1.6060\n",
      "Epoch [30/150], Train Loss: 0.8676, Validation Loss: 3.1436\n",
      "Epoch [31/150], Train Loss: 0.8007, Validation Loss: 1.7946\n",
      "Epoch [32/150], Train Loss: 0.7553, Validation Loss: 2.1303\n",
      "Epoch [33/150], Train Loss: 0.6880, Validation Loss: 2.2251\n",
      "Epoch [34/150], Train Loss: 0.6736, Validation Loss: 1.8844\n",
      "Epoch [35/150], Train Loss: 0.5340, Validation Loss: 1.7761\n",
      "Epoch [36/150], Train Loss: 0.7119, Validation Loss: 2.0417\n",
      "Epoch [37/150], Train Loss: 0.7430, Validation Loss: 1.5565\n",
      "Epoch [38/150], Train Loss: 0.7547, Validation Loss: 1.7107\n",
      "Epoch [39/150], Train Loss: 0.5560, Validation Loss: 1.4564\n",
      "Epoch [40/150], Train Loss: 0.4066, Validation Loss: 1.2528\n",
      "Epoch [41/150], Train Loss: 0.6305, Validation Loss: 2.1275\n",
      "Epoch [42/150], Train Loss: 0.4824, Validation Loss: 2.7001\n",
      "Epoch [43/150], Train Loss: 0.6739, Validation Loss: 1.6488\n",
      "Epoch [44/150], Train Loss: 0.4591, Validation Loss: 4.9875\n",
      "Epoch [45/150], Train Loss: 0.3001, Validation Loss: 2.4342\n",
      "Epoch [46/150], Train Loss: 0.3499, Validation Loss: 1.3820\n",
      "Epoch [47/150], Train Loss: 0.3712, Validation Loss: 1.9194\n",
      "Epoch [48/150], Train Loss: 0.3771, Validation Loss: 2.2354\n",
      "Epoch [49/150], Train Loss: 0.2955, Validation Loss: 4.2099\n",
      "Epoch [50/150], Train Loss: 0.3262, Validation Loss: 1.7642\n",
      "Epoch [51/150], Train Loss: 0.3003, Validation Loss: 2.7267\n",
      "Epoch [52/150], Train Loss: 0.2472, Validation Loss: 2.4337\n",
      "Epoch [53/150], Train Loss: 0.2059, Validation Loss: 1.5369\n",
      "Epoch [54/150], Train Loss: 0.4195, Validation Loss: 2.7272\n",
      "Epoch [55/150], Train Loss: 0.3424, Validation Loss: 3.4091\n",
      "Epoch [56/150], Train Loss: 0.2747, Validation Loss: 2.3411\n",
      "Epoch [57/150], Train Loss: 0.1128, Validation Loss: 1.6268\n",
      "Epoch [58/150], Train Loss: 0.1649, Validation Loss: 2.3872\n",
      "Epoch [59/150], Train Loss: 0.1767, Validation Loss: 2.5850\n",
      "Epoch [60/150], Train Loss: 0.1744, Validation Loss: 1.3258\n",
      "Epoch [61/150], Train Loss: 0.1773, Validation Loss: 2.2647\n",
      "Epoch [62/150], Train Loss: 0.1152, Validation Loss: 2.8830\n",
      "Epoch [63/150], Train Loss: 0.1407, Validation Loss: 2.9567\n",
      "Epoch [64/150], Train Loss: 0.2951, Validation Loss: 5.8799\n",
      "Epoch [65/150], Train Loss: 0.4960, Validation Loss: 4.4016\n",
      "Epoch [66/150], Train Loss: 0.1369, Validation Loss: 6.2257\n",
      "Epoch [67/150], Train Loss: 0.1411, Validation Loss: 3.0056\n",
      "Epoch [68/150], Train Loss: 0.1057, Validation Loss: 6.2420\n",
      "Epoch [69/150], Train Loss: 0.1317, Validation Loss: 1.9038\n",
      "Epoch [70/150], Train Loss: 0.1056, Validation Loss: 5.7050\n",
      "Epoch [71/150], Train Loss: 0.1097, Validation Loss: 2.8206\n",
      "Epoch [72/150], Train Loss: 0.2257, Validation Loss: 3.6663\n",
      "Epoch [73/150], Train Loss: 0.2945, Validation Loss: 5.2887\n",
      "Epoch [74/150], Train Loss: 0.1474, Validation Loss: 5.4311\n",
      "Epoch [75/150], Train Loss: 0.2691, Validation Loss: 2.6648\n",
      "Epoch [76/150], Train Loss: 0.1688, Validation Loss: 1.4662\n",
      "Epoch [77/150], Train Loss: 0.1069, Validation Loss: 1.5504\n",
      "Epoch [78/150], Train Loss: 0.0647, Validation Loss: 2.5572\n",
      "Epoch [79/150], Train Loss: 0.0679, Validation Loss: 2.8404\n",
      "Epoch [80/150], Train Loss: 0.0381, Validation Loss: 1.3105\n",
      "Epoch [81/150], Train Loss: 0.0677, Validation Loss: 1.6978\n",
      "Epoch [82/150], Train Loss: 0.1613, Validation Loss: 1.4924\n",
      "Epoch [83/150], Train Loss: 0.0966, Validation Loss: 4.2484\n",
      "Epoch [84/150], Train Loss: 0.1329, Validation Loss: 1.6992\n",
      "Epoch [85/150], Train Loss: 0.0318, Validation Loss: 1.9521\n",
      "Epoch [86/150], Train Loss: 0.0274, Validation Loss: 1.2757\n",
      "Epoch [87/150], Train Loss: 0.0444, Validation Loss: 1.5906\n",
      "Epoch [88/150], Train Loss: 0.0788, Validation Loss: 1.8077\n",
      "Epoch [89/150], Train Loss: 0.0899, Validation Loss: 1.3183\n",
      "Epoch [90/150], Train Loss: 0.0224, Validation Loss: 1.3516\n",
      "Epoch [91/150], Train Loss: 0.1186, Validation Loss: 1.3369\n",
      "Epoch [92/150], Train Loss: 0.0112, Validation Loss: 1.2328\n",
      "Epoch [93/150], Train Loss: 0.0189, Validation Loss: 1.6340\n",
      "Epoch [94/150], Train Loss: 0.0664, Validation Loss: 2.2656\n",
      "Epoch [95/150], Train Loss: 0.1942, Validation Loss: 2.8511\n",
      "Epoch [96/150], Train Loss: 0.1419, Validation Loss: 2.2724\n",
      "Epoch [97/150], Train Loss: 0.3485, Validation Loss: 3.4369\n",
      "Epoch [98/150], Train Loss: 0.1769, Validation Loss: 2.1838\n",
      "Epoch [99/150], Train Loss: 0.0330, Validation Loss: 1.1850\n",
      "Epoch [100/150], Train Loss: 0.0359, Validation Loss: 1.5561\n",
      "Epoch [101/150], Train Loss: 0.0652, Validation Loss: 1.5025\n",
      "Epoch [102/150], Train Loss: 0.0378, Validation Loss: 1.6383\n",
      "Epoch [103/150], Train Loss: 0.0119, Validation Loss: 1.1958\n",
      "Epoch [104/150], Train Loss: 0.0165, Validation Loss: 0.9049\n",
      "Epoch [105/150], Train Loss: 0.0278, Validation Loss: 1.3856\n",
      "Epoch [106/150], Train Loss: 0.0669, Validation Loss: 1.0882\n",
      "Epoch [107/150], Train Loss: 0.0145, Validation Loss: 1.4573\n",
      "Epoch [108/150], Train Loss: 0.0909, Validation Loss: 6.5481\n",
      "Epoch [109/150], Train Loss: 0.0494, Validation Loss: 3.6474\n",
      "Epoch [110/150], Train Loss: 0.0093, Validation Loss: 1.5277\n",
      "Epoch [111/150], Train Loss: 0.0577, Validation Loss: 1.5609\n",
      "Epoch [112/150], Train Loss: 0.0831, Validation Loss: 2.7849\n",
      "Epoch [113/150], Train Loss: 0.0437, Validation Loss: 1.2925\n",
      "Epoch [114/150], Train Loss: 0.0089, Validation Loss: 1.3801\n",
      "Epoch [115/150], Train Loss: 0.0197, Validation Loss: 1.2822\n",
      "Epoch [116/150], Train Loss: 0.0057, Validation Loss: 1.1569\n",
      "Epoch [117/150], Train Loss: 0.0078, Validation Loss: 1.0634\n",
      "Epoch [118/150], Train Loss: 0.0093, Validation Loss: 1.1828\n",
      "Epoch [119/150], Train Loss: 0.0089, Validation Loss: 1.0901\n",
      "Epoch [120/150], Train Loss: 0.0343, Validation Loss: 1.2864\n",
      "Epoch [121/150], Train Loss: 0.0094, Validation Loss: 1.0494\n",
      "Epoch [122/150], Train Loss: 0.0181, Validation Loss: 1.6858\n",
      "Epoch [123/150], Train Loss: 0.0075, Validation Loss: 1.3542\n",
      "Epoch [124/150], Train Loss: 0.0032, Validation Loss: 1.3071\n",
      "Epoch [125/150], Train Loss: 0.0133, Validation Loss: 1.5703\n",
      "Epoch [126/150], Train Loss: 0.0793, Validation Loss: 1.5335\n",
      "Epoch [127/150], Train Loss: 0.0293, Validation Loss: 1.8125\n",
      "Epoch [128/150], Train Loss: 0.0090, Validation Loss: 1.7076\n",
      "Epoch [129/150], Train Loss: 0.0137, Validation Loss: 1.5323\n",
      "Epoch [130/150], Train Loss: 0.0096, Validation Loss: 1.1820\n",
      "Epoch [131/150], Train Loss: 0.0397, Validation Loss: 1.7273\n",
      "Epoch [132/150], Train Loss: 0.0110, Validation Loss: 1.3873\n",
      "Epoch [133/150], Train Loss: 0.0481, Validation Loss: 1.4351\n",
      "Epoch [134/150], Train Loss: 0.0091, Validation Loss: 1.2841\n",
      "Epoch [135/150], Train Loss: 0.0398, Validation Loss: 1.3686\n",
      "Epoch [136/150], Train Loss: 0.0167, Validation Loss: 1.4820\n",
      "Epoch [137/150], Train Loss: 0.0088, Validation Loss: 1.1866\n",
      "Epoch [138/150], Train Loss: 0.0025, Validation Loss: 1.2467\n",
      "Epoch [139/150], Train Loss: 0.0025, Validation Loss: 1.0769\n",
      "Epoch [140/150], Train Loss: 0.0346, Validation Loss: 1.5244\n",
      "Epoch [141/150], Train Loss: 0.0211, Validation Loss: 2.2651\n",
      "Epoch [142/150], Train Loss: 0.0056, Validation Loss: 3.1352\n",
      "Epoch [143/150], Train Loss: 0.0085, Validation Loss: 3.0729\n",
      "Epoch [144/150], Train Loss: 0.0065, Validation Loss: 1.8103\n",
      "Epoch [145/150], Train Loss: 0.0059, Validation Loss: 1.5848\n",
      "Epoch [146/150], Train Loss: 0.0022, Validation Loss: 1.5969\n",
      "Epoch [147/150], Train Loss: 0.0024, Validation Loss: 1.4138\n",
      "Epoch [148/150], Train Loss: 0.0046, Validation Loss: 1.0732\n",
      "Epoch [149/150], Train Loss: 0.0039, Validation Loss: 1.4850\n",
      "Epoch [150/150], Train Loss: 0.0035, Validation Loss: 1.1850\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# エポックの数\n",
    "max_epoch = 150\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net3 = objModel.cuda()\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "  \n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net3.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net3.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y = net3(x)\n",
    "        loss = criterion(y[0], t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net3.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "  \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net3(x)\n",
    "            loss = criterion(y[0], t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "\n",
    "objModel_trained = net3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "def ShowTrainLoss(train_losses,val_losses,save):\n",
    "    # 日本時間のタイムゾーンを取得\n",
    "    jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "    # 現在の日本時間を取得\n",
    "    now = datetime.now(jst)\n",
    "\n",
    "    # 時刻を指定された形式の文字列に変換\n",
    "    time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # 学習曲線の可視化\n",
    "\n",
    "    title = 'Training and Validation Losses Object'\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0,5)\n",
    "    plt.legend()\n",
    "    if save == True:\n",
    "        plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "ShowTrainLoss(train_losses,val_losses,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.0%\n",
      "Accuracy: 78.7%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7869)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y[0], dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            # x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net3(x)\n",
    "            \n",
    "            y_label = torch.argmax(y[0], dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### soft-hard 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1050, 1, 128, 130])\n",
      "525 262 263\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fdd1bf3c700>\n",
      "[tensor([[[[-15.7372, -12.7907, -12.2806,  ..., -16.2258, -12.1957, -14.6959],\n",
      "          [-15.7418, -11.8346, -11.9373,  ..., -12.7932, -11.7111, -12.4843],\n",
      "          [-22.5785, -21.3953, -21.5793,  ..., -20.6679, -21.5296, -17.3727],\n",
      "          ...,\n",
      "          [-58.1976, -55.0280, -55.0888,  ..., -53.4471, -52.7718, -53.7474],\n",
      "          [-56.4661, -53.7698, -54.6103,  ..., -54.0908, -53.9045, -56.2288],\n",
      "          [-57.3117, -54.9557, -55.6911,  ..., -54.7845, -54.3604, -56.0656]]],\n",
      "\n",
      "\n",
      "        [[[ -5.8755,  -1.3352,   0.0000,  ...,  -8.2323,  -7.3307,  -8.7717],\n",
      "          [ -7.0860,  -4.6320,  -2.7805,  ...,  -6.8078,  -5.4152,  -6.6856],\n",
      "          [-14.4937, -18.4999, -18.0805,  ..., -15.1023, -14.4274, -11.6789],\n",
      "          ...,\n",
      "          [-50.1694, -46.3330, -44.8377,  ..., -47.9001, -46.6421, -47.7369],\n",
      "          [-49.2638, -46.9567, -46.7122,  ..., -46.9204, -46.5079, -49.3187],\n",
      "          [-46.9555, -45.9099, -47.1923,  ..., -47.8846, -48.9719, -50.9079]]],\n",
      "\n",
      "\n",
      "        [[[-14.0626, -12.4793, -12.4311,  ...,  -6.8308,  -6.2901, -10.4582],\n",
      "          [-18.8385, -19.3206, -16.3264,  ...,  -9.3470,  -9.8862, -12.6103],\n",
      "          [-26.0905, -30.3457, -25.2675,  ..., -20.0117, -23.9119, -21.9449],\n",
      "          ...,\n",
      "          [-53.3047, -52.0847, -53.4519,  ..., -52.4061, -53.3940, -56.5739],\n",
      "          [-58.1525, -54.5277, -52.5746,  ..., -53.0982, -53.9163, -56.1266],\n",
      "          [-55.2106, -52.8737, -53.1973,  ..., -52.8028, -52.4231, -54.3603]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -9.9831,  -7.1871, -11.7807,  ..., -11.2343,  -9.8302, -13.3886],\n",
      "          [-11.8676,  -9.5992, -15.2492,  ..., -12.9284, -12.4264, -17.9736],\n",
      "          [-19.0413, -18.4740, -26.9585,  ..., -21.7851, -23.7197, -26.1367],\n",
      "          ...,\n",
      "          [-53.6593, -52.2464, -51.7386,  ..., -51.2787, -51.4993, -56.2754],\n",
      "          [-55.0183, -52.9384, -52.6564,  ..., -51.3566, -51.8909, -54.7269],\n",
      "          [-56.5075, -52.0982, -52.3580,  ..., -51.7871, -52.0791, -53.2282]]],\n",
      "\n",
      "\n",
      "        [[[-17.2652, -11.0746,  -9.8907,  ...,  -0.6295,   0.0000,  -3.5875],\n",
      "          [-18.6370, -15.4748, -16.1502,  ...,  -6.1369,  -3.3467,  -4.0424],\n",
      "          [-28.6770, -30.6238, -34.6265,  ..., -19.3636, -16.2683, -12.0035],\n",
      "          ...,\n",
      "          [-56.7433, -54.9483, -56.3357,  ..., -56.7504, -55.6961, -54.8034],\n",
      "          [-59.7806, -56.2284, -55.0864,  ..., -54.5428, -54.2212, -54.7591],\n",
      "          [-60.2414, -56.0917, -55.5884,  ..., -56.2427, -55.2146, -53.6850]]],\n",
      "\n",
      "\n",
      "        [[[ -9.3511,  -5.2951,  -9.8728,  ..., -10.9083,  -9.2532, -11.2135],\n",
      "          [ -8.2031,  -6.5688, -12.9695,  ..., -10.1815, -11.6199, -10.9543],\n",
      "          [-13.0035, -13.6482, -18.5944,  ..., -16.5582, -14.2727, -13.9899],\n",
      "          ...,\n",
      "          [-45.4077, -44.2285, -46.0337,  ..., -45.8847, -45.8283, -47.6377],\n",
      "          [-47.8298, -45.4274, -44.8245,  ..., -45.7963, -45.1360, -47.9109],\n",
      "          [-46.2646, -44.5052, -46.9336,  ..., -47.0090, -46.8320, -47.4182]]]]), tensor([1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0])]\n",
      "[tensor([[[[ -6.0762,  -3.5017,  -3.3377,  ...,  -4.1093,  -2.1572,  -5.0010],\n",
      "          [ -8.7918,  -7.3907,  -5.0249,  ...,  -8.1448,  -4.9479,  -9.1982],\n",
      "          [ -9.1813,  -6.6263, -11.7422,  ...,  -8.8395, -12.1046, -19.2009],\n",
      "          ...,\n",
      "          [-52.7497, -48.8865, -48.6537,  ..., -51.1285, -49.8177, -50.1686],\n",
      "          [-50.9880, -48.3031, -49.1782,  ..., -49.3246, -50.4652, -51.6474],\n",
      "          [-53.7844, -50.3416, -49.3829,  ..., -49.5337, -51.0771, -51.4142]]],\n",
      "\n",
      "\n",
      "        [[[-23.0836, -17.6527, -16.0622,  ..., -10.6483, -10.1918, -12.0575],\n",
      "          [-23.1806, -22.3402, -18.6569,  ..., -13.4887, -13.7516, -13.3281],\n",
      "          [-26.3015, -25.4151, -28.7933,  ..., -27.0607, -24.7454, -19.3046],\n",
      "          ...,\n",
      "          [-66.6998, -62.6790, -60.6387,  ..., -61.7790, -61.7823, -62.4379],\n",
      "          [-63.1558, -60.9635, -61.3787,  ..., -63.1781, -63.1277, -62.9624],\n",
      "          [-64.4473, -63.1082, -63.1545,  ..., -62.6057, -62.2202, -63.7380]]],\n",
      "\n",
      "\n",
      "        [[[-19.4677, -13.8089, -14.6049,  ..., -10.6197,  -9.1130, -14.6017],\n",
      "          [-26.8576, -22.7456, -24.1618,  ..., -10.5441, -12.6558, -19.9263],\n",
      "          [-35.0707, -34.8668, -34.4597,  ..., -19.6834, -21.1026, -24.3130],\n",
      "          ...,\n",
      "          [-57.2477, -53.7524, -52.4263,  ..., -53.7950, -53.9968, -55.4982],\n",
      "          [-55.1792, -53.1644, -54.2603,  ..., -52.6724, -53.1959, -54.9959],\n",
      "          [-54.3971, -52.5030, -52.5609,  ..., -53.9797, -53.4432, -55.9142]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -6.2664,  -2.9890,  -5.2798,  ...,  -5.7535,  -4.7177,  -6.9648],\n",
      "          [ -7.5614,  -3.9616,  -7.6979,  ...,  -7.0264,  -8.9588, -11.5580],\n",
      "          [-15.4290, -14.8272, -17.7061,  ..., -19.6478, -22.2260, -23.2930],\n",
      "          ...,\n",
      "          [-51.9192, -50.1242, -49.7132,  ..., -47.8093, -47.7594, -49.0973],\n",
      "          [-52.1852, -48.6977, -48.1595,  ..., -47.4365, -47.7249, -49.1994],\n",
      "          [-51.3106, -48.8156, -48.8151,  ..., -47.7161, -48.4147, -50.3677]]],\n",
      "\n",
      "\n",
      "        [[[-12.9531,  -8.4623, -10.9949,  ..., -13.9743, -12.5583, -12.9040],\n",
      "          [-12.9575,  -9.1291,  -9.6971,  ..., -12.4427, -10.5136, -12.3491],\n",
      "          [-18.2892, -20.0374, -20.3422,  ..., -16.5155, -15.7638, -17.3400],\n",
      "          ...,\n",
      "          [-54.6013, -51.4329, -50.6813,  ..., -50.8779, -51.4110, -53.4678],\n",
      "          [-52.1137, -49.6309, -49.8039,  ..., -51.3086, -50.1676, -51.5474],\n",
      "          [-52.6111, -51.0972, -51.9317,  ..., -52.1191, -50.8958, -52.4753]]],\n",
      "\n",
      "\n",
      "        [[[-25.9034, -21.9119, -14.0451,  ...,  -5.3250,  -9.2805, -16.3978],\n",
      "          [-19.3675, -13.7969, -12.1835,  ...,  -7.1418,  -7.7071, -15.4302],\n",
      "          [-19.0328, -17.3201, -16.0753,  ..., -17.0908, -13.7243, -22.8432],\n",
      "          ...,\n",
      "          [-48.0925, -46.5962, -46.7822,  ..., -47.8841, -46.8159, -47.6297],\n",
      "          [-47.8132, -45.3680, -44.6936,  ..., -46.3455, -46.1164, -49.3973],\n",
      "          [-49.8005, -47.0284, -47.1830,  ..., -46.4303, -46.3429, -48.1432]]]]), tensor([0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0])]\n",
      "[tensor([[[[-10.0279,  -7.8579, -11.8001,  ..., -12.3195,  -7.2473,  -9.8667],\n",
      "          [-10.8272,  -8.6687, -14.2134,  ..., -12.5902,  -6.6770,  -8.9679],\n",
      "          [-17.5238, -18.0341, -23.8566,  ..., -20.1754, -14.4655, -14.4317],\n",
      "          ...,\n",
      "          [-53.8049, -51.9219, -53.2467,  ..., -50.7193, -51.2442, -53.0188],\n",
      "          [-54.4185, -52.8468, -53.4759,  ..., -52.1240, -51.0827, -54.4927],\n",
      "          [-55.8065, -52.5886, -52.4451,  ..., -53.5472, -51.6183, -53.5764]]],\n",
      "\n",
      "\n",
      "        [[[-10.7324,  -4.6517,  -3.8478,  ...,  -8.2309, -14.8002, -18.0520],\n",
      "          [-11.8236,  -6.3387,  -9.1619,  ..., -12.2978, -17.8332, -16.8948],\n",
      "          [-21.9459, -15.6345, -17.6357,  ..., -23.1039, -19.1691, -19.0841],\n",
      "          ...,\n",
      "          [-53.8330, -49.2684, -48.2273,  ..., -48.3188, -49.0298, -52.3784],\n",
      "          [-53.0411, -49.3866, -48.0516,  ..., -49.6745, -49.0690, -51.8535],\n",
      "          [-53.7364, -49.5175, -48.6195,  ..., -50.3162, -49.5507, -49.6395]]],\n",
      "\n",
      "\n",
      "        [[[ -7.1616,  -0.9457,   0.0000,  ...,  -5.7713,  -8.1283, -18.2104],\n",
      "          [ -7.6271,  -3.1601,  -2.3634,  ...,  -8.6473,  -7.9879, -13.6696],\n",
      "          [-13.9333, -14.6354, -14.1242,  ..., -19.9669, -18.1613, -17.1388],\n",
      "          ...,\n",
      "          [-54.6771, -51.6242, -50.7401,  ..., -50.1866, -50.7028, -51.4649],\n",
      "          [-54.6167, -51.3566, -50.3548,  ..., -51.2736, -51.6761, -52.4059],\n",
      "          [-52.7593, -50.6332, -51.0717,  ..., -49.3423, -51.7091, -53.6027]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -8.3681,  -5.1823,  -7.4577,  ...,  -3.7348,  -2.5485,  -6.6958],\n",
      "          [ -8.0277,  -4.9073,  -4.9623,  ...,  -4.2416,  -4.8608,  -9.5555],\n",
      "          [-13.0840, -13.7098, -12.8687,  ..., -17.7461, -19.1325, -21.0760],\n",
      "          ...,\n",
      "          [-50.0689, -46.2291, -45.4716,  ..., -46.8236, -47.4431, -49.0650],\n",
      "          [-50.4353, -47.2231, -45.5502,  ..., -46.8992, -46.7623, -48.7872],\n",
      "          [-48.1989, -46.7950, -47.2719,  ..., -46.1326, -46.5750, -47.0558]]],\n",
      "\n",
      "\n",
      "        [[[-24.0054, -16.5717, -12.2069,  ..., -10.8894, -11.0717, -14.5653],\n",
      "          [-26.5346, -21.9115, -16.5898,  ..., -15.5828, -16.0140, -14.1760],\n",
      "          [-30.1219, -23.5671, -23.9182,  ..., -19.3224, -19.7878, -16.0493],\n",
      "          ...,\n",
      "          [-55.0039, -50.1655, -47.9797,  ..., -48.1771, -49.0459, -50.6193],\n",
      "          [-50.9413, -48.6363, -49.1542,  ..., -50.7510, -50.4623, -51.4882],\n",
      "          [-51.2350, -50.3329, -50.0501,  ..., -51.2576, -50.9684, -51.8375]]],\n",
      "\n",
      "\n",
      "        [[[ -9.2767,  -5.4631,  -1.6625,  ..., -10.1021,  -7.4068,  -9.1599],\n",
      "          [ -7.2520,  -3.3959,  -2.4361,  ...,  -7.8024,  -6.9836,  -7.6628],\n",
      "          [-12.1627, -14.2867, -15.8049,  ..., -17.6147, -16.5750, -12.0232],\n",
      "          ...,\n",
      "          [-56.9290, -53.3854, -53.6736,  ..., -53.6213, -53.0371, -55.1418],\n",
      "          [-55.0039, -54.3032, -54.7474,  ..., -54.4607, -53.4741, -54.6051],\n",
      "          [-55.0830, -54.0245, -54.1530,  ..., -54.0167, -54.1413, -55.7217]]]]), tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1])]\n",
      "[tensor([[[[ -8.9003,  -5.6950,  -8.4137,  ...,  -7.9397, -14.6901, -13.7975],\n",
      "          [ -7.0621,  -4.2965,  -5.2679,  ...,  -6.8257, -10.7655, -12.5228],\n",
      "          [-12.1692, -14.2089, -16.3282,  ..., -14.7645, -16.9071, -14.4980],\n",
      "          ...,\n",
      "          [-51.3359, -48.0489, -47.7460,  ..., -48.3099, -47.7784, -49.3869],\n",
      "          [-49.6297, -48.2010, -48.3301,  ..., -48.2575, -48.2402, -50.6874],\n",
      "          [-50.8940, -48.3321, -48.8617,  ..., -48.8092, -48.8599, -50.0928]]],\n",
      "\n",
      "\n",
      "        [[[-17.7462, -15.1062, -26.7662,  ...,  -8.3707, -11.2060, -17.8887],\n",
      "          [-19.8870, -15.9270, -17.0375,  ..., -11.2934, -13.8616, -16.8674],\n",
      "          [-27.6479, -24.2454, -21.9514,  ..., -25.1244, -26.2341, -22.6001],\n",
      "          ...,\n",
      "          [-61.9573, -58.3460, -58.4538,  ..., -57.4640, -59.4890, -60.6936],\n",
      "          [-60.5880, -58.2899, -57.2648,  ..., -59.2312, -58.1507, -59.4468],\n",
      "          [-59.8953, -57.4230, -57.5208,  ..., -58.3148, -57.9805, -58.8456]]],\n",
      "\n",
      "\n",
      "        [[[-13.5176, -11.6368,  -8.7873,  ..., -17.7489, -16.9146, -20.3726],\n",
      "          [-16.1134, -14.8937, -12.4694,  ..., -18.9430, -14.6921, -16.7794],\n",
      "          [-22.4209, -19.2131, -22.1324,  ..., -22.3883, -22.1521, -21.7480],\n",
      "          ...,\n",
      "          [-51.0376, -48.7682, -49.6154,  ..., -49.2334, -49.2060, -50.9532],\n",
      "          [-54.0740, -50.1427, -49.8437,  ..., -49.6026, -50.2182, -51.0737],\n",
      "          [-50.7706, -48.5343, -48.9691,  ..., -50.4240, -50.7928, -52.9936]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-15.8294, -11.2537, -10.9465,  ..., -11.9487, -14.0252, -14.7746],\n",
      "          [-17.5562, -16.3954, -18.2899,  ..., -14.2846, -11.2523, -12.0967],\n",
      "          [-25.0954, -28.1919, -22.7930,  ..., -19.2034, -19.1958, -15.9922],\n",
      "          ...,\n",
      "          [-50.6322, -49.0325, -47.4819,  ..., -48.4302, -47.1102, -48.7352],\n",
      "          [-51.8628, -47.9553, -48.7344,  ..., -49.1368, -49.6521, -51.7342],\n",
      "          [-51.8983, -47.6698, -48.2550,  ..., -47.4888, -47.7807, -50.4829]]],\n",
      "\n",
      "\n",
      "        [[[-14.3831, -12.1354, -12.6169,  ..., -15.8074, -16.5729, -17.3791],\n",
      "          [-18.5885, -19.1402, -17.1982,  ..., -10.2863, -16.8677, -18.6861],\n",
      "          [-22.7160, -21.8464, -18.4663,  ..., -16.2206, -17.2931, -20.8829],\n",
      "          ...,\n",
      "          [-53.3006, -49.5118, -47.8410,  ..., -48.6413, -49.1530, -49.6687],\n",
      "          [-51.7591, -49.3027, -49.3969,  ..., -48.9461, -49.3949, -50.4807],\n",
      "          [-51.4795, -50.4085, -50.9016,  ..., -50.5438, -49.8652, -51.7285]]],\n",
      "\n",
      "\n",
      "        [[[-11.6841, -10.6428, -10.8915,  ...,  -1.7235,  -4.8453, -10.9071],\n",
      "          [-13.1581, -10.0602, -10.0689,  ...,  -3.7508,  -5.8531, -10.0624],\n",
      "          [-19.0680, -19.6948, -21.7907,  ..., -19.0947, -19.8550, -18.1728],\n",
      "          ...,\n",
      "          [-56.3883, -55.2090, -55.1556,  ..., -54.6343, -55.5138, -58.5798],\n",
      "          [-57.3524, -55.6003, -55.8850,  ..., -54.4737, -53.9710, -56.3188],\n",
      "          [-56.3898, -54.3298, -55.1854,  ..., -54.6399, -55.4026, -57.7112]]]]), tensor([1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[ -9.1439,  -6.3815,  -8.6553,  ...,  -9.9656, -15.8904, -22.7964],\n",
      "          [-12.4257, -10.7954, -15.2085,  ..., -11.7822, -20.2603, -23.9475],\n",
      "          [-20.7228, -24.3895, -28.4178,  ..., -24.0787, -26.8945, -27.7306],\n",
      "          ...,\n",
      "          [-50.6917, -48.3092, -48.8301,  ..., -50.6481, -49.7191, -51.0505],\n",
      "          [-51.6069, -48.9763, -49.3845,  ..., -50.7629, -50.2760, -51.0789],\n",
      "          [-52.5421, -50.3477, -51.9593,  ..., -49.8749, -50.1946, -52.2247]]],\n",
      "\n",
      "\n",
      "        [[[-12.8183,  -8.8736,  -9.9669,  ...,  -0.9775,  -1.1875,  -3.4887],\n",
      "          [-17.7811, -14.6838, -12.9425,  ...,  -5.8998,  -5.5387,  -6.5439],\n",
      "          [-26.6312, -26.0636, -23.6724,  ..., -25.0167, -22.3263, -16.4586],\n",
      "          ...,\n",
      "          [-58.4294, -54.7695, -54.3107,  ..., -55.4369, -54.4335, -56.1671],\n",
      "          [-59.0020, -54.6001, -54.8849,  ..., -52.7717, -53.4871, -55.4511],\n",
      "          [-58.0232, -54.3704, -54.5316,  ..., -54.1423, -53.6740, -55.1368]]],\n",
      "\n",
      "\n",
      "        [[[-15.6181, -17.4919, -20.0049,  ..., -11.2635, -18.8130, -19.6856],\n",
      "          [-17.4799, -19.6151, -21.3630,  ..., -11.9547, -16.5333, -17.9439],\n",
      "          [-23.0230, -26.7643, -25.9644,  ..., -21.4136, -18.9200, -21.3353],\n",
      "          ...,\n",
      "          [-57.8216, -55.8503, -55.6969,  ..., -53.9801, -54.6264, -56.9200],\n",
      "          [-59.3948, -56.9479, -56.4685,  ..., -53.6779, -54.0244, -55.7368],\n",
      "          [-57.8211, -55.0197, -55.2547,  ..., -55.0715, -54.6728, -57.3392]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-19.3755, -15.8834, -19.4765,  ..., -15.2986, -18.9731, -28.3482],\n",
      "          [-18.2080, -16.1983, -15.6329,  ..., -20.2465, -22.4688, -29.8424],\n",
      "          [-22.2617, -25.5475, -24.1155,  ..., -31.1005, -25.8298, -27.9543],\n",
      "          ...,\n",
      "          [-59.2608, -56.9048, -56.1722,  ..., -54.8316, -56.1192, -58.8295],\n",
      "          [-58.3115, -55.2242, -55.7536,  ..., -55.2191, -55.8394, -58.2460],\n",
      "          [-58.3019, -55.6733, -56.1740,  ..., -56.5903, -55.3230, -55.6876]]],\n",
      "\n",
      "\n",
      "        [[[-20.7064, -12.7469, -10.5713,  ...,  -5.6322, -11.0249, -23.3230],\n",
      "          [-23.0129, -15.8259, -15.6464,  ...,  -9.6322, -13.9740, -25.6630],\n",
      "          [-32.3584, -28.0187, -26.3400,  ..., -21.2980, -21.1598, -23.0218],\n",
      "          ...,\n",
      "          [-58.6716, -54.6895, -55.8372,  ..., -56.8688, -56.7343, -59.0497],\n",
      "          [-58.0728, -55.9267, -56.6812,  ..., -55.3060, -55.7754, -58.9926],\n",
      "          [-57.1548, -55.0041, -56.1730,  ..., -55.2742, -56.0316, -58.6850]]],\n",
      "\n",
      "\n",
      "        [[[-17.7484,  -7.8096,  -5.0597,  ...,  -7.1552, -10.3615, -15.7479],\n",
      "          [-24.1250, -11.6381,  -9.1836,  ..., -10.0575, -14.9263, -20.7033],\n",
      "          [-24.6713, -22.2962, -22.8559,  ..., -17.8255, -21.8843, -28.1199],\n",
      "          ...,\n",
      "          [-52.9812, -49.4930, -49.4893,  ..., -47.8044, -48.4419, -50.2379],\n",
      "          [-51.8783, -48.7094, -48.4333,  ..., -49.4847, -48.6194, -51.0819],\n",
      "          [-51.4531, -49.4110, -49.6053,  ..., -48.9175, -49.1056, -51.0907]]]]), tensor([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0])]\n",
      "[tensor([[[[-17.0427, -14.9856, -19.9267,  ...,  -5.5589,  -7.6223,  -9.4907],\n",
      "          [-18.2477, -14.8280, -17.3509,  ...,  -6.7090, -12.1974, -12.1394],\n",
      "          [-26.8981, -25.3371, -20.1127,  ..., -16.3102, -16.0153, -16.4981],\n",
      "          ...,\n",
      "          [-53.9200, -51.8853, -52.4520,  ..., -53.6749, -51.8540, -53.6749],\n",
      "          [-55.1911, -52.7323, -53.3232,  ..., -54.3976, -54.8286, -56.5963],\n",
      "          [-54.7715, -52.9818, -53.6572,  ..., -53.8595, -53.5804, -54.8806]]],\n",
      "\n",
      "\n",
      "        [[[-10.5205, -12.1467, -11.9641,  ..., -11.1011,  -7.8841, -10.2488],\n",
      "          [-10.7204, -10.2712, -14.8051,  ..., -17.4890, -10.1350,  -9.9657],\n",
      "          [-15.4316, -14.7884, -19.3225,  ..., -20.4244, -19.5974, -16.2358],\n",
      "          ...,\n",
      "          [-48.4588, -47.1349, -46.9040,  ..., -47.7909, -47.2344, -49.7415],\n",
      "          [-50.3802, -47.2370, -45.4467,  ..., -47.3579, -46.4145, -48.9298],\n",
      "          [-51.0459, -48.2725, -48.0139,  ..., -46.4444, -47.2485, -48.7807]]],\n",
      "\n",
      "\n",
      "        [[[-11.1962,  -5.1562,  -3.9529,  ..., -13.7877, -13.9695, -18.9762],\n",
      "          [-11.6165, -10.5394, -10.5728,  ..., -20.3477, -17.0996, -21.1129],\n",
      "          [-17.8774, -21.0547, -26.0836,  ..., -28.4353, -27.5213, -30.6109],\n",
      "          ...,\n",
      "          [-55.0200, -53.2546, -53.1739,  ..., -54.1681, -53.8253, -56.4622],\n",
      "          [-57.6203, -53.9981, -53.5916,  ..., -53.0469, -53.1876, -55.7428],\n",
      "          [-58.0921, -53.5759, -52.9358,  ..., -54.2606, -55.0854, -56.0155]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-13.0929,  -8.1490,  -6.0740,  ...,  -9.0175,  -8.1026, -11.2404],\n",
      "          [-10.8897,  -6.2664,  -5.4600,  ..., -10.1410, -10.2522, -13.9232],\n",
      "          [-16.1681, -14.1593, -16.3334,  ..., -17.0501, -17.4465, -21.9007],\n",
      "          ...,\n",
      "          [-51.3174, -47.6784, -46.9831,  ..., -50.6825, -49.8886, -49.5048],\n",
      "          [-51.6961, -49.0685, -48.9114,  ..., -49.4049, -49.1464, -50.9212],\n",
      "          [-50.2888, -48.5087, -49.5262,  ..., -49.4060, -50.3186, -50.6697]]],\n",
      "\n",
      "\n",
      "        [[[-10.5740,  -6.6337,  -8.5231,  ...,  -8.6571,  -5.7712,  -7.2641],\n",
      "          [-13.8897, -10.3217, -13.4287,  ..., -16.9600, -11.8110,  -9.2367],\n",
      "          [-23.7448, -22.1353, -25.4149,  ..., -25.1986, -20.3145, -14.5135],\n",
      "          ...,\n",
      "          [-56.6444, -52.8006, -52.6621,  ..., -51.8420, -53.6470, -55.4209],\n",
      "          [-55.7708, -51.4955, -51.6007,  ..., -51.9611, -51.7362, -53.4997],\n",
      "          [-55.3219, -52.4044, -52.4623,  ..., -52.5349, -53.7143, -56.9817]]],\n",
      "\n",
      "\n",
      "        [[[ -5.3598,  -3.5870,  -7.7213,  ...,  -2.1239,  -7.6019, -16.7891],\n",
      "          [ -5.8658,  -5.3685,  -7.8181,  ...,  -4.0615,  -8.9067, -14.8545],\n",
      "          [-11.5583, -15.3547, -19.3934,  ..., -16.7265, -17.2696, -18.3079],\n",
      "          ...,\n",
      "          [-47.5734, -45.8095, -45.9924,  ..., -44.0620, -45.6469, -47.2745],\n",
      "          [-48.5098, -45.7572, -45.2733,  ..., -44.6914, -46.3110, -48.8676],\n",
      "          [-49.0852, -46.0152, -45.1482,  ..., -44.7064, -45.7651, -47.9350]]]]), tensor([0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0])]\n",
      "[tensor([[[[-16.5098, -13.6158, -13.7698,  ..., -20.1823, -15.1784, -14.9491],\n",
      "          [-17.1146, -14.5767, -15.2056,  ..., -17.9235, -14.7208, -14.5118],\n",
      "          [-20.5487, -19.4128, -19.8824,  ..., -25.1827, -23.9422, -20.0301],\n",
      "          ...,\n",
      "          [-51.9878, -48.7872, -49.3824,  ..., -49.1425, -48.0484, -49.6893],\n",
      "          [-51.2758, -49.8633, -49.9142,  ..., -50.0475, -49.9551, -51.1813],\n",
      "          [-53.1391, -51.0403, -50.3494,  ..., -51.4081, -50.0263, -50.0482]]],\n",
      "\n",
      "\n",
      "        [[[-10.7208,  -5.1715,  -4.3676,  ..., -10.5834, -11.5595, -16.9046],\n",
      "          [-12.3766,  -8.8231, -10.9925,  ..., -15.4747, -12.9223, -19.2970],\n",
      "          [-18.7908, -21.4462, -20.5267,  ..., -22.6840, -21.4934, -24.3930],\n",
      "          ...,\n",
      "          [-49.9995, -48.0103, -48.4120,  ..., -49.7643, -49.8806, -51.6831],\n",
      "          [-47.4270, -47.3056, -48.4698,  ..., -49.4439, -47.8779, -49.5320],\n",
      "          [-51.3528, -48.1071, -48.6567,  ..., -48.5554, -48.1139, -51.5024]]],\n",
      "\n",
      "\n",
      "        [[[-15.0478, -13.8001, -14.4621,  ..., -15.5620, -12.5570, -13.9192],\n",
      "          [-16.9501, -15.3223, -15.4388,  ..., -23.5943, -17.3096, -17.4727],\n",
      "          [-21.4123, -20.9109, -20.8366,  ..., -28.2529, -30.6608, -29.5175],\n",
      "          ...,\n",
      "          [-51.7909, -49.2375, -49.9399,  ..., -50.1581, -49.0799, -51.5343],\n",
      "          [-50.2857, -49.8086, -50.5261,  ..., -49.6846, -49.2241, -50.3883],\n",
      "          [-55.8301, -51.5755, -50.2552,  ..., -49.5259, -50.5020, -52.1422]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -7.5071,  -3.8854,  -4.2999,  ...,  -9.5368,  -5.0302,  -8.2657],\n",
      "          [ -6.8737,  -3.2673,  -4.4442,  ...,  -7.8864,  -4.6115,  -6.8085],\n",
      "          [-12.2169, -13.6799, -16.4138,  ..., -11.7323,  -9.3301, -12.1456],\n",
      "          ...,\n",
      "          [-53.6855, -49.2084, -48.6956,  ..., -47.9869, -48.6832, -50.5034],\n",
      "          [-52.8633, -50.2232, -48.7245,  ..., -48.7317, -48.8106, -49.9419],\n",
      "          [-51.5715, -49.3451, -48.4451,  ..., -50.2108, -50.0642, -52.4181]]],\n",
      "\n",
      "\n",
      "        [[[-11.8320,  -9.3900, -12.8467,  ...,  -8.0388, -12.1001, -16.2452],\n",
      "          [-14.0154, -11.1234, -13.2705,  ..., -10.9791, -21.3799, -25.7574],\n",
      "          [-21.1259, -20.0579, -16.5633,  ..., -17.7590, -18.4349, -24.7722],\n",
      "          ...,\n",
      "          [-48.7344, -46.6707, -47.3893,  ..., -47.9304, -47.0027, -49.1107],\n",
      "          [-50.8510, -47.1817, -45.4753,  ..., -47.5742, -47.8928, -49.5717],\n",
      "          [-51.1758, -47.2426, -46.3059,  ..., -46.3051, -46.9690, -50.1339]]],\n",
      "\n",
      "\n",
      "        [[[-14.4391,  -9.1209, -13.9443,  ...,   0.0000,  -2.8345, -10.3333],\n",
      "          [-15.8548, -12.0871, -15.2193,  ...,  -4.8612,  -9.4798, -14.0009],\n",
      "          [-24.0867, -24.5031, -22.1925,  ..., -19.7124, -24.7431, -22.2317],\n",
      "          ...,\n",
      "          [-51.8401, -49.6562, -49.8052,  ..., -50.2163, -49.5208, -51.2952],\n",
      "          [-51.6299, -48.7858, -48.9311,  ..., -48.2765, -49.9220, -50.6108],\n",
      "          [-51.8833, -49.2698, -50.0158,  ..., -48.9768, -50.1476, -53.0972]]]]), tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1])]\n",
      "[tensor([[[[-12.9459, -10.7339, -10.5763,  ..., -20.9138, -20.2874, -14.5386],\n",
      "          [-16.2831, -17.0857, -17.3435,  ..., -20.9503, -15.2757, -11.8472],\n",
      "          [-19.1016, -23.3032, -27.8499,  ..., -24.8851, -16.8646, -13.7081],\n",
      "          ...,\n",
      "          [-56.1595, -54.5195, -52.6238,  ..., -53.5836, -51.8603, -54.6450],\n",
      "          [-55.6095, -52.5743, -51.9246,  ..., -53.2095, -52.6188, -55.5935],\n",
      "          [-56.4487, -52.2921, -53.7554,  ..., -52.4024, -51.2213, -51.8921]]],\n",
      "\n",
      "\n",
      "        [[[-18.0209, -11.7379, -10.2200,  ...,  -4.2470,   0.0000,  -3.4826],\n",
      "          [-23.1801, -15.6190, -14.9000,  ...,  -7.3462,  -2.9329,  -4.3133],\n",
      "          [-33.2646, -23.7604, -21.9551,  ..., -20.5872, -16.4038, -11.7417],\n",
      "          ...,\n",
      "          [-56.7785, -52.5463, -51.7002,  ..., -53.8370, -52.9018, -53.2154],\n",
      "          [-56.1939, -54.8628, -54.4604,  ..., -52.7387, -52.6176, -52.2500],\n",
      "          [-54.6674, -52.6126, -53.7326,  ..., -52.3661, -52.9609, -54.0416]]],\n",
      "\n",
      "\n",
      "        [[[-18.3027, -15.4641,  -9.5809,  ..., -11.0653, -12.1972, -19.5427],\n",
      "          [-19.2963, -18.3188, -13.0030,  ..., -15.4253, -15.2683, -24.6046],\n",
      "          [-20.2961, -20.8818, -20.8779,  ..., -24.6880, -25.6998, -30.8342],\n",
      "          ...,\n",
      "          [-48.0807, -45.6483, -45.3463,  ..., -47.3056, -47.6561, -47.9204],\n",
      "          [-47.8975, -44.5405, -43.8399,  ..., -47.5982, -47.1712, -48.2320],\n",
      "          [-48.5111, -45.4942, -44.9434,  ..., -46.1690, -44.6446, -46.2503]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.3386,  -8.1295,  -9.4182,  ...,  -3.5372,  -6.9823, -12.3089],\n",
      "          [-14.2323, -10.6343, -11.0549,  ...,  -6.1847, -12.1914, -14.8063],\n",
      "          [-23.5425, -23.3458, -19.9860,  ..., -17.2117, -20.5783, -20.5997],\n",
      "          ...,\n",
      "          [-49.5552, -46.5474, -46.3638,  ..., -47.1317, -46.2887, -47.9489],\n",
      "          [-50.2128, -46.6963, -46.5049,  ..., -46.7846, -48.3372, -50.4113],\n",
      "          [-49.7589, -48.1748, -49.3193,  ..., -48.4582, -49.2449, -50.2379]]],\n",
      "\n",
      "\n",
      "        [[[-11.0291,  -5.0556,  -7.3908,  ...,  -5.4382,  -8.5189, -14.6596],\n",
      "          [-11.8465,  -8.6335,  -9.1775,  ..., -10.5531, -13.6293, -21.6308],\n",
      "          [-17.3718, -17.8354, -16.5804,  ..., -19.8602, -21.2210, -25.3905],\n",
      "          ...,\n",
      "          [-50.1780, -48.1141, -49.1871,  ..., -47.1003, -47.3462, -50.3536],\n",
      "          [-49.9736, -48.0062, -49.3661,  ..., -47.9526, -48.1708, -51.8342],\n",
      "          [-52.2147, -48.4390, -48.6952,  ..., -48.9274, -48.7183, -51.3020]]],\n",
      "\n",
      "\n",
      "        [[[-12.6869,  -6.1255,  -5.5152,  ...,  -5.7381,  -3.4278,  -6.2596],\n",
      "          [-13.6166, -11.1559,  -8.7832,  ..., -11.3911,  -7.8598, -11.0899],\n",
      "          [-18.3389, -18.4038, -21.8603,  ..., -21.9691, -21.5309, -24.5514],\n",
      "          ...,\n",
      "          [-53.4539, -51.1406, -50.9320,  ..., -51.7844, -51.3928, -51.3885],\n",
      "          [-55.7355, -52.1812, -51.9173,  ..., -51.1953, -51.1556, -51.4325],\n",
      "          [-55.7891, -53.1854, -52.2578,  ..., -50.8765, -51.2024, -53.7012]]]]), tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])]\n",
      "[tensor([[[[ -5.1685,  -3.5431,  -6.1680,  ...,  -0.0917,  -0.7231,  -5.5518],\n",
      "          [ -7.6702,  -7.7361, -11.8104,  ...,  -6.2485,  -5.7362,  -8.8374],\n",
      "          [-13.8354, -15.0222, -20.2270,  ..., -22.6714, -23.3922, -22.0796],\n",
      "          ...,\n",
      "          [-55.2056, -52.8139, -52.3971,  ..., -52.7700, -53.1397, -54.7791],\n",
      "          [-55.8079, -52.0751, -50.6632,  ..., -52.3088, -52.0392, -54.6527],\n",
      "          [-56.1405, -53.2581, -52.3736,  ..., -53.7071, -53.6263, -53.4978]]],\n",
      "\n",
      "\n",
      "        [[[-10.6643,  -7.3887,  -8.8921,  ...,  -8.2710,  -7.0803, -11.5905],\n",
      "          [-10.7584,  -8.7772,  -8.7842,  ..., -12.7270,  -8.9024, -12.9026],\n",
      "          [-16.5672, -21.2453, -18.7724,  ..., -17.3295, -18.4741, -22.8398],\n",
      "          ...,\n",
      "          [-53.2704, -50.3550, -51.5633,  ..., -50.3345, -51.2440, -53.5748],\n",
      "          [-51.9836, -50.0980, -50.9822,  ..., -50.7501, -52.0841, -52.2893],\n",
      "          [-52.8884, -51.2494, -51.7744,  ..., -50.7838, -51.9005, -53.4901]]],\n",
      "\n",
      "\n",
      "        [[[-12.4899, -12.6390, -18.3412,  ..., -11.5354, -11.1510, -11.5272],\n",
      "          [-10.6332, -11.0089, -16.0313,  ..., -11.6983, -10.5265, -11.8239],\n",
      "          [-14.1030, -14.8124, -21.2318,  ..., -15.8251, -16.3481, -18.2146],\n",
      "          ...,\n",
      "          [-52.3472, -50.5478, -50.0083,  ..., -51.3235, -50.5600, -52.0638],\n",
      "          [-54.1867, -51.5227, -51.9898,  ..., -53.0278, -52.5103, -52.9369],\n",
      "          [-53.4603, -51.6214, -52.9473,  ..., -52.4769, -51.4700, -52.2444]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-18.7897, -15.7237, -19.1669,  ...,  -2.5864,  -3.4854,  -8.3363],\n",
      "          [-17.5980, -15.9615, -24.4952,  ..., -10.9740,  -9.5510, -10.4342],\n",
      "          [-23.2868, -20.0114, -26.7704,  ..., -31.7439, -22.8537, -20.2259],\n",
      "          ...,\n",
      "          [-55.7549, -51.1689, -50.3053,  ..., -50.8378, -50.6562, -53.0983],\n",
      "          [-54.3370, -50.7302, -50.5244,  ..., -51.5256, -51.2671, -51.4067],\n",
      "          [-55.3706, -51.2870, -50.2594,  ..., -52.2861, -51.2770, -52.1787]]],\n",
      "\n",
      "\n",
      "        [[[-19.4503, -11.6368,  -6.7816,  ..., -12.0678,  -8.9254,  -9.2904],\n",
      "          [-14.8976,  -8.0731,  -6.4716,  ..., -15.7901, -11.9013, -12.1636],\n",
      "          [-17.3328, -15.8321, -17.5205,  ..., -22.3996, -16.8316, -18.6882],\n",
      "          ...,\n",
      "          [-55.9450, -52.5807, -53.6123,  ..., -52.4918, -53.1196, -56.1903],\n",
      "          [-56.1926, -52.4201, -52.3664,  ..., -52.7488, -52.3760, -53.7092],\n",
      "          [-56.5493, -52.8165, -52.9666,  ..., -53.1975, -52.5657, -54.5543]]],\n",
      "\n",
      "\n",
      "        [[[ -8.2463,  -1.5153,  -0.3417,  ...,  -0.0767,  -0.2532,  -5.6081],\n",
      "          [ -7.9649,  -2.4761,  -3.8179,  ...,  -1.0361,  -2.4826,  -7.4762],\n",
      "          [-15.5043, -13.3370, -16.3814,  ..., -13.8375, -16.0605, -16.8942],\n",
      "          ...,\n",
      "          [-52.0576, -47.6453, -47.5434,  ..., -50.1476, -49.5708, -50.5257],\n",
      "          [-52.1544, -48.6912, -47.6840,  ..., -50.1298, -51.6062, -52.9518],\n",
      "          [-53.5745, -50.4228, -49.4765,  ..., -49.7564, -49.9691, -51.0382]]]]), tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0])]\n",
      "[tensor([[[[-11.7756,  -7.0410,  -4.9498,  ...,  -9.3433,  -6.6749,  -8.1286],\n",
      "          [-16.8265, -12.4159, -10.2116,  ...,  -8.9402,  -7.7014,  -9.2996],\n",
      "          [-22.2347, -21.5294, -20.6842,  ..., -16.5950, -21.3083, -17.7230],\n",
      "          ...,\n",
      "          [-52.1803, -50.2204, -50.7931,  ..., -50.7613, -50.6474, -51.4796],\n",
      "          [-53.6427, -51.5287, -50.7069,  ..., -49.1984, -50.5256, -53.1105],\n",
      "          [-53.3888, -50.0538, -50.9244,  ..., -50.5473, -49.6493, -52.5006]]],\n",
      "\n",
      "\n",
      "        [[[-16.8677, -10.9837, -11.5365,  ..., -17.7769, -14.8101, -12.9792],\n",
      "          [-16.3892, -12.8971, -14.8058,  ..., -26.5489, -17.9043, -13.9401],\n",
      "          [-21.4324, -22.9268, -26.4240,  ..., -31.6903, -24.6109, -19.1836],\n",
      "          ...,\n",
      "          [-55.8700, -52.3636, -51.3638,  ..., -50.5106, -52.0963, -54.2482],\n",
      "          [-56.1806, -52.7200, -51.4017,  ..., -50.6342, -51.1227, -53.4283],\n",
      "          [-57.3869, -54.4889, -53.0539,  ..., -54.0687, -52.3150, -53.6756]]],\n",
      "\n",
      "\n",
      "        [[[-11.7163,  -4.6254,  -3.2696,  ..., -16.9017, -12.0346, -14.7881],\n",
      "          [-12.1810,  -7.0967,  -6.9876,  ..., -15.8202, -15.7874, -15.3310],\n",
      "          [-20.1109, -21.1059, -22.1745,  ..., -18.4897, -20.9831, -20.7972],\n",
      "          ...,\n",
      "          [-50.0040, -47.9352, -48.0505,  ..., -48.1633, -48.3408, -50.5797],\n",
      "          [-52.1636, -49.2911, -48.9361,  ..., -48.9829, -48.4587, -51.9963],\n",
      "          [-53.8949, -50.1011, -49.6775,  ..., -49.2414, -48.3503, -52.0036]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -8.0873,  -7.3582,  -7.8443,  ..., -12.2081, -11.0819,  -8.1737],\n",
      "          [-10.2855, -11.8433, -10.3012,  ...,  -9.5623,  -9.5996,  -8.4761],\n",
      "          [-16.7114, -16.3081, -19.1141,  ..., -15.3856, -15.3966, -14.3635],\n",
      "          ...,\n",
      "          [-52.9925, -51.6669, -51.2964,  ..., -47.6690, -50.3343, -54.7010],\n",
      "          [-53.0450, -50.2613, -51.2696,  ..., -49.3092, -50.2960, -51.7941],\n",
      "          [-51.0952, -48.8961, -50.2779,  ..., -48.1650, -49.5840, -52.3887]]],\n",
      "\n",
      "\n",
      "        [[[-11.7221,  -7.5009,  -4.9032,  ...,  -3.8887,  -2.3518,  -5.2582],\n",
      "          [-12.1687,  -6.4206,  -4.1923,  ...,  -3.6549,  -2.2777,  -4.3293],\n",
      "          [-19.7003, -17.7530, -17.0349,  ..., -15.9735, -14.7695, -11.0209],\n",
      "          ...,\n",
      "          [-55.3763, -53.5250, -53.1544,  ..., -53.0976, -53.6414, -54.5680],\n",
      "          [-57.2011, -54.6884, -53.9950,  ..., -53.2046, -54.7418, -55.1734],\n",
      "          [-54.8278, -52.9933, -53.7695,  ..., -55.1222, -55.4178, -56.0121]]],\n",
      "\n",
      "\n",
      "        [[[-32.0508, -18.6434, -15.1491,  ..., -23.5368, -24.9932, -32.0979],\n",
      "          [-31.0583, -20.0940, -18.5767,  ..., -30.2197, -28.5712, -33.5006],\n",
      "          [-35.3113, -28.8498, -30.7482,  ..., -34.2117, -27.9173, -28.0230],\n",
      "          ...,\n",
      "          [-58.8011, -56.6923, -58.5047,  ..., -56.8365, -55.2544, -56.6119],\n",
      "          [-59.9491, -56.5991, -56.6075,  ..., -57.2557, -57.4822, -59.0407],\n",
      "          [-60.0381, -57.1882, -55.2488,  ..., -54.3049, -55.9977, -60.8532]]]]), tensor([0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1])]\n",
      "[tensor([[[[-13.8820, -13.2763, -12.7538,  ...,  -5.6196,  -4.1067,  -8.6514],\n",
      "          [-15.5819, -19.0227, -19.7076,  ...,  -8.1158,  -7.6211, -10.1307],\n",
      "          [-18.5374, -20.9645, -31.7378,  ..., -14.6175, -18.0286, -17.5111],\n",
      "          ...,\n",
      "          [-51.7487, -49.4922, -50.8934,  ..., -48.3644, -49.7760, -52.1333],\n",
      "          [-51.9308, -50.1141, -51.3312,  ..., -50.5186, -50.3585, -52.3874],\n",
      "          [-53.7617, -50.5438, -50.3975,  ..., -50.3885, -49.3604, -51.6796]]],\n",
      "\n",
      "\n",
      "        [[[ -3.6491,  -0.1169,  -1.2708,  ..., -15.0683, -18.6120, -16.5309],\n",
      "          [ -7.5189,  -4.7812,  -6.0383,  ..., -12.9051, -12.8131, -14.1332],\n",
      "          [-17.1251, -19.8379, -17.7177,  ..., -18.6443, -15.8214, -17.1822],\n",
      "          ...,\n",
      "          [-53.1104, -50.6421, -50.9671,  ..., -49.0212, -50.9348, -53.4743],\n",
      "          [-54.4481, -52.0334, -51.3920,  ..., -50.2045, -51.1214, -52.6923],\n",
      "          [-53.0755, -51.1130, -49.9918,  ..., -50.5614, -50.6246, -53.7614]]],\n",
      "\n",
      "\n",
      "        [[[ -9.7955,  -5.9862,  -3.8906,  ...,  -1.4620,  -6.8214, -12.6527],\n",
      "          [ -8.9254,  -3.9711,  -3.1762,  ...,  -1.2694,  -3.6564,  -9.0598],\n",
      "          [-14.6580, -14.2811, -15.4592,  ..., -13.5096, -13.4330, -13.1754],\n",
      "          ...,\n",
      "          [-55.6674, -53.4809, -53.3736,  ..., -53.4829, -54.8861, -55.5131],\n",
      "          [-56.9255, -55.2635, -54.5886,  ..., -53.6918, -53.9781, -54.3855],\n",
      "          [-56.1894, -53.2439, -53.3132,  ..., -54.0230, -53.9033, -54.7176]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -9.3630,  -8.0156, -10.7116,  ..., -15.6980, -18.4390, -22.9805],\n",
      "          [-11.0363, -10.8332, -16.3648,  ..., -12.0238, -11.7764, -16.9739],\n",
      "          [-17.6310, -19.5291, -27.1900,  ..., -18.5102, -14.0359, -19.7002],\n",
      "          ...,\n",
      "          [-56.1942, -53.0955, -53.3711,  ..., -53.7066, -53.6759, -55.7073],\n",
      "          [-55.1096, -52.2083, -52.4010,  ..., -52.3425, -51.5793, -54.9182],\n",
      "          [-55.2412, -52.8344, -52.3349,  ..., -54.3277, -52.6744, -54.7175]]],\n",
      "\n",
      "\n",
      "        [[[-16.5507, -16.8092, -13.3030,  ..., -11.8545,  -7.5122,  -7.1141],\n",
      "          [-17.8905, -15.7555, -15.3671,  ..., -12.9508,  -8.6334,  -8.8057],\n",
      "          [-22.0580, -20.2114, -21.9231,  ..., -21.1280, -17.4335, -16.1876],\n",
      "          ...,\n",
      "          [-51.2254, -49.3412, -48.4575,  ..., -48.8502, -49.8611, -52.1791],\n",
      "          [-51.9451, -48.5081, -48.4278,  ..., -48.6097, -48.3876, -50.1398],\n",
      "          [-52.1920, -49.4794, -48.2586,  ..., -48.9832, -49.5116, -51.7586]]],\n",
      "\n",
      "\n",
      "        [[[-12.6704, -10.0989, -15.7285,  ...,  -1.1067,  -4.9090, -11.6635],\n",
      "          [-17.0735, -12.7654, -14.1774,  ...,  -4.9070,  -9.1263, -17.1113],\n",
      "          [-24.4590, -19.2597, -19.7641,  ..., -18.5482, -19.4238, -18.5840],\n",
      "          ...,\n",
      "          [-61.6435, -58.9187, -57.5728,  ..., -59.3153, -58.2450, -59.3043],\n",
      "          [-60.0850, -57.6033, -56.7001,  ..., -58.3688, -58.7643, -59.3651],\n",
      "          [-62.3474, -59.6540, -58.1206,  ..., -57.3825, -57.4624, -59.3069]]]]), tensor([0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0])]\n",
      "[tensor([[[[ -7.6809,  -1.3894,  -6.1454,  ...,  -3.2551,  -6.2737, -16.9419],\n",
      "          [ -8.9156,  -3.4992,  -4.9761,  ...,  -5.3517,  -9.1741, -21.1846],\n",
      "          [-18.6063, -13.1490, -12.8090,  ..., -17.3216, -20.5329, -24.9092],\n",
      "          ...,\n",
      "          [-46.4100, -42.4945, -41.8615,  ..., -41.1409, -42.9757, -43.2790],\n",
      "          [-46.7894, -42.9631, -42.8739,  ..., -42.9658, -42.4366, -46.0061],\n",
      "          [-46.6880, -43.2702, -43.5808,  ..., -42.4506, -41.8991, -46.7900]]],\n",
      "\n",
      "\n",
      "        [[[-10.9027,  -5.9879,  -4.8815,  ..., -12.9866, -12.6573, -23.0787],\n",
      "          [-11.0216, -12.6848, -10.1498,  ..., -14.9163, -13.8779, -19.4198],\n",
      "          [-14.9135, -17.6198, -21.9165,  ..., -25.8100, -23.9186, -22.0997],\n",
      "          ...,\n",
      "          [-54.8032, -52.6899, -51.4362,  ..., -49.7228, -49.5046, -52.7644],\n",
      "          [-54.9945, -53.0867, -51.7927,  ..., -52.5484, -52.0616, -53.3008],\n",
      "          [-52.5169, -51.2426, -52.4969,  ..., -52.0333, -51.2828, -52.8398]]],\n",
      "\n",
      "\n",
      "        [[[-15.9130,  -9.9528,  -7.5890,  ..., -11.2977, -10.1811, -12.3607],\n",
      "          [-21.2572, -14.8245, -11.5313,  ..., -16.5643, -16.8365, -18.4382],\n",
      "          [-33.1820, -24.2761, -21.9110,  ..., -27.6454, -28.7181, -27.4541],\n",
      "          ...,\n",
      "          [-50.6144, -49.4790, -49.2020,  ..., -49.9200, -50.9647, -52.2441],\n",
      "          [-52.9786, -50.4453, -50.5858,  ..., -49.9498, -49.8033, -51.3987],\n",
      "          [-53.1406, -51.3434, -51.0862,  ..., -49.2642, -49.5327, -49.3084]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -6.2205,  -3.8830,  -4.9260,  ...,  -3.4583,  -2.2113,  -4.2974],\n",
      "          [ -6.9878,  -3.6763,  -4.0112,  ...,  -3.6516,  -2.7743,  -4.7081],\n",
      "          [-14.9627, -15.9165, -17.0534,  ..., -17.2712, -15.9078, -12.9416],\n",
      "          ...,\n",
      "          [-55.6110, -51.7466, -50.3878,  ..., -52.5192, -50.9247, -53.7009],\n",
      "          [-53.5899, -49.8057, -50.3230,  ..., -52.8653, -52.6432, -55.3551],\n",
      "          [-55.4416, -52.3089, -51.4771,  ..., -51.5620, -51.0621, -52.7299]]],\n",
      "\n",
      "\n",
      "        [[[-18.3339,  -9.2998,  -4.6474,  ..., -12.3196, -14.5386, -20.0846],\n",
      "          [-20.7360, -15.5852,  -7.0846,  ..., -14.6952, -17.1643, -24.0331],\n",
      "          [-26.5389, -24.6012, -16.0612,  ..., -22.2092, -19.4099, -23.9425],\n",
      "          ...,\n",
      "          [-51.2855, -47.6523, -48.5198,  ..., -48.6568, -48.5462, -50.3284],\n",
      "          [-52.5481, -49.4531, -48.6133,  ..., -48.4802, -48.6068, -50.3791],\n",
      "          [-52.2420, -49.7171, -48.2370,  ..., -49.4797, -50.1228, -51.8326]]],\n",
      "\n",
      "\n",
      "        [[[-12.6616,  -8.2074,  -9.9863,  ...,  -9.5144, -17.3313, -22.6666],\n",
      "          [-15.6575, -12.6969, -15.0423,  ..., -11.6336, -14.0662, -18.8411],\n",
      "          [-19.4713, -17.0566, -17.6623,  ..., -18.6267, -19.1972, -20.3666],\n",
      "          ...,\n",
      "          [-50.4674, -48.8755, -48.1325,  ..., -48.3828, -48.9122, -51.1367],\n",
      "          [-51.4188, -49.2578, -49.7904,  ..., -48.0029, -47.9695, -50.3255],\n",
      "          [-52.1345, -49.0089, -48.0940,  ..., -48.2453, -48.6368, -51.7287]]]]), tensor([0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0])]\n",
      "[tensor([[[[-12.3534,  -8.1414,  -7.3962,  ...,  -9.6710, -10.2073, -18.5057],\n",
      "          [-15.8491, -12.5674, -10.7024,  ..., -13.2207, -11.3987, -18.4529],\n",
      "          [-24.6950, -25.3183, -25.8794,  ..., -25.2772, -20.0603, -21.6492],\n",
      "          ...,\n",
      "          [-58.5614, -54.2405, -53.9698,  ..., -55.7635, -55.6912, -56.3000],\n",
      "          [-57.0635, -54.4432, -55.9435,  ..., -54.1819, -54.7409, -55.6478],\n",
      "          [-57.2229, -55.7335, -56.3952,  ..., -56.5256, -54.9140, -55.9728]]],\n",
      "\n",
      "\n",
      "        [[[ -4.0662,  -0.3494,   0.0000,  ...,  -4.6714,  -3.9676,  -8.6064],\n",
      "          [-10.3888,  -7.2953,  -5.8475,  ...,  -9.4470,  -8.2664, -10.5236],\n",
      "          [-17.5188, -18.0142, -23.6312,  ..., -20.8997, -20.2381, -17.0905],\n",
      "          ...,\n",
      "          [-54.4361, -50.9694, -49.5850,  ..., -50.9147, -48.4651, -49.2708],\n",
      "          [-53.5730, -49.8567, -50.6208,  ..., -51.8278, -50.4198, -52.0098],\n",
      "          [-53.8774, -52.0039, -51.2027,  ..., -49.0434, -48.4871, -52.2826]]],\n",
      "\n",
      "\n",
      "        [[[ -6.0855,  -4.9794,  -8.9611,  ...,  -4.5734,  -8.1216, -14.2574],\n",
      "          [ -8.3703,  -7.9510, -12.9993,  ...,  -3.3616,  -4.6402, -10.8244],\n",
      "          [-15.2722, -17.3643, -18.1749,  ..., -13.3375, -12.6844, -15.5775],\n",
      "          ...,\n",
      "          [-53.7831, -50.6899, -50.5273,  ..., -49.9324, -49.5276, -51.8852],\n",
      "          [-54.1276, -53.2184, -51.3571,  ..., -50.0235, -49.4541, -51.1497],\n",
      "          [-52.8796, -50.6453, -50.6585,  ..., -50.6192, -50.4637, -52.1600]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.5110,  -7.9269,  -7.1359,  ...,  -6.5687,  -8.4930, -13.5501],\n",
      "          [-16.0248, -13.7008, -10.5023,  ...,  -9.8067, -12.3579, -14.6271],\n",
      "          [-23.0445, -20.5140, -20.6409,  ..., -22.6591, -21.4507, -22.0410],\n",
      "          ...,\n",
      "          [-54.8558, -53.1715, -52.6942,  ..., -55.3365, -54.3472, -55.8967],\n",
      "          [-55.5346, -53.1642, -52.5521,  ..., -53.4395, -53.8366, -55.6236],\n",
      "          [-56.6218, -53.3334, -55.0011,  ..., -53.3813, -52.2190, -54.2354]]],\n",
      "\n",
      "\n",
      "        [[[-21.5801, -15.6315, -14.7686,  ..., -19.2304, -22.4431, -26.7380],\n",
      "          [-26.2056, -20.6170, -16.6030,  ..., -16.2064, -18.8988, -23.0298],\n",
      "          [-33.2804, -28.7255, -21.4495,  ..., -24.0527, -27.0809, -27.6899],\n",
      "          ...,\n",
      "          [-55.4699, -52.1332, -50.2111,  ..., -51.3910, -51.0190, -54.0519],\n",
      "          [-54.2748, -50.5112, -50.0293,  ..., -52.0322, -52.3634, -54.5737],\n",
      "          [-53.5809, -51.2456, -51.6310,  ..., -51.4344, -51.5829, -53.4043]]],\n",
      "\n",
      "\n",
      "        [[[ -9.9556,  -8.0223, -15.5049,  ...,  -5.8669,  -7.9880, -15.8333],\n",
      "          [ -7.7237,  -6.1376, -10.2059,  ...,  -5.8948, -10.3746, -19.1705],\n",
      "          [-11.4615, -14.8107, -14.7004,  ..., -17.7533, -22.1156, -32.2179],\n",
      "          ...,\n",
      "          [-51.2957, -49.0700, -49.1583,  ..., -48.1738, -49.3872, -52.2161],\n",
      "          [-50.7348, -48.1175, -49.4220,  ..., -47.8958, -48.5351, -49.4556],\n",
      "          [-50.5864, -48.8926, -49.5004,  ..., -48.6794, -49.1842, -52.3914]]]]), tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0])]\n",
      "[tensor([[[[-17.3370, -13.6840, -18.9090,  ...,  -6.2777,  -8.6486, -16.0327],\n",
      "          [-22.4095, -18.8803, -17.4200,  ..., -10.2325, -13.0265, -21.1505],\n",
      "          [-28.2006, -22.0807, -20.6433,  ..., -18.2779, -23.1035, -28.7418],\n",
      "          ...,\n",
      "          [-58.2493, -54.7077, -52.7674,  ..., -55.4682, -53.3706, -53.8794],\n",
      "          [-56.9645, -54.1312, -52.3820,  ..., -53.6517, -52.9824, -54.0226],\n",
      "          [-58.1695, -54.5925, -53.9564,  ..., -52.4616, -52.3464, -54.8691]]],\n",
      "\n",
      "\n",
      "        [[[ -8.0931,  -3.0809,  -2.1194,  ...,  -2.4892,  -3.2072,  -5.9954],\n",
      "          [ -8.8219,  -3.6177,  -2.6965,  ...,  -2.7955,  -3.2077,  -5.1771],\n",
      "          [-16.2112, -16.0135, -16.6433,  ..., -16.2770, -15.9546, -12.2362],\n",
      "          ...,\n",
      "          [-54.1955, -53.2327, -54.2320,  ..., -53.0093, -53.6045, -54.3664],\n",
      "          [-55.6548, -53.5421, -54.4195,  ..., -52.1077, -52.6243, -54.1062],\n",
      "          [-58.7440, -54.3559, -54.2793,  ..., -52.4463, -52.1186, -54.6892]]],\n",
      "\n",
      "\n",
      "        [[[ -9.6498,  -6.2075,  -4.5347,  ...,  -3.5316,  -4.4289,  -4.4301],\n",
      "          [ -9.5448,  -5.8848,  -5.0769,  ...,  -2.5754,  -3.3229,  -4.6227],\n",
      "          [-15.3968, -16.7912, -18.0456,  ..., -14.1376, -15.4660, -11.7303],\n",
      "          ...,\n",
      "          [-54.1135, -51.7630, -51.7465,  ..., -51.6635, -52.8606, -52.8051],\n",
      "          [-53.7857, -51.8269, -51.9632,  ..., -53.6480, -53.6472, -54.0929],\n",
      "          [-55.9510, -54.0242, -53.8441,  ..., -52.1160, -53.5992, -55.9835]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-19.3030, -20.0919, -14.3340,  ...,  -1.1654,  -4.4234, -15.1536],\n",
      "          [-17.3505, -16.7345, -13.2978,  ...,  -1.8424,  -3.4892, -11.1512],\n",
      "          [-21.5774, -23.9938, -20.7966,  ..., -10.2834, -12.9977, -13.8153],\n",
      "          ...,\n",
      "          [-53.1820, -51.2893, -52.1281,  ..., -50.9769, -50.3367, -52.9549],\n",
      "          [-55.8379, -51.9040, -52.0206,  ..., -50.9986, -51.2125, -53.2668],\n",
      "          [-55.7550, -52.6171, -52.5296,  ..., -52.2303, -52.8020, -53.9154]]],\n",
      "\n",
      "\n",
      "        [[[-11.1603,  -5.8698,  -5.5590,  ..., -11.9730, -12.3221, -11.9913],\n",
      "          [-12.4443,  -8.4158,  -7.2249,  ..., -15.0613, -12.1208, -13.6823],\n",
      "          [-21.6478, -22.9541, -19.5704,  ..., -17.1054, -19.1276, -21.0368],\n",
      "          ...,\n",
      "          [-47.0859, -46.2030, -46.4313,  ..., -44.2340, -44.1578, -46.9369],\n",
      "          [-48.9116, -46.0197, -45.4827,  ..., -44.7112, -45.0200, -47.0736],\n",
      "          [-50.2629, -46.8827, -46.5767,  ..., -45.6073, -46.9797, -48.5544]]],\n",
      "\n",
      "\n",
      "        [[[ -8.9465,  -4.9386,  -3.4910,  ...,  -8.8267,  -6.6299, -10.4541],\n",
      "          [-11.3466,  -9.8318,  -8.1840,  ..., -11.4609,  -7.0067, -10.0628],\n",
      "          [-18.8256, -24.1063, -22.3295,  ..., -17.7201, -17.6753, -18.2109],\n",
      "          ...,\n",
      "          [-56.3092, -54.5021, -54.6962,  ..., -54.3815, -55.0944, -58.3650],\n",
      "          [-57.5449, -54.3026, -53.5777,  ..., -55.1495, -55.4923, -57.5995],\n",
      "          [-56.4856, -56.0001, -56.5582,  ..., -55.7848, -55.2925, -56.0462]]]]), tensor([1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "        0])]\n",
      "[tensor([[[[-1.3163e+01, -1.3713e+01, -5.7044e+00,  ..., -1.2634e+01,\n",
      "           -1.5390e+01, -1.5345e+01],\n",
      "          [-1.2363e+01, -1.0146e+01, -7.4118e+00,  ..., -1.5231e+01,\n",
      "           -2.1727e+01, -1.8272e+01],\n",
      "          [-1.7476e+01, -1.6215e+01, -1.7197e+01,  ..., -2.2400e+01,\n",
      "           -2.5497e+01, -2.2533e+01],\n",
      "          ...,\n",
      "          [-5.1182e+01, -4.7666e+01, -4.9066e+01,  ..., -4.9475e+01,\n",
      "           -4.9563e+01, -5.2183e+01],\n",
      "          [-5.2512e+01, -5.0168e+01, -5.0191e+01,  ..., -5.0816e+01,\n",
      "           -5.0405e+01, -5.3730e+01],\n",
      "          [-5.1582e+01, -5.0124e+01, -5.0477e+01,  ..., -4.9791e+01,\n",
      "           -4.8661e+01, -5.0672e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8231e+01, -1.5682e+01, -1.6320e+01,  ..., -1.0946e+01,\n",
      "           -1.6421e+01, -2.0916e+01],\n",
      "          [-2.1584e+01, -2.1924e+01, -1.9308e+01,  ..., -1.6133e+01,\n",
      "           -2.4725e+01, -2.7363e+01],\n",
      "          [-2.5565e+01, -2.4838e+01, -2.4402e+01,  ..., -2.5382e+01,\n",
      "           -2.8689e+01, -3.0411e+01],\n",
      "          ...,\n",
      "          [-5.5260e+01, -5.1811e+01, -5.1724e+01,  ..., -5.4572e+01,\n",
      "           -5.2932e+01, -5.4526e+01],\n",
      "          [-5.2874e+01, -5.1235e+01, -5.1454e+01,  ..., -5.2265e+01,\n",
      "           -5.3131e+01, -5.6713e+01],\n",
      "          [-5.5489e+01, -5.3212e+01, -5.2562e+01,  ..., -5.1594e+01,\n",
      "           -5.2086e+01, -5.4104e+01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1001e+01, -1.1171e+01, -5.3095e+00,  ..., -1.7959e+00,\n",
      "           -8.4892e-01, -4.4087e+00],\n",
      "          [-1.6136e+01, -8.5612e+00, -6.8571e+00,  ..., -4.9754e+00,\n",
      "           -1.9684e+00, -5.6396e+00],\n",
      "          [-1.9678e+01, -1.6660e+01, -1.9172e+01,  ..., -1.8701e+01,\n",
      "           -1.3089e+01, -1.4169e+01],\n",
      "          ...,\n",
      "          [-5.3229e+01, -5.2300e+01, -5.2039e+01,  ..., -5.1505e+01,\n",
      "           -5.0635e+01, -5.2131e+01],\n",
      "          [-5.2583e+01, -5.1240e+01, -5.1056e+01,  ..., -5.1894e+01,\n",
      "           -5.0664e+01, -5.1814e+01],\n",
      "          [-5.2456e+01, -5.0066e+01, -5.1281e+01,  ..., -5.1113e+01,\n",
      "           -5.1398e+01, -5.3474e+01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.7889e+00, -5.3173e-02,  0.0000e+00,  ..., -1.3146e+01,\n",
      "           -1.3671e+01, -1.9899e+01],\n",
      "          [-9.5718e+00, -9.7293e+00, -8.9567e+00,  ..., -1.0821e+01,\n",
      "           -1.3538e+01, -2.3663e+01],\n",
      "          [-1.7641e+01, -1.7799e+01, -2.0182e+01,  ..., -1.7725e+01,\n",
      "           -2.0284e+01, -2.8764e+01],\n",
      "          ...,\n",
      "          [-4.6298e+01, -4.3867e+01, -4.4462e+01,  ..., -4.2813e+01,\n",
      "           -4.3264e+01, -4.6480e+01],\n",
      "          [-4.7597e+01, -4.4798e+01, -4.6027e+01,  ..., -4.4467e+01,\n",
      "           -4.4975e+01, -4.6983e+01],\n",
      "          [-4.6886e+01, -4.2917e+01, -4.3735e+01,  ..., -4.4047e+01,\n",
      "           -4.4016e+01, -4.7508e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9714e+01, -1.4077e+01, -1.0484e+01,  ..., -9.4866e+00,\n",
      "           -1.0080e+01, -1.4313e+01],\n",
      "          [-2.1948e+01, -1.4893e+01, -1.1055e+01,  ..., -1.3739e+01,\n",
      "           -1.2502e+01, -1.8532e+01],\n",
      "          [-2.1884e+01, -2.0928e+01, -1.5884e+01,  ..., -2.1130e+01,\n",
      "           -1.9600e+01, -2.5277e+01],\n",
      "          ...,\n",
      "          [-5.3528e+01, -5.1130e+01, -5.1114e+01,  ..., -4.9709e+01,\n",
      "           -5.0251e+01, -5.3770e+01],\n",
      "          [-5.5577e+01, -5.1963e+01, -5.0338e+01,  ..., -4.9454e+01,\n",
      "           -5.0415e+01, -5.4143e+01],\n",
      "          [-5.5766e+01, -5.1828e+01, -5.1872e+01,  ..., -5.2364e+01,\n",
      "           -5.4275e+01, -5.4615e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0949e+01, -8.2982e+00, -9.4104e+00,  ..., -8.3833e+00,\n",
      "           -1.0680e+01, -1.7655e+01],\n",
      "          [-1.4225e+01, -1.3354e+01, -1.2044e+01,  ..., -1.1007e+01,\n",
      "           -1.4488e+01, -2.0791e+01],\n",
      "          [-2.1753e+01, -2.3312e+01, -2.4889e+01,  ..., -2.6160e+01,\n",
      "           -2.6580e+01, -3.0275e+01],\n",
      "          ...,\n",
      "          [-5.5445e+01, -5.1929e+01, -5.1407e+01,  ..., -5.1096e+01,\n",
      "           -5.0680e+01, -5.1394e+01],\n",
      "          [-5.6412e+01, -5.3327e+01, -5.2589e+01,  ..., -5.1193e+01,\n",
      "           -5.1988e+01, -5.4647e+01],\n",
      "          [-5.4574e+01, -5.2384e+01, -5.2588e+01,  ..., -5.1052e+01,\n",
      "           -5.2922e+01, -5.4676e+01]]]]), tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0])]\n",
      "[tensor([[[[-10.5757,  -3.9565,  -2.4490,  ..., -14.0344,  -9.8667,  -8.6727],\n",
      "          [-11.0136,  -6.4531,  -5.1831,  ..., -15.6522, -15.9574, -11.5940],\n",
      "          [-16.8577, -18.9107, -17.7916,  ..., -25.2219, -21.9087, -16.2473],\n",
      "          ...,\n",
      "          [-49.0824, -47.5911, -48.4652,  ..., -47.4768, -46.8074, -49.4357],\n",
      "          [-50.9669, -46.5640, -47.5060,  ..., -47.9900, -48.4327, -50.0647],\n",
      "          [-50.7123, -46.7355, -48.1979,  ..., -49.1863, -48.1227, -50.5570]]],\n",
      "\n",
      "\n",
      "        [[[ -5.2120,  -4.1334,  -4.2097,  ...,  -3.1277,  -4.9027,  -9.8809],\n",
      "          [ -5.6036,  -2.7944,  -3.4257,  ...,  -1.8790,  -2.7097,  -7.4012],\n",
      "          [-12.0036, -13.3965, -15.7236,  ..., -13.7522, -12.8860, -12.6874],\n",
      "          ...,\n",
      "          [-55.8372, -55.1540, -55.6561,  ..., -54.8882, -53.8076, -53.9245],\n",
      "          [-57.1962, -55.5976, -54.3309,  ..., -53.6039, -53.9144, -54.7926],\n",
      "          [-57.5957, -53.3097, -53.5559,  ..., -52.3026, -52.0629, -55.3671]]],\n",
      "\n",
      "\n",
      "        [[[-10.9055,  -8.4470,  -7.5049,  ...,  -7.8123,  -8.2866,  -8.0311],\n",
      "          [-11.2018, -12.1854, -13.8080,  ...,  -8.2462,  -6.4423,  -8.3171],\n",
      "          [-16.2980, -16.6967, -25.5274,  ..., -18.9832, -15.7927, -17.1252],\n",
      "          ...,\n",
      "          [-47.6100, -45.3317, -44.1492,  ..., -43.8832, -44.8364, -47.1210],\n",
      "          [-46.9981, -43.2093, -44.3806,  ..., -44.0768, -44.4132, -46.8178],\n",
      "          [-47.9968, -46.1935, -45.9198,  ..., -44.9125, -44.4910, -47.1867]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-21.2481, -13.2318, -11.4360,  ..., -15.2457, -15.5091, -14.6598],\n",
      "          [-17.2403, -12.1630, -12.5750,  ..., -13.9417, -12.8999, -13.9763],\n",
      "          [-21.7108, -21.8343, -25.2063,  ..., -23.5583, -21.1637, -18.0900],\n",
      "          ...,\n",
      "          [-57.6918, -54.9767, -55.4636,  ..., -55.7728, -55.3717, -57.3948],\n",
      "          [-56.7882, -55.5966, -55.6308,  ..., -56.3670, -58.5222, -60.3500],\n",
      "          [-56.5126, -56.1400, -57.2627,  ..., -55.5291, -55.8905, -58.4184]]],\n",
      "\n",
      "\n",
      "        [[[ -8.8491,  -3.4978,  -2.1545,  ...,  -1.4982,  -2.7293,  -5.5224],\n",
      "          [-10.6318,  -8.1585,  -9.1547,  ...,  -6.2677,  -6.8292,  -7.6696],\n",
      "          [-17.5509, -18.6270, -23.1745,  ..., -18.0806, -17.0130, -17.8795],\n",
      "          ...,\n",
      "          [-55.0710, -53.1003, -52.7147,  ..., -54.3135, -54.2095, -54.4146],\n",
      "          [-56.1594, -53.1380, -52.6578,  ..., -54.8881, -52.9731, -53.5724],\n",
      "          [-57.9322, -53.9722, -51.9583,  ..., -54.1590, -52.9439, -53.9007]]],\n",
      "\n",
      "\n",
      "        [[[-16.7492, -12.9213, -15.4992,  ..., -12.9660, -18.1481, -28.5464],\n",
      "          [-16.1996, -16.6247, -23.7688,  ..., -17.7725, -19.2445, -21.1943],\n",
      "          [-21.6059, -22.9027, -25.0755,  ..., -29.1831, -24.5935, -21.2665],\n",
      "          ...,\n",
      "          [-59.5307, -55.9166, -53.8853,  ..., -52.0816, -53.1255, -55.9003],\n",
      "          [-56.8013, -54.8264, -54.2567,  ..., -51.6883, -52.1367, -53.6113],\n",
      "          [-54.8412, -54.4343, -53.4510,  ..., -52.3981, -52.6179, -53.7668]]]]), tensor([0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        1])]\n",
      "[tensor([[[[ -4.5473,  -6.2138,  -8.2985,  ...,  -9.9810,  -7.5181,  -8.0491],\n",
      "          [ -4.6183,  -6.6108,  -7.8492,  ...,  -9.0374, -12.7874, -10.7625],\n",
      "          [ -7.9839,  -7.1070, -11.3627,  ...,  -8.2434, -12.9951, -14.6108],\n",
      "          ...,\n",
      "          [-53.3331, -49.3938, -48.5414,  ..., -50.9687, -50.4058, -52.9669],\n",
      "          [-53.4087, -50.9847, -49.7883,  ..., -51.6659, -51.4237, -50.6602],\n",
      "          [-53.9578, -51.2299, -50.1041,  ..., -48.0495, -49.1640, -52.8801]]],\n",
      "\n",
      "\n",
      "        [[[-29.0853, -25.9006, -20.9731,  ...,  -4.6901,  -3.4193,  -6.6621],\n",
      "          [-31.8727, -30.8039, -26.8090,  ...,  -9.3810,  -8.3873, -10.8362],\n",
      "          [-34.7868, -31.7465, -26.1857,  ..., -22.7420, -23.9624, -23.2167],\n",
      "          ...,\n",
      "          [-56.9019, -54.4784, -53.9953,  ..., -51.4284, -52.9841, -54.8922],\n",
      "          [-55.0232, -53.2602, -52.1002,  ..., -51.9545, -52.1367, -54.1389],\n",
      "          [-57.8918, -54.3597, -53.4134,  ..., -53.0290, -53.1905, -53.7613]]],\n",
      "\n",
      "\n",
      "        [[[-12.3970, -12.6769, -11.6861,  ...,  -8.7590,  -8.7376, -15.7222],\n",
      "          [-13.7573, -12.4105, -11.5589,  ..., -10.1950,  -9.7541, -16.6158],\n",
      "          [-21.0281, -21.3274, -19.8277,  ..., -20.4875, -20.1054, -26.3162],\n",
      "          ...,\n",
      "          [-58.3173, -55.6905, -55.1446,  ..., -56.4763, -55.9175, -57.1586],\n",
      "          [-57.4746, -55.1483, -55.9968,  ..., -54.8604, -56.6697, -57.0417],\n",
      "          [-58.5717, -55.8531, -55.7319,  ..., -56.2001, -56.9702, -58.9404]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-13.5728, -14.9611, -20.2619,  ...,  -5.9169,  -4.7809,  -8.8456],\n",
      "          [-12.5747, -13.8058, -19.0077,  ...,  -9.9999,  -9.2723, -10.9084],\n",
      "          [-15.6077, -18.4661, -21.2161,  ..., -25.4814, -20.5172, -17.7988],\n",
      "          ...,\n",
      "          [-55.8372, -53.0905, -52.1294,  ..., -51.2333, -52.2833, -55.3700],\n",
      "          [-55.6846, -53.1335, -53.1861,  ..., -53.7703, -52.5696, -56.3729],\n",
      "          [-55.9756, -53.4670, -53.9101,  ..., -54.4707, -52.9915, -54.3717]]],\n",
      "\n",
      "\n",
      "        [[[-19.8387, -19.1716, -19.8422,  ..., -13.1208, -14.9518, -16.8472],\n",
      "          [-18.7445, -16.9057, -18.9242,  ..., -11.5250, -16.7029, -16.0062],\n",
      "          [-22.2301, -20.9569, -23.2562,  ..., -18.8113, -18.8529, -21.0423],\n",
      "          ...,\n",
      "          [-51.6377, -48.9324, -49.3959,  ..., -49.5261, -49.0410, -50.5903],\n",
      "          [-52.5942, -48.7486, -48.6424,  ..., -50.0788, -49.2967, -50.9648],\n",
      "          [-52.7858, -49.8041, -49.2364,  ..., -49.7302, -49.9798, -51.4836]]],\n",
      "\n",
      "\n",
      "        [[[-11.1326, -10.5856, -14.7633,  ..., -14.8453, -12.1551, -15.0998],\n",
      "          [-12.4634, -11.9332, -16.5080,  ..., -15.3169, -13.5214, -16.0434],\n",
      "          [-18.5694, -22.5046, -23.3326,  ..., -27.7116, -25.4419, -23.5093],\n",
      "          ...,\n",
      "          [-62.1397, -58.9528, -59.2467,  ..., -59.4400, -59.5343, -62.5773],\n",
      "          [-60.5881, -59.8082, -60.4605,  ..., -61.3787, -59.6531, -60.5962],\n",
      "          [-61.0361, -58.9775, -59.5100,  ..., -59.5443, -59.5720, -60.2610]]]]), tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[-14.5727,  -9.6321,  -9.2103,  ..., -11.8275, -12.9413, -14.7009],\n",
      "          [-14.8433, -10.5649, -10.4794,  ..., -11.4483, -14.5512, -22.0689],\n",
      "          [-19.2211, -19.8117, -23.7096,  ..., -19.3841, -21.9057, -22.2750],\n",
      "          ...,\n",
      "          [-48.0494, -45.3691, -45.0387,  ..., -44.0265, -44.6877, -46.3299],\n",
      "          [-47.9073, -45.6596, -44.2975,  ..., -43.3746, -44.3873, -46.3455],\n",
      "          [-46.8101, -43.1942, -42.5134,  ..., -44.2990, -44.3076, -46.7911]]],\n",
      "\n",
      "\n",
      "        [[[-11.4160,  -7.3010,  -6.6249,  ...,  -7.3409,  -7.4026,  -7.1805],\n",
      "          [-14.4316,  -9.6936,  -9.6551,  ..., -10.6789, -12.1702,  -8.9309],\n",
      "          [-23.1466, -21.0663, -21.5290,  ..., -16.4595, -22.0419, -14.9949],\n",
      "          ...,\n",
      "          [-53.4368, -51.5554, -52.7034,  ..., -53.0157, -51.8218, -53.0765],\n",
      "          [-55.1234, -52.2997, -52.0330,  ..., -52.9236, -53.6745, -53.7170],\n",
      "          [-55.4410, -52.7464, -54.5536,  ..., -52.0832, -51.6558, -53.0386]]],\n",
      "\n",
      "\n",
      "        [[[-25.4292, -21.1790, -22.2339,  ...,  -5.7871,  -9.1459, -14.4599],\n",
      "          [-26.4267, -23.9548, -24.4095,  ...,  -9.5116, -14.7796, -18.1322],\n",
      "          [-33.1059, -28.9126, -29.1085,  ..., -24.1106, -23.1945, -24.7255],\n",
      "          ...,\n",
      "          [-51.1722, -47.9533, -48.7014,  ..., -50.8125, -51.2782, -53.2235],\n",
      "          [-50.1713, -49.4649, -49.1165,  ..., -52.0051, -51.0308, -51.5985],\n",
      "          [-52.8469, -51.0000, -48.9094,  ..., -51.7971, -51.5983, -53.4973]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-10.5673,  -3.9909,  -2.2397,  ...,  -5.5005,  -9.2543, -11.1301],\n",
      "          [-12.1509, -11.3756,  -8.1727,  ...,  -9.4391, -16.0497, -16.9221],\n",
      "          [-18.5598, -21.9601, -23.0297,  ..., -23.3890, -22.1037, -25.7802],\n",
      "          ...,\n",
      "          [-52.5944, -51.0127, -51.3107,  ..., -49.6637, -48.0445, -49.6687],\n",
      "          [-52.9727, -50.3655, -51.2536,  ..., -50.5060, -49.5551, -51.8140],\n",
      "          [-51.6009, -49.8333, -50.5489,  ..., -49.9480, -49.9710, -53.0863]]],\n",
      "\n",
      "\n",
      "        [[[-31.1283, -19.7714, -13.0959,  ..., -15.0967, -13.8639, -12.3390],\n",
      "          [-28.8814, -18.6744, -14.8699,  ..., -15.0312, -14.5804, -12.8169],\n",
      "          [-27.4124, -22.4962, -26.7199,  ..., -21.2707, -22.0196, -19.5442],\n",
      "          ...,\n",
      "          [-56.3981, -53.3566, -54.6137,  ..., -54.7959, -55.6958, -57.0505],\n",
      "          [-60.1292, -54.9629, -54.1229,  ..., -53.5637, -53.8974, -56.5261],\n",
      "          [-59.2950, -54.1326, -54.6737,  ..., -53.2280, -54.1052, -56.9463]]],\n",
      "\n",
      "\n",
      "        [[[-15.2821, -11.3767, -11.9845,  ...,  -8.2670,  -8.7736, -12.1539],\n",
      "          [-16.1250, -13.5754, -12.0899,  ...,  -9.9776, -11.9258, -13.2226],\n",
      "          [-21.2551, -22.1299, -22.0504,  ..., -23.9481, -23.7623, -18.9937],\n",
      "          ...,\n",
      "          [-52.6190, -49.9110, -49.1751,  ..., -49.4075, -48.4457, -50.3696],\n",
      "          [-54.6232, -51.2046, -49.7113,  ..., -51.4984, -49.5948, -50.0063],\n",
      "          [-53.9702, -50.4028, -50.4095,  ..., -50.6015, -49.4070, -52.4006]]]]), tensor([1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[-20.4516, -17.9941, -20.7322,  ..., -10.1277,  -9.5659, -13.3434],\n",
      "          [-19.9730, -19.4323, -24.4138,  ..., -12.8505, -15.7333, -17.6391],\n",
      "          [-24.7819, -27.8253, -29.0989,  ..., -25.7507, -26.0385, -24.3234],\n",
      "          ...,\n",
      "          [-61.4442, -56.9441, -57.8352,  ..., -59.6203, -58.7586, -60.7551],\n",
      "          [-63.3090, -58.8948, -57.7879,  ..., -58.1593, -57.8995, -59.4014],\n",
      "          [-63.7417, -58.9781, -58.3609,  ..., -58.3074, -59.4399, -61.0138]]],\n",
      "\n",
      "\n",
      "        [[[-16.6691,  -6.9946,  -4.2131,  ...,  -4.6266,  -8.2105, -20.6552],\n",
      "          [-18.8094, -14.4730, -11.0312,  ...,  -8.4841, -11.0249, -22.1196],\n",
      "          [-30.1462, -28.0029, -26.0084,  ..., -21.5683, -20.1793, -19.5037],\n",
      "          ...,\n",
      "          [-56.2467, -52.7388, -52.5563,  ..., -53.2897, -53.3861, -55.1204],\n",
      "          [-56.1644, -53.2781, -54.2015,  ..., -55.0455, -55.1568, -57.1638],\n",
      "          [-56.9713, -53.0619, -52.9821,  ..., -55.6448, -54.6392, -57.0169]]],\n",
      "\n",
      "\n",
      "        [[[-18.9631, -13.8646,  -6.3394,  ...,  -5.7576,  -8.7145,  -9.8001],\n",
      "          [-14.4478,  -9.7717,  -6.0515,  ...,  -5.1902,  -6.5360,  -9.6219],\n",
      "          [-15.2846, -12.2192, -13.8214,  ..., -16.2318, -13.9726, -16.0866],\n",
      "          ...,\n",
      "          [-55.2470, -51.1208, -50.1670,  ..., -53.1796, -51.7913, -52.6755],\n",
      "          [-54.4827, -51.3380, -49.9832,  ..., -52.8669, -53.0000, -54.9691],\n",
      "          [-55.3948, -52.0201, -50.5608,  ..., -52.0717, -52.1901, -55.3488]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -7.9592,  -3.1344,  -2.6511,  ..., -10.3558, -11.6797, -17.3033],\n",
      "          [ -9.0071,  -7.6488, -11.3487,  ..., -11.8102,  -9.2244, -13.1895],\n",
      "          [-14.0929, -17.4014, -23.1372,  ..., -15.3419, -17.5167, -15.7416],\n",
      "          ...,\n",
      "          [-50.5680, -45.4783, -44.7638,  ..., -46.7668, -43.6946, -46.2976],\n",
      "          [-49.7016, -48.4203, -47.4780,  ..., -46.1984, -46.1178, -48.5836],\n",
      "          [-49.5079, -47.1403, -47.2599,  ..., -47.6474, -47.2906, -49.3603]]],\n",
      "\n",
      "\n",
      "        [[[-19.5398, -10.2152,  -8.2142,  ...,  -5.7538, -13.2875, -14.3327],\n",
      "          [-18.2087, -10.3713,  -9.4515,  ...,  -3.6821,  -9.0942, -14.3417],\n",
      "          [-25.1122, -20.6830, -19.5156,  ..., -10.5679, -16.3520, -18.6934],\n",
      "          ...,\n",
      "          [-54.8693, -52.6403, -53.0187,  ..., -53.9944, -51.9241, -53.2146],\n",
      "          [-55.0803, -53.3021, -52.8280,  ..., -52.2696, -52.6950, -55.4110],\n",
      "          [-56.9314, -52.7392, -52.0397,  ..., -52.4353, -52.6939, -54.9656]]],\n",
      "\n",
      "\n",
      "        [[[-21.1655,  -9.2806,  -5.2622,  ...,  -8.8647, -11.1282, -18.5056],\n",
      "          [-20.0558,  -9.4534,  -6.5965,  ..., -11.7341, -10.9992, -17.6177],\n",
      "          [-21.2958, -18.4667, -19.6582,  ..., -23.4726, -20.1104, -22.3423],\n",
      "          ...,\n",
      "          [-52.6853, -51.5193, -50.5851,  ..., -51.7641, -51.5040, -55.3226],\n",
      "          [-54.2208, -51.7189, -51.3510,  ..., -51.1839, -50.5015, -51.5194],\n",
      "          [-55.2196, -51.3944, -51.7383,  ..., -52.0318, -51.2384, -52.3445]]]]), tensor([0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[-24.0151, -14.0741,  -8.4813,  ...,  -7.1553,  -3.5366,  -4.7332],\n",
      "          [-23.5508, -12.4591,  -8.8935,  ..., -10.3823,  -6.3858,  -7.1951],\n",
      "          [-25.5836, -19.2200, -21.9387,  ..., -21.8384, -20.6047, -16.8313],\n",
      "          ...,\n",
      "          [-51.8312, -50.7193, -52.3980,  ..., -52.6845, -52.2245, -53.4746],\n",
      "          [-54.0043, -51.1681, -50.4154,  ..., -51.9934, -52.3931, -54.9598],\n",
      "          [-53.2392, -50.3139, -50.2935,  ..., -53.3171, -52.3102, -54.1964]]],\n",
      "\n",
      "\n",
      "        [[[ -6.1380,   0.0000,  -2.7168,  ..., -12.1368, -10.0503, -11.5785],\n",
      "          [ -6.2788,  -3.2301,  -6.3150,  ..., -10.3615, -11.0651, -13.5633],\n",
      "          [-13.6251, -15.8973, -17.5655,  ..., -20.3949, -22.2687, -22.6195],\n",
      "          ...,\n",
      "          [-51.9228, -51.6819, -54.1421,  ..., -51.6485, -50.9753, -53.2437],\n",
      "          [-52.7215, -51.4035, -51.8770,  ..., -55.0120, -55.5797, -56.5155],\n",
      "          [-54.9164, -52.4614, -52.8216,  ..., -53.7601, -53.2088, -53.1660]]],\n",
      "\n",
      "\n",
      "        [[[-42.9951, -36.3205, -36.3536,  ..., -48.3439, -42.3000, -41.3858],\n",
      "          [-43.3959, -39.5435, -39.7030,  ..., -49.3582, -46.7161, -47.5142],\n",
      "          [-50.4178, -53.0831, -55.0694,  ..., -57.7504, -54.0611, -50.6898],\n",
      "          ...,\n",
      "          [-80.0000, -79.2811, -80.0000,  ..., -79.9852, -79.7417, -80.0000],\n",
      "          [-80.0000, -80.0000, -80.0000,  ..., -79.3143, -79.0314, -80.0000],\n",
      "          [-80.0000, -79.0932, -79.6483,  ..., -79.6318, -79.4915, -80.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.7691, -12.9450,  -5.3312,  ..., -15.4166,  -9.5626,  -8.5781],\n",
      "          [-15.8101, -11.6237,  -6.9632,  ..., -18.2089, -12.4391, -10.7572],\n",
      "          [-20.8231, -16.4172, -15.3844,  ..., -20.1217, -24.1861, -17.7948],\n",
      "          ...,\n",
      "          [-47.6799, -43.9780, -42.7015,  ..., -42.8832, -45.8906, -47.8539],\n",
      "          [-45.3930, -43.2284, -43.3101,  ..., -42.7987, -44.2289, -46.8842],\n",
      "          [-45.2104, -43.1165, -44.7029,  ..., -43.2037, -42.8307, -45.3306]]],\n",
      "\n",
      "\n",
      "        [[[-12.8657, -11.2482, -13.4724,  ..., -10.0661, -11.7544,  -9.9558],\n",
      "          [-13.8016, -14.9496, -17.2188,  ..., -10.6228, -14.6726, -11.0705],\n",
      "          [-19.8329, -19.9795, -24.5743,  ..., -20.7737, -17.6161, -15.3557],\n",
      "          ...,\n",
      "          [-55.4961, -52.9254, -53.6704,  ..., -52.3865, -52.6815, -55.8604],\n",
      "          [-56.1053, -53.6912, -53.0935,  ..., -52.2997, -52.0639, -53.5094],\n",
      "          [-56.6315, -53.5775, -52.6498,  ..., -53.7087, -53.7046, -55.0886]]],\n",
      "\n",
      "\n",
      "        [[[-10.9037,  -9.6316, -15.9832,  ...,  -8.0860, -11.3804, -17.6645],\n",
      "          [-14.0838, -12.3146, -16.5750,  ..., -14.8592, -16.9757, -25.1795],\n",
      "          [-23.0597, -23.9344, -26.1906,  ..., -24.4917, -25.9262, -30.6096],\n",
      "          ...,\n",
      "          [-54.3032, -51.4389, -51.8348,  ..., -50.4987, -51.0670, -53.0224],\n",
      "          [-53.3753, -51.9854, -52.5193,  ..., -52.5263, -52.4781, -53.4447],\n",
      "          [-54.4793, -52.6034, -51.8446,  ..., -52.5953, -52.8672, -54.7190]]]]), tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[ -8.7493,  -4.5807,  -6.4738,  ..., -15.9647, -14.0820, -12.0870],\n",
      "          [-12.3815, -10.5802, -14.8960,  ..., -12.7258, -10.9269, -12.2491],\n",
      "          [-19.4824, -23.7299, -29.5765,  ..., -21.6016, -19.3830, -17.2908],\n",
      "          ...,\n",
      "          [-52.9048, -50.6366, -49.7437,  ..., -49.7154, -49.2230, -51.2233],\n",
      "          [-52.8697, -49.8926, -49.1587,  ..., -48.3543, -49.6159, -51.7414],\n",
      "          [-52.8566, -50.6728, -49.1883,  ..., -49.3658, -49.1887, -51.0989]]],\n",
      "\n",
      "\n",
      "        [[[ -7.6943,  -5.9382,  -7.4032,  ...,  -8.1046,  -6.6941,  -8.8680],\n",
      "          [-10.2469, -11.4874, -12.8954,  ..., -13.6241,  -9.5865, -11.0633],\n",
      "          [-16.2723, -19.8872, -23.0262,  ..., -26.5111, -22.3468, -21.9607],\n",
      "          ...,\n",
      "          [-54.4179, -52.9635, -53.7995,  ..., -54.1535, -54.6889, -56.2902],\n",
      "          [-55.2268, -52.4172, -53.1265,  ..., -54.1609, -53.8873, -56.5630],\n",
      "          [-56.8721, -53.6757, -53.8824,  ..., -52.9600, -53.5689, -56.0322]]],\n",
      "\n",
      "\n",
      "        [[[-21.2722, -15.7363,  -8.0751,  ...,  -7.4133,  -8.0877, -13.2537],\n",
      "          [-20.5599, -18.8401, -11.2284,  ..., -14.0391, -12.3484, -17.6471],\n",
      "          [-25.1204, -22.4697, -24.0603,  ..., -17.8006, -16.6104, -21.9891],\n",
      "          ...,\n",
      "          [-53.8747, -49.7312, -48.8353,  ..., -50.6623, -50.2794, -51.2271],\n",
      "          [-53.6322, -49.5831, -49.3631,  ..., -50.9076, -51.1527, -51.0633],\n",
      "          [-51.1943, -48.3772, -47.9430,  ..., -51.9853, -50.8899, -51.1673]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-20.3959, -16.9312,  -8.0731,  ...,  -4.7936, -11.8573, -10.2112],\n",
      "          [-19.3135, -13.2479,  -6.8360,  ...,  -4.4044,  -8.8201,  -9.5876],\n",
      "          [-21.3031, -17.6341, -14.4458,  ..., -12.8848, -15.2223, -13.6971],\n",
      "          ...,\n",
      "          [-51.9537, -48.4511, -47.5545,  ..., -47.8985, -46.5046, -47.7934],\n",
      "          [-52.2264, -48.3000, -47.6907,  ..., -45.9011, -46.9553, -50.1222],\n",
      "          [-52.2821, -48.0322, -48.4575,  ..., -46.2426, -46.7295, -50.8456]]],\n",
      "\n",
      "\n",
      "        [[[-12.5628,  -8.1854,  -7.5131,  ...,  -1.9018,  -2.7220,  -7.7348],\n",
      "          [-12.8445,  -8.3350,  -7.3685,  ...,  -5.0801,  -5.7026,  -8.7274],\n",
      "          [-18.6842, -20.4696, -18.0192,  ..., -18.9351, -18.2657, -18.4970],\n",
      "          ...,\n",
      "          [-53.3269, -52.5081, -53.6013,  ..., -52.3845, -53.6357, -55.7000],\n",
      "          [-55.8092, -53.5823, -53.8144,  ..., -51.1757, -51.5666, -53.6472],\n",
      "          [-56.6887, -53.7506, -53.7992,  ..., -50.3366, -51.5614, -52.8527]]],\n",
      "\n",
      "\n",
      "        [[[-13.8973,  -7.7259,  -5.2067,  ...,  -3.8277,  -7.8463, -10.4925],\n",
      "          [-16.4069, -15.3037,  -8.7685,  ...,  -8.0257, -12.5607, -11.9184],\n",
      "          [-19.6523, -18.2227, -19.9249,  ..., -21.0571, -15.6680, -14.9900],\n",
      "          ...,\n",
      "          [-54.9636, -52.6137, -52.2102,  ..., -51.4800, -52.3609, -53.2149],\n",
      "          [-53.9044, -51.6077, -52.3988,  ..., -53.3218, -53.4893, -53.3324],\n",
      "          [-53.8415, -52.4827, -53.0353,  ..., -54.9332, -53.2509, -52.9774]]]]), tensor([1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0])]\n"
     ]
    }
   ],
   "source": [
    "# ラベルの指定\n",
    "t_df = Dataset.shNum\n",
    "\n",
    "# テンソル形式に変換\n",
    "df_tenosor = torch.tensor(df, dtype=torch.float32)\n",
    "df_tenosor = torch.unsqueeze(df_tenosor, 1)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "print(df_tenosor.size())\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset = torch.utils.data.TensorDataset(df_tenosor, label_tensor)\n",
    "\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 50%　: 25% : 25%\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 25\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DyMN(\n",
      "  (layers): ModuleList(\n",
      "    (0): DY_Block(\n",
      "      (exp_conv): DynamicWrapper(\n",
      "        (module): Identity()\n",
      "      )\n",
      "      (exp_norm): Identity()\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Identity()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (1): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=256, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (3): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (4-5): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=480, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (6): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=960, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(40, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=800, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (8-9): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=736, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (10): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=1920, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (11): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (12): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (13-14): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=3840, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (in_c): ConvNormActivation(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (out_c): ConvNormActivation(\n",
      "    (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=960, out_features=1280, bias=False)\n",
      "    (3): Hardswish()\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Linear(in_features=1280, out_features=527, bias=False)\n",
      "    (6): Linear(in_features=527, out_features=176, bias=False)\n",
      "    (7): Linear(in_features=176, out_features=21, bias=False)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=21, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "shModel_2 = objModel_trained\n",
    "\n",
    "#パラメータの更新を許可\n",
    "for param in shModel_2.parameters():\n",
    "    param.requires_gred = False\n",
    "\n",
    "\n",
    "# print(model.classifier)\n",
    "\n",
    "# 出力層の最後だけ変更\n",
    "# model.classifier[5] = torch.nn.Linear(1280,2)\n",
    "shModel_2.classifier= nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(output_size=1),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    nn.Linear(in_features=960, out_features=1280, bias=False),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(p=0.2, inplace=False),\n",
    "    nn.Linear(in_features=1280, out_features=527, bias=False),\n",
    "    nn.Linear(in_features=527, out_features=176, bias=False),  # 新しい層\n",
    "    nn.Linear(in_features=176, out_features=21, bias=False),  # 新しい層\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=21, out_features=2, bias=True),  # 新しい層\n",
    "\n",
    "\n",
    ")\n",
    "print(shModel_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch [1/50], Train Loss: 0.6698, Validation Loss: 0.6919\n",
      "Epoch [2/50], Train Loss: 0.6400, Validation Loss: 0.6419\n",
      "Epoch [3/50], Train Loss: 0.5180, Validation Loss: 0.3330\n",
      "Epoch [4/50], Train Loss: 0.2368, Validation Loss: 0.1332\n",
      "Epoch [5/50], Train Loss: 0.1027, Validation Loss: 0.0683\n",
      "Epoch [6/50], Train Loss: 0.0433, Validation Loss: 0.0444\n",
      "Epoch [7/50], Train Loss: 0.0243, Validation Loss: 0.0270\n",
      "Epoch [8/50], Train Loss: 0.0128, Validation Loss: 0.0189\n",
      "Epoch [9/50], Train Loss: 0.0070, Validation Loss: 0.0165\n",
      "Epoch [10/50], Train Loss: 0.0053, Validation Loss: 0.0166\n",
      "Epoch [11/50], Train Loss: 0.0037, Validation Loss: 0.0143\n",
      "Epoch [12/50], Train Loss: 0.0024, Validation Loss: 0.0140\n",
      "Epoch [13/50], Train Loss: 0.0024, Validation Loss: 0.0127\n",
      "Epoch [14/50], Train Loss: 0.0025, Validation Loss: 0.0139\n",
      "Epoch [15/50], Train Loss: 0.0017, Validation Loss: 0.0123\n",
      "Epoch [16/50], Train Loss: 0.0058, Validation Loss: 0.0237\n",
      "Epoch [17/50], Train Loss: 0.0023, Validation Loss: 0.0158\n",
      "Epoch [18/50], Train Loss: 0.0012, Validation Loss: 0.0148\n",
      "Epoch [19/50], Train Loss: 0.0011, Validation Loss: 0.0150\n",
      "Epoch [20/50], Train Loss: 0.0011, Validation Loss: 0.0138\n",
      "Epoch [21/50], Train Loss: 0.0013, Validation Loss: 0.0107\n",
      "Epoch [22/50], Train Loss: 0.0006, Validation Loss: 0.0109\n",
      "Epoch [23/50], Train Loss: 0.0009, Validation Loss: 0.0109\n",
      "Epoch [24/50], Train Loss: 0.0004, Validation Loss: 0.0112\n",
      "Epoch [25/50], Train Loss: 0.0008, Validation Loss: 0.0120\n",
      "Epoch [26/50], Train Loss: 0.0004, Validation Loss: 0.0126\n",
      "Epoch [27/50], Train Loss: 0.0006, Validation Loss: 0.0130\n",
      "Epoch [28/50], Train Loss: 0.0003, Validation Loss: 0.0140\n",
      "Epoch [29/50], Train Loss: 0.0003, Validation Loss: 0.0147\n",
      "Epoch [30/50], Train Loss: 0.0009, Validation Loss: 0.0178\n",
      "Epoch [31/50], Train Loss: 0.0003, Validation Loss: 0.0171\n",
      "Epoch [32/50], Train Loss: 0.0002, Validation Loss: 0.0164\n",
      "Epoch [33/50], Train Loss: 0.0003, Validation Loss: 0.0156\n",
      "Epoch [34/50], Train Loss: 0.0002, Validation Loss: 0.0149\n",
      "Epoch [35/50], Train Loss: 0.0003, Validation Loss: 0.0146\n",
      "Epoch [36/50], Train Loss: 0.0002, Validation Loss: 0.0150\n",
      "Epoch [37/50], Train Loss: 0.0002, Validation Loss: 0.0151\n",
      "Epoch [38/50], Train Loss: 0.0026, Validation Loss: 0.0068\n",
      "Epoch [39/50], Train Loss: 0.0149, Validation Loss: 0.0507\n",
      "Epoch [40/50], Train Loss: 0.0002, Validation Loss: 0.0434\n",
      "Epoch [41/50], Train Loss: 0.0002, Validation Loss: 0.0377\n",
      "Epoch [42/50], Train Loss: 0.0005, Validation Loss: 0.0353\n",
      "Epoch [43/50], Train Loss: 0.0055, Validation Loss: 0.0377\n",
      "Epoch [44/50], Train Loss: 0.0003, Validation Loss: 0.0214\n",
      "Epoch [45/50], Train Loss: 0.0004, Validation Loss: 0.0159\n",
      "Epoch [46/50], Train Loss: 0.0002, Validation Loss: 0.0133\n",
      "Epoch [47/50], Train Loss: 0.0003, Validation Loss: 0.0106\n",
      "Epoch [48/50], Train Loss: 0.0004, Validation Loss: 0.0090\n",
      "Epoch [49/50], Train Loss: 0.0002, Validation Loss: 0.0083\n",
      "Epoch [50/50], Train Loss: 0.0003, Validation Loss: 0.0086\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# エポックの数\n",
    "max_epoch = 50\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net4 = shModel_2.cuda()\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "  \n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net4.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "for epoch in range(max_epoch):\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net4.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y = net4(x)\n",
    "        loss = criterion(y[0], t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net4.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "  \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net4(x)\n",
    "            loss = criterion(y[0], t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "shModel_2_trained = net4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "def ShowTrainLoss(train_losses,val_losses,save):\n",
    "    # 日本時間のタイムゾーンを取得\n",
    "    jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "    # 現在の日本時間を取得\n",
    "    now = datetime.now(jst)\n",
    "\n",
    "    # 時刻を指定された形式の文字列に変換\n",
    "    time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # 学習曲線の可視化\n",
    "\n",
    "    title = 'Training and Validation Losses Soft-hard'\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0,5)\n",
    "    plt.legend()\n",
    "    if save == True:\n",
    "        plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "ShowTrainLoss(train_losses,val_losses,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.6%\n",
      "Accuracy: 100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y[0], dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            # x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net4(x)\n",
    "            \n",
    "            y_label = torch.argmax(y[0], dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### material 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1050, 1, 128, 130])\n",
      "525 262 263\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fdd1bffb610>\n",
      "[tensor([[[[-15.7372, -12.7907, -12.2806,  ..., -16.2258, -12.1957, -14.6959],\n",
      "          [-15.7418, -11.8346, -11.9373,  ..., -12.7932, -11.7111, -12.4843],\n",
      "          [-22.5785, -21.3953, -21.5793,  ..., -20.6679, -21.5296, -17.3727],\n",
      "          ...,\n",
      "          [-58.1976, -55.0280, -55.0888,  ..., -53.4471, -52.7718, -53.7474],\n",
      "          [-56.4661, -53.7698, -54.6103,  ..., -54.0908, -53.9045, -56.2288],\n",
      "          [-57.3117, -54.9557, -55.6911,  ..., -54.7845, -54.3604, -56.0656]]],\n",
      "\n",
      "\n",
      "        [[[ -5.8755,  -1.3352,   0.0000,  ...,  -8.2323,  -7.3307,  -8.7717],\n",
      "          [ -7.0860,  -4.6320,  -2.7805,  ...,  -6.8078,  -5.4152,  -6.6856],\n",
      "          [-14.4937, -18.4999, -18.0805,  ..., -15.1023, -14.4274, -11.6789],\n",
      "          ...,\n",
      "          [-50.1694, -46.3330, -44.8377,  ..., -47.9001, -46.6421, -47.7369],\n",
      "          [-49.2638, -46.9567, -46.7122,  ..., -46.9204, -46.5079, -49.3187],\n",
      "          [-46.9555, -45.9099, -47.1923,  ..., -47.8846, -48.9719, -50.9079]]],\n",
      "\n",
      "\n",
      "        [[[-14.0626, -12.4793, -12.4311,  ...,  -6.8308,  -6.2901, -10.4582],\n",
      "          [-18.8385, -19.3206, -16.3264,  ...,  -9.3470,  -9.8862, -12.6103],\n",
      "          [-26.0905, -30.3457, -25.2675,  ..., -20.0117, -23.9119, -21.9449],\n",
      "          ...,\n",
      "          [-53.3047, -52.0847, -53.4519,  ..., -52.4061, -53.3940, -56.5739],\n",
      "          [-58.1525, -54.5277, -52.5746,  ..., -53.0982, -53.9163, -56.1266],\n",
      "          [-55.2106, -52.8737, -53.1973,  ..., -52.8028, -52.4231, -54.3603]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -9.9831,  -7.1871, -11.7807,  ..., -11.2343,  -9.8302, -13.3886],\n",
      "          [-11.8676,  -9.5992, -15.2492,  ..., -12.9284, -12.4264, -17.9736],\n",
      "          [-19.0413, -18.4740, -26.9585,  ..., -21.7851, -23.7197, -26.1367],\n",
      "          ...,\n",
      "          [-53.6593, -52.2464, -51.7386,  ..., -51.2787, -51.4993, -56.2754],\n",
      "          [-55.0183, -52.9384, -52.6564,  ..., -51.3566, -51.8909, -54.7269],\n",
      "          [-56.5075, -52.0982, -52.3580,  ..., -51.7871, -52.0791, -53.2282]]],\n",
      "\n",
      "\n",
      "        [[[-17.2652, -11.0746,  -9.8907,  ...,  -0.6295,   0.0000,  -3.5875],\n",
      "          [-18.6370, -15.4748, -16.1502,  ...,  -6.1369,  -3.3467,  -4.0424],\n",
      "          [-28.6770, -30.6238, -34.6265,  ..., -19.3636, -16.2683, -12.0035],\n",
      "          ...,\n",
      "          [-56.7433, -54.9483, -56.3357,  ..., -56.7504, -55.6961, -54.8034],\n",
      "          [-59.7806, -56.2284, -55.0864,  ..., -54.5428, -54.2212, -54.7591],\n",
      "          [-60.2414, -56.0917, -55.5884,  ..., -56.2427, -55.2146, -53.6850]]],\n",
      "\n",
      "\n",
      "        [[[ -9.3511,  -5.2951,  -9.8728,  ..., -10.9083,  -9.2532, -11.2135],\n",
      "          [ -8.2031,  -6.5688, -12.9695,  ..., -10.1815, -11.6199, -10.9543],\n",
      "          [-13.0035, -13.6482, -18.5944,  ..., -16.5582, -14.2727, -13.9899],\n",
      "          ...,\n",
      "          [-45.4077, -44.2285, -46.0337,  ..., -45.8847, -45.8283, -47.6377],\n",
      "          [-47.8298, -45.4274, -44.8245,  ..., -45.7963, -45.1360, -47.9109],\n",
      "          [-46.2646, -44.5052, -46.9336,  ..., -47.0090, -46.8320, -47.4182]]]]), tensor([5, 0, 4, 5, 0, 1, 1, 3, 0, 2, 0, 5, 2, 5, 5, 5, 0, 0, 0, 1, 2, 2, 3, 4,\n",
      "        2])]\n",
      "[tensor([[[[ -6.0762,  -3.5017,  -3.3377,  ...,  -4.1093,  -2.1572,  -5.0010],\n",
      "          [ -8.7918,  -7.3907,  -5.0249,  ...,  -8.1448,  -4.9479,  -9.1982],\n",
      "          [ -9.1813,  -6.6263, -11.7422,  ...,  -8.8395, -12.1046, -19.2009],\n",
      "          ...,\n",
      "          [-52.7497, -48.8865, -48.6537,  ..., -51.1285, -49.8177, -50.1686],\n",
      "          [-50.9880, -48.3031, -49.1782,  ..., -49.3246, -50.4652, -51.6474],\n",
      "          [-53.7844, -50.3416, -49.3829,  ..., -49.5337, -51.0771, -51.4142]]],\n",
      "\n",
      "\n",
      "        [[[-23.0836, -17.6527, -16.0622,  ..., -10.6483, -10.1918, -12.0575],\n",
      "          [-23.1806, -22.3402, -18.6569,  ..., -13.4887, -13.7516, -13.3281],\n",
      "          [-26.3015, -25.4151, -28.7933,  ..., -27.0607, -24.7454, -19.3046],\n",
      "          ...,\n",
      "          [-66.6998, -62.6790, -60.6387,  ..., -61.7790, -61.7823, -62.4379],\n",
      "          [-63.1558, -60.9635, -61.3787,  ..., -63.1781, -63.1277, -62.9624],\n",
      "          [-64.4473, -63.1082, -63.1545,  ..., -62.6057, -62.2202, -63.7380]]],\n",
      "\n",
      "\n",
      "        [[[-19.4677, -13.8089, -14.6049,  ..., -10.6197,  -9.1130, -14.6017],\n",
      "          [-26.8576, -22.7456, -24.1618,  ..., -10.5441, -12.6558, -19.9263],\n",
      "          [-35.0707, -34.8668, -34.4597,  ..., -19.6834, -21.1026, -24.3130],\n",
      "          ...,\n",
      "          [-57.2477, -53.7524, -52.4263,  ..., -53.7950, -53.9968, -55.4982],\n",
      "          [-55.1792, -53.1644, -54.2603,  ..., -52.6724, -53.1959, -54.9959],\n",
      "          [-54.3971, -52.5030, -52.5609,  ..., -53.9797, -53.4432, -55.9142]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -6.2664,  -2.9890,  -5.2798,  ...,  -5.7535,  -4.7177,  -6.9648],\n",
      "          [ -7.5614,  -3.9616,  -7.6979,  ...,  -7.0264,  -8.9588, -11.5580],\n",
      "          [-15.4290, -14.8272, -17.7061,  ..., -19.6478, -22.2260, -23.2930],\n",
      "          ...,\n",
      "          [-51.9192, -50.1242, -49.7132,  ..., -47.8093, -47.7594, -49.0973],\n",
      "          [-52.1852, -48.6977, -48.1595,  ..., -47.4365, -47.7249, -49.1994],\n",
      "          [-51.3106, -48.8156, -48.8151,  ..., -47.7161, -48.4147, -50.3677]]],\n",
      "\n",
      "\n",
      "        [[[-12.9531,  -8.4623, -10.9949,  ..., -13.9743, -12.5583, -12.9040],\n",
      "          [-12.9575,  -9.1291,  -9.6971,  ..., -12.4427, -10.5136, -12.3491],\n",
      "          [-18.2892, -20.0374, -20.3422,  ..., -16.5155, -15.7638, -17.3400],\n",
      "          ...,\n",
      "          [-54.6013, -51.4329, -50.6813,  ..., -50.8779, -51.4110, -53.4678],\n",
      "          [-52.1137, -49.6309, -49.8039,  ..., -51.3086, -50.1676, -51.5474],\n",
      "          [-52.6111, -51.0972, -51.9317,  ..., -52.1191, -50.8958, -52.4753]]],\n",
      "\n",
      "\n",
      "        [[[-25.9034, -21.9119, -14.0451,  ...,  -5.3250,  -9.2805, -16.3978],\n",
      "          [-19.3675, -13.7969, -12.1835,  ...,  -7.1418,  -7.7071, -15.4302],\n",
      "          [-19.0328, -17.3201, -16.0753,  ..., -17.0908, -13.7243, -22.8432],\n",
      "          ...,\n",
      "          [-48.0925, -46.5962, -46.7822,  ..., -47.8841, -46.8159, -47.6297],\n",
      "          [-47.8132, -45.3680, -44.6936,  ..., -46.3455, -46.1164, -49.3973],\n",
      "          [-49.8005, -47.0284, -47.1830,  ..., -46.4303, -46.3429, -48.1432]]]]), tensor([0, 4, 3, 0, 2, 5, 0, 1, 3, 0, 0, 0, 0, 0, 0, 4, 0, 1, 3, 4, 3, 0, 1, 0,\n",
      "        2])]\n",
      "[tensor([[[[-10.0279,  -7.8579, -11.8001,  ..., -12.3195,  -7.2473,  -9.8667],\n",
      "          [-10.8272,  -8.6687, -14.2134,  ..., -12.5902,  -6.6770,  -8.9679],\n",
      "          [-17.5238, -18.0341, -23.8566,  ..., -20.1754, -14.4655, -14.4317],\n",
      "          ...,\n",
      "          [-53.8049, -51.9219, -53.2467,  ..., -50.7193, -51.2442, -53.0188],\n",
      "          [-54.4185, -52.8468, -53.4759,  ..., -52.1240, -51.0827, -54.4927],\n",
      "          [-55.8065, -52.5886, -52.4451,  ..., -53.5472, -51.6183, -53.5764]]],\n",
      "\n",
      "\n",
      "        [[[-10.7324,  -4.6517,  -3.8478,  ...,  -8.2309, -14.8002, -18.0520],\n",
      "          [-11.8236,  -6.3387,  -9.1619,  ..., -12.2978, -17.8332, -16.8948],\n",
      "          [-21.9459, -15.6345, -17.6357,  ..., -23.1039, -19.1691, -19.0841],\n",
      "          ...,\n",
      "          [-53.8330, -49.2684, -48.2273,  ..., -48.3188, -49.0298, -52.3784],\n",
      "          [-53.0411, -49.3866, -48.0516,  ..., -49.6745, -49.0690, -51.8535],\n",
      "          [-53.7364, -49.5175, -48.6195,  ..., -50.3162, -49.5507, -49.6395]]],\n",
      "\n",
      "\n",
      "        [[[ -7.1616,  -0.9457,   0.0000,  ...,  -5.7713,  -8.1283, -18.2104],\n",
      "          [ -7.6271,  -3.1601,  -2.3634,  ...,  -8.6473,  -7.9879, -13.6696],\n",
      "          [-13.9333, -14.6354, -14.1242,  ..., -19.9669, -18.1613, -17.1388],\n",
      "          ...,\n",
      "          [-54.6771, -51.6242, -50.7401,  ..., -50.1866, -50.7028, -51.4649],\n",
      "          [-54.6167, -51.3566, -50.3548,  ..., -51.2736, -51.6761, -52.4059],\n",
      "          [-52.7593, -50.6332, -51.0717,  ..., -49.3423, -51.7091, -53.6027]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -8.3681,  -5.1823,  -7.4577,  ...,  -3.7348,  -2.5485,  -6.6958],\n",
      "          [ -8.0277,  -4.9073,  -4.9623,  ...,  -4.2416,  -4.8608,  -9.5555],\n",
      "          [-13.0840, -13.7098, -12.8687,  ..., -17.7461, -19.1325, -21.0760],\n",
      "          ...,\n",
      "          [-50.0689, -46.2291, -45.4716,  ..., -46.8236, -47.4431, -49.0650],\n",
      "          [-50.4353, -47.2231, -45.5502,  ..., -46.8992, -46.7623, -48.7872],\n",
      "          [-48.1989, -46.7950, -47.2719,  ..., -46.1326, -46.5750, -47.0558]]],\n",
      "\n",
      "\n",
      "        [[[-24.0054, -16.5717, -12.2069,  ..., -10.8894, -11.0717, -14.5653],\n",
      "          [-26.5346, -21.9115, -16.5898,  ..., -15.5828, -16.0140, -14.1760],\n",
      "          [-30.1219, -23.5671, -23.9182,  ..., -19.3224, -19.7878, -16.0493],\n",
      "          ...,\n",
      "          [-55.0039, -50.1655, -47.9797,  ..., -48.1771, -49.0459, -50.6193],\n",
      "          [-50.9413, -48.6363, -49.1542,  ..., -50.7510, -50.4623, -51.4882],\n",
      "          [-51.2350, -50.3329, -50.0501,  ..., -51.2576, -50.9684, -51.8375]]],\n",
      "\n",
      "\n",
      "        [[[ -9.2767,  -5.4631,  -1.6625,  ..., -10.1021,  -7.4068,  -9.1599],\n",
      "          [ -7.2520,  -3.3959,  -2.4361,  ...,  -7.8024,  -6.9836,  -7.6628],\n",
      "          [-12.1627, -14.2867, -15.8049,  ..., -17.6147, -16.5750, -12.0232],\n",
      "          ...,\n",
      "          [-56.9290, -53.3854, -53.6736,  ..., -53.6213, -53.0371, -55.1418],\n",
      "          [-55.0039, -54.3032, -54.7474,  ..., -54.4607, -53.4741, -54.6051],\n",
      "          [-55.0830, -54.0245, -54.1530,  ..., -54.0167, -54.1413, -55.7217]]]]), tensor([2, 2, 1, 2, 2, 3, 3, 1, 0, 2, 1, 3, 5, 5, 2, 2, 5, 3, 0, 5, 0, 4, 5, 4,\n",
      "        5])]\n",
      "[tensor([[[[ -8.9003,  -5.6950,  -8.4137,  ...,  -7.9397, -14.6901, -13.7975],\n",
      "          [ -7.0621,  -4.2965,  -5.2679,  ...,  -6.8257, -10.7655, -12.5228],\n",
      "          [-12.1692, -14.2089, -16.3282,  ..., -14.7645, -16.9071, -14.4980],\n",
      "          ...,\n",
      "          [-51.3359, -48.0489, -47.7460,  ..., -48.3099, -47.7784, -49.3869],\n",
      "          [-49.6297, -48.2010, -48.3301,  ..., -48.2575, -48.2402, -50.6874],\n",
      "          [-50.8940, -48.3321, -48.8617,  ..., -48.8092, -48.8599, -50.0928]]],\n",
      "\n",
      "\n",
      "        [[[-17.7462, -15.1062, -26.7662,  ...,  -8.3707, -11.2060, -17.8887],\n",
      "          [-19.8870, -15.9270, -17.0375,  ..., -11.2934, -13.8616, -16.8674],\n",
      "          [-27.6479, -24.2454, -21.9514,  ..., -25.1244, -26.2341, -22.6001],\n",
      "          ...,\n",
      "          [-61.9573, -58.3460, -58.4538,  ..., -57.4640, -59.4890, -60.6936],\n",
      "          [-60.5880, -58.2899, -57.2648,  ..., -59.2312, -58.1507, -59.4468],\n",
      "          [-59.8953, -57.4230, -57.5208,  ..., -58.3148, -57.9805, -58.8456]]],\n",
      "\n",
      "\n",
      "        [[[-13.5176, -11.6368,  -8.7873,  ..., -17.7489, -16.9146, -20.3726],\n",
      "          [-16.1134, -14.8937, -12.4694,  ..., -18.9430, -14.6921, -16.7794],\n",
      "          [-22.4209, -19.2131, -22.1324,  ..., -22.3883, -22.1521, -21.7480],\n",
      "          ...,\n",
      "          [-51.0376, -48.7682, -49.6154,  ..., -49.2334, -49.2060, -50.9532],\n",
      "          [-54.0740, -50.1427, -49.8437,  ..., -49.6026, -50.2182, -51.0737],\n",
      "          [-50.7706, -48.5343, -48.9691,  ..., -50.4240, -50.7928, -52.9936]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-15.8294, -11.2537, -10.9465,  ..., -11.9487, -14.0252, -14.7746],\n",
      "          [-17.5562, -16.3954, -18.2899,  ..., -14.2846, -11.2523, -12.0967],\n",
      "          [-25.0954, -28.1919, -22.7930,  ..., -19.2034, -19.1958, -15.9922],\n",
      "          ...,\n",
      "          [-50.6322, -49.0325, -47.4819,  ..., -48.4302, -47.1102, -48.7352],\n",
      "          [-51.8628, -47.9553, -48.7344,  ..., -49.1368, -49.6521, -51.7342],\n",
      "          [-51.8983, -47.6698, -48.2550,  ..., -47.4888, -47.7807, -50.4829]]],\n",
      "\n",
      "\n",
      "        [[[-14.3831, -12.1354, -12.6169,  ..., -15.8074, -16.5729, -17.3791],\n",
      "          [-18.5885, -19.1402, -17.1982,  ..., -10.2863, -16.8677, -18.6861],\n",
      "          [-22.7160, -21.8464, -18.4663,  ..., -16.2206, -17.2931, -20.8829],\n",
      "          ...,\n",
      "          [-53.3006, -49.5118, -47.8410,  ..., -48.6413, -49.1530, -49.6687],\n",
      "          [-51.7591, -49.3027, -49.3969,  ..., -48.9461, -49.3949, -50.4807],\n",
      "          [-51.4795, -50.4085, -50.9016,  ..., -50.5438, -49.8652, -51.7285]]],\n",
      "\n",
      "\n",
      "        [[[-11.6841, -10.6428, -10.8915,  ...,  -1.7235,  -4.8453, -10.9071],\n",
      "          [-13.1581, -10.0602, -10.0689,  ...,  -3.7508,  -5.8531, -10.0624],\n",
      "          [-19.0680, -19.6948, -21.7907,  ..., -19.0947, -19.8550, -18.1728],\n",
      "          ...,\n",
      "          [-56.3883, -55.2090, -55.1556,  ..., -54.6343, -55.5138, -58.5798],\n",
      "          [-57.3524, -55.6003, -55.8850,  ..., -54.4737, -53.9710, -56.3188],\n",
      "          [-56.3898, -54.3298, -55.1854,  ..., -54.6399, -55.4026, -57.7112]]]]), tensor([5, 4, 0, 5, 4, 2, 2, 2, 0, 0, 4, 2, 1, 4, 4, 0, 5, 2, 4, 0, 5, 0, 2, 0,\n",
      "        3])]\n",
      "[tensor([[[[ -9.1439,  -6.3815,  -8.6553,  ...,  -9.9656, -15.8904, -22.7964],\n",
      "          [-12.4257, -10.7954, -15.2085,  ..., -11.7822, -20.2603, -23.9475],\n",
      "          [-20.7228, -24.3895, -28.4178,  ..., -24.0787, -26.8945, -27.7306],\n",
      "          ...,\n",
      "          [-50.6917, -48.3092, -48.8301,  ..., -50.6481, -49.7191, -51.0505],\n",
      "          [-51.6069, -48.9763, -49.3845,  ..., -50.7629, -50.2760, -51.0789],\n",
      "          [-52.5421, -50.3477, -51.9593,  ..., -49.8749, -50.1946, -52.2247]]],\n",
      "\n",
      "\n",
      "        [[[-12.8183,  -8.8736,  -9.9669,  ...,  -0.9775,  -1.1875,  -3.4887],\n",
      "          [-17.7811, -14.6838, -12.9425,  ...,  -5.8998,  -5.5387,  -6.5439],\n",
      "          [-26.6312, -26.0636, -23.6724,  ..., -25.0167, -22.3263, -16.4586],\n",
      "          ...,\n",
      "          [-58.4294, -54.7695, -54.3107,  ..., -55.4369, -54.4335, -56.1671],\n",
      "          [-59.0020, -54.6001, -54.8849,  ..., -52.7717, -53.4871, -55.4511],\n",
      "          [-58.0232, -54.3704, -54.5316,  ..., -54.1423, -53.6740, -55.1368]]],\n",
      "\n",
      "\n",
      "        [[[-15.6181, -17.4919, -20.0049,  ..., -11.2635, -18.8130, -19.6856],\n",
      "          [-17.4799, -19.6151, -21.3630,  ..., -11.9547, -16.5333, -17.9439],\n",
      "          [-23.0230, -26.7643, -25.9644,  ..., -21.4136, -18.9200, -21.3353],\n",
      "          ...,\n",
      "          [-57.8216, -55.8503, -55.6969,  ..., -53.9801, -54.6264, -56.9200],\n",
      "          [-59.3948, -56.9479, -56.4685,  ..., -53.6779, -54.0244, -55.7368],\n",
      "          [-57.8211, -55.0197, -55.2547,  ..., -55.0715, -54.6728, -57.3392]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-19.3755, -15.8834, -19.4765,  ..., -15.2986, -18.9731, -28.3482],\n",
      "          [-18.2080, -16.1983, -15.6329,  ..., -20.2465, -22.4688, -29.8424],\n",
      "          [-22.2617, -25.5475, -24.1155,  ..., -31.1005, -25.8298, -27.9543],\n",
      "          ...,\n",
      "          [-59.2608, -56.9048, -56.1722,  ..., -54.8316, -56.1192, -58.8295],\n",
      "          [-58.3115, -55.2242, -55.7536,  ..., -55.2191, -55.8394, -58.2460],\n",
      "          [-58.3019, -55.6733, -56.1740,  ..., -56.5903, -55.3230, -55.6876]]],\n",
      "\n",
      "\n",
      "        [[[-20.7064, -12.7469, -10.5713,  ...,  -5.6322, -11.0249, -23.3230],\n",
      "          [-23.0129, -15.8259, -15.6464,  ...,  -9.6322, -13.9740, -25.6630],\n",
      "          [-32.3584, -28.0187, -26.3400,  ..., -21.2980, -21.1598, -23.0218],\n",
      "          ...,\n",
      "          [-58.6716, -54.6895, -55.8372,  ..., -56.8688, -56.7343, -59.0497],\n",
      "          [-58.0728, -55.9267, -56.6812,  ..., -55.3060, -55.7754, -58.9926],\n",
      "          [-57.1548, -55.0041, -56.1730,  ..., -55.2742, -56.0316, -58.6850]]],\n",
      "\n",
      "\n",
      "        [[[-17.7484,  -7.8096,  -5.0597,  ...,  -7.1552, -10.3615, -15.7479],\n",
      "          [-24.1250, -11.6381,  -9.1836,  ..., -10.0575, -14.9263, -20.7033],\n",
      "          [-24.6713, -22.2962, -22.8559,  ..., -17.8255, -21.8843, -28.1199],\n",
      "          ...,\n",
      "          [-52.9812, -49.4930, -49.4893,  ..., -47.8044, -48.4419, -50.2379],\n",
      "          [-51.8783, -48.7094, -48.4333,  ..., -49.4847, -48.6194, -51.0819],\n",
      "          [-51.4531, -49.4110, -49.6053,  ..., -48.9175, -49.1056, -51.0907]]]]), tensor([3, 0, 1, 4, 3, 2, 1, 4, 5, 4, 5, 5, 0, 0, 0, 0, 3, 0, 5, 3, 1, 0, 4, 0,\n",
      "        0])]\n",
      "[tensor([[[[-17.0427, -14.9856, -19.9267,  ...,  -5.5589,  -7.6223,  -9.4907],\n",
      "          [-18.2477, -14.8280, -17.3509,  ...,  -6.7090, -12.1974, -12.1394],\n",
      "          [-26.8981, -25.3371, -20.1127,  ..., -16.3102, -16.0153, -16.4981],\n",
      "          ...,\n",
      "          [-53.9200, -51.8853, -52.4520,  ..., -53.6749, -51.8540, -53.6749],\n",
      "          [-55.1911, -52.7323, -53.3232,  ..., -54.3976, -54.8286, -56.5963],\n",
      "          [-54.7715, -52.9818, -53.6572,  ..., -53.8595, -53.5804, -54.8806]]],\n",
      "\n",
      "\n",
      "        [[[-10.5205, -12.1467, -11.9641,  ..., -11.1011,  -7.8841, -10.2488],\n",
      "          [-10.7204, -10.2712, -14.8051,  ..., -17.4890, -10.1350,  -9.9657],\n",
      "          [-15.4316, -14.7884, -19.3225,  ..., -20.4244, -19.5974, -16.2358],\n",
      "          ...,\n",
      "          [-48.4588, -47.1349, -46.9040,  ..., -47.7909, -47.2344, -49.7415],\n",
      "          [-50.3802, -47.2370, -45.4467,  ..., -47.3579, -46.4145, -48.9298],\n",
      "          [-51.0459, -48.2725, -48.0139,  ..., -46.4444, -47.2485, -48.7807]]],\n",
      "\n",
      "\n",
      "        [[[-11.1962,  -5.1562,  -3.9529,  ..., -13.7877, -13.9695, -18.9762],\n",
      "          [-11.6165, -10.5394, -10.5728,  ..., -20.3477, -17.0996, -21.1129],\n",
      "          [-17.8774, -21.0547, -26.0836,  ..., -28.4353, -27.5213, -30.6109],\n",
      "          ...,\n",
      "          [-55.0200, -53.2546, -53.1739,  ..., -54.1681, -53.8253, -56.4622],\n",
      "          [-57.6203, -53.9981, -53.5916,  ..., -53.0469, -53.1876, -55.7428],\n",
      "          [-58.0921, -53.5759, -52.9358,  ..., -54.2606, -55.0854, -56.0155]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-13.0929,  -8.1490,  -6.0740,  ...,  -9.0175,  -8.1026, -11.2404],\n",
      "          [-10.8897,  -6.2664,  -5.4600,  ..., -10.1410, -10.2522, -13.9232],\n",
      "          [-16.1681, -14.1593, -16.3334,  ..., -17.0501, -17.4465, -21.9007],\n",
      "          ...,\n",
      "          [-51.3174, -47.6784, -46.9831,  ..., -50.6825, -49.8886, -49.5048],\n",
      "          [-51.6961, -49.0685, -48.9114,  ..., -49.4049, -49.1464, -50.9212],\n",
      "          [-50.2888, -48.5087, -49.5262,  ..., -49.4060, -50.3186, -50.6697]]],\n",
      "\n",
      "\n",
      "        [[[-10.5740,  -6.6337,  -8.5231,  ...,  -8.6571,  -5.7712,  -7.2641],\n",
      "          [-13.8897, -10.3217, -13.4287,  ..., -16.9600, -11.8110,  -9.2367],\n",
      "          [-23.7448, -22.1353, -25.4149,  ..., -25.1986, -20.3145, -14.5135],\n",
      "          ...,\n",
      "          [-56.6444, -52.8006, -52.6621,  ..., -51.8420, -53.6470, -55.4209],\n",
      "          [-55.7708, -51.4955, -51.6007,  ..., -51.9611, -51.7362, -53.4997],\n",
      "          [-55.3219, -52.4044, -52.4623,  ..., -52.5349, -53.7143, -56.9817]]],\n",
      "\n",
      "\n",
      "        [[[ -5.3598,  -3.5870,  -7.7213,  ...,  -2.1239,  -7.6019, -16.7891],\n",
      "          [ -5.8658,  -5.3685,  -7.8181,  ...,  -4.0615,  -8.9067, -14.8545],\n",
      "          [-11.5583, -15.3547, -19.3934,  ..., -16.7265, -17.2696, -18.3079],\n",
      "          ...,\n",
      "          [-47.5734, -45.8095, -45.9924,  ..., -44.0620, -45.6469, -47.2745],\n",
      "          [-48.5098, -45.7572, -45.2733,  ..., -44.6914, -46.3110, -48.8676],\n",
      "          [-49.0852, -46.0152, -45.1482,  ..., -44.7064, -45.7651, -47.9350]]]]), tensor([1, 0, 3, 5, 0, 2, 1, 3, 2, 4, 1, 0, 5, 4, 5, 5, 4, 3, 4, 3, 0, 2, 4, 3,\n",
      "        2])]\n",
      "[tensor([[[[-16.5098, -13.6158, -13.7698,  ..., -20.1823, -15.1784, -14.9491],\n",
      "          [-17.1146, -14.5767, -15.2056,  ..., -17.9235, -14.7208, -14.5118],\n",
      "          [-20.5487, -19.4128, -19.8824,  ..., -25.1827, -23.9422, -20.0301],\n",
      "          ...,\n",
      "          [-51.9878, -48.7872, -49.3824,  ..., -49.1425, -48.0484, -49.6893],\n",
      "          [-51.2758, -49.8633, -49.9142,  ..., -50.0475, -49.9551, -51.1813],\n",
      "          [-53.1391, -51.0403, -50.3494,  ..., -51.4081, -50.0263, -50.0482]]],\n",
      "\n",
      "\n",
      "        [[[-10.7208,  -5.1715,  -4.3676,  ..., -10.5834, -11.5595, -16.9046],\n",
      "          [-12.3766,  -8.8231, -10.9925,  ..., -15.4747, -12.9223, -19.2970],\n",
      "          [-18.7908, -21.4462, -20.5267,  ..., -22.6840, -21.4934, -24.3930],\n",
      "          ...,\n",
      "          [-49.9995, -48.0103, -48.4120,  ..., -49.7643, -49.8806, -51.6831],\n",
      "          [-47.4270, -47.3056, -48.4698,  ..., -49.4439, -47.8779, -49.5320],\n",
      "          [-51.3528, -48.1071, -48.6567,  ..., -48.5554, -48.1139, -51.5024]]],\n",
      "\n",
      "\n",
      "        [[[-15.0478, -13.8001, -14.4621,  ..., -15.5620, -12.5570, -13.9192],\n",
      "          [-16.9501, -15.3223, -15.4388,  ..., -23.5943, -17.3096, -17.4727],\n",
      "          [-21.4123, -20.9109, -20.8366,  ..., -28.2529, -30.6608, -29.5175],\n",
      "          ...,\n",
      "          [-51.7909, -49.2375, -49.9399,  ..., -50.1581, -49.0799, -51.5343],\n",
      "          [-50.2857, -49.8086, -50.5261,  ..., -49.6846, -49.2241, -50.3883],\n",
      "          [-55.8301, -51.5755, -50.2552,  ..., -49.5259, -50.5020, -52.1422]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -7.5071,  -3.8854,  -4.2999,  ...,  -9.5368,  -5.0302,  -8.2657],\n",
      "          [ -6.8737,  -3.2673,  -4.4442,  ...,  -7.8864,  -4.6115,  -6.8085],\n",
      "          [-12.2169, -13.6799, -16.4138,  ..., -11.7323,  -9.3301, -12.1456],\n",
      "          ...,\n",
      "          [-53.6855, -49.2084, -48.6956,  ..., -47.9869, -48.6832, -50.5034],\n",
      "          [-52.8633, -50.2232, -48.7245,  ..., -48.7317, -48.8106, -49.9419],\n",
      "          [-51.5715, -49.3451, -48.4451,  ..., -50.2108, -50.0642, -52.4181]]],\n",
      "\n",
      "\n",
      "        [[[-11.8320,  -9.3900, -12.8467,  ...,  -8.0388, -12.1001, -16.2452],\n",
      "          [-14.0154, -11.1234, -13.2705,  ..., -10.9791, -21.3799, -25.7574],\n",
      "          [-21.1259, -20.0579, -16.5633,  ..., -17.7590, -18.4349, -24.7722],\n",
      "          ...,\n",
      "          [-48.7344, -46.6707, -47.3893,  ..., -47.9304, -47.0027, -49.1107],\n",
      "          [-50.8510, -47.1817, -45.4753,  ..., -47.5742, -47.8928, -49.5717],\n",
      "          [-51.1758, -47.2426, -46.3059,  ..., -46.3051, -46.9690, -50.1339]]],\n",
      "\n",
      "\n",
      "        [[[-14.4391,  -9.1209, -13.9443,  ...,   0.0000,  -2.8345, -10.3333],\n",
      "          [-15.8548, -12.0871, -15.2193,  ...,  -4.8612,  -9.4798, -14.0009],\n",
      "          [-24.0867, -24.5031, -22.1925,  ..., -19.7124, -24.7431, -22.2317],\n",
      "          ...,\n",
      "          [-51.8401, -49.6562, -49.8052,  ..., -50.2163, -49.5208, -51.2952],\n",
      "          [-51.6299, -48.7858, -48.9311,  ..., -48.2765, -49.9220, -50.6108],\n",
      "          [-51.8833, -49.2698, -50.0158,  ..., -48.9768, -50.1476, -53.0972]]]]), tensor([4, 0, 3, 5, 5, 3, 0, 2, 4, 1, 3, 1, 4, 3, 2, 1, 1, 0, 4, 5, 4, 0, 5, 0,\n",
      "        5])]\n",
      "[tensor([[[[-12.9459, -10.7339, -10.5763,  ..., -20.9138, -20.2874, -14.5386],\n",
      "          [-16.2831, -17.0857, -17.3435,  ..., -20.9503, -15.2757, -11.8472],\n",
      "          [-19.1016, -23.3032, -27.8499,  ..., -24.8851, -16.8646, -13.7081],\n",
      "          ...,\n",
      "          [-56.1595, -54.5195, -52.6238,  ..., -53.5836, -51.8603, -54.6450],\n",
      "          [-55.6095, -52.5743, -51.9246,  ..., -53.2095, -52.6188, -55.5935],\n",
      "          [-56.4487, -52.2921, -53.7554,  ..., -52.4024, -51.2213, -51.8921]]],\n",
      "\n",
      "\n",
      "        [[[-18.0209, -11.7379, -10.2200,  ...,  -4.2470,   0.0000,  -3.4826],\n",
      "          [-23.1801, -15.6190, -14.9000,  ...,  -7.3462,  -2.9329,  -4.3133],\n",
      "          [-33.2646, -23.7604, -21.9551,  ..., -20.5872, -16.4038, -11.7417],\n",
      "          ...,\n",
      "          [-56.7785, -52.5463, -51.7002,  ..., -53.8370, -52.9018, -53.2154],\n",
      "          [-56.1939, -54.8628, -54.4604,  ..., -52.7387, -52.6176, -52.2500],\n",
      "          [-54.6674, -52.6126, -53.7326,  ..., -52.3661, -52.9609, -54.0416]]],\n",
      "\n",
      "\n",
      "        [[[-18.3027, -15.4641,  -9.5809,  ..., -11.0653, -12.1972, -19.5427],\n",
      "          [-19.2963, -18.3188, -13.0030,  ..., -15.4253, -15.2683, -24.6046],\n",
      "          [-20.2961, -20.8818, -20.8779,  ..., -24.6880, -25.6998, -30.8342],\n",
      "          ...,\n",
      "          [-48.0807, -45.6483, -45.3463,  ..., -47.3056, -47.6561, -47.9204],\n",
      "          [-47.8975, -44.5405, -43.8399,  ..., -47.5982, -47.1712, -48.2320],\n",
      "          [-48.5111, -45.4942, -44.9434,  ..., -46.1690, -44.6446, -46.2503]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.3386,  -8.1295,  -9.4182,  ...,  -3.5372,  -6.9823, -12.3089],\n",
      "          [-14.2323, -10.6343, -11.0549,  ...,  -6.1847, -12.1914, -14.8063],\n",
      "          [-23.5425, -23.3458, -19.9860,  ..., -17.2117, -20.5783, -20.5997],\n",
      "          ...,\n",
      "          [-49.5552, -46.5474, -46.3638,  ..., -47.1317, -46.2887, -47.9489],\n",
      "          [-50.2128, -46.6963, -46.5049,  ..., -46.7846, -48.3372, -50.4113],\n",
      "          [-49.7589, -48.1748, -49.3193,  ..., -48.4582, -49.2449, -50.2379]]],\n",
      "\n",
      "\n",
      "        [[[-11.0291,  -5.0556,  -7.3908,  ...,  -5.4382,  -8.5189, -14.6596],\n",
      "          [-11.8465,  -8.6335,  -9.1775,  ..., -10.5531, -13.6293, -21.6308],\n",
      "          [-17.3718, -17.8354, -16.5804,  ..., -19.8602, -21.2210, -25.3905],\n",
      "          ...,\n",
      "          [-50.1780, -48.1141, -49.1871,  ..., -47.1003, -47.3462, -50.3536],\n",
      "          [-49.9736, -48.0062, -49.3661,  ..., -47.9526, -48.1708, -51.8342],\n",
      "          [-52.2147, -48.4390, -48.6952,  ..., -48.9274, -48.7183, -51.3020]]],\n",
      "\n",
      "\n",
      "        [[[-12.6869,  -6.1255,  -5.5152,  ...,  -5.7381,  -3.4278,  -6.2596],\n",
      "          [-13.6166, -11.1559,  -8.7832,  ..., -11.3911,  -7.8598, -11.0899],\n",
      "          [-18.3389, -18.4038, -21.8603,  ..., -21.9691, -21.5309, -24.5514],\n",
      "          ...,\n",
      "          [-53.4539, -51.1406, -50.9320,  ..., -51.7844, -51.3928, -51.3885],\n",
      "          [-55.7355, -52.1812, -51.9173,  ..., -51.1953, -51.1556, -51.4325],\n",
      "          [-55.7891, -53.1854, -52.2578,  ..., -50.8765, -51.2024, -53.7012]]]]), tensor([0, 1, 2, 0, 2, 3, 0, 0, 3, 4, 5, 4, 0, 3, 2, 1, 3, 2, 2, 0, 0, 0, 2, 1,\n",
      "        1])]\n",
      "[tensor([[[[ -5.1685,  -3.5431,  -6.1680,  ...,  -0.0917,  -0.7231,  -5.5518],\n",
      "          [ -7.6702,  -7.7361, -11.8104,  ...,  -6.2485,  -5.7362,  -8.8374],\n",
      "          [-13.8354, -15.0222, -20.2270,  ..., -22.6714, -23.3922, -22.0796],\n",
      "          ...,\n",
      "          [-55.2056, -52.8139, -52.3971,  ..., -52.7700, -53.1397, -54.7791],\n",
      "          [-55.8079, -52.0751, -50.6632,  ..., -52.3088, -52.0392, -54.6527],\n",
      "          [-56.1405, -53.2581, -52.3736,  ..., -53.7071, -53.6263, -53.4978]]],\n",
      "\n",
      "\n",
      "        [[[-10.6643,  -7.3887,  -8.8921,  ...,  -8.2710,  -7.0803, -11.5905],\n",
      "          [-10.7584,  -8.7772,  -8.7842,  ..., -12.7270,  -8.9024, -12.9026],\n",
      "          [-16.5672, -21.2453, -18.7724,  ..., -17.3295, -18.4741, -22.8398],\n",
      "          ...,\n",
      "          [-53.2704, -50.3550, -51.5633,  ..., -50.3345, -51.2440, -53.5748],\n",
      "          [-51.9836, -50.0980, -50.9822,  ..., -50.7501, -52.0841, -52.2893],\n",
      "          [-52.8884, -51.2494, -51.7744,  ..., -50.7838, -51.9005, -53.4901]]],\n",
      "\n",
      "\n",
      "        [[[-12.4899, -12.6390, -18.3412,  ..., -11.5354, -11.1510, -11.5272],\n",
      "          [-10.6332, -11.0089, -16.0313,  ..., -11.6983, -10.5265, -11.8239],\n",
      "          [-14.1030, -14.8124, -21.2318,  ..., -15.8251, -16.3481, -18.2146],\n",
      "          ...,\n",
      "          [-52.3472, -50.5478, -50.0083,  ..., -51.3235, -50.5600, -52.0638],\n",
      "          [-54.1867, -51.5227, -51.9898,  ..., -53.0278, -52.5103, -52.9369],\n",
      "          [-53.4603, -51.6214, -52.9473,  ..., -52.4769, -51.4700, -52.2444]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-18.7897, -15.7237, -19.1669,  ...,  -2.5864,  -3.4854,  -8.3363],\n",
      "          [-17.5980, -15.9615, -24.4952,  ..., -10.9740,  -9.5510, -10.4342],\n",
      "          [-23.2868, -20.0114, -26.7704,  ..., -31.7439, -22.8537, -20.2259],\n",
      "          ...,\n",
      "          [-55.7549, -51.1689, -50.3053,  ..., -50.8378, -50.6562, -53.0983],\n",
      "          [-54.3370, -50.7302, -50.5244,  ..., -51.5256, -51.2671, -51.4067],\n",
      "          [-55.3706, -51.2870, -50.2594,  ..., -52.2861, -51.2770, -52.1787]]],\n",
      "\n",
      "\n",
      "        [[[-19.4503, -11.6368,  -6.7816,  ..., -12.0678,  -8.9254,  -9.2904],\n",
      "          [-14.8976,  -8.0731,  -6.4716,  ..., -15.7901, -11.9013, -12.1636],\n",
      "          [-17.3328, -15.8321, -17.5205,  ..., -22.3996, -16.8316, -18.6882],\n",
      "          ...,\n",
      "          [-55.9450, -52.5807, -53.6123,  ..., -52.4918, -53.1196, -56.1903],\n",
      "          [-56.1926, -52.4201, -52.3664,  ..., -52.7488, -52.3760, -53.7092],\n",
      "          [-56.5493, -52.8165, -52.9666,  ..., -53.1975, -52.5657, -54.5543]]],\n",
      "\n",
      "\n",
      "        [[[ -8.2463,  -1.5153,  -0.3417,  ...,  -0.0767,  -0.2532,  -5.6081],\n",
      "          [ -7.9649,  -2.4761,  -3.8179,  ...,  -1.0361,  -2.4826,  -7.4762],\n",
      "          [-15.5043, -13.3370, -16.3814,  ..., -13.8375, -16.0605, -16.8942],\n",
      "          ...,\n",
      "          [-52.0576, -47.6453, -47.5434,  ..., -50.1476, -49.5708, -50.5257],\n",
      "          [-52.1544, -48.6912, -47.6840,  ..., -50.1298, -51.6062, -52.9518],\n",
      "          [-53.5745, -50.4228, -49.4765,  ..., -49.7564, -49.9691, -51.0382]]]]), tensor([0, 2, 0, 3, 2, 3, 2, 1, 1, 3, 2, 3, 5, 5, 5, 2, 4, 0, 4, 3, 0, 0, 0, 0,\n",
      "        1])]\n",
      "[tensor([[[[-11.7756,  -7.0410,  -4.9498,  ...,  -9.3433,  -6.6749,  -8.1286],\n",
      "          [-16.8265, -12.4159, -10.2116,  ...,  -8.9402,  -7.7014,  -9.2996],\n",
      "          [-22.2347, -21.5294, -20.6842,  ..., -16.5950, -21.3083, -17.7230],\n",
      "          ...,\n",
      "          [-52.1803, -50.2204, -50.7931,  ..., -50.7613, -50.6474, -51.4796],\n",
      "          [-53.6427, -51.5287, -50.7069,  ..., -49.1984, -50.5256, -53.1105],\n",
      "          [-53.3888, -50.0538, -50.9244,  ..., -50.5473, -49.6493, -52.5006]]],\n",
      "\n",
      "\n",
      "        [[[-16.8677, -10.9837, -11.5365,  ..., -17.7769, -14.8101, -12.9792],\n",
      "          [-16.3892, -12.8971, -14.8058,  ..., -26.5489, -17.9043, -13.9401],\n",
      "          [-21.4324, -22.9268, -26.4240,  ..., -31.6903, -24.6109, -19.1836],\n",
      "          ...,\n",
      "          [-55.8700, -52.3636, -51.3638,  ..., -50.5106, -52.0963, -54.2482],\n",
      "          [-56.1806, -52.7200, -51.4017,  ..., -50.6342, -51.1227, -53.4283],\n",
      "          [-57.3869, -54.4889, -53.0539,  ..., -54.0687, -52.3150, -53.6756]]],\n",
      "\n",
      "\n",
      "        [[[-11.7163,  -4.6254,  -3.2696,  ..., -16.9017, -12.0346, -14.7881],\n",
      "          [-12.1810,  -7.0967,  -6.9876,  ..., -15.8202, -15.7874, -15.3310],\n",
      "          [-20.1109, -21.1059, -22.1745,  ..., -18.4897, -20.9831, -20.7972],\n",
      "          ...,\n",
      "          [-50.0040, -47.9352, -48.0505,  ..., -48.1633, -48.3408, -50.5797],\n",
      "          [-52.1636, -49.2911, -48.9361,  ..., -48.9829, -48.4587, -51.9963],\n",
      "          [-53.8949, -50.1011, -49.6775,  ..., -49.2414, -48.3503, -52.0036]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -8.0873,  -7.3582,  -7.8443,  ..., -12.2081, -11.0819,  -8.1737],\n",
      "          [-10.2855, -11.8433, -10.3012,  ...,  -9.5623,  -9.5996,  -8.4761],\n",
      "          [-16.7114, -16.3081, -19.1141,  ..., -15.3856, -15.3966, -14.3635],\n",
      "          ...,\n",
      "          [-52.9925, -51.6669, -51.2964,  ..., -47.6690, -50.3343, -54.7010],\n",
      "          [-53.0450, -50.2613, -51.2696,  ..., -49.3092, -50.2960, -51.7941],\n",
      "          [-51.0952, -48.8961, -50.2779,  ..., -48.1650, -49.5840, -52.3887]]],\n",
      "\n",
      "\n",
      "        [[[-11.7221,  -7.5009,  -4.9032,  ...,  -3.8887,  -2.3518,  -5.2582],\n",
      "          [-12.1687,  -6.4206,  -4.1923,  ...,  -3.6549,  -2.2777,  -4.3293],\n",
      "          [-19.7003, -17.7530, -17.0349,  ..., -15.9735, -14.7695, -11.0209],\n",
      "          ...,\n",
      "          [-55.3763, -53.5250, -53.1544,  ..., -53.0976, -53.6414, -54.5680],\n",
      "          [-57.2011, -54.6884, -53.9950,  ..., -53.2046, -54.7418, -55.1734],\n",
      "          [-54.8278, -52.9933, -53.7695,  ..., -55.1222, -55.4178, -56.0121]]],\n",
      "\n",
      "\n",
      "        [[[-32.0508, -18.6434, -15.1491,  ..., -23.5368, -24.9932, -32.0979],\n",
      "          [-31.0583, -20.0940, -18.5767,  ..., -30.2197, -28.5712, -33.5006],\n",
      "          [-35.3113, -28.8498, -30.7482,  ..., -34.2117, -27.9173, -28.0230],\n",
      "          ...,\n",
      "          [-58.8011, -56.6923, -58.5047,  ..., -56.8365, -55.2544, -56.6119],\n",
      "          [-59.9491, -56.5991, -56.6075,  ..., -57.2557, -57.4822, -59.0407],\n",
      "          [-60.0381, -57.1882, -55.2488,  ..., -54.3049, -55.9977, -60.8532]]]]), tensor([0, 4, 0, 3, 0, 2, 4, 4, 0, 1, 0, 0, 1, 5, 5, 0, 3, 4, 4, 4, 0, 3, 0, 3,\n",
      "        4])]\n",
      "[tensor([[[[-13.8820, -13.2763, -12.7538,  ...,  -5.6196,  -4.1067,  -8.6514],\n",
      "          [-15.5819, -19.0227, -19.7076,  ...,  -8.1158,  -7.6211, -10.1307],\n",
      "          [-18.5374, -20.9645, -31.7378,  ..., -14.6175, -18.0286, -17.5111],\n",
      "          ...,\n",
      "          [-51.7487, -49.4922, -50.8934,  ..., -48.3644, -49.7760, -52.1333],\n",
      "          [-51.9308, -50.1141, -51.3312,  ..., -50.5186, -50.3585, -52.3874],\n",
      "          [-53.7617, -50.5438, -50.3975,  ..., -50.3885, -49.3604, -51.6796]]],\n",
      "\n",
      "\n",
      "        [[[ -3.6491,  -0.1169,  -1.2708,  ..., -15.0683, -18.6120, -16.5309],\n",
      "          [ -7.5189,  -4.7812,  -6.0383,  ..., -12.9051, -12.8131, -14.1332],\n",
      "          [-17.1251, -19.8379, -17.7177,  ..., -18.6443, -15.8214, -17.1822],\n",
      "          ...,\n",
      "          [-53.1104, -50.6421, -50.9671,  ..., -49.0212, -50.9348, -53.4743],\n",
      "          [-54.4481, -52.0334, -51.3920,  ..., -50.2045, -51.1214, -52.6923],\n",
      "          [-53.0755, -51.1130, -49.9918,  ..., -50.5614, -50.6246, -53.7614]]],\n",
      "\n",
      "\n",
      "        [[[ -9.7955,  -5.9862,  -3.8906,  ...,  -1.4620,  -6.8214, -12.6527],\n",
      "          [ -8.9254,  -3.9711,  -3.1762,  ...,  -1.2694,  -3.6564,  -9.0598],\n",
      "          [-14.6580, -14.2811, -15.4592,  ..., -13.5096, -13.4330, -13.1754],\n",
      "          ...,\n",
      "          [-55.6674, -53.4809, -53.3736,  ..., -53.4829, -54.8861, -55.5131],\n",
      "          [-56.9255, -55.2635, -54.5886,  ..., -53.6918, -53.9781, -54.3855],\n",
      "          [-56.1894, -53.2439, -53.3132,  ..., -54.0230, -53.9033, -54.7176]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -9.3630,  -8.0156, -10.7116,  ..., -15.6980, -18.4390, -22.9805],\n",
      "          [-11.0363, -10.8332, -16.3648,  ..., -12.0238, -11.7764, -16.9739],\n",
      "          [-17.6310, -19.5291, -27.1900,  ..., -18.5102, -14.0359, -19.7002],\n",
      "          ...,\n",
      "          [-56.1942, -53.0955, -53.3711,  ..., -53.7066, -53.6759, -55.7073],\n",
      "          [-55.1096, -52.2083, -52.4010,  ..., -52.3425, -51.5793, -54.9182],\n",
      "          [-55.2412, -52.8344, -52.3349,  ..., -54.3277, -52.6744, -54.7175]]],\n",
      "\n",
      "\n",
      "        [[[-16.5507, -16.8092, -13.3030,  ..., -11.8545,  -7.5122,  -7.1141],\n",
      "          [-17.8905, -15.7555, -15.3671,  ..., -12.9508,  -8.6334,  -8.8057],\n",
      "          [-22.0580, -20.2114, -21.9231,  ..., -21.1280, -17.4335, -16.1876],\n",
      "          ...,\n",
      "          [-51.2254, -49.3412, -48.4575,  ..., -48.8502, -49.8611, -52.1791],\n",
      "          [-51.9451, -48.5081, -48.4278,  ..., -48.6097, -48.3876, -50.1398],\n",
      "          [-52.1920, -49.4794, -48.2586,  ..., -48.9832, -49.5116, -51.7586]]],\n",
      "\n",
      "\n",
      "        [[[-12.6704, -10.0989, -15.7285,  ...,  -1.1067,  -4.9090, -11.6635],\n",
      "          [-17.0735, -12.7654, -14.1774,  ...,  -4.9070,  -9.1263, -17.1113],\n",
      "          [-24.4590, -19.2597, -19.7641,  ..., -18.5482, -19.4238, -18.5840],\n",
      "          ...,\n",
      "          [-61.6435, -58.9187, -57.5728,  ..., -59.3153, -58.2450, -59.3043],\n",
      "          [-60.0850, -57.6033, -56.7001,  ..., -58.3688, -58.7643, -59.3651],\n",
      "          [-62.3474, -59.6540, -58.1206,  ..., -57.3825, -57.4624, -59.3069]]]]), tensor([0, 0, 3, 0, 2, 0, 3, 1, 0, 3, 4, 0, 2, 2, 5, 0, 4, 0, 1, 2, 5, 5, 0, 1,\n",
      "        1])]\n",
      "[tensor([[[[ -7.6809,  -1.3894,  -6.1454,  ...,  -3.2551,  -6.2737, -16.9419],\n",
      "          [ -8.9156,  -3.4992,  -4.9761,  ...,  -5.3517,  -9.1741, -21.1846],\n",
      "          [-18.6063, -13.1490, -12.8090,  ..., -17.3216, -20.5329, -24.9092],\n",
      "          ...,\n",
      "          [-46.4100, -42.4945, -41.8615,  ..., -41.1409, -42.9757, -43.2790],\n",
      "          [-46.7894, -42.9631, -42.8739,  ..., -42.9658, -42.4366, -46.0061],\n",
      "          [-46.6880, -43.2702, -43.5808,  ..., -42.4506, -41.8991, -46.7900]]],\n",
      "\n",
      "\n",
      "        [[[-10.9027,  -5.9879,  -4.8815,  ..., -12.9866, -12.6573, -23.0787],\n",
      "          [-11.0216, -12.6848, -10.1498,  ..., -14.9163, -13.8779, -19.4198],\n",
      "          [-14.9135, -17.6198, -21.9165,  ..., -25.8100, -23.9186, -22.0997],\n",
      "          ...,\n",
      "          [-54.8032, -52.6899, -51.4362,  ..., -49.7228, -49.5046, -52.7644],\n",
      "          [-54.9945, -53.0867, -51.7927,  ..., -52.5484, -52.0616, -53.3008],\n",
      "          [-52.5169, -51.2426, -52.4969,  ..., -52.0333, -51.2828, -52.8398]]],\n",
      "\n",
      "\n",
      "        [[[-15.9130,  -9.9528,  -7.5890,  ..., -11.2977, -10.1811, -12.3607],\n",
      "          [-21.2572, -14.8245, -11.5313,  ..., -16.5643, -16.8365, -18.4382],\n",
      "          [-33.1820, -24.2761, -21.9110,  ..., -27.6454, -28.7181, -27.4541],\n",
      "          ...,\n",
      "          [-50.6144, -49.4790, -49.2020,  ..., -49.9200, -50.9647, -52.2441],\n",
      "          [-52.9786, -50.4453, -50.5858,  ..., -49.9498, -49.8033, -51.3987],\n",
      "          [-53.1406, -51.3434, -51.0862,  ..., -49.2642, -49.5327, -49.3084]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -6.2205,  -3.8830,  -4.9260,  ...,  -3.4583,  -2.2113,  -4.2974],\n",
      "          [ -6.9878,  -3.6763,  -4.0112,  ...,  -3.6516,  -2.7743,  -4.7081],\n",
      "          [-14.9627, -15.9165, -17.0534,  ..., -17.2712, -15.9078, -12.9416],\n",
      "          ...,\n",
      "          [-55.6110, -51.7466, -50.3878,  ..., -52.5192, -50.9247, -53.7009],\n",
      "          [-53.5899, -49.8057, -50.3230,  ..., -52.8653, -52.6432, -55.3551],\n",
      "          [-55.4416, -52.3089, -51.4771,  ..., -51.5620, -51.0621, -52.7299]]],\n",
      "\n",
      "\n",
      "        [[[-18.3339,  -9.2998,  -4.6474,  ..., -12.3196, -14.5386, -20.0846],\n",
      "          [-20.7360, -15.5852,  -7.0846,  ..., -14.6952, -17.1643, -24.0331],\n",
      "          [-26.5389, -24.6012, -16.0612,  ..., -22.2092, -19.4099, -23.9425],\n",
      "          ...,\n",
      "          [-51.2855, -47.6523, -48.5198,  ..., -48.6568, -48.5462, -50.3284],\n",
      "          [-52.5481, -49.4531, -48.6133,  ..., -48.4802, -48.6068, -50.3791],\n",
      "          [-52.2420, -49.7171, -48.2370,  ..., -49.4797, -50.1228, -51.8326]]],\n",
      "\n",
      "\n",
      "        [[[-12.6616,  -8.2074,  -9.9863,  ...,  -9.5144, -17.3313, -22.6666],\n",
      "          [-15.6575, -12.6969, -15.0423,  ..., -11.6336, -14.0662, -18.8411],\n",
      "          [-19.4713, -17.0566, -17.6623,  ..., -18.6267, -19.1972, -20.3666],\n",
      "          ...,\n",
      "          [-50.4674, -48.8755, -48.1325,  ..., -48.3828, -48.9122, -51.1367],\n",
      "          [-51.4188, -49.2578, -49.7904,  ..., -48.0029, -47.9695, -50.3255],\n",
      "          [-52.1345, -49.0089, -48.0940,  ..., -48.2453, -48.6368, -51.7287]]]]), tensor([2, 4, 0, 0, 0, 4, 5, 0, 3, 0, 5, 0, 2, 0, 0, 3, 0, 2, 0, 0, 5, 0, 3, 1,\n",
      "        0])]\n",
      "[tensor([[[[-12.3534,  -8.1414,  -7.3962,  ...,  -9.6710, -10.2073, -18.5057],\n",
      "          [-15.8491, -12.5674, -10.7024,  ..., -13.2207, -11.3987, -18.4529],\n",
      "          [-24.6950, -25.3183, -25.8794,  ..., -25.2772, -20.0603, -21.6492],\n",
      "          ...,\n",
      "          [-58.5614, -54.2405, -53.9698,  ..., -55.7635, -55.6912, -56.3000],\n",
      "          [-57.0635, -54.4432, -55.9435,  ..., -54.1819, -54.7409, -55.6478],\n",
      "          [-57.2229, -55.7335, -56.3952,  ..., -56.5256, -54.9140, -55.9728]]],\n",
      "\n",
      "\n",
      "        [[[ -4.0662,  -0.3494,   0.0000,  ...,  -4.6714,  -3.9676,  -8.6064],\n",
      "          [-10.3888,  -7.2953,  -5.8475,  ...,  -9.4470,  -8.2664, -10.5236],\n",
      "          [-17.5188, -18.0142, -23.6312,  ..., -20.8997, -20.2381, -17.0905],\n",
      "          ...,\n",
      "          [-54.4361, -50.9694, -49.5850,  ..., -50.9147, -48.4651, -49.2708],\n",
      "          [-53.5730, -49.8567, -50.6208,  ..., -51.8278, -50.4198, -52.0098],\n",
      "          [-53.8774, -52.0039, -51.2027,  ..., -49.0434, -48.4871, -52.2826]]],\n",
      "\n",
      "\n",
      "        [[[ -6.0855,  -4.9794,  -8.9611,  ...,  -4.5734,  -8.1216, -14.2574],\n",
      "          [ -8.3703,  -7.9510, -12.9993,  ...,  -3.3616,  -4.6402, -10.8244],\n",
      "          [-15.2722, -17.3643, -18.1749,  ..., -13.3375, -12.6844, -15.5775],\n",
      "          ...,\n",
      "          [-53.7831, -50.6899, -50.5273,  ..., -49.9324, -49.5276, -51.8852],\n",
      "          [-54.1276, -53.2184, -51.3571,  ..., -50.0235, -49.4541, -51.1497],\n",
      "          [-52.8796, -50.6453, -50.6585,  ..., -50.6192, -50.4637, -52.1600]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.5110,  -7.9269,  -7.1359,  ...,  -6.5687,  -8.4930, -13.5501],\n",
      "          [-16.0248, -13.7008, -10.5023,  ...,  -9.8067, -12.3579, -14.6271],\n",
      "          [-23.0445, -20.5140, -20.6409,  ..., -22.6591, -21.4507, -22.0410],\n",
      "          ...,\n",
      "          [-54.8558, -53.1715, -52.6942,  ..., -55.3365, -54.3472, -55.8967],\n",
      "          [-55.5346, -53.1642, -52.5521,  ..., -53.4395, -53.8366, -55.6236],\n",
      "          [-56.6218, -53.3334, -55.0011,  ..., -53.3813, -52.2190, -54.2354]]],\n",
      "\n",
      "\n",
      "        [[[-21.5801, -15.6315, -14.7686,  ..., -19.2304, -22.4431, -26.7380],\n",
      "          [-26.2056, -20.6170, -16.6030,  ..., -16.2064, -18.8988, -23.0298],\n",
      "          [-33.2804, -28.7255, -21.4495,  ..., -24.0527, -27.0809, -27.6899],\n",
      "          ...,\n",
      "          [-55.4699, -52.1332, -50.2111,  ..., -51.3910, -51.0190, -54.0519],\n",
      "          [-54.2748, -50.5112, -50.0293,  ..., -52.0322, -52.3634, -54.5737],\n",
      "          [-53.5809, -51.2456, -51.6310,  ..., -51.4344, -51.5829, -53.4043]]],\n",
      "\n",
      "\n",
      "        [[[ -9.9556,  -8.0223, -15.5049,  ...,  -5.8669,  -7.9880, -15.8333],\n",
      "          [ -7.7237,  -6.1376, -10.2059,  ...,  -5.8948, -10.3746, -19.1705],\n",
      "          [-11.4615, -14.8107, -14.7004,  ..., -17.7533, -22.1156, -32.2179],\n",
      "          ...,\n",
      "          [-51.2957, -49.0700, -49.1583,  ..., -48.1738, -49.3872, -52.2161],\n",
      "          [-50.7348, -48.1175, -49.4220,  ..., -47.8958, -48.5351, -49.4556],\n",
      "          [-50.5864, -48.8926, -49.5004,  ..., -48.6794, -49.1842, -52.3914]]]]), tensor([0, 0, 1, 2, 3, 0, 0, 2, 0, 1, 0, 4, 1, 0, 2, 4, 4, 0, 3, 1, 2, 0, 1, 3,\n",
      "        1])]\n",
      "[tensor([[[[-17.3370, -13.6840, -18.9090,  ...,  -6.2777,  -8.6486, -16.0327],\n",
      "          [-22.4095, -18.8803, -17.4200,  ..., -10.2325, -13.0265, -21.1505],\n",
      "          [-28.2006, -22.0807, -20.6433,  ..., -18.2779, -23.1035, -28.7418],\n",
      "          ...,\n",
      "          [-58.2493, -54.7077, -52.7674,  ..., -55.4682, -53.3706, -53.8794],\n",
      "          [-56.9645, -54.1312, -52.3820,  ..., -53.6517, -52.9824, -54.0226],\n",
      "          [-58.1695, -54.5925, -53.9564,  ..., -52.4616, -52.3464, -54.8691]]],\n",
      "\n",
      "\n",
      "        [[[ -8.0931,  -3.0809,  -2.1194,  ...,  -2.4892,  -3.2072,  -5.9954],\n",
      "          [ -8.8219,  -3.6177,  -2.6965,  ...,  -2.7955,  -3.2077,  -5.1771],\n",
      "          [-16.2112, -16.0135, -16.6433,  ..., -16.2770, -15.9546, -12.2362],\n",
      "          ...,\n",
      "          [-54.1955, -53.2327, -54.2320,  ..., -53.0093, -53.6045, -54.3664],\n",
      "          [-55.6548, -53.5421, -54.4195,  ..., -52.1077, -52.6243, -54.1062],\n",
      "          [-58.7440, -54.3559, -54.2793,  ..., -52.4463, -52.1186, -54.6892]]],\n",
      "\n",
      "\n",
      "        [[[ -9.6498,  -6.2075,  -4.5347,  ...,  -3.5316,  -4.4289,  -4.4301],\n",
      "          [ -9.5448,  -5.8848,  -5.0769,  ...,  -2.5754,  -3.3229,  -4.6227],\n",
      "          [-15.3968, -16.7912, -18.0456,  ..., -14.1376, -15.4660, -11.7303],\n",
      "          ...,\n",
      "          [-54.1135, -51.7630, -51.7465,  ..., -51.6635, -52.8606, -52.8051],\n",
      "          [-53.7857, -51.8269, -51.9632,  ..., -53.6480, -53.6472, -54.0929],\n",
      "          [-55.9510, -54.0242, -53.8441,  ..., -52.1160, -53.5992, -55.9835]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-19.3030, -20.0919, -14.3340,  ...,  -1.1654,  -4.4234, -15.1536],\n",
      "          [-17.3505, -16.7345, -13.2978,  ...,  -1.8424,  -3.4892, -11.1512],\n",
      "          [-21.5774, -23.9938, -20.7966,  ..., -10.2834, -12.9977, -13.8153],\n",
      "          ...,\n",
      "          [-53.1820, -51.2893, -52.1281,  ..., -50.9769, -50.3367, -52.9549],\n",
      "          [-55.8379, -51.9040, -52.0206,  ..., -50.9986, -51.2125, -53.2668],\n",
      "          [-55.7550, -52.6171, -52.5296,  ..., -52.2303, -52.8020, -53.9154]]],\n",
      "\n",
      "\n",
      "        [[[-11.1603,  -5.8698,  -5.5590,  ..., -11.9730, -12.3221, -11.9913],\n",
      "          [-12.4443,  -8.4158,  -7.2249,  ..., -15.0613, -12.1208, -13.6823],\n",
      "          [-21.6478, -22.9541, -19.5704,  ..., -17.1054, -19.1276, -21.0368],\n",
      "          ...,\n",
      "          [-47.0859, -46.2030, -46.4313,  ..., -44.2340, -44.1578, -46.9369],\n",
      "          [-48.9116, -46.0197, -45.4827,  ..., -44.7112, -45.0200, -47.0736],\n",
      "          [-50.2629, -46.8827, -46.5767,  ..., -45.6073, -46.9797, -48.5544]]],\n",
      "\n",
      "\n",
      "        [[[ -8.9465,  -4.9386,  -3.4910,  ...,  -8.8267,  -6.6299, -10.4541],\n",
      "          [-11.3466,  -9.8318,  -8.1840,  ..., -11.4609,  -7.0067, -10.0628],\n",
      "          [-18.8256, -24.1063, -22.3295,  ..., -17.7201, -17.6753, -18.2109],\n",
      "          ...,\n",
      "          [-56.3092, -54.5021, -54.6962,  ..., -54.3815, -55.0944, -58.3650],\n",
      "          [-57.5449, -54.3026, -53.5777,  ..., -55.1495, -55.4923, -57.5995],\n",
      "          [-56.4856, -56.0001, -56.5582,  ..., -55.7848, -55.2925, -56.0462]]]]), tensor([4, 3, 5, 3, 0, 1, 4, 4, 0, 1, 5, 5, 2, 3, 0, 2, 2, 0, 5, 3, 1, 4, 5, 0,\n",
      "        1])]\n",
      "[tensor([[[[-1.3163e+01, -1.3713e+01, -5.7044e+00,  ..., -1.2634e+01,\n",
      "           -1.5390e+01, -1.5345e+01],\n",
      "          [-1.2363e+01, -1.0146e+01, -7.4118e+00,  ..., -1.5231e+01,\n",
      "           -2.1727e+01, -1.8272e+01],\n",
      "          [-1.7476e+01, -1.6215e+01, -1.7197e+01,  ..., -2.2400e+01,\n",
      "           -2.5497e+01, -2.2533e+01],\n",
      "          ...,\n",
      "          [-5.1182e+01, -4.7666e+01, -4.9066e+01,  ..., -4.9475e+01,\n",
      "           -4.9563e+01, -5.2183e+01],\n",
      "          [-5.2512e+01, -5.0168e+01, -5.0191e+01,  ..., -5.0816e+01,\n",
      "           -5.0405e+01, -5.3730e+01],\n",
      "          [-5.1582e+01, -5.0124e+01, -5.0477e+01,  ..., -4.9791e+01,\n",
      "           -4.8661e+01, -5.0672e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8231e+01, -1.5682e+01, -1.6320e+01,  ..., -1.0946e+01,\n",
      "           -1.6421e+01, -2.0916e+01],\n",
      "          [-2.1584e+01, -2.1924e+01, -1.9308e+01,  ..., -1.6133e+01,\n",
      "           -2.4725e+01, -2.7363e+01],\n",
      "          [-2.5565e+01, -2.4838e+01, -2.4402e+01,  ..., -2.5382e+01,\n",
      "           -2.8689e+01, -3.0411e+01],\n",
      "          ...,\n",
      "          [-5.5260e+01, -5.1811e+01, -5.1724e+01,  ..., -5.4572e+01,\n",
      "           -5.2932e+01, -5.4526e+01],\n",
      "          [-5.2874e+01, -5.1235e+01, -5.1454e+01,  ..., -5.2265e+01,\n",
      "           -5.3131e+01, -5.6713e+01],\n",
      "          [-5.5489e+01, -5.3212e+01, -5.2562e+01,  ..., -5.1594e+01,\n",
      "           -5.2086e+01, -5.4104e+01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1001e+01, -1.1171e+01, -5.3095e+00,  ..., -1.7959e+00,\n",
      "           -8.4892e-01, -4.4087e+00],\n",
      "          [-1.6136e+01, -8.5612e+00, -6.8571e+00,  ..., -4.9754e+00,\n",
      "           -1.9684e+00, -5.6396e+00],\n",
      "          [-1.9678e+01, -1.6660e+01, -1.9172e+01,  ..., -1.8701e+01,\n",
      "           -1.3089e+01, -1.4169e+01],\n",
      "          ...,\n",
      "          [-5.3229e+01, -5.2300e+01, -5.2039e+01,  ..., -5.1505e+01,\n",
      "           -5.0635e+01, -5.2131e+01],\n",
      "          [-5.2583e+01, -5.1240e+01, -5.1056e+01,  ..., -5.1894e+01,\n",
      "           -5.0664e+01, -5.1814e+01],\n",
      "          [-5.2456e+01, -5.0066e+01, -5.1281e+01,  ..., -5.1113e+01,\n",
      "           -5.1398e+01, -5.3474e+01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.7889e+00, -5.3173e-02,  0.0000e+00,  ..., -1.3146e+01,\n",
      "           -1.3671e+01, -1.9899e+01],\n",
      "          [-9.5718e+00, -9.7293e+00, -8.9567e+00,  ..., -1.0821e+01,\n",
      "           -1.3538e+01, -2.3663e+01],\n",
      "          [-1.7641e+01, -1.7799e+01, -2.0182e+01,  ..., -1.7725e+01,\n",
      "           -2.0284e+01, -2.8764e+01],\n",
      "          ...,\n",
      "          [-4.6298e+01, -4.3867e+01, -4.4462e+01,  ..., -4.2813e+01,\n",
      "           -4.3264e+01, -4.6480e+01],\n",
      "          [-4.7597e+01, -4.4798e+01, -4.6027e+01,  ..., -4.4467e+01,\n",
      "           -4.4975e+01, -4.6983e+01],\n",
      "          [-4.6886e+01, -4.2917e+01, -4.3735e+01,  ..., -4.4047e+01,\n",
      "           -4.4016e+01, -4.7508e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9714e+01, -1.4077e+01, -1.0484e+01,  ..., -9.4866e+00,\n",
      "           -1.0080e+01, -1.4313e+01],\n",
      "          [-2.1948e+01, -1.4893e+01, -1.1055e+01,  ..., -1.3739e+01,\n",
      "           -1.2502e+01, -1.8532e+01],\n",
      "          [-2.1884e+01, -2.0928e+01, -1.5884e+01,  ..., -2.1130e+01,\n",
      "           -1.9600e+01, -2.5277e+01],\n",
      "          ...,\n",
      "          [-5.3528e+01, -5.1130e+01, -5.1114e+01,  ..., -4.9709e+01,\n",
      "           -5.0251e+01, -5.3770e+01],\n",
      "          [-5.5577e+01, -5.1963e+01, -5.0338e+01,  ..., -4.9454e+01,\n",
      "           -5.0415e+01, -5.4143e+01],\n",
      "          [-5.5766e+01, -5.1828e+01, -5.1872e+01,  ..., -5.2364e+01,\n",
      "           -5.4275e+01, -5.4615e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0949e+01, -8.2982e+00, -9.4104e+00,  ..., -8.3833e+00,\n",
      "           -1.0680e+01, -1.7655e+01],\n",
      "          [-1.4225e+01, -1.3354e+01, -1.2044e+01,  ..., -1.1007e+01,\n",
      "           -1.4488e+01, -2.0791e+01],\n",
      "          [-2.1753e+01, -2.3312e+01, -2.4889e+01,  ..., -2.6160e+01,\n",
      "           -2.6580e+01, -3.0275e+01],\n",
      "          ...,\n",
      "          [-5.5445e+01, -5.1929e+01, -5.1407e+01,  ..., -5.1096e+01,\n",
      "           -5.0680e+01, -5.1394e+01],\n",
      "          [-5.6412e+01, -5.3327e+01, -5.2589e+01,  ..., -5.1193e+01,\n",
      "           -5.1988e+01, -5.4647e+01],\n",
      "          [-5.4574e+01, -5.2384e+01, -5.2588e+01,  ..., -5.1052e+01,\n",
      "           -5.2922e+01, -5.4676e+01]]]]), tensor([2, 4, 0, 4, 2, 3, 1, 4, 2, 5, 4, 0, 0, 3, 3, 5, 4, 4, 1, 3, 3, 4, 2, 0,\n",
      "        2])]\n",
      "[tensor([[[[-10.5757,  -3.9565,  -2.4490,  ..., -14.0344,  -9.8667,  -8.6727],\n",
      "          [-11.0136,  -6.4531,  -5.1831,  ..., -15.6522, -15.9574, -11.5940],\n",
      "          [-16.8577, -18.9107, -17.7916,  ..., -25.2219, -21.9087, -16.2473],\n",
      "          ...,\n",
      "          [-49.0824, -47.5911, -48.4652,  ..., -47.4768, -46.8074, -49.4357],\n",
      "          [-50.9669, -46.5640, -47.5060,  ..., -47.9900, -48.4327, -50.0647],\n",
      "          [-50.7123, -46.7355, -48.1979,  ..., -49.1863, -48.1227, -50.5570]]],\n",
      "\n",
      "\n",
      "        [[[ -5.2120,  -4.1334,  -4.2097,  ...,  -3.1277,  -4.9027,  -9.8809],\n",
      "          [ -5.6036,  -2.7944,  -3.4257,  ...,  -1.8790,  -2.7097,  -7.4012],\n",
      "          [-12.0036, -13.3965, -15.7236,  ..., -13.7522, -12.8860, -12.6874],\n",
      "          ...,\n",
      "          [-55.8372, -55.1540, -55.6561,  ..., -54.8882, -53.8076, -53.9245],\n",
      "          [-57.1962, -55.5976, -54.3309,  ..., -53.6039, -53.9144, -54.7926],\n",
      "          [-57.5957, -53.3097, -53.5559,  ..., -52.3026, -52.0629, -55.3671]]],\n",
      "\n",
      "\n",
      "        [[[-10.9055,  -8.4470,  -7.5049,  ...,  -7.8123,  -8.2866,  -8.0311],\n",
      "          [-11.2018, -12.1854, -13.8080,  ...,  -8.2462,  -6.4423,  -8.3171],\n",
      "          [-16.2980, -16.6967, -25.5274,  ..., -18.9832, -15.7927, -17.1252],\n",
      "          ...,\n",
      "          [-47.6100, -45.3317, -44.1492,  ..., -43.8832, -44.8364, -47.1210],\n",
      "          [-46.9981, -43.2093, -44.3806,  ..., -44.0768, -44.4132, -46.8178],\n",
      "          [-47.9968, -46.1935, -45.9198,  ..., -44.9125, -44.4910, -47.1867]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-21.2481, -13.2318, -11.4360,  ..., -15.2457, -15.5091, -14.6598],\n",
      "          [-17.2403, -12.1630, -12.5750,  ..., -13.9417, -12.8999, -13.9763],\n",
      "          [-21.7108, -21.8343, -25.2063,  ..., -23.5583, -21.1637, -18.0900],\n",
      "          ...,\n",
      "          [-57.6918, -54.9767, -55.4636,  ..., -55.7728, -55.3717, -57.3948],\n",
      "          [-56.7882, -55.5966, -55.6308,  ..., -56.3670, -58.5222, -60.3500],\n",
      "          [-56.5126, -56.1400, -57.2627,  ..., -55.5291, -55.8905, -58.4184]]],\n",
      "\n",
      "\n",
      "        [[[ -8.8491,  -3.4978,  -2.1545,  ...,  -1.4982,  -2.7293,  -5.5224],\n",
      "          [-10.6318,  -8.1585,  -9.1547,  ...,  -6.2677,  -6.8292,  -7.6696],\n",
      "          [-17.5509, -18.6270, -23.1745,  ..., -18.0806, -17.0130, -17.8795],\n",
      "          ...,\n",
      "          [-55.0710, -53.1003, -52.7147,  ..., -54.3135, -54.2095, -54.4146],\n",
      "          [-56.1594, -53.1380, -52.6578,  ..., -54.8881, -52.9731, -53.5724],\n",
      "          [-57.9322, -53.9722, -51.9583,  ..., -54.1590, -52.9439, -53.9007]]],\n",
      "\n",
      "\n",
      "        [[[-16.7492, -12.9213, -15.4992,  ..., -12.9660, -18.1481, -28.5464],\n",
      "          [-16.1996, -16.6247, -23.7688,  ..., -17.7725, -19.2445, -21.1943],\n",
      "          [-21.6059, -22.9027, -25.0755,  ..., -29.1831, -24.5935, -21.2665],\n",
      "          ...,\n",
      "          [-59.5307, -55.9166, -53.8853,  ..., -52.0816, -53.1255, -55.9003],\n",
      "          [-56.8013, -54.8264, -54.2567,  ..., -51.6883, -52.1367, -53.6113],\n",
      "          [-54.8412, -54.4343, -53.4510,  ..., -52.3981, -52.6179, -53.7668]]]]), tensor([0, 3, 2, 1, 4, 5, 2, 3, 1, 4, 0, 0, 5, 0, 0, 0, 0, 5, 1, 1, 4, 2, 5, 1,\n",
      "        4])]\n",
      "[tensor([[[[ -4.5473,  -6.2138,  -8.2985,  ...,  -9.9810,  -7.5181,  -8.0491],\n",
      "          [ -4.6183,  -6.6108,  -7.8492,  ...,  -9.0374, -12.7874, -10.7625],\n",
      "          [ -7.9839,  -7.1070, -11.3627,  ...,  -8.2434, -12.9951, -14.6108],\n",
      "          ...,\n",
      "          [-53.3331, -49.3938, -48.5414,  ..., -50.9687, -50.4058, -52.9669],\n",
      "          [-53.4087, -50.9847, -49.7883,  ..., -51.6659, -51.4237, -50.6602],\n",
      "          [-53.9578, -51.2299, -50.1041,  ..., -48.0495, -49.1640, -52.8801]]],\n",
      "\n",
      "\n",
      "        [[[-29.0853, -25.9006, -20.9731,  ...,  -4.6901,  -3.4193,  -6.6621],\n",
      "          [-31.8727, -30.8039, -26.8090,  ...,  -9.3810,  -8.3873, -10.8362],\n",
      "          [-34.7868, -31.7465, -26.1857,  ..., -22.7420, -23.9624, -23.2167],\n",
      "          ...,\n",
      "          [-56.9019, -54.4784, -53.9953,  ..., -51.4284, -52.9841, -54.8922],\n",
      "          [-55.0232, -53.2602, -52.1002,  ..., -51.9545, -52.1367, -54.1389],\n",
      "          [-57.8918, -54.3597, -53.4134,  ..., -53.0290, -53.1905, -53.7613]]],\n",
      "\n",
      "\n",
      "        [[[-12.3970, -12.6769, -11.6861,  ...,  -8.7590,  -8.7376, -15.7222],\n",
      "          [-13.7573, -12.4105, -11.5589,  ..., -10.1950,  -9.7541, -16.6158],\n",
      "          [-21.0281, -21.3274, -19.8277,  ..., -20.4875, -20.1054, -26.3162],\n",
      "          ...,\n",
      "          [-58.3173, -55.6905, -55.1446,  ..., -56.4763, -55.9175, -57.1586],\n",
      "          [-57.4746, -55.1483, -55.9968,  ..., -54.8604, -56.6697, -57.0417],\n",
      "          [-58.5717, -55.8531, -55.7319,  ..., -56.2001, -56.9702, -58.9404]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-13.5728, -14.9611, -20.2619,  ...,  -5.9169,  -4.7809,  -8.8456],\n",
      "          [-12.5747, -13.8058, -19.0077,  ...,  -9.9999,  -9.2723, -10.9084],\n",
      "          [-15.6077, -18.4661, -21.2161,  ..., -25.4814, -20.5172, -17.7988],\n",
      "          ...,\n",
      "          [-55.8372, -53.0905, -52.1294,  ..., -51.2333, -52.2833, -55.3700],\n",
      "          [-55.6846, -53.1335, -53.1861,  ..., -53.7703, -52.5696, -56.3729],\n",
      "          [-55.9756, -53.4670, -53.9101,  ..., -54.4707, -52.9915, -54.3717]]],\n",
      "\n",
      "\n",
      "        [[[-19.8387, -19.1716, -19.8422,  ..., -13.1208, -14.9518, -16.8472],\n",
      "          [-18.7445, -16.9057, -18.9242,  ..., -11.5250, -16.7029, -16.0062],\n",
      "          [-22.2301, -20.9569, -23.2562,  ..., -18.8113, -18.8529, -21.0423],\n",
      "          ...,\n",
      "          [-51.6377, -48.9324, -49.3959,  ..., -49.5261, -49.0410, -50.5903],\n",
      "          [-52.5942, -48.7486, -48.6424,  ..., -50.0788, -49.2967, -50.9648],\n",
      "          [-52.7858, -49.8041, -49.2364,  ..., -49.7302, -49.9798, -51.4836]]],\n",
      "\n",
      "\n",
      "        [[[-11.1326, -10.5856, -14.7633,  ..., -14.8453, -12.1551, -15.0998],\n",
      "          [-12.4634, -11.9332, -16.5080,  ..., -15.3169, -13.5214, -16.0434],\n",
      "          [-18.5694, -22.5046, -23.3326,  ..., -27.7116, -25.4419, -23.5093],\n",
      "          ...,\n",
      "          [-62.1397, -58.9528, -59.2467,  ..., -59.4400, -59.5343, -62.5773],\n",
      "          [-60.5881, -59.8082, -60.4605,  ..., -61.3787, -59.6531, -60.5962],\n",
      "          [-61.0361, -58.9775, -59.5100,  ..., -59.5443, -59.5720, -60.2610]]]]), tensor([0, 2, 2, 5, 1, 0, 1, 2, 4, 0, 2, 0, 5, 5, 1, 2, 0, 0, 0, 1, 2, 1, 0, 2,\n",
      "        5])]\n",
      "[tensor([[[[-14.5727,  -9.6321,  -9.2103,  ..., -11.8275, -12.9413, -14.7009],\n",
      "          [-14.8433, -10.5649, -10.4794,  ..., -11.4483, -14.5512, -22.0689],\n",
      "          [-19.2211, -19.8117, -23.7096,  ..., -19.3841, -21.9057, -22.2750],\n",
      "          ...,\n",
      "          [-48.0494, -45.3691, -45.0387,  ..., -44.0265, -44.6877, -46.3299],\n",
      "          [-47.9073, -45.6596, -44.2975,  ..., -43.3746, -44.3873, -46.3455],\n",
      "          [-46.8101, -43.1942, -42.5134,  ..., -44.2990, -44.3076, -46.7911]]],\n",
      "\n",
      "\n",
      "        [[[-11.4160,  -7.3010,  -6.6249,  ...,  -7.3409,  -7.4026,  -7.1805],\n",
      "          [-14.4316,  -9.6936,  -9.6551,  ..., -10.6789, -12.1702,  -8.9309],\n",
      "          [-23.1466, -21.0663, -21.5290,  ..., -16.4595, -22.0419, -14.9949],\n",
      "          ...,\n",
      "          [-53.4368, -51.5554, -52.7034,  ..., -53.0157, -51.8218, -53.0765],\n",
      "          [-55.1234, -52.2997, -52.0330,  ..., -52.9236, -53.6745, -53.7170],\n",
      "          [-55.4410, -52.7464, -54.5536,  ..., -52.0832, -51.6558, -53.0386]]],\n",
      "\n",
      "\n",
      "        [[[-25.4292, -21.1790, -22.2339,  ...,  -5.7871,  -9.1459, -14.4599],\n",
      "          [-26.4267, -23.9548, -24.4095,  ...,  -9.5116, -14.7796, -18.1322],\n",
      "          [-33.1059, -28.9126, -29.1085,  ..., -24.1106, -23.1945, -24.7255],\n",
      "          ...,\n",
      "          [-51.1722, -47.9533, -48.7014,  ..., -50.8125, -51.2782, -53.2235],\n",
      "          [-50.1713, -49.4649, -49.1165,  ..., -52.0051, -51.0308, -51.5985],\n",
      "          [-52.8469, -51.0000, -48.9094,  ..., -51.7971, -51.5983, -53.4973]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-10.5673,  -3.9909,  -2.2397,  ...,  -5.5005,  -9.2543, -11.1301],\n",
      "          [-12.1509, -11.3756,  -8.1727,  ...,  -9.4391, -16.0497, -16.9221],\n",
      "          [-18.5598, -21.9601, -23.0297,  ..., -23.3890, -22.1037, -25.7802],\n",
      "          ...,\n",
      "          [-52.5944, -51.0127, -51.3107,  ..., -49.6637, -48.0445, -49.6687],\n",
      "          [-52.9727, -50.3655, -51.2536,  ..., -50.5060, -49.5551, -51.8140],\n",
      "          [-51.6009, -49.8333, -50.5489,  ..., -49.9480, -49.9710, -53.0863]]],\n",
      "\n",
      "\n",
      "        [[[-31.1283, -19.7714, -13.0959,  ..., -15.0967, -13.8639, -12.3390],\n",
      "          [-28.8814, -18.6744, -14.8699,  ..., -15.0312, -14.5804, -12.8169],\n",
      "          [-27.4124, -22.4962, -26.7199,  ..., -21.2707, -22.0196, -19.5442],\n",
      "          ...,\n",
      "          [-56.3981, -53.3566, -54.6137,  ..., -54.7959, -55.6958, -57.0505],\n",
      "          [-60.1292, -54.9629, -54.1229,  ..., -53.5637, -53.8974, -56.5261],\n",
      "          [-59.2950, -54.1326, -54.6737,  ..., -53.2280, -54.1052, -56.9463]]],\n",
      "\n",
      "\n",
      "        [[[-15.2821, -11.3767, -11.9845,  ...,  -8.2670,  -8.7736, -12.1539],\n",
      "          [-16.1250, -13.5754, -12.0899,  ...,  -9.9776, -11.9258, -13.2226],\n",
      "          [-21.2551, -22.1299, -22.0504,  ..., -23.9481, -23.7623, -18.9937],\n",
      "          ...,\n",
      "          [-52.6190, -49.9110, -49.1751,  ..., -49.4075, -48.4457, -50.3696],\n",
      "          [-54.6232, -51.2046, -49.7113,  ..., -51.4984, -49.5948, -50.0063],\n",
      "          [-53.9702, -50.4028, -50.4095,  ..., -50.6015, -49.4070, -52.4006]]]]), tensor([4, 1, 3, 1, 0, 4, 0, 1, 0, 0, 0, 0, 1, 0, 5, 3, 0, 2, 1, 4, 5, 0, 0, 0,\n",
      "        3])]\n",
      "[tensor([[[[-20.4516, -17.9941, -20.7322,  ..., -10.1277,  -9.5659, -13.3434],\n",
      "          [-19.9730, -19.4323, -24.4138,  ..., -12.8505, -15.7333, -17.6391],\n",
      "          [-24.7819, -27.8253, -29.0989,  ..., -25.7507, -26.0385, -24.3234],\n",
      "          ...,\n",
      "          [-61.4442, -56.9441, -57.8352,  ..., -59.6203, -58.7586, -60.7551],\n",
      "          [-63.3090, -58.8948, -57.7879,  ..., -58.1593, -57.8995, -59.4014],\n",
      "          [-63.7417, -58.9781, -58.3609,  ..., -58.3074, -59.4399, -61.0138]]],\n",
      "\n",
      "\n",
      "        [[[-16.6691,  -6.9946,  -4.2131,  ...,  -4.6266,  -8.2105, -20.6552],\n",
      "          [-18.8094, -14.4730, -11.0312,  ...,  -8.4841, -11.0249, -22.1196],\n",
      "          [-30.1462, -28.0029, -26.0084,  ..., -21.5683, -20.1793, -19.5037],\n",
      "          ...,\n",
      "          [-56.2467, -52.7388, -52.5563,  ..., -53.2897, -53.3861, -55.1204],\n",
      "          [-56.1644, -53.2781, -54.2015,  ..., -55.0455, -55.1568, -57.1638],\n",
      "          [-56.9713, -53.0619, -52.9821,  ..., -55.6448, -54.6392, -57.0169]]],\n",
      "\n",
      "\n",
      "        [[[-18.9631, -13.8646,  -6.3394,  ...,  -5.7576,  -8.7145,  -9.8001],\n",
      "          [-14.4478,  -9.7717,  -6.0515,  ...,  -5.1902,  -6.5360,  -9.6219],\n",
      "          [-15.2846, -12.2192, -13.8214,  ..., -16.2318, -13.9726, -16.0866],\n",
      "          ...,\n",
      "          [-55.2470, -51.1208, -50.1670,  ..., -53.1796, -51.7913, -52.6755],\n",
      "          [-54.4827, -51.3380, -49.9832,  ..., -52.8669, -53.0000, -54.9691],\n",
      "          [-55.3948, -52.0201, -50.5608,  ..., -52.0717, -52.1901, -55.3488]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -7.9592,  -3.1344,  -2.6511,  ..., -10.3558, -11.6797, -17.3033],\n",
      "          [ -9.0071,  -7.6488, -11.3487,  ..., -11.8102,  -9.2244, -13.1895],\n",
      "          [-14.0929, -17.4014, -23.1372,  ..., -15.3419, -17.5167, -15.7416],\n",
      "          ...,\n",
      "          [-50.5680, -45.4783, -44.7638,  ..., -46.7668, -43.6946, -46.2976],\n",
      "          [-49.7016, -48.4203, -47.4780,  ..., -46.1984, -46.1178, -48.5836],\n",
      "          [-49.5079, -47.1403, -47.2599,  ..., -47.6474, -47.2906, -49.3603]]],\n",
      "\n",
      "\n",
      "        [[[-19.5398, -10.2152,  -8.2142,  ...,  -5.7538, -13.2875, -14.3327],\n",
      "          [-18.2087, -10.3713,  -9.4515,  ...,  -3.6821,  -9.0942, -14.3417],\n",
      "          [-25.1122, -20.6830, -19.5156,  ..., -10.5679, -16.3520, -18.6934],\n",
      "          ...,\n",
      "          [-54.8693, -52.6403, -53.0187,  ..., -53.9944, -51.9241, -53.2146],\n",
      "          [-55.0803, -53.3021, -52.8280,  ..., -52.2696, -52.6950, -55.4110],\n",
      "          [-56.9314, -52.7392, -52.0397,  ..., -52.4353, -52.6939, -54.9656]]],\n",
      "\n",
      "\n",
      "        [[[-21.1655,  -9.2806,  -5.2622,  ...,  -8.8647, -11.1282, -18.5056],\n",
      "          [-20.0558,  -9.4534,  -6.5965,  ..., -11.7341, -10.9992, -17.6177],\n",
      "          [-21.2958, -18.4667, -19.6582,  ..., -23.4726, -20.1104, -22.3423],\n",
      "          ...,\n",
      "          [-52.6853, -51.5193, -50.5851,  ..., -51.7641, -51.5040, -55.3226],\n",
      "          [-54.2208, -51.7189, -51.3510,  ..., -51.1839, -50.5015, -51.5194],\n",
      "          [-55.2196, -51.3944, -51.7383,  ..., -52.0318, -51.2384, -52.3445]]]]), tensor([1, 4, 2, 1, 5, 0, 3, 3, 0, 4, 0, 4, 1, 5, 0, 2, 0, 2, 0, 1, 0, 1, 0, 1,\n",
      "        5])]\n",
      "[tensor([[[[-24.0151, -14.0741,  -8.4813,  ...,  -7.1553,  -3.5366,  -4.7332],\n",
      "          [-23.5508, -12.4591,  -8.8935,  ..., -10.3823,  -6.3858,  -7.1951],\n",
      "          [-25.5836, -19.2200, -21.9387,  ..., -21.8384, -20.6047, -16.8313],\n",
      "          ...,\n",
      "          [-51.8312, -50.7193, -52.3980,  ..., -52.6845, -52.2245, -53.4746],\n",
      "          [-54.0043, -51.1681, -50.4154,  ..., -51.9934, -52.3931, -54.9598],\n",
      "          [-53.2392, -50.3139, -50.2935,  ..., -53.3171, -52.3102, -54.1964]]],\n",
      "\n",
      "\n",
      "        [[[ -6.1380,   0.0000,  -2.7168,  ..., -12.1368, -10.0503, -11.5785],\n",
      "          [ -6.2788,  -3.2301,  -6.3150,  ..., -10.3615, -11.0651, -13.5633],\n",
      "          [-13.6251, -15.8973, -17.5655,  ..., -20.3949, -22.2687, -22.6195],\n",
      "          ...,\n",
      "          [-51.9228, -51.6819, -54.1421,  ..., -51.6485, -50.9753, -53.2437],\n",
      "          [-52.7215, -51.4035, -51.8770,  ..., -55.0120, -55.5797, -56.5155],\n",
      "          [-54.9164, -52.4614, -52.8216,  ..., -53.7601, -53.2088, -53.1660]]],\n",
      "\n",
      "\n",
      "        [[[-42.9951, -36.3205, -36.3536,  ..., -48.3439, -42.3000, -41.3858],\n",
      "          [-43.3959, -39.5435, -39.7030,  ..., -49.3582, -46.7161, -47.5142],\n",
      "          [-50.4178, -53.0831, -55.0694,  ..., -57.7504, -54.0611, -50.6898],\n",
      "          ...,\n",
      "          [-80.0000, -79.2811, -80.0000,  ..., -79.9852, -79.7417, -80.0000],\n",
      "          [-80.0000, -80.0000, -80.0000,  ..., -79.3143, -79.0314, -80.0000],\n",
      "          [-80.0000, -79.0932, -79.6483,  ..., -79.6318, -79.4915, -80.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.7691, -12.9450,  -5.3312,  ..., -15.4166,  -9.5626,  -8.5781],\n",
      "          [-15.8101, -11.6237,  -6.9632,  ..., -18.2089, -12.4391, -10.7572],\n",
      "          [-20.8231, -16.4172, -15.3844,  ..., -20.1217, -24.1861, -17.7948],\n",
      "          ...,\n",
      "          [-47.6799, -43.9780, -42.7015,  ..., -42.8832, -45.8906, -47.8539],\n",
      "          [-45.3930, -43.2284, -43.3101,  ..., -42.7987, -44.2289, -46.8842],\n",
      "          [-45.2104, -43.1165, -44.7029,  ..., -43.2037, -42.8307, -45.3306]]],\n",
      "\n",
      "\n",
      "        [[[-12.8657, -11.2482, -13.4724,  ..., -10.0661, -11.7544,  -9.9558],\n",
      "          [-13.8016, -14.9496, -17.2188,  ..., -10.6228, -14.6726, -11.0705],\n",
      "          [-19.8329, -19.9795, -24.5743,  ..., -20.7737, -17.6161, -15.3557],\n",
      "          ...,\n",
      "          [-55.4961, -52.9254, -53.6704,  ..., -52.3865, -52.6815, -55.8604],\n",
      "          [-56.1053, -53.6912, -53.0935,  ..., -52.2997, -52.0639, -53.5094],\n",
      "          [-56.6315, -53.5775, -52.6498,  ..., -53.7087, -53.7046, -55.0886]]],\n",
      "\n",
      "\n",
      "        [[[-10.9037,  -9.6316, -15.9832,  ...,  -8.0860, -11.3804, -17.6645],\n",
      "          [-14.0838, -12.3146, -16.5750,  ..., -14.8592, -16.9757, -25.1795],\n",
      "          [-23.0597, -23.9344, -26.1906,  ..., -24.4917, -25.9262, -30.6096],\n",
      "          ...,\n",
      "          [-54.3032, -51.4389, -51.8348,  ..., -50.4987, -51.0670, -53.0224],\n",
      "          [-53.3753, -51.9854, -52.5193,  ..., -52.5263, -52.4781, -53.4447],\n",
      "          [-54.4793, -52.6034, -51.8446,  ..., -52.5953, -52.8672, -54.7190]]]]), tensor([0, 5, 4, 5, 1, 0, 1, 1, 0, 0, 5, 0, 1, 0, 5, 0, 2, 1, 0, 0, 1, 0, 2, 1,\n",
      "        4])]\n",
      "[tensor([[[[ -8.7493,  -4.5807,  -6.4738,  ..., -15.9647, -14.0820, -12.0870],\n",
      "          [-12.3815, -10.5802, -14.8960,  ..., -12.7258, -10.9269, -12.2491],\n",
      "          [-19.4824, -23.7299, -29.5765,  ..., -21.6016, -19.3830, -17.2908],\n",
      "          ...,\n",
      "          [-52.9048, -50.6366, -49.7437,  ..., -49.7154, -49.2230, -51.2233],\n",
      "          [-52.8697, -49.8926, -49.1587,  ..., -48.3543, -49.6159, -51.7414],\n",
      "          [-52.8566, -50.6728, -49.1883,  ..., -49.3658, -49.1887, -51.0989]]],\n",
      "\n",
      "\n",
      "        [[[ -7.6943,  -5.9382,  -7.4032,  ...,  -8.1046,  -6.6941,  -8.8680],\n",
      "          [-10.2469, -11.4874, -12.8954,  ..., -13.6241,  -9.5865, -11.0633],\n",
      "          [-16.2723, -19.8872, -23.0262,  ..., -26.5111, -22.3468, -21.9607],\n",
      "          ...,\n",
      "          [-54.4179, -52.9635, -53.7995,  ..., -54.1535, -54.6889, -56.2902],\n",
      "          [-55.2268, -52.4172, -53.1265,  ..., -54.1609, -53.8873, -56.5630],\n",
      "          [-56.8721, -53.6757, -53.8824,  ..., -52.9600, -53.5689, -56.0322]]],\n",
      "\n",
      "\n",
      "        [[[-21.2722, -15.7363,  -8.0751,  ...,  -7.4133,  -8.0877, -13.2537],\n",
      "          [-20.5599, -18.8401, -11.2284,  ..., -14.0391, -12.3484, -17.6471],\n",
      "          [-25.1204, -22.4697, -24.0603,  ..., -17.8006, -16.6104, -21.9891],\n",
      "          ...,\n",
      "          [-53.8747, -49.7312, -48.8353,  ..., -50.6623, -50.2794, -51.2271],\n",
      "          [-53.6322, -49.5831, -49.3631,  ..., -50.9076, -51.1527, -51.0633],\n",
      "          [-51.1943, -48.3772, -47.9430,  ..., -51.9853, -50.8899, -51.1673]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-20.3959, -16.9312,  -8.0731,  ...,  -4.7936, -11.8573, -10.2112],\n",
      "          [-19.3135, -13.2479,  -6.8360,  ...,  -4.4044,  -8.8201,  -9.5876],\n",
      "          [-21.3031, -17.6341, -14.4458,  ..., -12.8848, -15.2223, -13.6971],\n",
      "          ...,\n",
      "          [-51.9537, -48.4511, -47.5545,  ..., -47.8985, -46.5046, -47.7934],\n",
      "          [-52.2264, -48.3000, -47.6907,  ..., -45.9011, -46.9553, -50.1222],\n",
      "          [-52.2821, -48.0322, -48.4575,  ..., -46.2426, -46.7295, -50.8456]]],\n",
      "\n",
      "\n",
      "        [[[-12.5628,  -8.1854,  -7.5131,  ...,  -1.9018,  -2.7220,  -7.7348],\n",
      "          [-12.8445,  -8.3350,  -7.3685,  ...,  -5.0801,  -5.7026,  -8.7274],\n",
      "          [-18.6842, -20.4696, -18.0192,  ..., -18.9351, -18.2657, -18.4970],\n",
      "          ...,\n",
      "          [-53.3269, -52.5081, -53.6013,  ..., -52.3845, -53.6357, -55.7000],\n",
      "          [-55.8092, -53.5823, -53.8144,  ..., -51.1757, -51.5666, -53.6472],\n",
      "          [-56.6887, -53.7506, -53.7992,  ..., -50.3366, -51.5614, -52.8527]]],\n",
      "\n",
      "\n",
      "        [[[-13.8973,  -7.7259,  -5.2067,  ...,  -3.8277,  -7.8463, -10.4925],\n",
      "          [-16.4069, -15.3037,  -8.7685,  ...,  -8.0257, -12.5607, -11.9184],\n",
      "          [-19.6523, -18.2227, -19.9249,  ..., -21.0571, -15.6680, -14.9900],\n",
      "          ...,\n",
      "          [-54.9636, -52.6137, -52.2102,  ..., -51.4800, -52.3609, -53.2149],\n",
      "          [-53.9044, -51.6077, -52.3988,  ..., -53.3218, -53.4893, -53.3324],\n",
      "          [-53.8415, -52.4827, -53.0353,  ..., -54.9332, -53.2509, -52.9774]]]]), tensor([3, 2, 2, 2, 3, 3, 0, 4, 2, 0, 5, 2, 4, 0, 5, 0, 2, 4, 1, 5, 4, 1, 1, 3,\n",
      "        1])]\n"
     ]
    }
   ],
   "source": [
    "# ラベルの指定\n",
    "t_df = Dataset.matNum\n",
    "\n",
    "# テンソル形式に変換\n",
    "df_tenosor = torch.tensor(df, dtype=torch.float32)\n",
    "df_tenosor = torch.unsqueeze(df_tenosor, 1)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "print(df_tenosor.size())\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset = torch.utils.data.TensorDataset(df_tenosor, label_tensor)\n",
    "\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 50%　: 25% : 25%\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 25\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DyMN(\n",
      "  (layers): ModuleList(\n",
      "    (0): DY_Block(\n",
      "      (exp_conv): DynamicWrapper(\n",
      "        (module): Identity()\n",
      "      )\n",
      "      (exp_norm): Identity()\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Identity()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (1): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=256, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (3): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (4-5): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=480, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (6): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=960, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(40, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=800, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (8-9): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=736, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (10): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=1920, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (11): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (12): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (13-14): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=3840, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (in_c): ConvNormActivation(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (out_c): ConvNormActivation(\n",
      "    (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=960, out_features=1280, bias=False)\n",
      "    (3): Hardswish()\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Linear(in_features=1280, out_features=527, bias=False)\n",
      "    (6): Linear(in_features=527, out_features=176, bias=False)\n",
      "    (7): Linear(in_features=176, out_features=21, bias=False)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=21, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "matModel_2 = shModel_2_trained\n",
    "\n",
    "#パラメータの更新を許可\n",
    "for param in matModel_2.parameters():\n",
    "    param.requires_gred = False\n",
    "\n",
    "\n",
    "# print(model.classifier)\n",
    "\n",
    "# 出力層の最後だけ変更\n",
    "# model.classifier[5] = torch.nn.Linear(1280,2)\n",
    "matModel_2.classifier= nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(output_size=1),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    nn.Linear(in_features=960, out_features=1280, bias=False),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(p=0.2, inplace=False),\n",
    "    nn.Linear(in_features=1280, out_features=527, bias=False),\n",
    "    nn.Linear(in_features=527, out_features=176, bias=False),  # 新しい層\n",
    "    nn.Linear(in_features=176, out_features=21, bias=False),  # 新しい層\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=21, out_features=6, bias=True),  # 新しい層\n",
    "    # nn.ReLU(),\n",
    "    # nn.Linear(in_features=2, out_features=21, bias=True),  # 新しい層\n",
    "    # nn.ReLU(),\n",
    "    # nn.Linear(in_features=21, out_features=6, bias=True),  # 新しい層\n",
    ")\n",
    "print(matModel_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch [1/50], Train Loss: 1.7872, Validation Loss: 1.7734\n",
      "Epoch [2/50], Train Loss: 1.7394, Validation Loss: 1.7454\n",
      "Epoch [3/50], Train Loss: 1.6910, Validation Loss: 1.6852\n",
      "Epoch [4/50], Train Loss: 1.5312, Validation Loss: 1.3821\n",
      "Epoch [5/50], Train Loss: 1.1437, Validation Loss: 1.0934\n",
      "Epoch [6/50], Train Loss: 0.8466, Validation Loss: 0.8820\n",
      "Epoch [7/50], Train Loss: 0.5011, Validation Loss: 0.6129\n",
      "Epoch [8/50], Train Loss: 0.1617, Validation Loss: 0.6176\n",
      "Epoch [9/50], Train Loss: 0.0772, Validation Loss: 0.7202\n",
      "Epoch [10/50], Train Loss: 0.0611, Validation Loss: 0.7038\n",
      "Epoch [11/50], Train Loss: 0.0608, Validation Loss: 0.5331\n",
      "Epoch [12/50], Train Loss: 0.0348, Validation Loss: 0.6136\n",
      "Epoch [13/50], Train Loss: 0.0441, Validation Loss: 0.5472\n",
      "Epoch [14/50], Train Loss: 0.0426, Validation Loss: 1.6313\n",
      "Epoch [15/50], Train Loss: 0.1651, Validation Loss: 0.5805\n",
      "Epoch [16/50], Train Loss: 0.0605, Validation Loss: 1.3454\n",
      "Epoch [17/50], Train Loss: 0.0424, Validation Loss: 0.5780\n",
      "Epoch [18/50], Train Loss: 0.0156, Validation Loss: 0.8088\n",
      "Epoch [19/50], Train Loss: 0.2113, Validation Loss: 2.3963\n",
      "Epoch [20/50], Train Loss: 0.2645, Validation Loss: 0.5275\n",
      "Epoch [21/50], Train Loss: 0.0406, Validation Loss: 0.8405\n",
      "Epoch [22/50], Train Loss: 0.0103, Validation Loss: 0.8293\n",
      "Epoch [23/50], Train Loss: 0.0179, Validation Loss: 0.5765\n",
      "Epoch [24/50], Train Loss: 0.0326, Validation Loss: 0.4961\n",
      "Epoch [25/50], Train Loss: 0.0191, Validation Loss: 1.2692\n",
      "Epoch [26/50], Train Loss: 0.0059, Validation Loss: 0.5864\n",
      "Epoch [27/50], Train Loss: 0.0029, Validation Loss: 0.4559\n",
      "Epoch [28/50], Train Loss: 0.0023, Validation Loss: 0.4428\n",
      "Epoch [29/50], Train Loss: 0.0044, Validation Loss: 0.4434\n",
      "Epoch [30/50], Train Loss: 0.0019, Validation Loss: 0.4054\n",
      "Epoch [31/50], Train Loss: 0.0025, Validation Loss: 0.4188\n",
      "Epoch [32/50], Train Loss: 0.0015, Validation Loss: 0.4137\n",
      "Epoch [33/50], Train Loss: 0.0027, Validation Loss: 0.5183\n",
      "Epoch [34/50], Train Loss: 0.0013, Validation Loss: 0.4756\n",
      "Epoch [35/50], Train Loss: 0.0064, Validation Loss: 0.6133\n",
      "Epoch [36/50], Train Loss: 0.0029, Validation Loss: 0.5853\n",
      "Epoch [37/50], Train Loss: 0.0043, Validation Loss: 0.4398\n",
      "Epoch [38/50], Train Loss: 0.0048, Validation Loss: 0.4164\n",
      "Epoch [39/50], Train Loss: 0.0073, Validation Loss: 0.6226\n",
      "Epoch [40/50], Train Loss: 0.0012, Validation Loss: 0.5932\n",
      "Epoch [41/50], Train Loss: 0.0014, Validation Loss: 0.5404\n",
      "Epoch [42/50], Train Loss: 0.0021, Validation Loss: 0.6674\n",
      "Epoch [43/50], Train Loss: 0.0016, Validation Loss: 0.4882\n",
      "Epoch [44/50], Train Loss: 0.0050, Validation Loss: 0.4627\n",
      "Epoch [45/50], Train Loss: 0.0009, Validation Loss: 0.4343\n",
      "Epoch [46/50], Train Loss: 0.0006, Validation Loss: 0.4430\n",
      "Epoch [47/50], Train Loss: 0.0017, Validation Loss: 0.7551\n",
      "Epoch [48/50], Train Loss: 0.0018, Validation Loss: 0.7471\n",
      "Epoch [49/50], Train Loss: 0.0057, Validation Loss: 0.7522\n",
      "Epoch [50/50], Train Loss: 0.0018, Validation Loss: 0.5764\n",
      "Epoch [51/50], Train Loss: 0.0011, Validation Loss: 0.4969\n",
      "Epoch [52/50], Train Loss: 0.0007, Validation Loss: 0.4623\n",
      "Epoch [53/50], Train Loss: 0.0008, Validation Loss: 0.4690\n",
      "Epoch [54/50], Train Loss: 0.0008, Validation Loss: 0.4663\n",
      "Epoch [55/50], Train Loss: 0.0022, Validation Loss: 0.5067\n",
      "Epoch [56/50], Train Loss: 0.0313, Validation Loss: 0.8600\n",
      "Epoch [57/50], Train Loss: 0.0109, Validation Loss: 0.7760\n",
      "Epoch [58/50], Train Loss: 0.0062, Validation Loss: 1.2187\n",
      "Epoch [59/50], Train Loss: 0.0023, Validation Loss: 0.5438\n",
      "Epoch [60/50], Train Loss: 0.0065, Validation Loss: 1.3094\n",
      "Epoch [61/50], Train Loss: 0.0048, Validation Loss: 2.2076\n",
      "Epoch [62/50], Train Loss: 0.0023, Validation Loss: 1.4056\n",
      "Epoch [63/50], Train Loss: 0.0032, Validation Loss: 0.6624\n",
      "Epoch [64/50], Train Loss: 0.0054, Validation Loss: 0.9903\n",
      "Epoch [65/50], Train Loss: 0.0092, Validation Loss: 1.3722\n",
      "Epoch [66/50], Train Loss: 0.0057, Validation Loss: 1.6223\n",
      "Epoch [67/50], Train Loss: 0.0084, Validation Loss: 0.8425\n",
      "Epoch [68/50], Train Loss: 0.0095, Validation Loss: 0.9224\n",
      "Epoch [69/50], Train Loss: 0.0052, Validation Loss: 0.7618\n",
      "Epoch [70/50], Train Loss: 0.0014, Validation Loss: 0.7032\n",
      "Epoch [71/50], Train Loss: 0.0009, Validation Loss: 0.5963\n",
      "Epoch [72/50], Train Loss: 0.0006, Validation Loss: 0.6008\n",
      "Epoch [73/50], Train Loss: 0.0351, Validation Loss: 1.2648\n",
      "Epoch [74/50], Train Loss: 0.0063, Validation Loss: 0.8363\n",
      "Epoch [75/50], Train Loss: 0.0125, Validation Loss: 1.1079\n",
      "Epoch [76/50], Train Loss: 0.0029, Validation Loss: 0.8548\n",
      "Epoch [77/50], Train Loss: 0.0005, Validation Loss: 0.7239\n",
      "Epoch [78/50], Train Loss: 0.0011, Validation Loss: 0.6940\n",
      "Epoch [79/50], Train Loss: 0.0004, Validation Loss: 0.6780\n",
      "Epoch [80/50], Train Loss: 0.0166, Validation Loss: 1.8465\n",
      "Epoch [81/50], Train Loss: 0.0104, Validation Loss: 1.1655\n",
      "Epoch [82/50], Train Loss: 0.0102, Validation Loss: 0.6990\n",
      "Epoch [83/50], Train Loss: 0.0100, Validation Loss: 0.7271\n",
      "Epoch [84/50], Train Loss: 0.0237, Validation Loss: 0.9810\n",
      "Epoch [85/50], Train Loss: 0.0067, Validation Loss: 0.8506\n",
      "Epoch [86/50], Train Loss: 0.0016, Validation Loss: 0.8053\n",
      "Epoch [87/50], Train Loss: 0.0151, Validation Loss: 0.8398\n",
      "Epoch [88/50], Train Loss: 0.0115, Validation Loss: 0.6275\n",
      "Epoch [89/50], Train Loss: 0.0205, Validation Loss: 0.6840\n",
      "Epoch [90/50], Train Loss: 0.0019, Validation Loss: 0.5524\n",
      "Epoch [91/50], Train Loss: 0.1457, Validation Loss: 1.1944\n",
      "Epoch [92/50], Train Loss: 0.0046, Validation Loss: 1.6058\n",
      "Epoch [93/50], Train Loss: 0.0024, Validation Loss: 1.2938\n",
      "Epoch [94/50], Train Loss: 0.3132, Validation Loss: 0.6917\n",
      "Epoch [95/50], Train Loss: 0.0210, Validation Loss: 0.4852\n",
      "Epoch [96/50], Train Loss: 0.0051, Validation Loss: 0.6553\n",
      "Epoch [97/50], Train Loss: 0.0112, Validation Loss: 1.0094\n",
      "Epoch [98/50], Train Loss: 0.0022, Validation Loss: 0.7382\n",
      "Epoch [99/50], Train Loss: 0.0020, Validation Loss: 0.6741\n",
      "Epoch [100/50], Train Loss: 0.0179, Validation Loss: 1.7777\n",
      "Epoch [101/50], Train Loss: 0.0324, Validation Loss: 1.1778\n",
      "Epoch [102/50], Train Loss: 0.0060, Validation Loss: 0.5357\n",
      "Epoch [103/50], Train Loss: 0.0035, Validation Loss: 0.5053\n",
      "Epoch [104/50], Train Loss: 0.0013, Validation Loss: 0.4974\n",
      "Epoch [105/50], Train Loss: 0.0029, Validation Loss: 0.5909\n",
      "Epoch [106/50], Train Loss: 0.0006, Validation Loss: 0.5862\n",
      "Epoch [107/50], Train Loss: 0.0016, Validation Loss: 0.5634\n",
      "Epoch [108/50], Train Loss: 0.0038, Validation Loss: 0.6506\n",
      "Epoch [109/50], Train Loss: 0.0040, Validation Loss: 0.5671\n",
      "Epoch [110/50], Train Loss: 0.0059, Validation Loss: 0.8882\n",
      "Epoch [111/50], Train Loss: 0.0059, Validation Loss: 0.6891\n",
      "Epoch [112/50], Train Loss: 0.0262, Validation Loss: 0.8210\n",
      "Epoch [113/50], Train Loss: 0.0025, Validation Loss: 0.7683\n",
      "Epoch [114/50], Train Loss: 0.0012, Validation Loss: 0.7240\n",
      "Epoch [115/50], Train Loss: 0.0006, Validation Loss: 0.7083\n",
      "Epoch [116/50], Train Loss: 0.0005, Validation Loss: 0.7304\n",
      "Epoch [117/50], Train Loss: 0.0005, Validation Loss: 0.7135\n",
      "Epoch [118/50], Train Loss: 0.0004, Validation Loss: 0.6878\n",
      "Epoch [119/50], Train Loss: 0.0175, Validation Loss: 2.3298\n",
      "Epoch [120/50], Train Loss: 0.0032, Validation Loss: 1.2681\n",
      "Epoch [121/50], Train Loss: 0.0013, Validation Loss: 0.7796\n",
      "Epoch [122/50], Train Loss: 0.0014, Validation Loss: 0.6464\n",
      "Epoch [123/50], Train Loss: 0.0053, Validation Loss: 0.7802\n",
      "Epoch [124/50], Train Loss: 0.0006, Validation Loss: 0.7676\n",
      "Epoch [125/50], Train Loss: 0.0007, Validation Loss: 0.7144\n",
      "Epoch [126/50], Train Loss: 0.0046, Validation Loss: 0.6388\n",
      "Epoch [127/50], Train Loss: 0.0038, Validation Loss: 0.5947\n",
      "Epoch [128/50], Train Loss: 0.0008, Validation Loss: 0.5787\n",
      "Epoch [129/50], Train Loss: 0.0017, Validation Loss: 0.6496\n",
      "Epoch [130/50], Train Loss: 0.0019, Validation Loss: 0.5808\n",
      "Epoch [131/50], Train Loss: 0.0040, Validation Loss: 0.6801\n",
      "Epoch [132/50], Train Loss: 0.0002, Validation Loss: 0.6040\n",
      "Epoch [133/50], Train Loss: 0.0019, Validation Loss: 0.5377\n",
      "Epoch [134/50], Train Loss: 0.0006, Validation Loss: 0.5270\n",
      "Epoch [135/50], Train Loss: 0.0011, Validation Loss: 0.5059\n",
      "Epoch [136/50], Train Loss: 0.0019, Validation Loss: 0.5272\n",
      "Epoch [137/50], Train Loss: 0.0007, Validation Loss: 0.5216\n",
      "Epoch [138/50], Train Loss: 0.0002, Validation Loss: 0.5248\n",
      "Epoch [139/50], Train Loss: 0.0004, Validation Loss: 0.4976\n",
      "Epoch [140/50], Train Loss: 0.0133, Validation Loss: 0.9282\n",
      "Epoch [141/50], Train Loss: 0.0006, Validation Loss: 0.7150\n",
      "Epoch [142/50], Train Loss: 0.0005, Validation Loss: 0.5711\n",
      "Epoch [143/50], Train Loss: 0.0015, Validation Loss: 0.5591\n",
      "Epoch [144/50], Train Loss: 0.0010, Validation Loss: 0.5517\n",
      "Epoch [145/50], Train Loss: 0.0006, Validation Loss: 0.5390\n",
      "Epoch [146/50], Train Loss: 0.0009, Validation Loss: 0.5463\n",
      "Epoch [147/50], Train Loss: 0.0001, Validation Loss: 0.5415\n",
      "Epoch [148/50], Train Loss: 0.0003, Validation Loss: 0.5357\n",
      "Epoch [149/50], Train Loss: 0.0003, Validation Loss: 0.5331\n",
      "Epoch [150/50], Train Loss: 0.0020, Validation Loss: 0.6600\n",
      "Epoch [151/50], Train Loss: 0.0004, Validation Loss: 0.6501\n",
      "Epoch [152/50], Train Loss: 0.0002, Validation Loss: 0.6357\n",
      "Epoch [153/50], Train Loss: 0.0042, Validation Loss: 0.7422\n",
      "Epoch [154/50], Train Loss: 0.0004, Validation Loss: 0.6857\n",
      "Epoch [155/50], Train Loss: 0.0008, Validation Loss: 0.5754\n",
      "Epoch [156/50], Train Loss: 0.0006, Validation Loss: 0.5656\n",
      "Epoch [157/50], Train Loss: 0.0004, Validation Loss: 0.5671\n",
      "Epoch [158/50], Train Loss: 0.0003, Validation Loss: 0.5655\n",
      "Epoch [159/50], Train Loss: 0.0001, Validation Loss: 0.5673\n",
      "Epoch [160/50], Train Loss: 0.0004, Validation Loss: 0.5714\n",
      "Epoch [161/50], Train Loss: 0.0001, Validation Loss: 0.5721\n",
      "Epoch [162/50], Train Loss: 0.0023, Validation Loss: 0.5906\n",
      "Epoch [163/50], Train Loss: 0.0004, Validation Loss: 0.5522\n",
      "Epoch [164/50], Train Loss: 0.0003, Validation Loss: 0.5270\n",
      "Epoch [165/50], Train Loss: 0.0004, Validation Loss: 0.5370\n",
      "Epoch [166/50], Train Loss: 0.0011, Validation Loss: 0.6232\n",
      "Epoch [167/50], Train Loss: 0.0003, Validation Loss: 0.6058\n",
      "Epoch [168/50], Train Loss: 0.0002, Validation Loss: 0.5999\n",
      "Epoch [169/50], Train Loss: 0.0003, Validation Loss: 0.5937\n",
      "Epoch [170/50], Train Loss: 0.0002, Validation Loss: 0.5933\n",
      "Epoch [171/50], Train Loss: 0.0001, Validation Loss: 0.5925\n",
      "Epoch [172/50], Train Loss: 0.0001, Validation Loss: 0.5956\n",
      "Epoch [173/50], Train Loss: 0.0010, Validation Loss: 0.5771\n",
      "Epoch [174/50], Train Loss: 0.0002, Validation Loss: 0.5800\n",
      "Epoch [175/50], Train Loss: 0.0006, Validation Loss: 0.6351\n",
      "Epoch [176/50], Train Loss: 0.0004, Validation Loss: 0.6182\n",
      "Epoch [177/50], Train Loss: 0.0001, Validation Loss: 0.6112\n",
      "Epoch [178/50], Train Loss: 0.0002, Validation Loss: 0.6046\n",
      "Epoch [179/50], Train Loss: 0.0001, Validation Loss: 0.6043\n",
      "Epoch [180/50], Train Loss: 0.0001, Validation Loss: 0.6037\n",
      "Epoch [181/50], Train Loss: 0.0005, Validation Loss: 0.6040\n",
      "Epoch [182/50], Train Loss: 0.0016, Validation Loss: 0.6662\n",
      "Epoch [183/50], Train Loss: 0.0002, Validation Loss: 0.6563\n",
      "Epoch [184/50], Train Loss: 0.0002, Validation Loss: 0.6492\n",
      "Epoch [185/50], Train Loss: 0.0001, Validation Loss: 0.6483\n",
      "Epoch [186/50], Train Loss: 0.0004, Validation Loss: 0.6551\n",
      "Epoch [187/50], Train Loss: 0.0001, Validation Loss: 0.6539\n",
      "Epoch [188/50], Train Loss: 0.0003, Validation Loss: 0.6485\n",
      "Epoch [189/50], Train Loss: 0.0003, Validation Loss: 0.6361\n",
      "Epoch [190/50], Train Loss: 0.0003, Validation Loss: 0.6405\n",
      "Epoch [191/50], Train Loss: 0.0002, Validation Loss: 0.6373\n",
      "Epoch [192/50], Train Loss: 0.0001, Validation Loss: 0.6366\n",
      "Epoch [193/50], Train Loss: 0.0018, Validation Loss: 0.7999\n",
      "Epoch [194/50], Train Loss: 0.0004, Validation Loss: 0.8414\n",
      "Epoch [195/50], Train Loss: 0.0001, Validation Loss: 0.8357\n",
      "Epoch [196/50], Train Loss: 0.0012, Validation Loss: 0.7843\n",
      "Epoch [197/50], Train Loss: 0.1686, Validation Loss: 4.9275\n",
      "Epoch [198/50], Train Loss: 0.1346, Validation Loss: 2.8758\n",
      "Epoch [199/50], Train Loss: 0.0431, Validation Loss: 2.3107\n",
      "Epoch [200/50], Train Loss: 0.0059, Validation Loss: 1.0400\n",
      "Epoch [201/50], Train Loss: 0.0282, Validation Loss: 0.5040\n",
      "Epoch [202/50], Train Loss: 0.0086, Validation Loss: 0.5930\n",
      "Epoch [203/50], Train Loss: 0.0064, Validation Loss: 0.4515\n",
      "Epoch [204/50], Train Loss: 0.0114, Validation Loss: 0.8043\n",
      "Epoch [205/50], Train Loss: 0.0015, Validation Loss: 0.7766\n",
      "Epoch [206/50], Train Loss: 0.0063, Validation Loss: 0.4582\n",
      "Epoch [207/50], Train Loss: 0.0014, Validation Loss: 0.4692\n",
      "Epoch [208/50], Train Loss: 0.0038, Validation Loss: 0.5332\n",
      "Epoch [209/50], Train Loss: 0.0010, Validation Loss: 0.4939\n",
      "Epoch [210/50], Train Loss: 0.0005, Validation Loss: 0.4761\n",
      "Epoch [211/50], Train Loss: 0.0017, Validation Loss: 0.4716\n",
      "Epoch [212/50], Train Loss: 0.0173, Validation Loss: 0.7034\n",
      "Epoch [213/50], Train Loss: 0.0030, Validation Loss: 0.6270\n",
      "Epoch [214/50], Train Loss: 0.0014, Validation Loss: 0.5710\n",
      "Epoch [215/50], Train Loss: 0.0006, Validation Loss: 0.5525\n",
      "Epoch [216/50], Train Loss: 0.0010, Validation Loss: 0.5241\n",
      "Epoch [217/50], Train Loss: 0.0194, Validation Loss: 0.7996\n",
      "Epoch [218/50], Train Loss: 0.0062, Validation Loss: 0.5557\n",
      "Epoch [219/50], Train Loss: 0.0023, Validation Loss: 0.5223\n",
      "Epoch [220/50], Train Loss: 0.0005, Validation Loss: 0.5008\n",
      "Epoch [221/50], Train Loss: 0.0059, Validation Loss: 1.4391\n",
      "Epoch [222/50], Train Loss: 0.0024, Validation Loss: 1.2556\n",
      "Epoch [223/50], Train Loss: 0.0003, Validation Loss: 0.8854\n",
      "Epoch [224/50], Train Loss: 0.0007, Validation Loss: 0.5895\n",
      "Epoch [225/50], Train Loss: 0.0004, Validation Loss: 0.5639\n",
      "Epoch [226/50], Train Loss: 0.0007, Validation Loss: 0.5825\n",
      "Epoch [227/50], Train Loss: 0.0133, Validation Loss: 0.6820\n",
      "Epoch [228/50], Train Loss: 0.0013, Validation Loss: 0.7846\n",
      "Epoch [229/50], Train Loss: 0.0050, Validation Loss: 0.6526\n",
      "Epoch [230/50], Train Loss: 0.0019, Validation Loss: 0.5780\n",
      "Epoch [231/50], Train Loss: 0.0002, Validation Loss: 0.5364\n",
      "Epoch [232/50], Train Loss: 0.0008, Validation Loss: 0.5415\n",
      "Epoch [233/50], Train Loss: 0.0011, Validation Loss: 0.5711\n",
      "Epoch [234/50], Train Loss: 0.0007, Validation Loss: 0.5394\n",
      "Epoch [235/50], Train Loss: 0.0047, Validation Loss: 0.6637\n",
      "Epoch [236/50], Train Loss: 0.0132, Validation Loss: 0.7062\n",
      "Epoch [237/50], Train Loss: 0.0012, Validation Loss: 0.6001\n",
      "Epoch [238/50], Train Loss: 0.0617, Validation Loss: 1.1170\n",
      "Epoch [239/50], Train Loss: 0.0088, Validation Loss: 0.8234\n",
      "Epoch [240/50], Train Loss: 0.0259, Validation Loss: 0.9908\n",
      "Epoch [241/50], Train Loss: 0.0007, Validation Loss: 0.7028\n",
      "Epoch [242/50], Train Loss: 0.0403, Validation Loss: 1.0215\n",
      "Epoch [243/50], Train Loss: 0.0055, Validation Loss: 0.7387\n",
      "Epoch [244/50], Train Loss: 0.0562, Validation Loss: 0.8653\n",
      "Epoch [245/50], Train Loss: 0.0865, Validation Loss: 2.8803\n",
      "Epoch [246/50], Train Loss: 0.0261, Validation Loss: 1.9189\n",
      "Epoch [247/50], Train Loss: 0.0062, Validation Loss: 0.9637\n",
      "Epoch [248/50], Train Loss: 0.1400, Validation Loss: 0.7021\n",
      "Epoch [249/50], Train Loss: 0.0146, Validation Loss: 0.7023\n",
      "Epoch [250/50], Train Loss: 0.0043, Validation Loss: 0.7150\n",
      "Epoch [251/50], Train Loss: 0.0006, Validation Loss: 0.6458\n",
      "Epoch [252/50], Train Loss: 0.0326, Validation Loss: 0.7304\n",
      "Epoch [253/50], Train Loss: 0.0023, Validation Loss: 0.6687\n",
      "Epoch [254/50], Train Loss: 0.0072, Validation Loss: 0.7646\n",
      "Epoch [255/50], Train Loss: 0.0016, Validation Loss: 0.7532\n",
      "Epoch [256/50], Train Loss: 0.0007, Validation Loss: 0.7064\n",
      "Epoch [257/50], Train Loss: 0.0163, Validation Loss: 0.4729\n",
      "Epoch [258/50], Train Loss: 0.0017, Validation Loss: 0.4585\n",
      "Epoch [259/50], Train Loss: 0.0014, Validation Loss: 0.5015\n",
      "Epoch [260/50], Train Loss: 0.0016, Validation Loss: 0.5148\n",
      "Epoch [261/50], Train Loss: 0.0010, Validation Loss: 0.4689\n",
      "Epoch [262/50], Train Loss: 0.0003, Validation Loss: 0.4655\n",
      "Epoch [263/50], Train Loss: 0.0004, Validation Loss: 0.5133\n",
      "Epoch [264/50], Train Loss: 0.0005, Validation Loss: 0.5212\n",
      "Epoch [265/50], Train Loss: 0.0009, Validation Loss: 0.5315\n",
      "Epoch [266/50], Train Loss: 0.0003, Validation Loss: 0.5241\n",
      "Epoch [267/50], Train Loss: 0.0004, Validation Loss: 0.5042\n",
      "Epoch [268/50], Train Loss: 0.0015, Validation Loss: 0.4855\n",
      "Epoch [269/50], Train Loss: 0.0009, Validation Loss: 0.4567\n",
      "Epoch [270/50], Train Loss: 0.0015, Validation Loss: 0.4861\n",
      "Epoch [271/50], Train Loss: 0.0010, Validation Loss: 0.4652\n",
      "Epoch [272/50], Train Loss: 0.0005, Validation Loss: 0.4546\n",
      "Epoch [273/50], Train Loss: 0.0005, Validation Loss: 0.4550\n",
      "Epoch [274/50], Train Loss: 0.0092, Validation Loss: 1.4041\n",
      "Epoch [275/50], Train Loss: 0.0014, Validation Loss: 1.2894\n",
      "Epoch [276/50], Train Loss: 0.0017, Validation Loss: 0.7154\n",
      "Epoch [277/50], Train Loss: 0.0004, Validation Loss: 0.6061\n",
      "Epoch [278/50], Train Loss: 0.0008, Validation Loss: 0.4931\n",
      "Epoch [279/50], Train Loss: 0.0168, Validation Loss: 0.5648\n",
      "Epoch [280/50], Train Loss: 0.0912, Validation Loss: 0.8871\n",
      "Epoch [281/50], Train Loss: 0.0266, Validation Loss: 0.5313\n",
      "Epoch [282/50], Train Loss: 0.0079, Validation Loss: 0.8210\n",
      "Epoch [283/50], Train Loss: 0.0219, Validation Loss: 0.6851\n",
      "Epoch [284/50], Train Loss: 0.0018, Validation Loss: 0.6601\n",
      "Epoch [285/50], Train Loss: 0.0006, Validation Loss: 0.5951\n",
      "Epoch [286/50], Train Loss: 0.0003, Validation Loss: 0.5426\n",
      "Epoch [287/50], Train Loss: 0.0009, Validation Loss: 0.5469\n",
      "Epoch [288/50], Train Loss: 0.0005, Validation Loss: 0.5264\n",
      "Epoch [289/50], Train Loss: 0.0006, Validation Loss: 0.5004\n",
      "Epoch [290/50], Train Loss: 0.0023, Validation Loss: 0.4567\n",
      "Epoch [291/50], Train Loss: 0.0005, Validation Loss: 0.4564\n",
      "Epoch [292/50], Train Loss: 0.0013, Validation Loss: 0.4080\n",
      "Epoch [293/50], Train Loss: 0.0008, Validation Loss: 0.4057\n",
      "Epoch [294/50], Train Loss: 0.0009, Validation Loss: 0.3786\n",
      "Epoch [295/50], Train Loss: 0.0012, Validation Loss: 0.3769\n",
      "Epoch [296/50], Train Loss: 0.0005, Validation Loss: 0.3858\n",
      "Epoch [297/50], Train Loss: 0.0003, Validation Loss: 0.3885\n",
      "Epoch [298/50], Train Loss: 0.0003, Validation Loss: 0.3995\n",
      "Epoch [299/50], Train Loss: 0.0101, Validation Loss: 0.6557\n",
      "Epoch [300/50], Train Loss: 0.0015, Validation Loss: 0.5015\n",
      "Epoch [301/50], Train Loss: 0.0004, Validation Loss: 0.4608\n",
      "Epoch [302/50], Train Loss: 0.0001, Validation Loss: 0.4371\n",
      "Epoch [303/50], Train Loss: 0.0001, Validation Loss: 0.4272\n",
      "Epoch [304/50], Train Loss: 0.0003, Validation Loss: 0.4242\n",
      "Epoch [305/50], Train Loss: 0.0004, Validation Loss: 0.4252\n",
      "Epoch [306/50], Train Loss: 0.0028, Validation Loss: 0.5451\n",
      "Epoch [307/50], Train Loss: 0.0006, Validation Loss: 0.4832\n",
      "Epoch [308/50], Train Loss: 0.0078, Validation Loss: 1.4991\n",
      "Epoch [309/50], Train Loss: 0.0205, Validation Loss: 0.5718\n",
      "Epoch [310/50], Train Loss: 0.0004, Validation Loss: 0.5346\n",
      "Epoch [311/50], Train Loss: 0.0045, Validation Loss: 0.7027\n",
      "Epoch [312/50], Train Loss: 0.0009, Validation Loss: 0.6587\n",
      "Epoch [313/50], Train Loss: 0.0013, Validation Loss: 0.6109\n",
      "Epoch [314/50], Train Loss: 0.0019, Validation Loss: 0.7248\n",
      "Epoch [315/50], Train Loss: 0.0005, Validation Loss: 0.6741\n",
      "Epoch [316/50], Train Loss: 0.0009, Validation Loss: 0.6026\n",
      "Epoch [317/50], Train Loss: 0.0263, Validation Loss: 1.1969\n",
      "Epoch [318/50], Train Loss: 0.0038, Validation Loss: 0.8333\n",
      "Epoch [319/50], Train Loss: 0.0008, Validation Loss: 0.7350\n",
      "Epoch [320/50], Train Loss: 0.0063, Validation Loss: 0.8659\n",
      "Epoch [321/50], Train Loss: 0.0014, Validation Loss: 0.7698\n",
      "Epoch [322/50], Train Loss: 0.0001, Validation Loss: 0.6698\n",
      "Epoch [323/50], Train Loss: 0.0004, Validation Loss: 0.6336\n",
      "Epoch [324/50], Train Loss: 0.0009, Validation Loss: 0.6169\n",
      "Epoch [325/50], Train Loss: 0.0058, Validation Loss: 0.6737\n",
      "Epoch [326/50], Train Loss: 0.0003, Validation Loss: 0.5931\n",
      "Epoch [327/50], Train Loss: 0.0007, Validation Loss: 0.5150\n",
      "Epoch [328/50], Train Loss: 0.0003, Validation Loss: 0.4991\n",
      "Epoch [329/50], Train Loss: 0.0017, Validation Loss: 0.4811\n",
      "Epoch [330/50], Train Loss: 0.6082, Validation Loss: 1.0094\n",
      "Epoch [331/50], Train Loss: 0.0254, Validation Loss: 0.7476\n",
      "Epoch [332/50], Train Loss: 0.1988, Validation Loss: 1.5745\n",
      "Epoch [333/50], Train Loss: 0.0375, Validation Loss: 0.5767\n",
      "Epoch [334/50], Train Loss: 0.0148, Validation Loss: 0.3625\n",
      "Epoch [335/50], Train Loss: 0.0030, Validation Loss: 0.3129\n",
      "Epoch [336/50], Train Loss: 0.0087, Validation Loss: 0.3800\n",
      "Epoch [337/50], Train Loss: 0.0053, Validation Loss: 0.2921\n",
      "Epoch [338/50], Train Loss: 0.0022, Validation Loss: 0.3029\n",
      "Epoch [339/50], Train Loss: 0.0039, Validation Loss: 0.2921\n",
      "Epoch [340/50], Train Loss: 0.0018, Validation Loss: 0.2964\n",
      "Epoch [341/50], Train Loss: 0.0024, Validation Loss: 0.3019\n",
      "Epoch [342/50], Train Loss: 0.0020, Validation Loss: 0.3186\n",
      "Epoch [343/50], Train Loss: 0.0015, Validation Loss: 0.3189\n",
      "Epoch [344/50], Train Loss: 0.0025, Validation Loss: 0.3501\n",
      "Epoch [345/50], Train Loss: 0.0012, Validation Loss: 0.3625\n",
      "Epoch [346/50], Train Loss: 0.0008, Validation Loss: 0.3555\n",
      "Epoch [347/50], Train Loss: 0.0014, Validation Loss: 0.3388\n",
      "Epoch [348/50], Train Loss: 0.0019, Validation Loss: 0.3103\n",
      "Epoch [349/50], Train Loss: 0.0007, Validation Loss: 0.3111\n",
      "Epoch [350/50], Train Loss: 0.0007, Validation Loss: 0.3115\n",
      "Epoch [351/50], Train Loss: 0.0011, Validation Loss: 0.3182\n",
      "Epoch [352/50], Train Loss: 0.0005, Validation Loss: 0.3200\n",
      "Epoch [353/50], Train Loss: 0.0008, Validation Loss: 0.3212\n",
      "Epoch [354/50], Train Loss: 0.0005, Validation Loss: 0.3220\n",
      "Epoch [355/50], Train Loss: 0.0008, Validation Loss: 0.3324\n",
      "Epoch [356/50], Train Loss: 0.0010, Validation Loss: 0.3351\n",
      "Epoch [357/50], Train Loss: 0.0005, Validation Loss: 0.3438\n",
      "Epoch [358/50], Train Loss: 0.0015, Validation Loss: 0.3910\n",
      "Epoch [359/50], Train Loss: 0.0002, Validation Loss: 0.3844\n",
      "Epoch [360/50], Train Loss: 0.0008, Validation Loss: 0.3824\n",
      "Epoch [361/50], Train Loss: 0.0002, Validation Loss: 0.3788\n",
      "Epoch [362/50], Train Loss: 0.0003, Validation Loss: 0.3737\n",
      "Epoch [363/50], Train Loss: 0.0018, Validation Loss: 0.3694\n",
      "Epoch [364/50], Train Loss: 0.0013, Validation Loss: 0.3564\n",
      "Epoch [365/50], Train Loss: 0.0007, Validation Loss: 0.3506\n",
      "Epoch [366/50], Train Loss: 0.0002, Validation Loss: 0.3536\n",
      "Epoch [367/50], Train Loss: 0.0007, Validation Loss: 0.3547\n",
      "Epoch [368/50], Train Loss: 0.0002, Validation Loss: 0.3598\n",
      "Epoch [369/50], Train Loss: 0.0004, Validation Loss: 0.3668\n",
      "Epoch [370/50], Train Loss: 0.0350, Validation Loss: 0.5998\n",
      "Epoch [371/50], Train Loss: 0.0093, Validation Loss: 0.4704\n",
      "Epoch [372/50], Train Loss: 0.0012, Validation Loss: 0.4190\n",
      "Epoch [373/50], Train Loss: 0.0037, Validation Loss: 0.4693\n",
      "Epoch [374/50], Train Loss: 0.0021, Validation Loss: 0.4450\n",
      "Epoch [375/50], Train Loss: 0.0020, Validation Loss: 0.4468\n",
      "Epoch [376/50], Train Loss: 0.0004, Validation Loss: 0.4417\n",
      "Epoch [377/50], Train Loss: 0.0009, Validation Loss: 0.4557\n",
      "Epoch [378/50], Train Loss: 0.0004, Validation Loss: 0.4478\n",
      "Epoch [379/50], Train Loss: 0.0003, Validation Loss: 0.4403\n",
      "Epoch [380/50], Train Loss: 0.0016, Validation Loss: 0.4583\n",
      "Epoch [381/50], Train Loss: 0.0003, Validation Loss: 0.4532\n",
      "Epoch [382/50], Train Loss: 0.0017, Validation Loss: 0.3974\n",
      "Epoch [383/50], Train Loss: 0.0036, Validation Loss: 0.4335\n",
      "Epoch [384/50], Train Loss: 0.0004, Validation Loss: 0.4161\n",
      "Epoch [385/50], Train Loss: 0.0005, Validation Loss: 0.3966\n",
      "Epoch [386/50], Train Loss: 0.0002, Validation Loss: 0.3939\n",
      "Epoch [387/50], Train Loss: 0.0005, Validation Loss: 0.3932\n",
      "Epoch [388/50], Train Loss: 0.0002, Validation Loss: 0.3929\n",
      "Epoch [389/50], Train Loss: 0.0014, Validation Loss: 0.5865\n",
      "Epoch [390/50], Train Loss: 0.0001, Validation Loss: 0.5656\n",
      "Epoch [391/50], Train Loss: 0.0009, Validation Loss: 0.5010\n",
      "Epoch [392/50], Train Loss: 0.0003, Validation Loss: 0.5023\n",
      "Epoch [393/50], Train Loss: 0.0002, Validation Loss: 0.5010\n",
      "Epoch [394/50], Train Loss: 0.0005, Validation Loss: 0.4948\n",
      "Epoch [395/50], Train Loss: 0.0001, Validation Loss: 0.4913\n",
      "Epoch [396/50], Train Loss: 0.0020, Validation Loss: 0.5212\n",
      "Epoch [397/50], Train Loss: 0.0001, Validation Loss: 0.5031\n",
      "Epoch [398/50], Train Loss: 0.0003, Validation Loss: 0.4919\n",
      "Epoch [399/50], Train Loss: 0.0006, Validation Loss: 0.4510\n",
      "Epoch [400/50], Train Loss: 0.0005, Validation Loss: 0.4598\n",
      "Epoch [401/50], Train Loss: 0.0003, Validation Loss: 0.4477\n",
      "Epoch [402/50], Train Loss: 0.0002, Validation Loss: 0.4446\n",
      "Epoch [403/50], Train Loss: 0.0009, Validation Loss: 0.4444\n",
      "Epoch [404/50], Train Loss: 0.0008, Validation Loss: 0.4943\n",
      "Epoch [405/50], Train Loss: 0.0006, Validation Loss: 0.4914\n",
      "Epoch [406/50], Train Loss: 0.0001, Validation Loss: 0.4747\n",
      "Epoch [407/50], Train Loss: 0.0002, Validation Loss: 0.4643\n",
      "Epoch [408/50], Train Loss: 0.0003, Validation Loss: 0.4768\n",
      "Epoch [409/50], Train Loss: 0.0002, Validation Loss: 0.4672\n",
      "Epoch [410/50], Train Loss: 0.0001, Validation Loss: 0.4570\n",
      "Epoch [411/50], Train Loss: 0.0001, Validation Loss: 0.4503\n",
      "Epoch [412/50], Train Loss: 0.0001, Validation Loss: 0.4443\n",
      "Epoch [413/50], Train Loss: 0.0002, Validation Loss: 0.4399\n",
      "Epoch [414/50], Train Loss: 0.0009, Validation Loss: 0.4351\n",
      "Epoch [415/50], Train Loss: 0.0000, Validation Loss: 0.4323\n",
      "Epoch [416/50], Train Loss: 0.0002, Validation Loss: 0.4290\n",
      "Epoch [417/50], Train Loss: 0.0001, Validation Loss: 0.4271\n",
      "Epoch [418/50], Train Loss: 0.0002, Validation Loss: 0.4300\n",
      "Epoch [419/50], Train Loss: 0.0002, Validation Loss: 0.4200\n",
      "Epoch [420/50], Train Loss: 0.0002, Validation Loss: 0.4127\n",
      "Epoch [421/50], Train Loss: 0.0001, Validation Loss: 0.4145\n",
      "Epoch [422/50], Train Loss: 0.0003, Validation Loss: 0.4005\n",
      "Epoch [423/50], Train Loss: 0.0004, Validation Loss: 0.4245\n",
      "Epoch [424/50], Train Loss: 0.0012, Validation Loss: 0.4675\n",
      "Epoch [425/50], Train Loss: 0.0001, Validation Loss: 0.4600\n",
      "Epoch [426/50], Train Loss: 0.0007, Validation Loss: 0.4326\n",
      "Epoch [427/50], Train Loss: 0.0001, Validation Loss: 0.4291\n",
      "Epoch [428/50], Train Loss: 0.0002, Validation Loss: 0.4312\n",
      "Epoch [429/50], Train Loss: 0.0000, Validation Loss: 0.4296\n",
      "Epoch [430/50], Train Loss: 0.0001, Validation Loss: 0.4292\n",
      "Epoch [431/50], Train Loss: 0.0000, Validation Loss: 0.4276\n",
      "Epoch [432/50], Train Loss: 0.0001, Validation Loss: 0.4276\n",
      "Epoch [433/50], Train Loss: 0.0003, Validation Loss: 0.4247\n",
      "Epoch [434/50], Train Loss: 0.0001, Validation Loss: 0.4253\n",
      "Epoch [435/50], Train Loss: 0.0001, Validation Loss: 0.4255\n",
      "Epoch [436/50], Train Loss: 0.0004, Validation Loss: 0.4341\n",
      "Epoch [437/50], Train Loss: 0.0002, Validation Loss: 0.4372\n",
      "Epoch [438/50], Train Loss: 0.0002, Validation Loss: 0.4360\n",
      "Epoch [439/50], Train Loss: 0.0000, Validation Loss: 0.4353\n",
      "Epoch [440/50], Train Loss: 0.0001, Validation Loss: 0.4346\n",
      "Epoch [441/50], Train Loss: 0.0001, Validation Loss: 0.4341\n",
      "Epoch [442/50], Train Loss: 0.0002, Validation Loss: 0.4330\n",
      "Epoch [443/50], Train Loss: 0.0000, Validation Loss: 0.4334\n",
      "Epoch [444/50], Train Loss: 0.0002, Validation Loss: 0.4373\n",
      "Epoch [445/50], Train Loss: 0.0006, Validation Loss: 0.4381\n",
      "Epoch [446/50], Train Loss: 0.0001, Validation Loss: 0.4334\n",
      "Epoch [447/50], Train Loss: 0.0000, Validation Loss: 0.4309\n",
      "Epoch [448/50], Train Loss: 0.0001, Validation Loss: 0.4262\n",
      "Epoch [449/50], Train Loss: 0.0006, Validation Loss: 0.4108\n",
      "Epoch [450/50], Train Loss: 0.0001, Validation Loss: 0.4128\n",
      "Epoch [451/50], Train Loss: 0.0001, Validation Loss: 0.4126\n",
      "Epoch [452/50], Train Loss: 0.0039, Validation Loss: 0.6424\n",
      "Epoch [453/50], Train Loss: 0.0078, Validation Loss: 0.5081\n",
      "Epoch [454/50], Train Loss: 0.0004, Validation Loss: 0.4204\n",
      "Epoch [455/50], Train Loss: 0.0002, Validation Loss: 0.3898\n",
      "Epoch [456/50], Train Loss: 0.0002, Validation Loss: 0.3849\n",
      "Epoch [457/50], Train Loss: 0.0001, Validation Loss: 0.3840\n",
      "Epoch [458/50], Train Loss: 0.0001, Validation Loss: 0.3861\n",
      "Epoch [459/50], Train Loss: 0.0005, Validation Loss: 0.3952\n",
      "Epoch [460/50], Train Loss: 0.0002, Validation Loss: 0.3978\n",
      "Epoch [461/50], Train Loss: 0.0001, Validation Loss: 0.3994\n",
      "Epoch [462/50], Train Loss: 0.0002, Validation Loss: 0.4018\n",
      "Epoch [463/50], Train Loss: 0.0001, Validation Loss: 0.4050\n",
      "Epoch [464/50], Train Loss: 0.0000, Validation Loss: 0.4052\n",
      "Epoch [465/50], Train Loss: 0.0002, Validation Loss: 0.4073\n",
      "Epoch [466/50], Train Loss: 0.0012, Validation Loss: 0.3769\n",
      "Epoch [467/50], Train Loss: 0.0002, Validation Loss: 0.3845\n",
      "Epoch [468/50], Train Loss: 0.0026, Validation Loss: 0.4603\n",
      "Epoch [469/50], Train Loss: 0.0001, Validation Loss: 0.4336\n",
      "Epoch [470/50], Train Loss: 0.0011, Validation Loss: 0.4984\n",
      "Epoch [471/50], Train Loss: 0.0002, Validation Loss: 0.4792\n",
      "Epoch [472/50], Train Loss: 0.0005, Validation Loss: 0.4622\n",
      "Epoch [473/50], Train Loss: 0.0001, Validation Loss: 0.4550\n",
      "Epoch [474/50], Train Loss: 0.0018, Validation Loss: 0.4551\n",
      "Epoch [475/50], Train Loss: 0.0001, Validation Loss: 0.4513\n",
      "Epoch [476/50], Train Loss: 0.0001, Validation Loss: 0.4461\n",
      "Epoch [477/50], Train Loss: 0.0002, Validation Loss: 0.4362\n",
      "Epoch [478/50], Train Loss: 0.0001, Validation Loss: 0.4348\n",
      "Epoch [479/50], Train Loss: 0.0007, Validation Loss: 0.4644\n",
      "Epoch [480/50], Train Loss: 0.0002, Validation Loss: 0.4590\n",
      "Epoch [481/50], Train Loss: 0.0002, Validation Loss: 0.4609\n",
      "Epoch [482/50], Train Loss: 0.0001, Validation Loss: 0.4613\n",
      "Epoch [483/50], Train Loss: 0.0001, Validation Loss: 0.4594\n",
      "Epoch [484/50], Train Loss: 0.0002, Validation Loss: 0.4421\n",
      "Epoch [485/50], Train Loss: 0.0001, Validation Loss: 0.4417\n",
      "Epoch [486/50], Train Loss: 0.0002, Validation Loss: 0.4429\n",
      "Epoch [487/50], Train Loss: 0.0001, Validation Loss: 0.4438\n",
      "Epoch [488/50], Train Loss: 0.0000, Validation Loss: 0.4465\n",
      "Epoch [489/50], Train Loss: 0.0005, Validation Loss: 0.4804\n",
      "Epoch [490/50], Train Loss: 0.0003, Validation Loss: 0.4702\n",
      "Epoch [491/50], Train Loss: 0.0001, Validation Loss: 0.4684\n",
      "Epoch [492/50], Train Loss: 0.0001, Validation Loss: 0.4663\n",
      "Epoch [493/50], Train Loss: 0.0001, Validation Loss: 0.4679\n",
      "Epoch [494/50], Train Loss: 0.0001, Validation Loss: 0.4670\n",
      "Epoch [495/50], Train Loss: 0.0000, Validation Loss: 0.4650\n",
      "Epoch [496/50], Train Loss: 0.0000, Validation Loss: 0.4641\n",
      "Epoch [497/50], Train Loss: 0.0002, Validation Loss: 0.4732\n",
      "Epoch [498/50], Train Loss: 0.0000, Validation Loss: 0.4733\n",
      "Epoch [499/50], Train Loss: 0.0001, Validation Loss: 0.4692\n",
      "Epoch [500/50], Train Loss: 0.0004, Validation Loss: 0.4837\n",
      "Epoch [501/50], Train Loss: 0.0001, Validation Loss: 0.4788\n",
      "Epoch [502/50], Train Loss: 0.0002, Validation Loss: 0.4745\n",
      "Epoch [503/50], Train Loss: 0.0000, Validation Loss: 0.4716\n",
      "Epoch [504/50], Train Loss: 0.0001, Validation Loss: 0.4723\n",
      "Epoch [505/50], Train Loss: 0.0001, Validation Loss: 0.4711\n",
      "Epoch [506/50], Train Loss: 0.0001, Validation Loss: 0.4694\n",
      "Epoch [507/50], Train Loss: 0.0001, Validation Loss: 0.4680\n",
      "Epoch [508/50], Train Loss: 0.0025, Validation Loss: 0.4341\n",
      "Epoch [509/50], Train Loss: 0.0002, Validation Loss: 0.4218\n",
      "Epoch [510/50], Train Loss: 0.0001, Validation Loss: 0.4169\n",
      "Epoch [511/50], Train Loss: 0.0034, Validation Loss: 0.6190\n",
      "Epoch [512/50], Train Loss: 0.3562, Validation Loss: 4.1640\n",
      "Epoch [513/50], Train Loss: 0.0514, Validation Loss: 3.5325\n",
      "Epoch [514/50], Train Loss: 0.0275, Validation Loss: 3.4945\n",
      "Epoch [515/50], Train Loss: 0.0048, Validation Loss: 2.4277\n",
      "Epoch [516/50], Train Loss: 0.0080, Validation Loss: 0.6729\n",
      "Epoch [517/50], Train Loss: 0.0026, Validation Loss: 0.9514\n",
      "Epoch [518/50], Train Loss: 0.0014, Validation Loss: 0.4906\n",
      "Epoch [519/50], Train Loss: 0.0013, Validation Loss: 0.3211\n",
      "Epoch [520/50], Train Loss: 0.0143, Validation Loss: 0.4461\n",
      "Epoch [521/50], Train Loss: 0.0019, Validation Loss: 0.3733\n",
      "Epoch [522/50], Train Loss: 0.0015, Validation Loss: 0.3274\n",
      "Epoch [523/50], Train Loss: 0.0391, Validation Loss: 0.6577\n",
      "Epoch [524/50], Train Loss: 0.0032, Validation Loss: 0.4636\n",
      "Epoch [525/50], Train Loss: 0.0027, Validation Loss: 0.3668\n",
      "Epoch [526/50], Train Loss: 0.0009, Validation Loss: 0.3370\n",
      "Epoch [527/50], Train Loss: 0.0040, Validation Loss: 0.3005\n",
      "Epoch [528/50], Train Loss: 0.0026, Validation Loss: 0.3029\n",
      "Epoch [529/50], Train Loss: 0.0061, Validation Loss: 0.5271\n",
      "Epoch [530/50], Train Loss: 0.0026, Validation Loss: 0.3651\n",
      "Epoch [531/50], Train Loss: 0.0060, Validation Loss: 0.3868\n",
      "Epoch [532/50], Train Loss: 0.0630, Validation Loss: 2.0790\n",
      "Epoch [533/50], Train Loss: 0.0055, Validation Loss: 1.1527\n",
      "Epoch [534/50], Train Loss: 0.0020, Validation Loss: 0.4503\n",
      "Epoch [535/50], Train Loss: 0.0254, Validation Loss: 0.9075\n",
      "Epoch [536/50], Train Loss: 0.0024, Validation Loss: 0.5468\n",
      "Epoch [537/50], Train Loss: 0.0031, Validation Loss: 0.5106\n",
      "Epoch [538/50], Train Loss: 0.0080, Validation Loss: 0.5136\n",
      "Epoch [539/50], Train Loss: 0.0016, Validation Loss: 0.4197\n",
      "Epoch [540/50], Train Loss: 0.0006, Validation Loss: 0.4130\n",
      "Epoch [541/50], Train Loss: 0.0003, Validation Loss: 0.4078\n",
      "Epoch [542/50], Train Loss: 0.0009, Validation Loss: 0.4020\n",
      "Epoch [543/50], Train Loss: 0.0004, Validation Loss: 0.3850\n",
      "Epoch [544/50], Train Loss: 0.0006, Validation Loss: 0.3820\n",
      "Epoch [545/50], Train Loss: 0.0014, Validation Loss: 0.3846\n",
      "Epoch [546/50], Train Loss: 0.0004, Validation Loss: 0.3759\n",
      "Epoch [547/50], Train Loss: 0.0027, Validation Loss: 0.5132\n",
      "Epoch [548/50], Train Loss: 0.0019, Validation Loss: 0.3751\n",
      "Epoch [549/50], Train Loss: 0.0005, Validation Loss: 0.3650\n",
      "Epoch [550/50], Train Loss: 0.0012, Validation Loss: 0.3017\n",
      "Epoch [551/50], Train Loss: 0.0004, Validation Loss: 0.3034\n",
      "Epoch [552/50], Train Loss: 0.0012, Validation Loss: 0.2704\n",
      "Epoch [553/50], Train Loss: 0.0009, Validation Loss: 0.2811\n",
      "Epoch [554/50], Train Loss: 0.0019, Validation Loss: 0.2900\n",
      "Epoch [555/50], Train Loss: 0.0006, Validation Loss: 0.2840\n",
      "Epoch [556/50], Train Loss: 0.0008, Validation Loss: 0.3044\n",
      "Epoch [557/50], Train Loss: 0.0002, Validation Loss: 0.2983\n",
      "Epoch [558/50], Train Loss: 0.0002, Validation Loss: 0.2955\n",
      "Epoch [559/50], Train Loss: 0.0006, Validation Loss: 0.2988\n",
      "Epoch [560/50], Train Loss: 0.0001, Validation Loss: 0.3002\n",
      "Epoch [561/50], Train Loss: 0.0002, Validation Loss: 0.3024\n",
      "Epoch [562/50], Train Loss: 0.0001, Validation Loss: 0.2997\n",
      "Epoch [563/50], Train Loss: 0.0004, Validation Loss: 0.2968\n",
      "Epoch [564/50], Train Loss: 0.0002, Validation Loss: 0.3012\n",
      "Epoch [565/50], Train Loss: 0.0002, Validation Loss: 0.3003\n",
      "Epoch [566/50], Train Loss: 0.0003, Validation Loss: 0.2956\n",
      "Epoch [567/50], Train Loss: 0.0052, Validation Loss: 0.8856\n",
      "Epoch [568/50], Train Loss: 0.0003, Validation Loss: 0.6823\n",
      "Epoch [569/50], Train Loss: 0.0021, Validation Loss: 0.3181\n",
      "Epoch [570/50], Train Loss: 0.0008, Validation Loss: 0.3012\n",
      "Epoch [571/50], Train Loss: 0.0002, Validation Loss: 0.2913\n",
      "Epoch [572/50], Train Loss: 0.0010, Validation Loss: 0.2782\n",
      "Epoch [573/50], Train Loss: 0.0005, Validation Loss: 0.3135\n",
      "Epoch [574/50], Train Loss: 0.0004, Validation Loss: 0.3194\n",
      "Epoch [575/50], Train Loss: 0.0004, Validation Loss: 0.3107\n",
      "Epoch [576/50], Train Loss: 0.0002, Validation Loss: 0.3073\n",
      "Epoch [577/50], Train Loss: 0.0015, Validation Loss: 0.3027\n",
      "Epoch [578/50], Train Loss: 0.0007, Validation Loss: 0.3136\n",
      "Epoch [579/50], Train Loss: 0.0003, Validation Loss: 0.3163\n",
      "Epoch [580/50], Train Loss: 0.0003, Validation Loss: 0.3221\n",
      "Epoch [581/50], Train Loss: 0.0001, Validation Loss: 0.3186\n",
      "Epoch [582/50], Train Loss: 0.0002, Validation Loss: 0.3105\n",
      "Epoch [583/50], Train Loss: 0.0007, Validation Loss: 0.3118\n",
      "Epoch [584/50], Train Loss: 0.0002, Validation Loss: 0.3043\n",
      "Epoch [585/50], Train Loss: 0.0046, Validation Loss: 0.2788\n",
      "Epoch [586/50], Train Loss: 0.0034, Validation Loss: 0.4345\n",
      "Epoch [587/50], Train Loss: 0.0011, Validation Loss: 0.4487\n",
      "Epoch [588/50], Train Loss: 0.0003, Validation Loss: 0.4260\n",
      "Epoch [589/50], Train Loss: 0.0003, Validation Loss: 0.3923\n",
      "Epoch [590/50], Train Loss: 0.0005, Validation Loss: 0.3181\n",
      "Epoch [591/50], Train Loss: 0.0005, Validation Loss: 0.2916\n",
      "Epoch [592/50], Train Loss: 0.0004, Validation Loss: 0.2880\n",
      "Epoch [593/50], Train Loss: 0.0001, Validation Loss: 0.2874\n",
      "Epoch [594/50], Train Loss: 0.0002, Validation Loss: 0.2862\n",
      "Epoch [595/50], Train Loss: 0.0015, Validation Loss: 0.4274\n",
      "Epoch [596/50], Train Loss: 0.0002, Validation Loss: 0.3905\n",
      "Epoch [597/50], Train Loss: 0.0043, Validation Loss: 1.5943\n",
      "Epoch [598/50], Train Loss: 0.0007, Validation Loss: 0.9065\n",
      "Epoch [599/50], Train Loss: 0.0007, Validation Loss: 0.4002\n",
      "Epoch [600/50], Train Loss: 0.0004, Validation Loss: 0.3430\n",
      "Epoch [601/50], Train Loss: 0.0004, Validation Loss: 0.2890\n",
      "Epoch [602/50], Train Loss: 0.0007, Validation Loss: 0.2704\n",
      "Epoch [603/50], Train Loss: 0.0002, Validation Loss: 0.2678\n",
      "Epoch [604/50], Train Loss: 0.0002, Validation Loss: 0.2679\n",
      "Epoch [605/50], Train Loss: 0.0002, Validation Loss: 0.2684\n",
      "Epoch [606/50], Train Loss: 0.0002, Validation Loss: 0.2672\n",
      "Epoch [607/50], Train Loss: 0.0001, Validation Loss: 0.2684\n",
      "Epoch [608/50], Train Loss: 0.0001, Validation Loss: 0.2698\n",
      "Epoch [609/50], Train Loss: 0.0005, Validation Loss: 0.2530\n",
      "Epoch [610/50], Train Loss: 0.9761, Validation Loss: 0.9113\n",
      "Epoch [611/50], Train Loss: 0.0914, Validation Loss: 0.3833\n",
      "Epoch [612/50], Train Loss: 0.0239, Validation Loss: 0.3503\n",
      "Epoch [613/50], Train Loss: 0.0139, Validation Loss: 0.3470\n",
      "Epoch [614/50], Train Loss: 0.0134, Validation Loss: 0.3335\n",
      "Epoch [615/50], Train Loss: 0.0054, Validation Loss: 0.2974\n",
      "Epoch [616/50], Train Loss: 0.0034, Validation Loss: 0.2998\n",
      "Epoch [617/50], Train Loss: 0.0026, Validation Loss: 0.3026\n",
      "Epoch [618/50], Train Loss: 0.0506, Validation Loss: 0.7274\n",
      "Epoch [619/50], Train Loss: 0.0158, Validation Loss: 0.5787\n",
      "Epoch [620/50], Train Loss: 0.0044, Validation Loss: 0.3272\n",
      "Epoch [621/50], Train Loss: 0.0028, Validation Loss: 0.2813\n",
      "Epoch [622/50], Train Loss: 0.0018, Validation Loss: 0.2425\n",
      "Epoch [623/50], Train Loss: 0.0042, Validation Loss: 0.2277\n",
      "Epoch [624/50], Train Loss: 0.0068, Validation Loss: 0.2371\n",
      "Epoch [625/50], Train Loss: 0.0028, Validation Loss: 0.2107\n",
      "Epoch [626/50], Train Loss: 0.0046, Validation Loss: 0.2440\n",
      "Epoch [627/50], Train Loss: 0.0029, Validation Loss: 0.2317\n",
      "Epoch [628/50], Train Loss: 0.0009, Validation Loss: 0.2332\n",
      "Epoch [629/50], Train Loss: 0.0007, Validation Loss: 0.2358\n",
      "Epoch [630/50], Train Loss: 0.0006, Validation Loss: 0.2400\n",
      "Epoch [631/50], Train Loss: 0.0023, Validation Loss: 0.2258\n",
      "Epoch [632/50], Train Loss: 0.0012, Validation Loss: 0.2232\n",
      "Epoch [633/50], Train Loss: 0.0013, Validation Loss: 0.2038\n",
      "Epoch [634/50], Train Loss: 0.0024, Validation Loss: 0.2241\n",
      "Epoch [635/50], Train Loss: 0.0023, Validation Loss: 0.1864\n",
      "Epoch [636/50], Train Loss: 0.0005, Validation Loss: 0.1883\n",
      "Epoch [637/50], Train Loss: 0.0006, Validation Loss: 0.1908\n",
      "Epoch [638/50], Train Loss: 0.0005, Validation Loss: 0.1941\n",
      "Epoch [639/50], Train Loss: 0.0006, Validation Loss: 0.1994\n",
      "Epoch [640/50], Train Loss: 0.0016, Validation Loss: 0.2321\n",
      "Epoch [641/50], Train Loss: 0.0003, Validation Loss: 0.2317\n",
      "Epoch [642/50], Train Loss: 0.0004, Validation Loss: 0.2334\n",
      "Epoch [643/50], Train Loss: 0.0006, Validation Loss: 0.2410\n",
      "Epoch [644/50], Train Loss: 0.0032, Validation Loss: 0.2479\n",
      "Epoch [645/50], Train Loss: 0.0033, Validation Loss: 0.3064\n",
      "Epoch [646/50], Train Loss: 0.0005, Validation Loss: 0.2970\n",
      "Epoch [647/50], Train Loss: 0.0020, Validation Loss: 0.2990\n",
      "Epoch [648/50], Train Loss: 0.0010, Validation Loss: 0.2897\n",
      "Epoch [649/50], Train Loss: 0.0062, Validation Loss: 0.3546\n",
      "Epoch [650/50], Train Loss: 0.0004, Validation Loss: 0.3228\n",
      "Epoch [651/50], Train Loss: 0.0006, Validation Loss: 0.3043\n",
      "Epoch [652/50], Train Loss: 0.0003, Validation Loss: 0.2924\n",
      "Epoch [653/50], Train Loss: 0.0003, Validation Loss: 0.2830\n",
      "Epoch [654/50], Train Loss: 0.0002, Validation Loss: 0.2726\n",
      "Epoch [655/50], Train Loss: 0.0003, Validation Loss: 0.2658\n",
      "Epoch [656/50], Train Loss: 0.0003, Validation Loss: 0.2599\n",
      "Epoch [657/50], Train Loss: 0.0002, Validation Loss: 0.2530\n",
      "Epoch [658/50], Train Loss: 0.0002, Validation Loss: 0.2516\n",
      "Epoch [659/50], Train Loss: 0.0132, Validation Loss: 0.6841\n",
      "Epoch [660/50], Train Loss: 0.0052, Validation Loss: 0.5503\n",
      "Epoch [661/50], Train Loss: 0.0010, Validation Loss: 0.4238\n",
      "Epoch [662/50], Train Loss: 0.0033, Validation Loss: 0.4156\n",
      "Epoch [663/50], Train Loss: 0.0009, Validation Loss: 0.3727\n",
      "Epoch [664/50], Train Loss: 0.0004, Validation Loss: 0.3556\n",
      "Epoch [665/50], Train Loss: 0.0007, Validation Loss: 0.3418\n",
      "Epoch [666/50], Train Loss: 0.0002, Validation Loss: 0.3259\n",
      "Epoch [667/50], Train Loss: 0.0006, Validation Loss: 0.3528\n",
      "Epoch [668/50], Train Loss: 0.0001, Validation Loss: 0.3417\n",
      "Epoch [669/50], Train Loss: 0.0003, Validation Loss: 0.3374\n",
      "Epoch [670/50], Train Loss: 0.0002, Validation Loss: 0.3284\n",
      "Epoch [671/50], Train Loss: 0.0003, Validation Loss: 0.3218\n",
      "Epoch [672/50], Train Loss: 0.0002, Validation Loss: 0.3225\n",
      "Epoch [673/50], Train Loss: 0.0002, Validation Loss: 0.3195\n",
      "Epoch [674/50], Train Loss: 0.0010, Validation Loss: 0.3384\n",
      "Epoch [675/50], Train Loss: 0.0003, Validation Loss: 0.3374\n",
      "Epoch [676/50], Train Loss: 0.0024, Validation Loss: 0.2998\n",
      "Epoch [677/50], Train Loss: 0.0005, Validation Loss: 0.2886\n",
      "Epoch [678/50], Train Loss: 0.0001, Validation Loss: 0.2910\n",
      "Epoch [679/50], Train Loss: 0.0003, Validation Loss: 0.2948\n",
      "Epoch [680/50], Train Loss: 0.0202, Validation Loss: 0.5060\n",
      "Epoch [681/50], Train Loss: 0.0012, Validation Loss: 0.3897\n",
      "Epoch [682/50], Train Loss: 0.0022, Validation Loss: 0.3685\n",
      "Epoch [683/50], Train Loss: 0.0003, Validation Loss: 0.3584\n",
      "Epoch [684/50], Train Loss: 0.0016, Validation Loss: 0.3270\n",
      "Epoch [685/50], Train Loss: 0.0005, Validation Loss: 0.3254\n",
      "Epoch [686/50], Train Loss: 0.0004, Validation Loss: 0.3445\n",
      "Epoch [687/50], Train Loss: 0.0022, Validation Loss: 0.3214\n",
      "Epoch [688/50], Train Loss: 0.0005, Validation Loss: 0.3245\n",
      "Epoch [689/50], Train Loss: 0.0008, Validation Loss: 0.3178\n",
      "Epoch [690/50], Train Loss: 0.0006, Validation Loss: 0.3318\n",
      "Epoch [691/50], Train Loss: 0.0004, Validation Loss: 0.3270\n",
      "Epoch [692/50], Train Loss: 0.0002, Validation Loss: 0.3191\n",
      "Epoch [693/50], Train Loss: 0.0002, Validation Loss: 0.3159\n",
      "Epoch [694/50], Train Loss: 0.0002, Validation Loss: 0.3128\n",
      "Epoch [695/50], Train Loss: 0.0011, Validation Loss: 0.3323\n",
      "Epoch [696/50], Train Loss: 0.0028, Validation Loss: 0.4684\n",
      "Epoch [697/50], Train Loss: 0.0001, Validation Loss: 0.4461\n",
      "Epoch [698/50], Train Loss: 0.0001, Validation Loss: 0.4341\n",
      "Epoch [699/50], Train Loss: 0.0001, Validation Loss: 0.4171\n",
      "Epoch [700/50], Train Loss: 0.0001, Validation Loss: 0.4076\n",
      "Epoch [701/50], Train Loss: 0.0004, Validation Loss: 0.3971\n",
      "Epoch [702/50], Train Loss: 0.0001, Validation Loss: 0.3888\n",
      "Epoch [703/50], Train Loss: 0.0004, Validation Loss: 0.3856\n",
      "Epoch [704/50], Train Loss: 0.0000, Validation Loss: 0.3810\n",
      "Epoch [705/50], Train Loss: 0.0006, Validation Loss: 0.3990\n",
      "Epoch [706/50], Train Loss: 0.0001, Validation Loss: 0.3948\n",
      "Epoch [707/50], Train Loss: 0.0005, Validation Loss: 0.3967\n",
      "Epoch [708/50], Train Loss: 0.0024, Validation Loss: 0.5465\n",
      "Epoch [709/50], Train Loss: 0.0010, Validation Loss: 0.5224\n",
      "Epoch [710/50], Train Loss: 0.0002, Validation Loss: 0.4926\n",
      "Epoch [711/50], Train Loss: 0.0002, Validation Loss: 0.4699\n",
      "Epoch [712/50], Train Loss: 0.0002, Validation Loss: 0.4512\n",
      "Epoch [713/50], Train Loss: 0.0003, Validation Loss: 0.4362\n",
      "Epoch [714/50], Train Loss: 0.0004, Validation Loss: 0.4290\n",
      "Epoch [715/50], Train Loss: 0.0001, Validation Loss: 0.4243\n",
      "Epoch [716/50], Train Loss: 0.0001, Validation Loss: 0.4175\n",
      "Epoch [717/50], Train Loss: 0.0005, Validation Loss: 0.4289\n",
      "Epoch [718/50], Train Loss: 0.0002, Validation Loss: 0.4248\n",
      "Epoch [719/50], Train Loss: 0.0001, Validation Loss: 0.4199\n",
      "Epoch [720/50], Train Loss: 0.0002, Validation Loss: 0.4155\n",
      "Epoch [721/50], Train Loss: 0.0002, Validation Loss: 0.4121\n",
      "Epoch [722/50], Train Loss: 0.0001, Validation Loss: 0.4090\n",
      "Epoch [723/50], Train Loss: 0.0001, Validation Loss: 0.4080\n",
      "Epoch [724/50], Train Loss: 0.0006, Validation Loss: 0.3804\n",
      "Epoch [725/50], Train Loss: 0.0003, Validation Loss: 0.3707\n",
      "Epoch [726/50], Train Loss: 0.0004, Validation Loss: 0.3624\n",
      "Epoch [727/50], Train Loss: 0.0000, Validation Loss: 0.3657\n",
      "Epoch [728/50], Train Loss: 0.0001, Validation Loss: 0.3685\n",
      "Epoch [729/50], Train Loss: 0.0001, Validation Loss: 0.3708\n",
      "Epoch [730/50], Train Loss: 0.0012, Validation Loss: 0.3713\n",
      "Epoch [731/50], Train Loss: 0.0001, Validation Loss: 0.3546\n",
      "Epoch [732/50], Train Loss: 0.0001, Validation Loss: 0.3535\n",
      "Epoch [733/50], Train Loss: 0.0006, Validation Loss: 0.3669\n",
      "Epoch [734/50], Train Loss: 0.0001, Validation Loss: 0.3707\n",
      "Epoch [735/50], Train Loss: 0.0001, Validation Loss: 0.3824\n",
      "Epoch [736/50], Train Loss: 0.0000, Validation Loss: 0.3839\n",
      "Epoch [737/50], Train Loss: 0.0001, Validation Loss: 0.3837\n",
      "Epoch [738/50], Train Loss: 0.0001, Validation Loss: 0.3845\n",
      "Epoch [739/50], Train Loss: 0.0001, Validation Loss: 0.3850\n",
      "Epoch [740/50], Train Loss: 0.0001, Validation Loss: 0.3873\n",
      "Epoch [741/50], Train Loss: 0.0002, Validation Loss: 0.3868\n",
      "Epoch [742/50], Train Loss: 0.0001, Validation Loss: 0.3851\n",
      "Epoch [743/50], Train Loss: 0.0001, Validation Loss: 0.3869\n",
      "Epoch [744/50], Train Loss: 0.0003, Validation Loss: 0.3892\n",
      "Epoch [745/50], Train Loss: 0.0000, Validation Loss: 0.3883\n",
      "Epoch [746/50], Train Loss: 0.0001, Validation Loss: 0.3889\n",
      "Epoch [747/50], Train Loss: 0.0000, Validation Loss: 0.3896\n",
      "Epoch [748/50], Train Loss: 0.0001, Validation Loss: 0.3891\n",
      "Epoch [749/50], Train Loss: 0.0001, Validation Loss: 0.3859\n",
      "Epoch [750/50], Train Loss: 0.0001, Validation Loss: 0.3844\n",
      "Epoch [751/50], Train Loss: 0.0001, Validation Loss: 0.3845\n",
      "Epoch [752/50], Train Loss: 0.0000, Validation Loss: 0.3859\n",
      "Epoch [753/50], Train Loss: 0.0001, Validation Loss: 0.3868\n",
      "Epoch [754/50], Train Loss: 0.0001, Validation Loss: 0.3857\n",
      "Epoch [755/50], Train Loss: 0.0000, Validation Loss: 0.3858\n",
      "Epoch [756/50], Train Loss: 0.0001, Validation Loss: 0.3863\n",
      "Epoch [757/50], Train Loss: 0.0000, Validation Loss: 0.3850\n",
      "Epoch [758/50], Train Loss: 0.0000, Validation Loss: 0.3841\n",
      "Epoch [759/50], Train Loss: 0.0001, Validation Loss: 0.3874\n",
      "Epoch [760/50], Train Loss: 0.0000, Validation Loss: 0.3865\n",
      "Epoch [761/50], Train Loss: 0.0001, Validation Loss: 0.3875\n",
      "Epoch [762/50], Train Loss: 0.0001, Validation Loss: 0.3893\n",
      "Epoch [763/50], Train Loss: 0.0001, Validation Loss: 0.3894\n",
      "Epoch [764/50], Train Loss: 0.0000, Validation Loss: 0.3878\n",
      "Epoch [765/50], Train Loss: 0.0000, Validation Loss: 0.3904\n",
      "Epoch [766/50], Train Loss: 0.0000, Validation Loss: 0.3898\n",
      "Epoch [767/50], Train Loss: 0.0000, Validation Loss: 0.3901\n",
      "Epoch [768/50], Train Loss: 0.0001, Validation Loss: 0.3927\n",
      "Epoch [769/50], Train Loss: 0.0000, Validation Loss: 0.3933\n",
      "Epoch [770/50], Train Loss: 0.0000, Validation Loss: 0.3941\n",
      "Epoch [771/50], Train Loss: 0.0001, Validation Loss: 0.3918\n",
      "Epoch [772/50], Train Loss: 0.0000, Validation Loss: 0.3913\n",
      "Epoch [773/50], Train Loss: 0.0001, Validation Loss: 0.3943\n",
      "Epoch [774/50], Train Loss: 0.0001, Validation Loss: 0.3938\n",
      "Epoch [775/50], Train Loss: 0.0001, Validation Loss: 0.3936\n",
      "Epoch [776/50], Train Loss: 0.0188, Validation Loss: 1.2431\n",
      "Epoch [777/50], Train Loss: 0.0023, Validation Loss: 0.8431\n",
      "Epoch [778/50], Train Loss: 0.0017, Validation Loss: 0.7488\n",
      "Epoch [779/50], Train Loss: 0.0004, Validation Loss: 0.7413\n",
      "Epoch [780/50], Train Loss: 0.0004, Validation Loss: 0.7008\n",
      "Epoch [781/50], Train Loss: 0.0001, Validation Loss: 0.6594\n",
      "Epoch [782/50], Train Loss: 0.0002, Validation Loss: 0.6269\n",
      "Epoch [783/50], Train Loss: 0.0004, Validation Loss: 0.5743\n",
      "Epoch [784/50], Train Loss: 0.0001, Validation Loss: 0.5597\n",
      "Epoch [785/50], Train Loss: 0.0003, Validation Loss: 0.5372\n",
      "Epoch [786/50], Train Loss: 0.0001, Validation Loss: 0.5217\n",
      "Epoch [787/50], Train Loss: 0.0002, Validation Loss: 0.5058\n",
      "Epoch [788/50], Train Loss: 0.0004, Validation Loss: 0.5027\n",
      "Epoch [789/50], Train Loss: 0.0001, Validation Loss: 0.5001\n",
      "Epoch [790/50], Train Loss: 0.0013, Validation Loss: 0.5722\n",
      "Epoch [791/50], Train Loss: 0.0002, Validation Loss: 0.5438\n",
      "Epoch [792/50], Train Loss: 0.0003, Validation Loss: 0.4956\n",
      "Epoch [793/50], Train Loss: 0.0003, Validation Loss: 0.4796\n",
      "Epoch [794/50], Train Loss: 0.0001, Validation Loss: 0.4685\n",
      "Epoch [795/50], Train Loss: 0.0014, Validation Loss: 0.4830\n",
      "Epoch [796/50], Train Loss: 0.0004, Validation Loss: 0.4664\n",
      "Epoch [797/50], Train Loss: 0.0001, Validation Loss: 0.4600\n",
      "Epoch [798/50], Train Loss: 0.0001, Validation Loss: 0.4584\n",
      "Epoch [799/50], Train Loss: 0.0001, Validation Loss: 0.4531\n",
      "Epoch [800/50], Train Loss: 0.0001, Validation Loss: 0.4496\n",
      "Epoch [801/50], Train Loss: 0.0000, Validation Loss: 0.4478\n",
      "Epoch [802/50], Train Loss: 0.0002, Validation Loss: 0.4306\n",
      "Epoch [803/50], Train Loss: 0.0000, Validation Loss: 0.4326\n",
      "Epoch [804/50], Train Loss: 0.0001, Validation Loss: 0.4334\n",
      "Epoch [805/50], Train Loss: 0.0001, Validation Loss: 0.4355\n",
      "Epoch [806/50], Train Loss: 0.0000, Validation Loss: 0.4351\n",
      "Epoch [807/50], Train Loss: 0.0001, Validation Loss: 0.4326\n",
      "Epoch [808/50], Train Loss: 0.0001, Validation Loss: 0.4319\n",
      "Epoch [809/50], Train Loss: 0.0001, Validation Loss: 0.4280\n",
      "Epoch [810/50], Train Loss: 0.0001, Validation Loss: 0.4239\n",
      "Epoch [811/50], Train Loss: 0.0001, Validation Loss: 0.4248\n",
      "Epoch [812/50], Train Loss: 0.0003, Validation Loss: 0.4221\n",
      "Epoch [813/50], Train Loss: 0.0000, Validation Loss: 0.4196\n",
      "Epoch [814/50], Train Loss: 0.0001, Validation Loss: 0.4194\n",
      "Epoch [815/50], Train Loss: 0.0000, Validation Loss: 0.4190\n",
      "Epoch [816/50], Train Loss: 0.0000, Validation Loss: 0.4187\n",
      "Epoch [817/50], Train Loss: 0.0001, Validation Loss: 0.4165\n",
      "Epoch [818/50], Train Loss: 0.0001, Validation Loss: 0.4255\n",
      "Epoch [819/50], Train Loss: 0.0002, Validation Loss: 0.4322\n",
      "Epoch [820/50], Train Loss: 0.0002, Validation Loss: 0.4197\n",
      "Epoch [821/50], Train Loss: 0.0000, Validation Loss: 0.4189\n",
      "Epoch [822/50], Train Loss: 0.0004, Validation Loss: 0.4277\n",
      "Epoch [823/50], Train Loss: 0.0000, Validation Loss: 0.4248\n",
      "Epoch [824/50], Train Loss: 0.0000, Validation Loss: 0.4245\n",
      "Epoch [825/50], Train Loss: 0.0000, Validation Loss: 0.4255\n",
      "Epoch [826/50], Train Loss: 0.0001, Validation Loss: 0.4263\n",
      "Epoch [827/50], Train Loss: 0.0002, Validation Loss: 0.4315\n",
      "Epoch [828/50], Train Loss: 0.0000, Validation Loss: 0.4296\n",
      "Epoch [829/50], Train Loss: 0.0000, Validation Loss: 0.4286\n",
      "Epoch [830/50], Train Loss: 0.0000, Validation Loss: 0.4282\n",
      "Epoch [831/50], Train Loss: 0.0000, Validation Loss: 0.4256\n",
      "Epoch [832/50], Train Loss: 0.0001, Validation Loss: 0.4233\n",
      "Epoch [833/50], Train Loss: 0.0002, Validation Loss: 0.4432\n",
      "Epoch [834/50], Train Loss: 0.0001, Validation Loss: 0.4227\n",
      "Epoch [835/50], Train Loss: 0.0000, Validation Loss: 0.4245\n",
      "Epoch [836/50], Train Loss: 0.0000, Validation Loss: 0.4258\n",
      "Epoch [837/50], Train Loss: 0.0000, Validation Loss: 0.4270\n",
      "Epoch [838/50], Train Loss: 0.0001, Validation Loss: 0.4339\n",
      "Epoch [839/50], Train Loss: 0.0000, Validation Loss: 0.4340\n",
      "Epoch [840/50], Train Loss: 0.0001, Validation Loss: 0.4300\n",
      "Epoch [841/50], Train Loss: 0.0002, Validation Loss: 0.4387\n",
      "Epoch [842/50], Train Loss: 0.0000, Validation Loss: 0.4401\n",
      "Epoch [843/50], Train Loss: 0.0000, Validation Loss: 0.4385\n",
      "Epoch [844/50], Train Loss: 0.0001, Validation Loss: 0.4407\n",
      "Epoch [845/50], Train Loss: 0.0001, Validation Loss: 0.4381\n",
      "Epoch [846/50], Train Loss: 0.0000, Validation Loss: 0.4370\n",
      "Epoch [847/50], Train Loss: 0.0000, Validation Loss: 0.4363\n",
      "Epoch [848/50], Train Loss: 0.0000, Validation Loss: 0.4346\n",
      "Epoch [849/50], Train Loss: 0.0000, Validation Loss: 0.4343\n",
      "Epoch [850/50], Train Loss: 0.0001, Validation Loss: 0.4313\n",
      "Epoch [851/50], Train Loss: 0.0000, Validation Loss: 0.4329\n",
      "Epoch [852/50], Train Loss: 0.0000, Validation Loss: 0.4330\n",
      "Epoch [853/50], Train Loss: 0.0000, Validation Loss: 0.4315\n",
      "Epoch [854/50], Train Loss: 0.0000, Validation Loss: 0.4301\n",
      "Epoch [855/50], Train Loss: 0.0000, Validation Loss: 0.4284\n",
      "Epoch [856/50], Train Loss: 0.0000, Validation Loss: 0.4266\n",
      "Epoch [857/50], Train Loss: 0.0001, Validation Loss: 0.4302\n",
      "Epoch [858/50], Train Loss: 0.0001, Validation Loss: 0.4201\n",
      "Epoch [859/50], Train Loss: 0.0000, Validation Loss: 0.4205\n",
      "Epoch [860/50], Train Loss: 0.0000, Validation Loss: 0.4191\n",
      "Epoch [861/50], Train Loss: 0.0001, Validation Loss: 0.4195\n",
      "Epoch [862/50], Train Loss: 0.0001, Validation Loss: 0.4194\n",
      "Epoch [863/50], Train Loss: 0.0002, Validation Loss: 0.4055\n",
      "Epoch [864/50], Train Loss: 0.0000, Validation Loss: 0.4069\n",
      "Epoch [865/50], Train Loss: 0.0000, Validation Loss: 0.4092\n",
      "Epoch [866/50], Train Loss: 0.0000, Validation Loss: 0.4106\n",
      "Epoch [867/50], Train Loss: 0.0000, Validation Loss: 0.4142\n",
      "Epoch [868/50], Train Loss: 0.0000, Validation Loss: 0.4145\n",
      "Epoch [869/50], Train Loss: 0.0000, Validation Loss: 0.4182\n",
      "Epoch [870/50], Train Loss: 0.0000, Validation Loss: 0.4171\n",
      "Epoch [871/50], Train Loss: 0.0001, Validation Loss: 0.4143\n",
      "Epoch [872/50], Train Loss: 0.0002, Validation Loss: 0.3907\n",
      "Epoch [873/50], Train Loss: 0.0001, Validation Loss: 0.3899\n",
      "Epoch [874/50], Train Loss: 0.0000, Validation Loss: 0.3932\n",
      "Epoch [875/50], Train Loss: 0.0000, Validation Loss: 0.3945\n",
      "Epoch [876/50], Train Loss: 0.0000, Validation Loss: 0.3974\n",
      "Epoch [877/50], Train Loss: 0.0002, Validation Loss: 0.4157\n",
      "Epoch [878/50], Train Loss: 0.0000, Validation Loss: 0.4166\n",
      "Epoch [879/50], Train Loss: 0.0000, Validation Loss: 0.4170\n",
      "Epoch [880/50], Train Loss: 0.0001, Validation Loss: 0.4188\n",
      "Epoch [881/50], Train Loss: 0.0003, Validation Loss: 0.4193\n",
      "Epoch [882/50], Train Loss: 0.0000, Validation Loss: 0.4189\n",
      "Epoch [883/50], Train Loss: 0.0001, Validation Loss: 0.4068\n",
      "Epoch [884/50], Train Loss: 0.0000, Validation Loss: 0.4062\n",
      "Epoch [885/50], Train Loss: 0.0001, Validation Loss: 0.4059\n",
      "Epoch [886/50], Train Loss: 0.0000, Validation Loss: 0.4058\n",
      "Epoch [887/50], Train Loss: 0.0000, Validation Loss: 0.4063\n",
      "Epoch [888/50], Train Loss: 0.0000, Validation Loss: 0.4071\n",
      "Epoch [889/50], Train Loss: 0.0000, Validation Loss: 0.4063\n",
      "Epoch [890/50], Train Loss: 0.0000, Validation Loss: 0.4051\n",
      "Epoch [891/50], Train Loss: 0.0012, Validation Loss: 0.3771\n",
      "Epoch [892/50], Train Loss: 0.0000, Validation Loss: 0.3751\n",
      "Epoch [893/50], Train Loss: 0.0000, Validation Loss: 0.3729\n",
      "Epoch [894/50], Train Loss: 0.0000, Validation Loss: 0.3715\n",
      "Epoch [895/50], Train Loss: 0.0001, Validation Loss: 0.3711\n",
      "Epoch [896/50], Train Loss: 0.0002, Validation Loss: 0.3697\n",
      "Epoch [897/50], Train Loss: 0.0000, Validation Loss: 0.3722\n",
      "Epoch [898/50], Train Loss: 0.0000, Validation Loss: 0.3716\n",
      "Epoch [899/50], Train Loss: 0.0000, Validation Loss: 0.3738\n",
      "Epoch [900/50], Train Loss: 0.0000, Validation Loss: 0.3736\n",
      "Epoch [901/50], Train Loss: 0.0003, Validation Loss: 0.3794\n",
      "Epoch [902/50], Train Loss: 0.0001, Validation Loss: 0.3802\n",
      "Epoch [903/50], Train Loss: 0.0000, Validation Loss: 0.3800\n",
      "Epoch [904/50], Train Loss: 0.0000, Validation Loss: 0.3795\n",
      "Epoch [905/50], Train Loss: 0.0000, Validation Loss: 0.3807\n",
      "Epoch [906/50], Train Loss: 0.0000, Validation Loss: 0.3825\n",
      "Epoch [907/50], Train Loss: 0.0000, Validation Loss: 0.3831\n",
      "Epoch [908/50], Train Loss: 0.0000, Validation Loss: 0.3836\n",
      "Epoch [909/50], Train Loss: 0.0000, Validation Loss: 0.3833\n",
      "Epoch [910/50], Train Loss: 0.0000, Validation Loss: 0.3845\n",
      "Epoch [911/50], Train Loss: 0.0000, Validation Loss: 0.3846\n",
      "Epoch [912/50], Train Loss: 0.0000, Validation Loss: 0.3861\n",
      "Epoch [913/50], Train Loss: 0.0000, Validation Loss: 0.3860\n",
      "Epoch [914/50], Train Loss: 0.0000, Validation Loss: 0.3846\n",
      "Epoch [915/50], Train Loss: 0.0000, Validation Loss: 0.3838\n",
      "Epoch [916/50], Train Loss: 0.0000, Validation Loss: 0.3853\n",
      "Epoch [917/50], Train Loss: 0.0000, Validation Loss: 0.3850\n",
      "Epoch [918/50], Train Loss: 0.0000, Validation Loss: 0.3845\n",
      "Epoch [919/50], Train Loss: 0.0000, Validation Loss: 0.3851\n",
      "Epoch [920/50], Train Loss: 0.0000, Validation Loss: 0.3843\n",
      "Epoch [921/50], Train Loss: 0.0000, Validation Loss: 0.3825\n",
      "Epoch [922/50], Train Loss: 0.0000, Validation Loss: 0.3835\n",
      "Epoch [923/50], Train Loss: 0.0000, Validation Loss: 0.3838\n",
      "Epoch [924/50], Train Loss: 0.0001, Validation Loss: 0.3830\n",
      "Epoch [925/50], Train Loss: 0.0000, Validation Loss: 0.3849\n",
      "Epoch [926/50], Train Loss: 0.0001, Validation Loss: 0.3859\n",
      "Epoch [927/50], Train Loss: 0.0000, Validation Loss: 0.3839\n",
      "Epoch [928/50], Train Loss: 0.0000, Validation Loss: 0.3851\n",
      "Epoch [929/50], Train Loss: 0.0000, Validation Loss: 0.3857\n",
      "Epoch [930/50], Train Loss: 0.0000, Validation Loss: 0.3857\n",
      "Epoch [931/50], Train Loss: 0.0000, Validation Loss: 0.3872\n",
      "Epoch [932/50], Train Loss: 0.0000, Validation Loss: 0.3876\n",
      "Epoch [933/50], Train Loss: 0.0000, Validation Loss: 0.3891\n",
      "Epoch [934/50], Train Loss: 0.0000, Validation Loss: 0.3891\n",
      "Epoch [935/50], Train Loss: 0.0000, Validation Loss: 0.3904\n",
      "Epoch [936/50], Train Loss: 0.0000, Validation Loss: 0.3917\n",
      "Epoch [937/50], Train Loss: 0.0000, Validation Loss: 0.3904\n",
      "Epoch [938/50], Train Loss: 0.0000, Validation Loss: 0.3902\n",
      "Epoch [939/50], Train Loss: 0.0003, Validation Loss: 0.4003\n",
      "Epoch [940/50], Train Loss: 0.0001, Validation Loss: 0.4039\n",
      "Epoch [941/50], Train Loss: 0.0000, Validation Loss: 0.4038\n",
      "Epoch [942/50], Train Loss: 0.0000, Validation Loss: 0.4034\n",
      "Epoch [943/50], Train Loss: 0.0001, Validation Loss: 0.4084\n",
      "Epoch [944/50], Train Loss: 0.0000, Validation Loss: 0.4083\n",
      "Epoch [945/50], Train Loss: 0.0001, Validation Loss: 0.4038\n",
      "Epoch [946/50], Train Loss: 0.0051, Validation Loss: 0.5094\n",
      "Epoch [947/50], Train Loss: 0.0000, Validation Loss: 0.4827\n",
      "Epoch [948/50], Train Loss: 0.0003, Validation Loss: 0.4796\n",
      "Epoch [949/50], Train Loss: 0.0005, Validation Loss: 0.4510\n",
      "Epoch [950/50], Train Loss: 0.0045, Validation Loss: 0.4736\n",
      "Epoch [951/50], Train Loss: 0.0001, Validation Loss: 0.4605\n",
      "Epoch [952/50], Train Loss: 0.0000, Validation Loss: 0.4504\n",
      "Epoch [953/50], Train Loss: 0.0000, Validation Loss: 0.4444\n",
      "Epoch [954/50], Train Loss: 0.0010, Validation Loss: 0.4155\n",
      "Epoch [955/50], Train Loss: 0.0000, Validation Loss: 0.4171\n",
      "Epoch [956/50], Train Loss: 0.0001, Validation Loss: 0.4186\n",
      "Epoch [957/50], Train Loss: 0.0004, Validation Loss: 0.4066\n",
      "Epoch [958/50], Train Loss: 0.0004, Validation Loss: 0.4192\n",
      "Epoch [959/50], Train Loss: 0.0000, Validation Loss: 0.4182\n",
      "Epoch [960/50], Train Loss: 0.0001, Validation Loss: 0.4125\n",
      "Epoch [961/50], Train Loss: 0.0000, Validation Loss: 0.4113\n",
      "Epoch [962/50], Train Loss: 0.1153, Validation Loss: 0.5023\n",
      "Epoch [963/50], Train Loss: 0.0488, Validation Loss: 1.5876\n",
      "Epoch [964/50], Train Loss: 0.0087, Validation Loss: 1.7971\n",
      "Epoch [965/50], Train Loss: 0.0013, Validation Loss: 1.0427\n",
      "Epoch [966/50], Train Loss: 0.0020, Validation Loss: 0.6167\n",
      "Epoch [967/50], Train Loss: 0.0026, Validation Loss: 0.3771\n",
      "Epoch [968/50], Train Loss: 0.0014, Validation Loss: 0.4288\n",
      "Epoch [969/50], Train Loss: 0.0003, Validation Loss: 0.4117\n",
      "Epoch [970/50], Train Loss: 0.0002, Validation Loss: 0.4020\n",
      "Epoch [971/50], Train Loss: 0.0015, Validation Loss: 0.4055\n",
      "Epoch [972/50], Train Loss: 0.0006, Validation Loss: 0.4148\n",
      "Epoch [973/50], Train Loss: 0.0011, Validation Loss: 0.3807\n",
      "Epoch [974/50], Train Loss: 0.0010, Validation Loss: 0.3500\n",
      "Epoch [975/50], Train Loss: 0.0001, Validation Loss: 0.3458\n",
      "Epoch [976/50], Train Loss: 0.0005, Validation Loss: 0.3446\n",
      "Epoch [977/50], Train Loss: 0.0001, Validation Loss: 0.3443\n",
      "Epoch [978/50], Train Loss: 0.0001, Validation Loss: 0.3438\n",
      "Epoch [979/50], Train Loss: 0.0004, Validation Loss: 0.3448\n",
      "Epoch [980/50], Train Loss: 0.0004, Validation Loss: 0.3350\n",
      "Epoch [981/50], Train Loss: 0.0001, Validation Loss: 0.3352\n",
      "Epoch [982/50], Train Loss: 0.0000, Validation Loss: 0.3364\n",
      "Epoch [983/50], Train Loss: 0.0000, Validation Loss: 0.3359\n",
      "Epoch [984/50], Train Loss: 0.0000, Validation Loss: 0.3365\n",
      "Epoch [985/50], Train Loss: 0.0055, Validation Loss: 0.8242\n",
      "Epoch [986/50], Train Loss: 0.0004, Validation Loss: 0.6106\n",
      "Epoch [987/50], Train Loss: 0.0000, Validation Loss: 0.5621\n",
      "Epoch [988/50], Train Loss: 0.0002, Validation Loss: 0.5259\n",
      "Epoch [989/50], Train Loss: 0.0000, Validation Loss: 0.4989\n",
      "Epoch [990/50], Train Loss: 0.0009, Validation Loss: 0.4582\n",
      "Epoch [991/50], Train Loss: 0.0000, Validation Loss: 0.4361\n",
      "Epoch [992/50], Train Loss: 0.0000, Validation Loss: 0.4196\n",
      "Epoch [993/50], Train Loss: 0.0001, Validation Loss: 0.4051\n",
      "Epoch [994/50], Train Loss: 0.0001, Validation Loss: 0.3913\n",
      "Epoch [995/50], Train Loss: 0.0001, Validation Loss: 0.3860\n",
      "Epoch [996/50], Train Loss: 0.0002, Validation Loss: 0.3651\n",
      "Epoch [997/50], Train Loss: 0.0000, Validation Loss: 0.3658\n",
      "Epoch [998/50], Train Loss: 0.0001, Validation Loss: 0.3629\n",
      "Epoch [999/50], Train Loss: 0.0002, Validation Loss: 0.3567\n",
      "Epoch [1000/50], Train Loss: 0.0000, Validation Loss: 0.3582\n",
      "Epoch [1001/50], Train Loss: 0.0001, Validation Loss: 0.3583\n",
      "Epoch [1002/50], Train Loss: 0.0001, Validation Loss: 0.3597\n",
      "Epoch [1003/50], Train Loss: 0.0001, Validation Loss: 0.3609\n",
      "Epoch [1004/50], Train Loss: 0.0001, Validation Loss: 0.3590\n",
      "Epoch [1005/50], Train Loss: 0.0001, Validation Loss: 0.3574\n",
      "Epoch [1006/50], Train Loss: 0.0009, Validation Loss: 0.3436\n",
      "Epoch [1007/50], Train Loss: 0.0000, Validation Loss: 0.3472\n",
      "Epoch [1008/50], Train Loss: 0.0006, Validation Loss: 0.3436\n",
      "Epoch [1009/50], Train Loss: 0.0000, Validation Loss: 0.3480\n",
      "Epoch [1010/50], Train Loss: 0.0000, Validation Loss: 0.3519\n",
      "Epoch [1011/50], Train Loss: 0.0000, Validation Loss: 0.3530\n",
      "Epoch [1012/50], Train Loss: 0.0002, Validation Loss: 0.3594\n",
      "Epoch [1013/50], Train Loss: 0.0001, Validation Loss: 0.3615\n",
      "Epoch [1014/50], Train Loss: 0.0000, Validation Loss: 0.3614\n",
      "Epoch [1015/50], Train Loss: 0.0192, Validation Loss: 0.6317\n",
      "Epoch [1016/50], Train Loss: 0.0001, Validation Loss: 0.6210\n",
      "Epoch [1017/50], Train Loss: 0.0002, Validation Loss: 0.5904\n",
      "Epoch [1018/50], Train Loss: 0.0001, Validation Loss: 0.5673\n",
      "Epoch [1019/50], Train Loss: 0.0001, Validation Loss: 0.5475\n",
      "Epoch [1020/50], Train Loss: 0.0001, Validation Loss: 0.5455\n",
      "Epoch [1021/50], Train Loss: 0.0001, Validation Loss: 0.5378\n",
      "Epoch [1022/50], Train Loss: 0.0001, Validation Loss: 0.5237\n",
      "Epoch [1023/50], Train Loss: 0.0002, Validation Loss: 0.5152\n",
      "Epoch [1024/50], Train Loss: 0.0003, Validation Loss: 0.4752\n",
      "Epoch [1025/50], Train Loss: 0.0001, Validation Loss: 0.4733\n",
      "Epoch [1026/50], Train Loss: 0.0002, Validation Loss: 0.4375\n",
      "Epoch [1027/50], Train Loss: 0.0000, Validation Loss: 0.4348\n",
      "Epoch [1028/50], Train Loss: 0.0001, Validation Loss: 0.4351\n",
      "Epoch [1029/50], Train Loss: 0.0000, Validation Loss: 0.4362\n",
      "Epoch [1030/50], Train Loss: 0.0003, Validation Loss: 0.4160\n",
      "Epoch [1031/50], Train Loss: 0.0000, Validation Loss: 0.4168\n",
      "Epoch [1032/50], Train Loss: 0.0000, Validation Loss: 0.4215\n",
      "Epoch [1033/50], Train Loss: 0.0000, Validation Loss: 0.4228\n",
      "Epoch [1034/50], Train Loss: 0.0001, Validation Loss: 0.4288\n",
      "Epoch [1035/50], Train Loss: 0.0001, Validation Loss: 0.4303\n",
      "Epoch [1036/50], Train Loss: 0.0001, Validation Loss: 0.4337\n",
      "Epoch [1037/50], Train Loss: 0.0000, Validation Loss: 0.4345\n",
      "Epoch [1038/50], Train Loss: 0.0000, Validation Loss: 0.4377\n",
      "Epoch [1039/50], Train Loss: 0.0000, Validation Loss: 0.4402\n",
      "Epoch [1040/50], Train Loss: 0.0000, Validation Loss: 0.4393\n",
      "Epoch [1041/50], Train Loss: 0.0060, Validation Loss: 0.4571\n",
      "Epoch [1042/50], Train Loss: 0.0002, Validation Loss: 0.4579\n",
      "Epoch [1043/50], Train Loss: 0.0016, Validation Loss: 0.5013\n",
      "Epoch [1044/50], Train Loss: 0.0003, Validation Loss: 0.4719\n",
      "Epoch [1045/50], Train Loss: 0.0001, Validation Loss: 0.4705\n",
      "Epoch [1046/50], Train Loss: 0.0001, Validation Loss: 0.4721\n",
      "Epoch [1047/50], Train Loss: 0.0003, Validation Loss: 0.4669\n",
      "Epoch [1048/50], Train Loss: 0.0001, Validation Loss: 0.4739\n",
      "Epoch [1049/50], Train Loss: 0.0001, Validation Loss: 0.4700\n",
      "Epoch [1050/50], Train Loss: 0.0001, Validation Loss: 0.4733\n",
      "Epoch [1051/50], Train Loss: 0.0008, Validation Loss: 0.4639\n",
      "Epoch [1052/50], Train Loss: 0.0003, Validation Loss: 0.4773\n",
      "Epoch [1053/50], Train Loss: 0.0001, Validation Loss: 0.4773\n",
      "Epoch [1054/50], Train Loss: 0.0002, Validation Loss: 0.4847\n",
      "Epoch [1055/50], Train Loss: 0.0001, Validation Loss: 0.4822\n",
      "Epoch [1056/50], Train Loss: 0.0001, Validation Loss: 0.4847\n",
      "Epoch [1057/50], Train Loss: 0.0002, Validation Loss: 0.4802\n",
      "Epoch [1058/50], Train Loss: 0.0015, Validation Loss: 0.4407\n",
      "Epoch [1059/50], Train Loss: 0.0003, Validation Loss: 0.4414\n",
      "Epoch [1060/50], Train Loss: 0.0002, Validation Loss: 0.4393\n",
      "Epoch [1061/50], Train Loss: 0.0001, Validation Loss: 0.4413\n",
      "Epoch [1062/50], Train Loss: 0.0000, Validation Loss: 0.4412\n",
      "Epoch [1063/50], Train Loss: 0.0001, Validation Loss: 0.4501\n",
      "Epoch [1064/50], Train Loss: 0.0001, Validation Loss: 0.4543\n",
      "Epoch [1065/50], Train Loss: 0.0003, Validation Loss: 0.4508\n",
      "Epoch [1066/50], Train Loss: 0.0000, Validation Loss: 0.4555\n",
      "Epoch [1067/50], Train Loss: 0.0001, Validation Loss: 0.4884\n",
      "Epoch [1068/50], Train Loss: 0.0000, Validation Loss: 0.4842\n",
      "Epoch [1069/50], Train Loss: 0.0000, Validation Loss: 0.4837\n",
      "Epoch [1070/50], Train Loss: 0.0009, Validation Loss: 0.3946\n",
      "Epoch [1071/50], Train Loss: 0.0001, Validation Loss: 0.3996\n",
      "Epoch [1072/50], Train Loss: 0.0005, Validation Loss: 0.4811\n",
      "Epoch [1073/50], Train Loss: 0.0000, Validation Loss: 0.4697\n",
      "Epoch [1074/50], Train Loss: 0.0001, Validation Loss: 0.4633\n",
      "Epoch [1075/50], Train Loss: 0.0001, Validation Loss: 0.4596\n",
      "Epoch [1076/50], Train Loss: 0.0000, Validation Loss: 0.4546\n",
      "Epoch [1077/50], Train Loss: 0.0001, Validation Loss: 0.4549\n",
      "Epoch [1078/50], Train Loss: 0.0000, Validation Loss: 0.4507\n",
      "Epoch [1079/50], Train Loss: 0.0013, Validation Loss: 0.4607\n",
      "Epoch [1080/50], Train Loss: 0.0001, Validation Loss: 0.4382\n",
      "Epoch [1081/50], Train Loss: 0.0002, Validation Loss: 0.4300\n",
      "Epoch [1082/50], Train Loss: 0.0001, Validation Loss: 0.4180\n",
      "Epoch [1083/50], Train Loss: 0.0005, Validation Loss: 0.3889\n",
      "Epoch [1084/50], Train Loss: 0.0000, Validation Loss: 0.3778\n",
      "Epoch [1085/50], Train Loss: 0.0001, Validation Loss: 0.3662\n",
      "Epoch [1086/50], Train Loss: 0.0000, Validation Loss: 0.3591\n",
      "Epoch [1087/50], Train Loss: 0.0001, Validation Loss: 0.3558\n",
      "Epoch [1088/50], Train Loss: 0.0000, Validation Loss: 0.3520\n",
      "Epoch [1089/50], Train Loss: 0.0005, Validation Loss: 0.3897\n",
      "Epoch [1090/50], Train Loss: 0.0000, Validation Loss: 0.3841\n",
      "Epoch [1091/50], Train Loss: 0.0000, Validation Loss: 0.3799\n",
      "Epoch [1092/50], Train Loss: 0.0000, Validation Loss: 0.3776\n",
      "Epoch [1093/50], Train Loss: 0.0000, Validation Loss: 0.3728\n",
      "Epoch [1094/50], Train Loss: 0.0002, Validation Loss: 0.3734\n",
      "Epoch [1095/50], Train Loss: 0.0001, Validation Loss: 0.3754\n",
      "Epoch [1096/50], Train Loss: 0.0001, Validation Loss: 0.3705\n",
      "Epoch [1097/50], Train Loss: 0.0000, Validation Loss: 0.3685\n",
      "Epoch [1098/50], Train Loss: 0.0000, Validation Loss: 0.3690\n",
      "Epoch [1099/50], Train Loss: 0.0001, Validation Loss: 0.3643\n",
      "Epoch [1100/50], Train Loss: 0.0002, Validation Loss: 0.3655\n",
      "Epoch [1101/50], Train Loss: 0.0000, Validation Loss: 0.3664\n",
      "Epoch [1102/50], Train Loss: 0.0001, Validation Loss: 0.3670\n",
      "Epoch [1103/50], Train Loss: 0.0000, Validation Loss: 0.3677\n",
      "Epoch [1104/50], Train Loss: 0.0001, Validation Loss: 0.3708\n",
      "Epoch [1105/50], Train Loss: 0.0001, Validation Loss: 0.3649\n",
      "Epoch [1106/50], Train Loss: 0.0001, Validation Loss: 0.3644\n",
      "Epoch [1107/50], Train Loss: 0.0000, Validation Loss: 0.3661\n",
      "Epoch [1108/50], Train Loss: 0.0000, Validation Loss: 0.3663\n",
      "Epoch [1109/50], Train Loss: 0.0000, Validation Loss: 0.3675\n",
      "Epoch [1110/50], Train Loss: 0.0000, Validation Loss: 0.3687\n",
      "Epoch [1111/50], Train Loss: 0.0000, Validation Loss: 0.3701\n",
      "Epoch [1112/50], Train Loss: 0.0000, Validation Loss: 0.3694\n",
      "Epoch [1113/50], Train Loss: 0.0001, Validation Loss: 0.3731\n",
      "Epoch [1114/50], Train Loss: 0.0000, Validation Loss: 0.3710\n",
      "Epoch [1115/50], Train Loss: 0.0003, Validation Loss: 0.3732\n",
      "Epoch [1116/50], Train Loss: 0.0000, Validation Loss: 0.3742\n",
      "Epoch [1117/50], Train Loss: 0.0000, Validation Loss: 0.3736\n",
      "Epoch [1118/50], Train Loss: 0.0000, Validation Loss: 0.3730\n",
      "Epoch [1119/50], Train Loss: 0.0000, Validation Loss: 0.3750\n",
      "Epoch [1120/50], Train Loss: 0.0000, Validation Loss: 0.3733\n",
      "Epoch [1121/50], Train Loss: 0.0000, Validation Loss: 0.3719\n",
      "Epoch [1122/50], Train Loss: 0.0001, Validation Loss: 0.3732\n",
      "Epoch [1123/50], Train Loss: 0.0001, Validation Loss: 0.3726\n",
      "Epoch [1124/50], Train Loss: 0.0000, Validation Loss: 0.3772\n",
      "Epoch [1125/50], Train Loss: 0.0000, Validation Loss: 0.3754\n",
      "Epoch [1126/50], Train Loss: 0.0017, Validation Loss: 0.3156\n",
      "Epoch [1127/50], Train Loss: 0.0000, Validation Loss: 0.3158\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m t \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     41\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 42\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mnet5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y[\u001b[38;5;241m0\u001b[39m], t)\n\u001b[1;32m     44\u001b[0m train_epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# エポック全体の訓練データの損失に加算\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/app/models/dymn/model.py:179\u001b[0m, in \u001b[0;36mDyMN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m (Tensor, Tensor):\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/models/dymn/model.py:174\u001b[0m, in \u001b[0;36mDyMN._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m (Tensor, Tensor):\n\u001b[0;32m--> 174\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     x, embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clf_forward(x)\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, embed\n",
      "File \u001b[0;32m/app/models/dymn/model.py:161\u001b[0m, in \u001b[0;36mDyMN._feature_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    159\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 161\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_c(x)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/app/models/dymn/dy_block.py:395\u001b[0m, in \u001b[0;36mDY_Block.forward\u001b[0;34m(self, x, g)\u001b[0m\n\u001b[1;32m    392\u001b[0m inp \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    394\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_gen(x, g)\n\u001b[0;32m--> 395\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexp_norm(x)\n\u001b[1;32m    397\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexp_act(x, g)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1514\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1514\u001b[0m     forward_call \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tracing_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward)\n\u001b[1;32m   1515\u001b[0m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# エポックの数\n",
    "epoch = 0\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net5 = matModel_2.cuda()\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "  \n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net5.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 学習ループ\n",
    "# for epoch in range(max_epoch):\n",
    "train_epoch_loss = 1.0\n",
    "val_epoch_loss = 1.0\n",
    "\n",
    "while train_epoch_loss > 0.1 or val_epoch_loss  > 0.1 or epoch<50:\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net5.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y = net5(x)\n",
    "        loss = criterion(y[0], t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net5.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "  \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net5(x)\n",
    "            loss = criterion(y[0], t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "    epoch+=1\n",
    "\n",
    "matModel_2_trained = net5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "matModel_2_trained = net5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAHHCAYAAACRAnNyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACAKklEQVR4nO3dd3gUVdsG8HuzSTaNJCQkhN57E0EQEEFBaaJgR0TAggVUVCx8KAIWsLyKoiI2sAEKCqJSBKRI7733ToCQRkjbPd8fk92d7W02M0vu33Xlyu7s7MzZ2dmZZ855zhmdEEKAiIiISIPC1C4AERERkSsMVIiIiEizGKgQERGRZjFQISIiIs1ioEJERESaxUCFiIiINIuBChEREWkWAxUiIiLSLAYqREREpFkMVEh1gwYNQs2aNf1675gxY6DT6ZQtkMYcO3YMOp0O06ZNK/V163Q6jBkzxvJ82rRp0Ol0OHbsmMf31qxZE4MGDVK0PIHsK1S2BPK78WU/p+BjoEIu6XQ6r/6WL1+udlHLvOeeew46nQ6HDh1yOc+oUaOg0+mwY8eOUiyZ786cOYMxY8Zg27ZtahfFwnzS+/DDD9UuSqlZvny55Tf+008/OZ2nQ4cO0Ol0aNq0qV/r+OKLL1QJwCm0hKtdANKuH3/80eb5Dz/8gMWLFztMb9SoUUDr+frrr2Eymfx67+uvv47XXnstoPVfC/r3749JkyZh+vTpGD16tNN5ZsyYgWbNmqF58+Z+r2fAgAF48MEHYTAY/F6GJ2fOnMHYsWNRs2ZNXHfddTavBbKvkH+ioqIwffp0PPzwwzbTjx07hjVr1iAqKsrvZX/xxReoUKGC4jVvAFCjRg1cvXoVERERii+bShcDFXLJ/sC0bt06LF682GG6vby8PMTExHi9nkAOJOHh4QgP527ctm1b1K1bFzNmzHAaqKxduxZHjx7FhAkTAlqPXq+HXq8PaBmB4Emn9PXs2RPz5s3DxYsXUaFCBcv06dOno2LFiqhXrx4uX76sYgltFRcXw2QyITIyMqAgirSDTT8UkM6dO6Np06bYvHkzbr75ZsTExOD//u//AAB//PEHevXqhcqVK8NgMKBOnTp46623YDQabZZhn3cgr2b/6quvUKdOHRgMBtxwww3YuHGjzXud5ajodDoMGzYMc+fORdOmTWEwGNCkSRMsXLjQofzLly9H69atERUVhTp16mDKlCle5738999/uO+++1C9enUYDAZUq1YNL7zwAq5everw+eLi4nD69Gn06dMHcXFxSElJwYgRIxy2RWZmJgYNGoSEhAQkJiZi4MCByMzM9FgWQKpV2bdvH7Zs2eLw2vTp06HT6dCvXz8UFhZi9OjRaNWqFRISEhAbG4uOHTti2bJlHtfhrO1eCIG3334bVatWRUxMDG655Rbs3r3b4b0ZGRkYMWIEmjVrhri4OMTHx6NHjx7Yvn27ZZ7ly5fjhhtuAAAMHjzY0vRgbh5wlqNy5coVvPTSS6hWrRoMBgMaNGiADz/8EPY3hvdlv/BXeno6HnvsMVSsWBFRUVFo0aIFvv/+e4f5Zs6ciVatWqFcuXKIj49Hs2bN8Mknn1heLyoqwtixY1GvXj1ERUUhOTkZN910ExYvXmyznH379uHee+9FUlISoqKi0Lp1a8ybN89mHm+X5cpdd90Fg8GAWbNm2UyfPn067r//fqeB69SpU3HrrbciNTUVBoMBjRs3xuTJk23mqVmzJnbv3o0VK1ZYvufOnTtbXs/MzMTw4cMt32vdunXx3nvv2dSoyY8VEydOtBwr9uzZ4zRHZceOHRg0aBBq166NqKgopKWl4dFHH8WlS5e82hakDl6KUsAuXbqEHj164MEHH8TDDz+MihUrApBOanFxcXjxxRcRFxeHf//9F6NHj0Z2djY++OADj8udPn06cnJy8OSTT0Kn0+H999/H3XffjSNHjni8sl61ahV+//13PPPMMyhXrhw+/fRT3HPPPThx4gSSk5MBAFu3bkX37t1RqVIljB07FkajEePGjUNKSopXn3vWrFnIy8vD008/jeTkZGzYsAGTJk3CqVOnHA7qRqMR3bp1Q9u2bfHhhx9iyZIl+N///oc6derg6aefBiCd8O+66y6sWrUKTz31FBo1aoQ5c+Zg4MCBXpWnf//+GDt2LKZPn47rr7/eZt2//vorOnbsiOrVq+PixYv45ptv0K9fPzzxxBPIycnBt99+i27dumHDhg0OzS2ejB49Gm+//TZ69uyJnj17YsuWLbj99ttRWFhoM9+RI0cwd+5c3HfffahVqxbOnz+PKVOmoFOnTtizZw8qV66MRo0aYdy4cRg9ejSGDBmCjh07AgDat2/vdN1CCNx5551YtmwZHnvsMVx33XVYtGgRXn75ZZw+fRoff/yxzfze7Bf+unr1Kjp37oxDhw5h2LBhqFWrFmbNmoVBgwYhMzMTzz//PABg8eLF6NevH7p06YL33nsPALB3716sXr3aMs+YMWMwfvx4PP7442jTpg2ys7OxadMmbNmyBbfddhsAYPfu3ejQoQOqVKmC1157DbGxsfj111/Rp08f/Pbbb+jbt6/Xy3InJiYGd911F2bMmGHZV7dv347du3fjm2++cZrzNHnyZDRp0gR33nknwsPD8eeff+KZZ56ByWTC0KFDAQATJ07Es88+i7i4OIwaNQoALMeOvLw8dOrUCadPn8aTTz6J6tWrY82aNRg5ciTOnj2LiRMn2qxv6tSpyM/Px5AhQ2AwGJCUlOS0iXDx4sU4cuQIBg8ejLS0NOzevRtfffUVdu/ejXXr1l3zifkhSxB5aejQocJ+l+nUqZMAIL788kuH+fPy8hymPfnkkyImJkbk5+dbpg0cOFDUqFHD8vzo0aMCgEhOThYZGRmW6X/88YcAIP7880/LtDfffNOhTABEZGSkOHTokGXa9u3bBQAxadIky7TevXuLmJgYcfr0acu0gwcPivDwcIdlOuPs840fP17odDpx/Phxm88HQIwbN85m3pYtW4pWrVpZns+dO1cAEO+//75lWnFxsejYsaMAIKZOneqxTDfccIOoWrWqMBqNlmkLFy4UAMSUKVMsyywoKLB53+XLl0XFihXFo48+ajMdgHjzzTctz6dOnSoAiKNHjwohhEhPTxeRkZGiV69ewmQyWeb7v//7PwFADBw40DItPz/fplxCSN+1wWCw2TYbN250+Xnt9xXzNnv77bdt5rv33nuFTqez2Qe83S+cMe+TH3zwgct5Jk6cKACIn376yTKtsLBQtGvXTsTFxYns7GwhhBDPP/+8iI+PF8XFxS6X1aJFC9GrVy+3ZerSpYto1qyZzW/JZDKJ9u3bi3r16vm0LGeWLVsmAIhZs2aJv/76S+h0OnHixAkhhBAvv/yyqF27thBCOgY0adLE5r3OfhvdunWzvMesSZMmolOnTg7zvvXWWyI2NlYcOHDAZvprr70m9Hq9pRzm7yU+Pl6kp6fbzGt+Tb4fOSvXjBkzBACxcuVKyzT7/ZzUxaYfCpjBYMDgwYMdpkdHR1se5+Tk4OLFi+jYsSPy8vKwb98+j8t94IEHUL58ectz89X1kSNHPL63a9euqFOnjuV58+bNER8fb3mv0WjEkiVL0KdPH1SuXNkyX926ddGjRw+PywdsP9+VK1dw8eJFtG/fHkIIbN261WH+p556yuZ5x44dbT7L/PnzER4ebrlqBaSckGeffdar8gBSXtGpU6ewcuVKy7Tp06cjMjIS9913n2WZkZGRAACTyYSMjAwUFxejdevWTpuN3FmyZAkKCwvx7LPP2lyNDh8+3GFeg8GAsDDpkGM0GnHp0iXExcWhQYMGPq/XbP78+dDr9Xjuuedspr/00ksQQmDBggU20z3tF4GYP38+0tLS0K9fP8u0iIgIPPfcc8jNzcWKFSsAAImJibhy5YrbppfExETs3r0bBw8edPp6RkYG/v33X9x///2W39bFixdx6dIldOvWDQcPHsTp06e9WpY3br/9diQlJWHmzJkQQmDmzJk2n9Oe/LeRlZWFixcvolOnTjhy5AiysrI8rm/WrFno2LEjypcvb/lsFy9eRNeuXWE0Gm32bwC45557vKoJlZcrPz8fFy9exI033ggAfu+DFHwMVChgVapUsZz45Hbv3o2+ffsiISEB8fHxSElJsSTienOwql69us1zc9DiTeKe/XvN7ze/Nz09HVevXkXdunUd5nM2zZkTJ05g0KBBSEpKsuSddOrUCYDj54uKinI4kMrLAwDHjx9HpUqVEBcXZzNfgwYNvCoPADz44IPQ6/WYPn06AOlgPGfOHPTo0cMm6Pv+++/RvHlzS85CSkoK/v77b6++F7njx48DAOrVq2czPSUlxWZ9gBQUffzxx6hXrx4MBgMqVKiAlJQU7Nixw+f1ytdfuXJllCtXzma6uSeauXxmnvaLQBw/fhz16tWzBGOuyvLMM8+gfv366NGjB6pWrYpHH33UIU9m3LhxyMzMRP369dGsWTO8/PLLNk0shw4dghACb7zxBlJSUmz+3nzzTQDSPu7NsrwRERGB++67D9OnT8fKlStx8uRJPPTQQy7nX716Nbp27YrY2FgkJiYiJSXFkrvmzXd98OBBLFy40OGzde3a1eazmdWqVcurz5GRkYHnn38eFStWRHR0NFJSUizv9XcfpOBjjgoFTH6VYpaZmYlOnTohPj4e48aNQ506dRAVFYUtW7bg1Vdf9aqLqaveJcIuSVLp93rDaDTitttuQ0ZGBl599VU0bNgQsbGxOH36NAYNGuTw+Uqrp0xqaipuu+02/Pbbb/j888/x559/IicnB/3797fM89NPP2HQoEHo06cPXn75ZaSmpkKv12P8+PE4fPhw0Mr27rvv4o033sCjjz6Kt956C0lJSQgLC8Pw4cNLrctxsPcLb6SmpmLbtm1YtGgRFixYgAULFmDq1Kl45JFHLIm3N998Mw4fPow//vgD//zzD7755ht8/PHH+PLLL/H4449btteIESPQrVs3p+sxB9yeluWthx56CF9++SXGjBmDFi1aoHHjxk7nO3z4MLp06YKGDRvio48+QrVq1RAZGYn58+fj448/9uq7NplMuO222/DKK684fb1+/fo2z50dg5y5//77sWbNGrz88su47rrrEBcXB5PJhO7du7Pbu4YxUKGgWL58OS5duoTff/8dN998s2X60aNHVSyVVWpqKqKiopwOkOZu0DSznTt34sCBA/j+++/xyCOPWKZ725PCmRo1amDp0qXIzc21qVXZv3+/T8vp378/Fi5ciAULFmD69OmIj49H7969La/Pnj0btWvXxu+//27TXGO+Eve1zIB0BVy7dm3L9AsXLjjUUsyePRu33HILvv32W5vpmZmZNt1efUlorFGjBpYsWYKcnBybWhVz06K5fKWhRo0a2LFjB0wmk02tirOyREZGonfv3ujduzdMJhOeeeYZTJkyBW+88YYlwEhKSsLgwYMxePBg5Obm4uabb8aYMWPw+OOPW7Z1RESEpZbBHXfL8tZNN92E6tWrY/ny5ZYkYGf+/PNPFBQUYN68eTY1WM56lbn6ruvUqYPc3FyvPpu3Ll++jKVLl2Ls2LE2XfgDaRKj0sGmHwoK85Wr/Eq1sLAQX3zxhVpFsqHX69G1a1fMnTsXZ86csUw/dOiQQ16Dq/cDtp9PCGHTxdRXPXv2RHFxsU03TqPRiEmTJvm0nD59+iAmJgZffPEFFixYgLvvvttmPAlnZV+/fj3Wrl3rc5m7du2KiIgITJo0yWZ59r0yzOu1r7mYNWuWJZfCLDY2FgC86pbds2dPGI1GfPbZZzbTP/74Y+h0Oq/zjZTQs2dPnDt3Dr/88otlWnFxMSZNmoS4uDhLs6B9V9iwsDDLIHwFBQVO54mLi0PdunUtr6empqJz586YMmUKzp4961CWCxcuWB57Wpa3dDodPv30U7z55psYMGCAy/mc7V9ZWVmYOnWqw7yxsbFOv+f7778fa9euxaJFixxey8zMRHFxsU9ld1UuwPm+StrCGhUKivbt26N8+fIYOHCgZXj3H3/8sVSr2D0ZM2YM/vnnH3To0AFPP/205YTXtGlTj8O3N2zYEHXq1MGIESNw+vRpxMfH47fffgso16F3797o0KEDXnvtNRw7dgyNGzfG77//7nPbeVxcHPr06WPJU5E3+wDAHXfcgd9//x19+/ZFr169cPToUXz55Zdo3LgxcnNzfVqXeTyY8ePH44477kDPnj2xdetWLFiwwKaWxLzecePGYfDgwWjfvj127tyJn3/+2aYmBpCuphMTE/Hll1+iXLlyiI2NRdu2bZ3mIfTu3Ru33HILRo0ahWPHjqFFixb4559/8Mcff2D48OE2ibNKWLp0KfLz8x2m9+nTB0OGDMGUKVMwaNAgbN68GTVr1sTs2bOxevVqTJw40VLj8/jjjyMjIwO33norqlatiuPHj2PSpEm47rrrLPksjRs3RufOndGqVSskJSVh06ZNmD17NoYNG2ZZ5+eff46bbroJzZo1wxNPPIHatWvj/PnzWLt2LU6dOmUZn8abZXnrrrvuwl133eV2nttvv91SY/Tkk08iNzcXX3/9NVJTUx2CqlatWmHy5Ml4++23UbduXaSmpuLWW2/Fyy+/jHnz5uGOO+7AoEGD0KpVK1y5cgU7d+7E7NmzcezYMYf9y5P4+HjcfPPNeP/991FUVIQqVargn3/+0UwtL7lR+h2NKFS56p5s3zXRbPXq1eLGG28U0dHRonLlyuKVV14RixYtEgDEsmXLLPO56p7srCso7LrLuuqePHToUIf31qhRw6a7rBBCLF26VLRs2VJERkaKOnXqiG+++Ua89NJLIioqysVWsNqzZ4/o2rWriIuLExUqVBBPPPGEpburvEvkwIEDRWxsrMP7nZX90qVLYsCAASI+Pl4kJCSIAQMGiK1bt3rdPdns77//FgBEpUqVHLoEm0wm8e6774oaNWoIg8EgWrZsKf766y+H70EIz92ThRDCaDSKsWPHikqVKono6GjRuXNnsWvXLoftnZ+fL1566SXLfB06dBBr164VnTp1cuii+scff4jGjRtbuoqbP7uzMubk5IgXXnhBVK5cWURERIh69eqJDz74wKa7tPmzeLtf2DPvk67+fvzxRyGEEOfPnxeDBw8WFSpUEJGRkaJZs2YO39vs2bPF7bffLlJTU0VkZKSoXr26ePLJJ8XZs2ct87z99tuiTZs2IjExUURHR4uGDRuKd955RxQWFtos6/Dhw+KRRx4RaWlpIiIiQlSpUkXccccdYvbs2T4vy568e7I7zo4B8+bNE82bNxdRUVGiZs2a4r333hPfffedw75z7tw50atXL1GuXDkBwGY/yMnJESNHjhR169YVkZGRokKFCqJ9+/biww8/tJTd3bHCWffkU6dOib59+4rExESRkJAg7rvvPnHmzBmv9nNSj04IDV3iEmlAnz59Au7OSUREymCOCpVp9sPdHzx4EPPnz7cZypuIiNTDGhUq0ypVqmS598fx48cxefJkFBQUYOvWrQ5jgxARUeljMi2Vad27d8eMGTNw7tw5GAwGtGvXDu+++y6DFCIijVC1RmXMmDEYO3aszbQGDRp4Nbw6ERERXftUr1Fp0qQJlixZYnkeHq56kYiIiEgjVI8KwsPDkZaWpnYxiIiISINUD1QOHjyIypUrIyoqCu3atcP48eOd3jgMkEZtlI+maL7za3Jysk/DbhMREZF6hBDIyclB5cqVHW7kaU/VHJUFCxYgNzcXDRo0wNmzZzF27FicPn0au3btcrgbKuA8p4WIiIhC08mTJ1G1alW382iqe3JmZiZq1KiBjz76CI899pjD6/Y1KllZWahevTpOnjyJ+Pj40iwqERER+Sk7OxvVqlVDZmYmEhIS3M6retOPXGJiIurXr+/y7rUGgwEGg8Fhenx8PAMVIiKiEONN2oamRqbNzc3F4cOHUalSJbWLQkRERBqgaqAyYsQIrFixAseOHcOaNWvQt29f6PV69OvXT81iUSBObgA2fA1op0WRiIhCmKpNP6dOnUK/fv1w6dIlpKSk4KabbsK6deuQkpKiZrEoEN/eJv1PqAY06K5uWYiIKOSpGqjMnDlTzdVTMF08wECFiHxiNBpRVFSkdjFIAREREdDr9YosS1PJtEREVPYIIXDu3DlkZmaqXRRSUGJiItLS0gIe54yBChERqcocpKSmpiImJoYDeIY4IQTy8vKQnp4OAAF3kGGgQkHCZFoi8sxoNFqClOTkZLWLQwqJjo4GAKSnpyM1NTWgZiBNdU8mIqKyxZyTEhMTo3JJSGnm7zTQvCMGKkREpDo291x7lPpOGahQcHAcFSIiUgADFSIiIo2oWbMmJk6cqHYxNIWBChERkY90Op3bvzFjxvi13I0bN2LIkCHKFjbEsdcPBQmbfojo2nX27FnL419++QWjR4/G/v37LdPi4uIsj4UQMBqNCA/3fMrlyOyOWKNCRETko7S0NMtfQkICdDqd5fm+fftQrlw5LFiwAK1atYLBYMCqVatw+PBh3HXXXahYsSLi4uJwww03YMmSJTbLtW/60el0+Oabb9C3b1/ExMSgXr16mDdvXil/WnUxUCEiIk0RQiCvsFiVP6FgR4DXXnsNEyZMwN69e9G8eXPk5uaiZ8+eWLp0KbZu3Yru3bujd+/eOHHihNvljB07Fvfffz927NiBnj17on///sjIyFCsnFrHph8KDvb6ISI/XS0yovHoRaqse8+4boiJVObUOG7cONx2222W50lJSWjRooXl+VtvvYU5c+Zg3rx5GDZsmMvlDBo0CP369QMAvPvuu/j000+xYcMGdO9eNu6nxhoVIiKiIGjdurXN89zcXIwYMQKNGjVCYmIi4uLisHfvXo81Ks2bN7c8jo2NRXx8vGV4+rKANSpERKQp0RF67BnXTbV1KyU2Ntbm+YgRI7B48WJ8+OGHqFu3LqKjo3HvvfeisLDQ7XIiIiJsnut0OphMJsXKqXUMVChI2PRDRP7R6XSKNb9oyerVqzFo0CD07dsXgFTDcuzYMXULFQLY9ENERFQK6tWrh99//x3btm3D9u3b8dBDD5WpmhF/MVAhIiIqBR999BHKly+P9u3bo3fv3ujWrRuuv/56tYuleTqhZF+sUpadnY2EhARkZWUhPj5e7eIQAIxJkP7f+gZw8wh1y0JEmpefn4+jR4+iVq1aiIqKUrs4pCB3360v52/WqBAREZFmMVAhIiIizWKgQkESsi2KRESkIQxUiIiISLMYqBAREZFmMVCh4GDLDxERKYCBCgUJIxUiIgocAxUiIiLSLAYqREREpFkMVCg4QnfAYyKiUtG5c2cMHz7c8rxmzZqYOHGi2/fodDrMnTs34HUrtZzSwECFiIjIR71790b37t2dvvbff/9Bp9Nhx44dPi1z48aNGDJkiBLFsxgzZgyuu+46h+lnz55Fjx49FF1XsDBQISIi8tFjjz2GxYsX49SpUw6vTZ06Fa1bt0bz5s19WmZKSgpiYmKUKqJbaWlpMBgMpbKuQDFQoSBh0w8RXbvuuOMOpKSkYNq0aTbTc3NzMWvWLPTp0wf9+vVDlSpVEBMTg2bNmmHGjBlul2nf9HPw4EHcfPPNiIqKQuPGjbF48WKH97z66quoX78+YmJiULt2bbzxxhsoKioCAEybNg1jx47F9u3bodPpoNPpLOW1b/rZuXMnbr31VkRHRyM5ORlDhgxBbm6u5fVBgwahT58++PDDD1GpUiUkJydj6NChlnUFU3jQ10BEROQLIYCiPHXWHRED6HQeZwsPD8cjjzyCadOmYdSoUdCVvGfWrFkwGo14+OGHMWvWLLz66quIj4/H33//jQEDBqBOnTpo06aNx+WbTCbcfffdqFixItavX4+srCybfBazcuXKYdq0aahcuTJ27tyJJ554AuXKlcMrr7yCBx54ALt27cLChQuxZMkSAEBCQoLDMq5cuYJu3bqhXbt22LhxI9LT0/H4449j2LBhNoHYsmXLUKlSJSxbtgyHDh3CAw88gOuuuw5PPPGEx88TCAYqRESkLUV5wLuV1Vn3/50BImO9mvXRRx/FBx98gBUrVqBz584ApGafe+65BzVq1MCIESMs8z777LNYtGgRfv31V68ClSVLlmDfvn1YtGgRKleWtsW7777rkFfy+uuvWx7XrFkTI0aMwMyZM/HKK68gOjoacXFxCA8PR1pamst1TZ8+Hfn5+fjhhx8QGyt99s8++wy9e/fGe++9h4oVKwIAypcvj88++wx6vR4NGzZEr169sHTp0qAHKmz6oeBgrx8iusY1bNgQ7du3x3fffQcAOHToEP777z889thjMBqNeOutt9CsWTMkJSUhLi4OixYtwokTJ7xa9t69e1GtWjVLkAIA7dq1c5jvl19+QYcOHZCWloa4uDi8/vrrXq9Dvq4WLVpYghQA6NChA0wmE/bv32+Z1qRJE+j1esvzSpUqIT093ad1+YM1KkREpC0RMVLNhlrr9sFjjz2GZ599Fp9//jmmTp2KOnXqoFOnTnjvvffwySefYOLEiWjWrBliY2MxfPhwFBYWKlbUtWvXon///hg7diy6deuGhIQEzJw5E//73/8UW4dcRESEzXOdTgeTyRSUdckxUCEiIm3R6bxuflHb/fffj+effx7Tp0/HDz/8gKeffho6nQ6rV6/GXXfdhYcffhiAlHNy4MABNG7c2KvlNmrUCCdPnsTZs2dRqVIlAMC6dets5lmzZg1q1KiBUaNGWaYdP37cZp7IyEgYjUaP65o2bRquXLliqVVZvXo1wsLC0KBBA6/KG0xs+qEgYdMPEV374uLi8MADD2DkyJE4e/YsBg0aBACoV68eFi9ejDVr1mDv3r148skncf78ea+X27VrV9SvXx8DBw7E9u3b8d9//9kEJOZ1nDhxAjNnzsThw4fx6aefYs6cOTbz1KxZE0ePHsW2bdtw8eJFFBQUOKyrf//+iIqKwsCBA7Fr1y4sW7YMzz77LAYMGGDJT1ETAxUiIqIAPPbYY7h8+TK6detmySl5/fXXcf3116Nbt27o3Lkz0tLS0KdPH6+XGRYWhjlz5uDq1ato06YNHn/8cbzzzjs289x555144YUXMGzYMFx33XVYs2YN3njjDZt57rnnHnTv3h233HILUlJSnHaRjomJwaJFi5CRkYEbbrgB9957L7p06YLPPvvM940RBDohQjfrMTs7GwkJCcjKykJ8fLzaxSEAGFPS9a3Tq8At/6duWYhI8/Lz83H06FHUqlULUVFRaheHFOTuu/Xl/M0aFQqO0I1/iYhIQxioEBERkWYxUCEiIiLNYqBCQcKmHyIiChwDFSIiUl0I9+sgF5T6ThmoEBGRasyjneblqXQTQgoa83dqP6KtrzgyLQUHr46IyAt6vR6JiYmWe8bExMRY7kRMoUkIgby8PKSnpyMxMdHm/kD+YKBCRESqMt/ZtzRucEelJzEx0e1dm73FQIWIiFSl0+lQqVIlpKamoqioSO3ikAIiIiICrkkxY6BCQcKmHyLyjV6vV+zkRtcOJtMSERGRZjFQISIiIs1ioELBwV4/RESkAAYqREREpFkMVIhIGYUcsIuIlMdAhYKETT9lyoLXgHcrASfWq10SIrrGMFAhosCtnyz9//ctdctBRNccBipEpBwmURORwhioUHDwhFU2CZPaJSCiawwDFSJSEANUIlIWAxUiUo7JqHYJiOgaw0CFgoRX1mUSm36ISGEMVIhIQQxQiUhZDFSISDmsUSEihWkmUJkwYQJ0Oh2GDx+udlFICez1UzbxeycihWkiUNm4cSOmTJmC5s2bq10UIgqEYDItESlL9UAlNzcX/fv3x9dff43y5curXRwiCgRrVIhIYaoHKkOHDkWvXr3QtWtXj/MWFBQgOzvb5o+0iiesMomBChEpLFzNlc+cORNbtmzBxo0bvZp//PjxGDt2bJBLRUR+YzItESlMtRqVkydP4vnnn8fPP/+MqKgor94zcuRIZGVlWf5OnjwZ5FISkW9Yo0JEylKtRmXz5s1IT0/H9ddfb5lmNBqxcuVKfPbZZygoKIBer7d5j8FggMFgKO2ikj/YBFA2cWRaIlKYaoFKly5dsHPnTptpgwcPRsOGDfHqq686BClEFALY9ENEClMtUClXrhyaNm1qMy02NhbJyckO04koVLAmjYiUpXqvHyK6hrBGhYgUpmqvH3vLly9XuwhEFAjmJhGRwlijQkTKYaBCRApjoELBwRNW2cSmHyJSGAMVIlIOAxUiUhgDFQoS1qiUSQxUiEhhDFSISEEMUIlIWQxUiEg5rFEhIoUxUKHgYDJt2cRAhYgUxkCFiJTDQIWIFMZAhYiUw0CFiBTGQIWChE0/ZRK/diJSGAMVIlIOa1SISGEMVIhIOQxUiEhhDFQoONjrp2xioEJECmOgQkTKYaBCRApjoEJECmJNGhEpi4EKBQlPWGUSa1SISGEMVIhIOQxUiEhhDFSISDkMVIhIYQxUKDjY64eIiBTAQIWIiIg0i4EKERERaRYDFQoSNv0QEVHgGKgQERGRZjFQISIiIs1ioELBwV4/RESkAAYqREREpFkMVIiIiEizGKhQkLDph4iIAsdAhYgCFxaudgmI6BrFQIWIAle+lvVxfrZ65SCiaw4DFQoO9vopWwzlrI+zz6hXDiK65jBQoSBhoFK2yL5vYVSvGER0zWGgQkTKEia1S0BE1xAGKkSkLDb7EZGCGKhQcPBkVbbYfN/87olIOQxUSDkMTghg0w8RKYqBChEpQJ5My4CViJTDQIWChCersovfPREph4EKKYdX0gQwTiEiRTFQIaLAyYNU5qgQkYIYqFBwsHalDON3T0TKYaBCCuIJquxiMi0RBQcDFSJSFpt+iEhBDFQoSHhVXXbxuyci5TBQIeWwyr/sshmYlvsBESmHgQoRKYtNP0SkIAYqFBy8qC7D+OUTkXIYqJCCeIIqu9jrh4iCg4EKESmMgQoRKYeBCgUJT1ZlCkemJaIgYaBCymGVPwHcD4hIUQxUiEhhDFSISDkMVCg4eFVdxjCZloiCg4EKKYgnKAIDFSJSFAMVIgqcTXDCQIWIlMNAhYKEJ6syi71+iEhBDFRIOazyJ4D7AREpioEKESmATT9EFBwMVCg4eFVddrHph4gUxECFFMTgpMwS7J5MRMHBQIWIFMZAhYiUw0CFgoQnqzKLNSpEpCAGKqQcnqDKMN6UkIiCQ9VAZfLkyWjevDni4+MRHx+Pdu3aYcGCBWoWiYgCxoCViJSjaqBStWpVTJgwAZs3b8amTZtw66234q677sLu3bvVLBYpgbUrZQuTaYkoSMLVXHnv3r1tnr/zzjuYPHky1q1bhyZNmqhUKvIfT1AEBipEpChVAxU5o9GIWbNm4cqVK2jXrp3TeQoKClBQUGB5np2dXVrFIyKvMVAhIuWonky7c+dOxMXFwWAw4KmnnsKcOXPQuHFjp/OOHz8eCQkJlr9q1aqVcmnJezxZlS1s+iGi4FA9UGnQoAG2bduG9evX4+mnn8bAgQOxZ88ep/OOHDkSWVlZlr+TJ0+WcmnJLZ6gCGCvHyJSlOpNP5GRkahbty4AoFWrVti4cSM++eQTTJkyxWFeg8EAg8FQ2kUkIk8E7/VDRMGheo2KPZPJZJOHQiGKtStlF797IlKQqjUqI0eORI8ePVC9enXk5ORg+vTpWL58ORYtWqRmschvPEER2PRDRIpSNVBJT0/HI488grNnzyIhIQHNmzfHokWLcNttt6lZLCLyGZt+iCg4VA1Uvv32WzVXT0HFk1WZxaYfIlKQ5nJUKIQpfYIymYDLx5VdJpUCBipEpBwGKqRdfz4LfNIc2DxN7ZKQJ4I3JSSi4GCgQsGhxMlq60/S/2XjA18WlR42/RCRghiokIKCdVXNE5/2MZmWiIKDgQoFB6v/yy7WqBCRghioUHAoebLiiS+08PsiIgUxUCHlBC2hkic+zeMQ+kQUJAxUKDjY9FN28bsnIgUxUKHgUPJkxaaEECCvTeP3RUTKYaBCCmLTDwH8vohISQxUKDhYo1J2semHiBTEQIWCw2RUcGEMVDTPJpeW3xcRKYeBCiknWL1+eOILMfy+iEg5DFQoOBhclDFMpiWi4GCgQsHBZNqyizkqRKQgBioUHIo2/Si3KCoN/MKISDkMVCg4eFVdtgg2/RBRcDBQoeAQ7PVTZjFQISIF+RWonDx5EqdOnbI837BhA4YPH46vvvpKsYJRCGKvnzKM9/ohouDwK1B56KGHsGzZMgDAuXPncNttt2HDhg0YNWoUxo0bp2gBKUQxmbbsYmBJRAryK1DZtWsX2rRpAwD49ddf0bRpU6xZswY///wzpk2bpmT5KFQxR6Xs4ndPRAryK1ApKiqCwWAAACxZsgR33nknAKBhw4Y4e/ascqWjEBOkhEpeoWufYNMPEQWHX4FKkyZN8OWXX+K///7D4sWL0b17dwDAmTNnkJycrGgBKUSx6afsYmBJRAryK1B57733MGXKFHTu3Bn9+vVDixYtAADz5s2zNAlRGcdk2jKGNSpEFBzh/rypc+fOuHjxIrKzs1G+fHnL9CFDhiAmJkaxwlGIkQcUvClh2cUcFSJSkF81KlevXkVBQYElSDl+/DgmTpyI/fv3IzU1VdECUohijUrZxe+LiBTkV6By11134YcffgAAZGZmom3btvjf//6HPn36YPLkyYoWkEKUogO+keYxmZaIgsSvQGXLli3o2LEjAGD27NmoWLEijh8/jh9++AGffvqpogWkUBKkAd944gstbPohIgX5Fajk5eWhXLlyAIB//vkHd999N8LCwnDjjTfi+PHjihaQQpSJTT9lFr8vIlKQX4FK3bp1MXfuXJw8eRKLFi3C7bffDgBIT09HfHy8ogWkEMWr6jKGTT9EFBx+BSqjR4/GiBEjULNmTbRp0wbt2rUDINWutGzZUtECUgixudcPe/2UWaxRISIF+dU9+d5778VNN92Es2fPWsZQAYAuXbqgb9++ihWOQhh7/ZQtIkijEhNRmedXoAIAaWlpSEtLs9xFuWrVqhzsjaw4jkoZxu+LiJTjV9OPyWTCuHHjkJCQgBo1aqBGjRpITEzEW2+9BZOSSZQUYoLV64dCCr97IlKQXzUqo0aNwrfffosJEyagQ4cOAIBVq1ZhzJgxyM/PxzvvvKNoISkEsemnjGHTDxEFh1+Byvfff49vvvnGctdkAGjevDmqVKmCZ555hoEKcRyVMo3fFxEpx6+mn4yMDDRs2NBhesOGDZGRkRFwoTTv0FLg7Ha1S6E9gk0/ZRaTaYkoSPwKVFq0aIHPPvvMYfpnn32G5s2bB1woTbt0GPjpbmDKzWqXRNsUTaal0MJAhYiU41fTz/vvv49evXphyZIlljFU1q5di5MnT2L+/PmKFlBzLh9VuwShgTUqRESkAL9qVDp16oQDBw6gb9++yMzMRGZmJu6++27s3r0bP/74o9Jl1BZeLLoRrAHfSPvY9ENEweH3OCqVK1d2SJrdvn07vv32W3z11VcBF4xCHGtUyjAGKkSkHL9qVMo0ndoF8MKeP4DD/6pdCmVvTEjaxmRaIgoSv2tUSKOyzwK/PiI9HpNVuuu2P0EJExgLl0UMVIhIOTyL+Errx+C8i2qXwIp5KkREFCCfalTuvvtut69nZmYGUhZSmhCATsW2KuaplCFs+iGi4PApUElISPD4+iOPPBJQgShQssCk1AMV+6YfnrDKJn7vRKQcnwKVqVOnBqscpBSbwETtE4ba66dSw2RaIgoS5qj4LIQOwmqfMNReP6mE3zsRKYeByjVH3vRTyjkiDoEJT1hERBQYBio+C4WBVMxYo0KlRTh9SEQUKAYqPlPgKGwyAlt+BC4eCnxZ7qgeKKi9flIHv3ciUg4HfFPD5mnA3y9Kj5UelE2nYtMPe/2UXfKvmt87ESmINSpqOLm+lFak9glD7fUTEVGoY6ByzbEbR0VNaq+fVMLvnYiUw0DFV6F08lW91w+VHRxHhYiCg4HKtUZLA75xCP0yioEKESmHgUogtH7lqHb51F4/qYPfOxEpiIGKr3QaygHxRO1eP7yyLju0/lsgopDFQMVXihyQgzlonIYGpOPJq4zi905EymGgEhCNH5BVDxTUXj+VHibTElFwMFAJhBYPyGom09pvDy1uHyoFTr73DV8D/2sEXDhQ+sUhopDGQCUgGjwRy4MD1XvdaHD7UPA5C1DnjwByzlhHZCYi8hIDFZ9p/eSroSp4tddPpcfb79pUHNxyENE1R9VAZfz48bjhhhtQrlw5pKamok+fPti/f7+aRfKNFk/ENmUq7fKx1w8Bbr93Lf5miEjTVA1UVqxYgaFDh2LdunVYvHgxioqKcPvtt+PKlStqFssDBXJAdMHsmaOhph+elMoQDdXkEdE1RdW7Jy9cuNDm+bRp05CamorNmzfj5ptvVqlUpaC0DuSqnzDUXj+pw933zn2CiHyjaqBiLysrCwCQlJTk9PWCggIUFBRYnmdnZ5dKuWxp/MpRzaYf9vohT7hPEJGPNJNMazKZMHz4cHTo0AFNmzZ1Os/48eORkJBg+atWrVopl9Iem37cUnv9VHqEtwE8AxUi8o1mApWhQ4di165dmDlzpst5Ro4ciaysLMvfyZMnS7GETmjx6tDrE0ZpUHv9pA4m0xKRcjTR9DNs2DD89ddfWLlyJapWrepyPoPBAIPBUIolC0Vq9vqxw5NSGcIaFSIKDlUDFSEEnn32WcyZMwfLly9HrVq11CyOd1Tt/usFTQ34RkREFBhVA5WhQ4di+vTp+OOPP1CuXDmcO3cOAJCQkIDo6Gg1i+YdTdYYaKjpR+31k/ZwnyAiH6maozJ58mRkZWWhc+fOqFSpkuXvl19+UbNY7ql5Lx2tczgJcfuUGd7mRrGWj4h8pHrTT9kUxF4/Wmr6KbPfb1nHHBUiUo5mev2EDE31qnFGS+VTe/1UerS03xHRtYSBSkA0eEDW0r1+eMIqo9g9mYiUw0AlEJo86Grpylbt9ZP2cJ8gIt8wUNGiA4uA6Q8Cuem+v9emQoU5KlRKvE6mDX5RiOjawkDFZ6XQtDL9fuDAAmDhawEuSO17/bCHR9nEZFoiUg4DlUD4W2Pg7b1+cs77sXA2/ZAavK1R4T5BRL5hoOIzBboWe32w9uOgzu7JRESBEwK4mql2KQgMVJw6ciEXP649hvk7z6pbEL9O9Brq9cMalTKKTT90DfjzOeC9GsCxVWqXpMxjoOLE/n27sPuvSdi//GcnryrQtOJt04+rg/rxNcDcoUBehpO3aKjpR+31U+nxOpmW+wSFiC0/SP9XvKduOUgbd0/WmnpXNqNHxDfYnNkcwAg3cwb5oOvqoD61R8nrJqDvZPs3yR6qnczKk1LZxCH06RoSFqF2Cco81qg4EVP9egBAneIjECY3B9agXx16WH7GESdvUbHpx6HXDwOVskNDNXlEStIzUFEbAxUnkmq1QJHQI1GXi+wLJ2xfVPogHNDyPLxX9fOF6gUgzeE+QSEmjA0PamOg4kRUdAwu6soDADLOHnczpwIH3UDa851Wo2uo6YfnpDKKOSp0DWGgojoGKi7k6KVAJfviabtXFK7idhtMeApUnLyupXv9MFIpO7xO4uY+QSGGTT+qY6DiwlVDMgAg77JdF2VFrghlvX7cBSp+1YhoKFdA7fWTSlijQtcQJtOqjoGKC8XRFaT/2fajwypcY+E2UPG0fA81Kmo3/fDquWxijQpdS8L0apegzGOg4oIxMgEAoC/Itn1B6XFKAgkmnK5fS71+1A6UqPR4ua+xRoVCDZt+VMdAxYWw8EgAgDAV272idCAQwNWns0CAA74RESmHTT+qY6Digq4kihbGItsXFO+eHMxxWtQOFNReP6mCTT90LWGNiurY78qFsPCSndMcqJiMwPQHgAv7rDMpEbRcPg5UqA+U1ODY8iNHRdXuyRzwjQAm01LIMxmtj9k9WXWsUXFBb65RMTf9HF8NHFoMZJ2UzaXAQffLDsC0Xs5f8zTSq6fuyaqfFNReP2kP9wkKAcUF1scMVFTHQMUFa41KSaBiLHScSalA4NQGFy/Ilj93KDCpFVCY52H9ao6jYkf1QIlKhS+3Tgj6XSeE85t1EvnCKAtU2PSjOgYqLuhLmmJ0piIPc5aSbT8BGYeBfX+5n0/N7skOJ6hAz0re3mWatEXFHJX5I4D3awH7FwZ3PXRtk+cm6tg9WW0MVFzQR0hRtM6h149csO+e7GyaydMMsochXqOi01CgcnAJ8PcI2yphkmjpZpQbv5H+Lx2nXhko9Nl3oiBVsfHNhXBzcqtwE6j4e0D2uqYj0BwUtZterqEalZ/vkf4nVgc6PKduWTRPC8m0au/7FNLkx2iOB6U61qi4YK5RCQtGjYq3O76nHBSn46h4en8wKXxlLa9RUbt2yMwmmZp8VloHfa3sLxSaGKhoCgMVF8w1KmHualT85u1B1NNNBz28R/WDtYI1Kqp/FnLNlwC1lL5HnlwoIFq6FQkxUHEh3JyjIoyuZwp604/TN7t4bJ50rfb60UqgoqHmKM3SwnelhTJQyNLUPdOIgYoL5l4/erc1Kio0/XjMUdFQr59QafopyA3esssCn7onl1aNCgMVCgQDFS1hoOKCeQj98KAk0/rY9OMqutf6vX4UbfoJ0sHi8DJgfBXgn9eDs/wySQNNP6xRoUCwRkVTGKi4oC8Z8C0Mbpp+/OVrjYp8OGefhtVn049H5gBlzSTv5tdSl+lQxBoVCgVaakInBiqumEemDYcRJlMp3ojQdkbpn7znkS8/ILXv9RPoD1xXCjUqpAANJtPy5EIBYY2KljBQcSFML+WoRMAIo6sDr99XbV6+z7x84aJGRev3+gl4/ez1E5q0kKPCkwsFwKaJnccetTFQccE8jooeRhgVr1HxcXnyph+PNSpaqrJ0sX5jMbDw/4D9C9y/nTUqoUFLI9NqqQwUupijoikMVFwIK0mmjdAZUewyUCmlkWltBp3TcI2KtyesnbOAdZ8DMx70ZeF+F8s9X3NOmKMSGDb9UChgoKIlDFRcMHdPDocRRqPCTT/evs/S9OOqGlJj3ZMduPicuee9fL+PNSrGYuvdrklFWmj6KZ3V0DWKNSqawkDFBX24dBskPYwoNrnaUYM9jkrJfPKmH5fNQM6maTRHpST/xyNfxlERAviyAzCxGYOVUufLOCqlddBnpEIBYI6KpjBQcUEnT6Y1CSha5R9I04+pyPF1l28v7R+Yl71+SprVfFu0h21WXABc2AfknAEuH/N9+aQgDRzYeXKhgLBGRUsYqLiil2pUwmHOUfFUe+ELH98n7/Vj01XZw7LVPlgHWqPib3BYdMW/95F/HHKT3M4czJLIVsOTCwWATT+awkDFlTBroOK6108pDaEvb+4xukistX+Pq9dLk6vPKQ9U3AVTPjX9yNZVdNVz2fzFAd8CU2q7JGtUKBAMVLSEgYorYdYB34pdNf0E/aaETgIVl4O/2b3H5etB5LA+L5p+TF7mk3jcZrJ1FbJGRV0aGPBN7dpECm2eblVCpYqBiivme/3oTDAajVD0AOt1rx/zf3mg4iFHRUtVlt40/RTne7sw79cVzBoVcsKXZFp2T6YQoKWBM4mBikthesvD4uIiFzOpMI6KLzUqqh+svahRKS5083Yfgi6bpp88z0Uz87klh00/nrFGhUKdhi74iIGKS2HWk6mxuAjKNv34OI6Kvzkqavf6cbl+2bZ0W6Piy2dh049maCJI0EIZKGQJl09IBQxUXJFd9ZtcXvWr3evHhwRTLZGXy1jgZr5SqFGhwPkSmPBePxQKmKOiKQxUXHGoUXFRe1GQ4/uylUqm9RjwqN3rx4veUsVuAhVX7/G0Lvb6URmbfijUselHSxiouBIWBlNJE4VwNdLpn88B46sCpzb5tmxnO/75PcBP9wCnN8vmcxKoeBoxUc1kWofiuDhZyMvlNlDxpUZFS7k5ZQ2Taekao6VOCcRAxZ1iSAm1Rlcn0zNbpf8r3vdtwc4O1j/dDRxaAnx9q3zGkn8uAhWP9/rRaI2K8LJGxad8G+H0IamBNSqaVZALXM1UuxTax6YfTWGg4oYR0qBvpuIiZY+vznb8nLNO5nPS60f4cK8f+byq8KJGxeSqR5WXy3K2TJ8OLGzKKVWsUVHX+CrAezWYcO4Ra1S0hIGKG0adVKNiKi5Wbmctugqc9rGpyOWNCD3UqLi8mWKweNsEIC+juwHf/Gz6UT1AK2MchtDXQo1K6awmZGUcUbsE2sZxVDSFgYobxpKmH5PRRTKtP/5+yYeZPTT9XBM1Km4CFV8OFqyq1RANHNi5Dzhi3oUPuK20hIGKG0ad1PQjjIXKRdXbfvZ+Xk/JtJ5OCCaVAxVXP3D5tnSVqOzuPc5n8Lxeb+ycDfz6CFDILs7eYzJtSPB0kUNW3FaaEq52AbTMZG76MRZDnQRBZ92TPeSoQMUaFW+bAOTTvW368SVHJZAA7bfHpP9pzYCbX/Z/OWWau0CllK5OeXJxxFpH77H2SVMYqLhhTqYVRoWTab1l/rG4PMBorHuygwBzVHwa8E3hz33lYuDLICdYo6Ia5l34QEvHUWLTjxuWpp/iInV+2OYfiKtAxWmR5EGA2k0/AeaoeLMsZ8tU4sDian0c8M2RT8m0pUQLZdAa1qh4T1MXfMRAxQ1R0vQjPDb9BK0EJf/kBxij4+s2b1HzB2ZfHm+aftwFU758FoU/N9uoA8AcFU1ioOI9bitNYaDihjWZtkidndVp04+n6ttQq1FxM46KL6PN+huguaohYaDiAy12T+Z35oi1BN7z4dhDQcdAxQ2TpUbFQ6+fYB0U/clRsXm/Rrsnu8tRuXgQ+LoLsH+h7Xy+NP0oEqC5Oqiz6cczDRzYeSJ2xFoC79nEKdxWamMyrRsmc42KSaWmH485Khpr+vG614+bHJXfHgfObgNmPADowpy/x2M5FG760cKJl3zE78wBAxXvcVtpCmtU3DCFlcRxxmLtJNOaPOSoaKnpx58clasZzufzaQh9BT43k+m85xCgqlMMG2z6ccQbd/qAPaS0hIGKGyZdBABAmNTKUQm0RiUUclTsalRKmttKZnT+Hk/rUjyZVvaYvX68oIUDuxbKoDGsJfAeL1Q0hYGKG+amH52xUKUS+JOjIq+tULvXjxfzOQQqLnbJUh9Cn1dU3mP35JDDk68HDFS0hIGKG6YwqUYFRk/jqAQrmdZZjUoI3T3Z5RD6sulGu14//gYqfgdornr98EAV2hioOGCNivfY609TVA1UVq5cid69e6Ny5crQ6XSYO3eumsVxYA5UdMZClZp+nAyh79Pdk9UOVPzIUXEVqPiUoxLEph/yAg/smmTT5Mp92i0tXfCRuoHKlStX0KJFC3z++edqFsMlS41KKPX6cfb+0uKQVOnFTQm9bvrxJUdF4WRam++eOSoOtDgyLTniydcHGrrgI3W7J/fo0QM9evRQswhuCZsaFY0EKsdXy2dw8h4NHYxcBhchlqNy4B8FlleWMFDRJH9uXVFWaek4SqE1jkpBQQEKCgosz7Ozs4O6PlHSPVlnKoI6B19zMq2f61b7SsDVD9xtrx8/m36COYT+748HvryyhDUq2qT4oIjXMDaTaUpIJdOOHz8eCQkJlr9q1aoFdX2WGhW1uicDwL9ve9eE4mya2vf68arpxz5HxYsh7T29rsRBmDclvGbkFRZj1qaTuJRb4Hnma5qbmkyywxoVLQmpQGXkyJHIysqy/J08eTKo6/O6108wryBXfuBdzYR1ovWh2ldNLtcvL6NCvX6COY6KL+UgaK3pZ9yfe/Dy7B0Y8O0GtYuiLiaIe89dHh2VupBq+jEYDDAYDKW3Qn0kACBMtaafEkVXXbwQojkq7pp+wvRwytNnKa1ARWMnYU2wD95yzwMFOYChnDrlsfP3jrMAgD1ng9tUrHnMUfEem8k0JaRqVEqbueknTKjY9ANIB31/hGKvH1e9ajweWP0MVFw25XjRtZpcW/au2iUge+6aXMk1tS/4SN1AJTc3F9u2bcO2bdsAAEePHsW2bdtw4sQJNYtlpS8JVEyeBnwLssIrPszsxcFoxyzgi3bApcMBFcsjV+t3d7XiqunHfmA4d8tUpEbFi+H/ybXzu9UuAdljjYr3bII6/ubVpmqgsmnTJrRs2RItW7YEALz44oto2bIlRo8erWaxLITenEyr0jgqZoW53s/rTdPP748D6XuAP4YFVi6PZfGje7Krph+PgYrCV4sMSHzg5LfhsvcWgAIf9mcFVMBljAufinq6U6W6Xs3RUrOw5jFHRUtUzVHp3LkzhJar0sNKclSESkPom/kSqPgylHx+ll/F8WrdgLLdk+2Tbt2tO5hBhpb3Vy1xF6jMfhTo/2upFWUCPkXb8N14UP8vgCdLbb3aw6Yfryl9N3YKCHNU3ClJptWr2T0Z8HwFuvl7YGJz4OJB366agv0DdNn0IyujQ02Ji5wRX5p+jiwDvroFOL/HYxFdlsubRGCSOAve3AUqBxd5v+zDy4BfBgA5530vV4nGuiMAgEhdGT/hMEHUe8zn0RQGKm7o5DkqavJUo/Lnc0DmceDP5+HTVVOwf4BKjqPiS9MPAJzZAvw6wP177MnLcnwNYHRW5csaFa+4C1R88WMfYO88YP5Lfi9C8LYHEna59QGbybSEgYob5hwVvShWpso/94J/7/O2Tb8oz7duukofrLzt9eNPjoqnYNHZuvIuuX8PAJsaHPky8jOBFe95tx5ypFSgYnb5mLLLK4vYnOE91qhoCgMVN3Th5hyVYmVOUKs+9u99F/Z6N5/9D6q0m34O2t0Tx59xVPzt9aNETYd9eVd95GQe1qg48rHpxx8BnSxYowKAvX58wWYyTWGg4o45R0V4GPDN25OXsTDwMrkjTPCt6UfB2oH8LGDNp3bL9yJHxdtxVHzJUfGXfeDm9GDOQMUrSt9qwGOg6hq/MTN3uWFky8umn8vHgeIgH9eJgYo7OkvTj0LjqETGBr4Md87vsm0m8nh/HAWvFDKOer98t1crLrazx6YfJ++7ehm4ctH9+1yVK5B5yhpfk2n9wRqAwMn3XX8HkSwrvGn6ObkB+KQ58G3X0ilTGcZAxQ2dpUZFoXFUDHGBL8Oe/Ulixy/Wxx5rVBQ8+Gced5y26TvHEUozjtg2EdkHIK6COU+1Ua4CiLWfuX+fN8uwmYfX516RBypKbLMA9lUm05awCVTK+O0EPPGmmWz7DOn/2e3BL08Zx0DFDXOOil6pHJXIYAQqduWS1yB4TKZVsEYl08UNIle8B2TJBtr6tCVwdpv1ubEQOLUJKMqXnrs6qTntgSPn4n3m5XrDm+3BGhXvKB2osKkicPLvIZ+BinvC9rGzfTgspG6VF9IYqLhhrlEJV6rXT8nyFGV/4iySDbd/agOwe67r9yoZqLgb5v/sDtevndkKfNMF+O0x92Xyp+nHm/d5swzbmbxfXpnhqelH3RoVKiHfv1mj4p79scDZcUnnoociKY6Bihth4VKOSrinZFp3r5lM1rsfB+Nq3NMyZw10814FA5ViWc1FahPb15w1C9nb95f7MhkLgcWjgb9fcp4E7LImxodENzb9KEfxpp9AkmnZ9AOAOSo+8WKUbVdDKZDiGKi4YalRgYemH3cH4h/vAt5JA2Y8FJyrQm9qRVwdlOzfm5vu/0nFHKh0GA5c18/2NV+q7V1t56uZwOpPgI3fAPv/9v59ntYt753iTeDGQMVRqSTT+h9U8xszk22Jq5fVK0Yo8KZGhYFKqWGg4kZYhAJNP0dXSv/3/x2cQMWbWoCccy7eK/vx7ZwNfFjPMfnVW+ZAJSLasUrUl8/t6oQkv9PzmW1OZnBVo+JDkOTVyZCnPa9ouemnrHYnlR8rMo4AF/arVxatcwhUnOx/zFEpNQxU3NCFGwAAiciWhlQPlKtmiOjy/i/Tq0DlrPPp8h/f3yVDlK98379yFBdI/8MNjlcavpxkXNVqnJBt/+zTTt7nYjv40mQwz8ndpIsLgLRmntdDtjSVTCurNcs+A7xXA5g7NOAihRz77+HUJnXKERK8afphoFJaGKi4oQ+XJb8eWhz4AgvznE+PTfV/md6cOLNdBCry9wbaI8mchxMe7VjtbyoG8jKAc7vcL0MIaw2UWdexjvPJexHJ3+uMLye4w/86TivIsbstAWtUHDlr+tG5f93nVSiUT7Xha+lWE9t+UmZ5ocT+WOFN7lhZ5VCj4uQ4y2TaUsOQ0A1zMq1nXh6Ii1wEKnGpwEU/q2G9CVS8uedNZIx/6zeT16jYl8lUDHx2A5DnYfC1/fMdp5XUatlwWkOkQDKtXESs1IOqINuuSYiBileUrlHxhxCATmebTBuMnnehwv53eZmBikv228pTMq3JBITxuj9YuGXdCHN2kvSFfRTu6i7IUQnWxxXqWx/HpgL1urlfhzeBypUL0n2G3FX1ygda8+fEUlxSoxLhpEbFWOQ5SAGAo/9ZH+v0QO9PgXq3O1lXgeM0f5NpXTGUk/7nXrA9SLHpx5HTZFqFa1T8URJg2qxd7+3FhxurPwWm3eG6hlSz7L4H1qi44U2OiixQCfbtUco4BipumJNp/bLnD2DlB7bTXI01Yj4pAkCz+6yPX9zjPB9DTn7ivGUU8PhSIKWh7TzrvgCWjJHGK3FFHlwUezFI2skN0siz5toGtzkqXlbby2t+HvgRaDUQSK4DdHrVdj5nwYer4MpZM5ENF11Xo+Kl/9/dDlw84Hk9ZEsLN3JzFlQqUaOy+A3g2H/S/h9KHGpUjqlSjJDgVa8fWYMEA5WgYtOPG/pAalR+fcRxmrNARae3zQ+pc6v0PLq8dPXnabwD+TKv6w8kVAGGrgfGyGppPAUeqz8FTm+2XWZEtPv3zH4MyDoB/PUCcONQa3fH8GjHz+ltMu3VDOtjeeBk3xbs7KDgqqYj47DUy0Oeb7R8grRdu73juiwxyc6ns0bFNV2Ydfvkngcm3wS0fBi43slvoTSUlCVoTT+h1sXX/N2UqyQ1n+aclUZujohSt1xa5FXTDwOV0sIaFTfCA6lRccb+BF63K/DEv7b3ANKFAe2esY5F4qyZI6UhEFZShf3P69bp/mah23dJdhUcFRdYuwlnnbBOX/c5kL5HehxucNI92cvmF/n2MSfnAo4HUqfNOW5qOnJl3bONxcDy8dI9gNy10SfVcfFCiNao7P0TmP6glNSsuJJtEhYO3PaW9PjgP8D5ncDCV6HaNnNaoyJr+gl0WH6jk9+mlplrCWIqWC+Oslzc+qLM86JGRb5/MVAJKgYqboSHe3nit68mdHWTKvsclYdmAZWvs61RsW82yc9yXI4uzFrjYB7RFbANVNo+5bwM8gAAkE7cyXYnZXnAcGI9kHNeerzsXWDS9e6rvA3l/O+eLG/6kZez5QAgvirQoGdJmZ3VqLgLVNKtj+XvdZXcDDhuE2/Wo2W/PAwcWAAsddKLSjE654NgqZZM6+TkIq8ltf8t+CrUxmMxfw86HZBYQ3rM5h/nvGn6kU9zdkFp78pFYGIz4J83AitbGcRAxQ19mI9Db5/cCMx5Gphys/PX7ZPvzAmH8hwV+0TUNo87WZCLE4JeFqj0eA942snYL/ZX1MVXHavDzQHV2R1SjsYnzaXnqydK//96QfofHg28mQnc8rpUA9FuGFD5eifdk73MV5Dnk8iDiJgk4IVdQO9PpOfGQscDidtA5bysLLKraHflqtra+fRQb/rJPqP8MuXb3mmXTXVrVGyafuTlCzhQ8eGGl1pg3nd1OqA8AxX3vBhHRT7Nm9q5Y/8BmSeANZ9yu/uIgYob4WFhOCUqeP+Gb7sC26e7ft3+Ct4cqETaNf3I3eok+tbpnA9Rbt/0k1DNcZ68S44Ha/tyFZQEKua8leJ8YNNUx2XFpkhl6fQy8NwWKecjLMyxbN5cbQC25XC2rSyfTzgGGe4CCJsaFXmg4qamp3p7Fy/4cdK9dBhY8BqQ5SExujQE5TYOJcsMC1d3WHGH4NXZPaHkV8GBBioh1vRj3nd1YUD5mtJj9vxxzn7fcRaIyI9B7mpnzeTH3ZMb/CtXGcVAxQ29XocnC1/EblMNZRboqnuyfGRa+8HfnCX0ehuomHuuyF3NsP0RFuVZa3rMNSuFucCiUcBfw63zyR+b1eroOA1wLJs/V65VnNRoyGt+HJp/vG36kR1wXLUrJ9eTaqcG/un4mj/NGN/fCayfDPw6wPnrW34E/vuodJpIAs3LcLrMku2oj3C+X5ZW0483g3TZnFwCDFRCLkfFXKMSJmv6YaDilMO+5KynoWz/8tQ7034ZZ7b6V64yir1+3AgP02G3qIm1psZoEubmB+1t04ar7sl1bpFySmp0AOJSPC9HF2Y3TkWJMC/GiLhyETYn9aJ8aWAzAIirKCXXrZ9iO2S9vZf2W+d3xv6q2purDbnbxgE1OzhOdwhUZIPUuatRuSILVOQHC/sTVeO7gB4fWMe1KVfJcVn+nHSzS5q05D2r5MxD91drA9S8yffl+yIY3YbNgYqzrukASq/px3mNik3Tj1AwUAm5HBXzb8Su6acgB1g1EWjSx/Z2EWWa3b5kdFITKT/meBPwyZfBQMUnrFFxw5yjEgUPByRvT8SuruAjoqWcksZ3elkynfNcAGcjIz66yPb5FbuB1y7ss9aopDaS/tsHKW2eBAbMkdbZ6E6gXJr05yxYApzUqPgYqDTo5Xy6ux4b3uaoyN9XnG9392QBlKto7WUUlei4LKWbTuRX/c6G8FdaMJp+zCdsvZMeX0Ap1qjYdyl1EqjIA7VAe2qEXI6KrOnHPLBk+l5gyVjgvw+BL4McJIcS+13W2b4i35e8aUKTXySd3RGc2s1rFAMVN/QlJzEDPOxQvp6IA+Ws6afVIOfzVr8RGJMFXD9Qei6vXQCAWQOtbfWdRwIpjRxP0FEJ0vgub1yUBmLzxP7E5Gr7JFQHwqOsvXnMXA3nr9NZa43sDxzualT2/mm9ejba1aic2mh9bj80f3Si47KU7oYoX56ru1wrKRiBirkJJDxS3RoVhxwVDz01Au6erMC+YCwG/h4B7Pot8GV5Im/6Sa4DVGwmnTw3fi2bJ0R7tSnNIUfFWU9DeaBywvF1ezbHniuhN2CgihiouBEWpkOYDojSyXbSdk7usBvsobT7TAZSm8gm2AUqjy2x9ohxJSZJ+n/gH9fzpDQAhq4DXjsO9PnSOt3cFOLtvSzsc3HO7XQ+X5vHgdfPAy0etJ0e4ea+Q+bmH2MhcPGQNOKufXOWM/v+tr7PbP8C23nse8ToIxxv1qj0VZA8z6EgW9llO+PL3aS9ZU4qdVWj4mzslkCbXZxy1fQjn6axGpUjy6RAYfajpRAkyLonA0Cdzo6zyGsfyzT7ph8PybTeNP3YXyQsGROcXnjXIAYqHoSHhWGhsY11grO7+RbleTFUu0yNm4CHfbiCuu4h4BlZc4wuzDZR1pu8lsotpf/nZUFDr/9ZH8ckS92NzeTdcyvKgyQveBpN117VNkBkSRftJnc7r8kwMzf/7F8A/NJfuofR3Kc9dxs+sU76Lz9RZxyxnafza47vkyc6A8onUMp7juRlAL8/Cfz3P9fzByqoOSoualQmXe84zXwnbWORFHAqwZteP/LPH2jtkhK9fuRlvKTQdvC0LvNFTu3OjvP4chy7ltnvSx5rVI57DjTNwU6DnlJtVlEea1W8xEDFA32YDn+b2iL9nt+BV45KvUH6z7adqSgP+O0J7xd63UPSqLT+0ulsb15ocNK7x17DOxyntXxEahZ6eg3w6D+2NSbJdaXaow7POz+gueOqdxMAxKVZH5vvoRNfCXj5kDQmy31OukHLmWtUFo2U8msAaRTUq5mO8z69BrhvmvTYHKjIr4zktVKdXpMGlrPnEKgo3PQjP9kdXw3smAksHRekEWThYoRNYe2S7g9LjUqk814/zvzSv+T/AOCzVsDuOf6v38Kb0UQDrFGR5xS5en/OOWDuM66Tp22WJyvPyfW+l8cX8mRaAKjVCYhOsp2nrAUq856Txr2y7+jgTdOPfF8ozAUuH3W/LvNFUlQC0LFkLKq1XzhP1AWkmugL+90vs4xgoOJBeJgOgA55lW60Np/Uuw14cIZ1puJ8971k7Hm6j45H9oFKOdezmoXppV4t9tMAqcakQl27VeikcVFuG+c6adaVlEbOp5erBLy0z/pc3osnIsrL9bi4atnsJMCp2ASodqP0+Pwu6WQsD1Tko/5GJzpff7W2ts+V7unh6mS3c7bURfzHu4Hss87n8Yez5ordvwPjq0jdpL3lrJu33lWOihPm38CBkua3tV94v25XXNaoyJNpZScFf5rxbMZhcdH08+dwYNvPwNe3el6ePH8r6IGKXdOPPgJofr/tPGUtUNnyvTSS+I5fbafbByrOat/sc6DObHO/LvP+FhYONO4j/V6Krlh7BcrlZ0vJzZ+3sR5zhJBGCZcft4rypSD/Gm9CYqDigV4v/aiLTXYHwdqdAUOC4xu8Ye4a6K/o8sBNLwBVWgFN+np/6/o7PwMemQfU7CjVsARrcK763ZxPzzkrHSQf/Qdoei/QcYTvy75ywfl0+5Ee690u/Y+vVJIcLKSEN3lgcFF2teLsVgUA0Ki37fNg1qjI7f5duh/R4aXARw2B9H3O5/OGycPJdeFI6f88J/lXgNR19bcnpLyS/Gxg7lDgrQrSCMXp++zunO3liAf+BAnOxkWx4cVoxTY1Iv6UQb4tXewLF324CpZ/H8EeBEze68esy5vATS9an/8zCljzWXDLoRXy/eOfN2yPAfa1wt7cCDXjsPv1mfc3fYR07DUPuues5k1+PNvwFbDxG+DTlsD/6gPv1wGOrJBe2/IDMGsQ8FEj6Ua0Bxe7L0OIYqDiQXhJF2WjfaASGSM1V5i5G8PEfryR8rX8K8w930q5Jr0+lGoAnvjX2rThjah4oHYnYNBfwIM/+1cGb+h0QESs43RzM0r1tsC930p3eg5UI7su3Q3vkLbL/T9YpyVWl/5nnrC9MpIfaFz1mqrRAZlC9ln8ClRkV/RrJkknS/OVqznnJb4KMOIg0Pox6fmJtbaLcFY9vWQsMLO/52Yb+55OckLYJlDmpgO75wJ/DAW2/izlGy15E9j5K/BOGjChGrDtJ2neTd8BX7QF/nhGeq43OB+g0Bn7PCZvatM85ZS4uOOty3FU/Eks9qZGxdUdmoWQmrpm9LMGTPLv48K+4DX5AbZD6JtFxgBd3wSGyoKkf0YFtxxaIf89FeYA3/e2Bi/5dont7ronmwM/T8Pim/c38/6RVFv6v9pJRwj5sv4ZBfz9krVpyVRkzW05s8X2fT/fK7330BIvAvvQwUDFA/NYKsXOvvTwSGsPlVi7hFb583KVrHkkeoNj3oO3mt0LDFluPfFqmX0tT3xVqRYoUAl2n735A47zVGll27xm3l7zX3Z+Fd1ygDQujDP6cLQvmIQHC0vuUu1PoCLvOfTP68C48sDHTaSruGJZs0lcqvOEXkAKaJaPlz0vAlZ9JN2U8r8P3a/f5kaMdoHKoaW2zz9vK3VZ3/qTFIB818P1cstVkvZns/BIqbu5NwpyfD+QOutunHNeKqvJ6LLpx2ZqoOOoePN+VxcthVeAvfOA/fOtJxj77+PUJt/L5DUnNSpmKQ2k5gizyR2u2atzC/tak7PbgaMrpcf2NazOjhvm/dF8p/VLXtaomGsdm94j/b98zHHf/fsl58tIbVzynqNSTef2GY7zfNIC+OkeKd/tGsGRaT0IL0kwLTa6yI1Irguc2wHknHGcbm6myDwO3P+91FOlw3Dfcz5C0Q2PWXuvdB0L3DRcmeU+MldKgGt+H1ChgTROTIOe0sEfkIIUe5VbSif0giznJxcPOT55iMIFUdLM509Pj5gk6YrN3ppPpfID1poI+4A3oRpQ62Yp52HNJKl3VLtnbJvA9v0tVd9HxUuPDy0F4itLJ8Gcs7aJ1KYiKXnPfANL83Yzu2p3JW3uJRZfReomn30GSKkPVGopJV//+zaw8gNpHr0PgQqE823ijrMale/vkJKyC/OAFnZBq8ccFT96/djUqLjYF/QuDqvyoOToSqlnnX2tzMF/gPq3+14ub9j3+rF373fAkUekHJusE9LV+Q2PSzcabdDDmqNXmCeNYJ3SQAo2Lx6QXvv6Vmlk244jpGT3KxekC7nqN0rNHCmNgEotpP3U25q3YHJWE/n3S8CwjdahAvSR0jHDXY1KlVbApYNSE07hFSDSSW0yYN33zBdxjXoD0ElB0cKRUs1W5gmphsU83tW9U6VtVpwvBTRJtYEvbpSCqrPb3X++rT9JHTeuAQxUPLDWqLgIVG58Wuoea+/KRSCloVSdW729NGBaHS+S664VnUdKn7t6W++Sfb2VXAcY/LfttH4zpKuV3HTnzUlthgD/viUdEPIzHV93dWCRKTT/VPzJa3AXmM4sOZCYq4N1OuCp1VJtRl6GVMPS8mEpUFj5PrD8XekvWZb8fPEAMKG6dFIouuK4jm12zXwF2daTjrwm6d6pwJ/PS69XvUGqlTq6UrovzO1vSc2G9lIaWh/rIzyfgB74WWpTNxU5Vq97Yh+o5Gdbe47t+AVIbWg3v7npR0bJXj+mIum5/fhCrmpU5N/Nlh+kGkZz8FKhvvRZNn4t/d0yCuj4krJ5ZM4CN7kwPVC3C/D0aumO6VcvS7kRgLR/tugn5eb9OVwK+gGpplSeDJp10jH4Pb/LcV2N7gRaDZR6HgkTkHEUqFBPKkN+trSc/JL90FXgFyhzoBwWAfSeKDV3XjoIbJsOHC/pHBGVIAVci0cD7Z+zG8m6ZHumNpRqerNOAMdWuw40LTUqJftHRLR0PLt0SLoX2PrJtvPX6gQ0vdv6vGITKTguV9l6YZxQTTqvbPleet7zQ+liYtVHUs7TpcPSOkIcAxUPXOaomF33kPNApSBHygPZO0864JQ1+gigXgBdsP1Zn6ucl6h4qemtIBs4v9vxdWd3mbZTJMyBih81KvLgpv1z0v7wnl1CtfwEn9YUeHKl7eu3jpKasBaPlmo9HMbcENYTYbUbgaRaUqBz+ZhjcmfeJan58cxW6arLrElfoMr10smpSV+p1iTvEhBbwXWwZR98e6pRaXSHtO4r6VLtgTv2TUP23Y3lA+TlXZRq2uScDqFvF2j4yj5YOvKv41ADrnJU5DUql49KoyKbpzXoKTUhmHtBLXtHuqVCj/ekK2olOEumdSYqHuj7FbDwNSmAOr9bOglv+d56QjRz1mPFrOUAKdC4eEAaHuDqZWvC6d550h9QEmDnSfO2fkwKGMwBZfV2QNsnpeaSOl1cj1rtq5zz1p5m5dKki4E1nwEX9lpzrgCpzGZjE6Xeng1LRtK25KiUBHibp0rfn6tAxZKjIgtk7/teyj+TB9C1OkmDYNqP2A1Ix4lnN0nfSXR56YJlyw/W7yUmSaoFO7NVGkxw03dS780Qx0DFA7c5Ks7cN02qxuv9qVS1Kx84jdSTWENqxjBfITboKQUMuemueynJFKLk4GIqdn4VLZd5UqoBMc9jvnJPqgPc/LLzu1rrvagKv36A1J309yeAPX9I01o/Kl1FXbkgVT1HxEhXvebAorgA+F8D2wPuusnS1ZZ88L9bX5feU74mcPvb1umeBhOMSZJOaivek4Ibb6r0Wz8KrJjguh3ezFMX0SJZs8nl4465X84GfLOpUQkwmRYATqx3EqjIDqtCWL8L+1tJ/PqI9bYNETFS8/DvQ4A9c6Vg4sRaYNZg4Dm7hEn5sovypO0SWc5xnyzIkfbvjCNS8/OWkgRzb5qe699uPeEWF0j724GF0rLObpe2bVJtab+peoO0rp2zpAuCmh2Bajc4X27WaWDZu9JnNOeImLfLqY22t7QApG1gTixveo/UPOWvoqtS+Vd9LJXVzBxct3hAGi3WLCxCqm2V18Iue8caqJj3L/PQD5unSrdC6Pau8yEozE2N8p5xaU2B4TuBb2+T9oHb35Ka2dyJjJVuYGpmHjkckHo46nTAdf2lQMW8PQtyAYPdKNshhIGKB3pPNSoA8NCv0kHgtnFSNVuTvqVUOvJas3tsT8zlKvkURBbJfyoX91tv4Gjv2CpgWi/pSrDPZKlmw3xCfOgXa5CSVMe2O6MXzU8ApEDg3mnAN12khMzWj0oHynJpQEMnN3MMN0i3WLh4ANj6o1Qtv+lbx/n8TfAGpAO8OT8k10X3cbnOr0nNAfv+cj+fp0ClWFZDAeHYlONs4EGb8V8C7J4MOL/Hi7xGpTjfetIy155ExkmfTX5vqdgK0nd1f8mV8enNUs5HxmGpZiwmScoN+fdtadtd2Cc1jZi3QWxKSWK/kE6IRXnOmzkBH/KIzPMbpADZfswVe96MYJ1QBejzudTUMv9lKaej0R1S4LD3T2mesAhg2AZg8/fA2W3S+CT5mVKzitnl48DRFVKAlL5HCsgyT0onbVOx9HuKSpDel58lbbuMI7aBZkSsVENz41PS85tekI7dK96XajUqNgZ+6GNbfnlvNSGrUanVSaqZzToJrP4U6Pyq42d3VqNi3iYv7vG87VyJS7U+Tmkg/a/UXPp/bhewfIJ0IdFxhPQZI6I9B6tCSH+Xj0q9VL29fUqQMFDxINzVOCpy9bt5dVVOKmo5wHq1FBEL3PiM29ntFcp/Kl+U3OjRfEUrDzLMbdsn1gJTOgH9f7UdP8Hs0YXSAF8n10sH3RudNB+6EhYGPL5EWrc3+T8V6kp/+siS+xsJoEYH6aD1873SPIk1vV+/O97UqOh0QLuhtoGKsxtX2tde2AcJRXaJqNFJtsFJrpSQWCz/7uS9OfzJUbEvk7O75soDlbPbrQnT5nuCJdeReqst+j/pebUbpStguSqtpBqLjCPAV51LchkOu75Lr6vxhQCpdi+ptrRtzCNOq01fkhdiFp0kjcSaWEMaDTupNnBbye1KCq8A71YBcs8Bk2+STvjmUal9ZUiQLhZq3iRdSNifsMvXBPrIBh+MjJWaFc2yT0s99cIjbbsnh4VJ5Z4/QsohazvEMfg3J1+7G8rCH9VulDosVG4JJFSVpiXXteaymHsLrnxf+qvcUvr9A9IwCTU6SPvV0RVSk1hBjvTbMO/rzR8A7v5K2TL7iIGKB+ZeP0ZXvX4oNMRWkA4kB/4B7vjYcSReDwqd/VTWfyk18/X8AGhTcgsF+R2QC7KA72QBrHxsmbhUKevffkA5b4XpfU9SrtcVeGqVlLdS7zbpAFu/u1SWABO9d5zKxN87z+LZTjXgVQVzjfZS8u7swdLzczulgE0+GKJPNSpw7HlX8l3kQxY8yU9w3t7r5/QWqWff9QMdg6UTa4Fdv0tde81XnfLlbp9pDVTMwVhErBSoJdWRavluetF50myrwcDiN6STiDxAafu01PwQlybt12F6qQkqMlZqVriaIdWupDWTmmKClYyqpFodgedd9GKJjJV6EW781rZWtHwtqekktbFUQ5pQVWrijIiWAtKrmdKI15Fx0lhWFer7PnbTfdOAv1+Uastn9pfyoi4dkmpbzCdy8/fecoA0/EBxPvBeTSn4iooHuk+QyrVnrjSf0t9HWJhjr8owPdB+mDUYljuzVfozM5fLlSPLAyxg4EJgD1ZXuKdePxQ6bhsn/flB2A85ZCyWkg0B6Srq+kek2gRzU0CXN4GVH1oTXJvd793NI4Mtran0Z/bQL4os9s7PpGr5oiITRruaachy2+dN75b+JrWWeltkegpUPNSomAMEc3JmrhSo6CBbjrwHirc1Kl/fIv2PqWC9dUVUgtTccumQFGzduEmqoUrfbTuQ2OapJePjjLQ2/Zibghp0l/5cufFp6So3fa90JQ9IIzr3mOA4b7C6NGtFr/9J+V3HVkn7RVozqcdZsId6qHK9db9NaSDlfEzrKa0775I03XzH8IgoKXF16biSQClD+pshuzt8RKx0E9bS0Gqw1HxmTqZ/dosUvO+aLdX0la9pvetzWlOpFiuuopS8bSySmh1nDZJ6sHrKywsyBioeeJWjQmVPul2b8vHV0onzUMkgWdXaSKPvrvpYGs6//bOlX0YV7D3nYmyU5HrWO3jbi6soBSr2zRf2gYm8pqIg17FGxax8LSlgyJFG3A1zdX8oX3NUjq60dvUMC5eChhUlQcO6z6U/Z1a8J42NYR6sy9t7fekjrHdZ3/OH1HOmLPYgNCuXJg16qZbWj0qBytXLtiNHy5Njb3hcql07slxqcvvlYanpSBcmDZNw6+vKDtfgTmSM1MS88oOSHkJ1pL+aHbx7vzkPTxilgCu2QvDK6gEDFQ+sOSrqD0f838ELiDOEo2X1ABIfSRl/v2j7/EdZAnXd26R2X53OcwZ/WWE/Aquc+QB45aLtdPsalb9ekE4KSTWl4f1dBSBJJYFKSY2Ky0DFXZnM5IO65Z637ZLaTBaoeFxOvnU0Wvtbanij8V2ONxWl0nXdQ1KS/L6/S/I+dNK+WOtm2/liK1gDqqf+kxLYa3RwnYAfTDFJQPfxnudzRh8hBThXL0u1RHd+qmzZfMBAxQO9OUdF5RqV89n5GPCtdD+OYxOc9O6goDsjklFZV1Lda9+N0qzGTdJ9hsrC6MNOCAig+YPS8N2d/09KLATcj7dhDlT+fUcaH+LyMemgbr+NT66T/h9f5b4Q5pu9ldSomJt+Lop4VNDJxl7xdKfgs9ulMS7MzmyR5SXopQHK7vhYSq7c84fjHdQ7PC+N1WE/XkudW9yvl7QrqZaU+9Hey4Tk+MpSLUuoSq4r/Q5LEtPVwkDFA63kqJzLsrbHCyGgK6MnQjU9XPQ6/o2U3a9IFwY8v0MaoCoiWkqKrN5WvQJqgBAA7p4C9P1SCtZOrJXGc6h8ves3me/FVJBlHbjq6Ar3K0qu62TQuxJJtaT/ubZNP4dFZdtAxVUPGrNNU22fZ54A9pWMumrOS2j9qPT/xqekGqEPZKOA1uki5UQV5ADZZ6Uux7nngAa80KAQcffX0g0OzTdQVAkDFQ+0mKNiNAlLkxSVnuNIk/ISds2WJgz8E0isBgycp27BtMgcSN/xEbB/oe1Q4PbaDJFG3JWr29U6QFdac+DgIml6nS5Svk/tztJIoWZxFa13ga7YDNI9VDKBY6tRC1Ii6mzjzWjboIZ0r6I1k6QEVWOR47gWFk5+8+amHme9dGIrAPV7SKOTlqtkHVfEUA5IKSetlyiUJNWy9mhUEQMVD5zVqMzZegoz1p/EZw+1RGq8j4Mn+UlegVJsEghX8BYg5IO7v5Yy+6OTpLEUyIbDqT2ptnQTRXcioqUTu3kAtCf+dby55ILXpHuhdHzJmgx4z7fAb48BPd6XApvtM4CYZCmRucr1Ug3GNOsw5IdNlYH+H0jVPhu+lvJGsk66vlo058xc/4g09sjXXWT3h3HxA7z7K+kKtG5X5yMQE5HP1B1uLgRYalSM1sS+F37Zjg3HMvDZMhdVz0FWZFQ/sbfMCguTeh8wSHHO34rHvl8CTe4GXtzr/A7Y3d4FRhy07bHQ7F7g1ePSvWCS60g9Km58Worqu46Vel3IROtKEmN1Omtz06Gl0kBqwknBzTU09W6XuqZ2f9fz54iKl2qPGKQQKYY1Kh64y1FRK29FS81QZYlwdjIjG8LfSKV2Z+nPlbAw26HCzaITnc9fq6NlWPJ/xvZAS9Nu7DLVsr6eWEO6rcD8EdZpd06Sak+KrgJrP7cOimUOaq5/BLh4EFjzqfNgioiCgoGKB/a9fkyyICEppvSuquWxSRFHySXy2v/pX0TG1XyY5BXI1dpYx7wxm/cssH4K0Ow+4N+3pGmN+0g5Mma3vyUN7BbIvZGIyCds+vHAvkblcp51NMvEGIXv2eCGUTaOixbGdCFyRquVTib7Q12rwc5nPL9LuvEfII0i2ucLx67mMUlltvs5kRoYqHig19v2+sm6ah0TwVSKR+ViWS1KMWtUVGESQHp2vucZSfviUoB+JbcPuP1tKSHXzDzuSd8vvb+rNREFDQMVD+xrVApliayl2QQjz0tRe0yXsmzyisNqF0HTQmrPbNAdeOUocONQ63goZlEJ1jvMEpGqGKh4YO71U2w04ciFXHy36qjltcLi0muCKZIHKhru9fPrxpN44ZdtpbptShNrs64xMUlSoq4+AnjyPylxtn4P4NF/gNhktUtHRGAyrUfyGpVb/2c7WmZpdhPOL7LeoE3LybSv/LYDANC8agIGd6jlYW661mizZ5SX+SSVmgPDdwa3KETkM9aoeBBrkGK5KwXFDq+VVqBy4lIenvxxs+V5KCTT7j6T7XkmL1zKLcCYebux96wyywuU391vywhuHSJSGgMVD+KjpJ498iRas9Jq3vjcbmC5UMhROXU5T5HljJ63G9PWHEOPT/5TZHmB0mSFARHRNYyBigfx0VKgkp3vWKNSqFITTCjkSVwpMHqeyQs7T2UpshwqHQzk6Fqw50w2HvxqLTYfz1C7KAQGKh4lRLuuUVFrKHutJtPK8xPUTqYN1ui9PA+HNm3m0JDWPPnTJqw7koF7Jq9VuygEBioexUdJOSo5KgYq9mNLFWm06ce263bg22bnqSycyPC9CemXjSfQbMwirDl0MeAy2ON5zpF8tGYtbh7574e3nyBvnMnkeElawkDFg4SS0WczZCPSmpVWoGJ/ctRqjUqBrBalQIEald6frfLrfa/+thN5hUYMm7E14DKQZ1rPmYqKsB7mrhQq0yRJ17aocJ4atYTfhgdVEqMRodchM89ZMq1KOSoaPTHIu1AXFPt3QjiUnou7Pl+NpXvPK1oepZg0uu3VZFNL4aLK6cd1x9Fhwr84lJ5bSqWyitBbD3OXrxSyVoU8iorQq10EktFEoPL555+jZs2aiIqKQtu2bbFhwwa1i2RRLioCLas5vwFZoUpNP1pNpi0osm4PZ8nH3njttx3YfjITj32/KeDyBOOElO9nAHYtk3eXl2/yc1n5llrHN+buwunMq3jn7z2lXTyb9qi9Z7PR6u3FeH0ux0sh1xioaIvqgcovv/yCF198EW+++Sa2bNmCFi1aoFu3bkhPT1e7aBYf3tfC6fSVBy7gx3XHvV5OsdGET5cexI5TmQ6v7TqdhV6f/of1Ry45vGZ/kZpbUISxf+7GygMXLNOy84twLkvddlV5c09hsQmHL/h+9XzOzb103v5rj0/NXv7ci+lKQTFOusmLuepH08GGoxm487NV2H3m2uzBJA8Ij128ApNJYPeZLNw4fimG/7LNZt6jF6+UekKrfD/4YvlhZOYV4ad1J0q1DBRaYg3WQMWf3zwpS/VA5aOPPsITTzyBwYMHo3Hjxvjyyy8RExOD7777Tu2iWVRPjkHzqglOX3tj7i6vxwz5ef0JfLT4AO78bLXNdCEEhvywCbvPZOOBr9bh8IVcfLz4AFqO+wctx/2DXzadtJl/zLw9mLr6GB75zlrzNPC7Dbj1f8txJvMqZm8+hQU7z7osR36REbtOK3/StG/u6fK/FZbmlw1HMzB19VHM3Xoao+bstEy/fKUQB87nWN5z6vJVl8v/ZtVRjPtrD37bfMqrk12RUeCPbacdpgshLE04Qgi8/dcevD53J0wmgRd/3YbOHy53GVQc9KPpYsC367HjVBYGfqedmkIlyZsicwqKsf98Dh76ej0A4O8dtvvhsUt5+H7NsdIsnk2C707Zfp/pJO/MG5l5hTiUnuPy9TOZV/HotI1Ye9jxokNtP607ji+WH2LvJw/Cw6ynRn8S+p3JLzLi9bk7sWRP4M3aZY1OqLjHFhYWIiYmBrNnz0afPn0s0wcOHIjMzEz88ccfbt+fnZ2NhIQEZGVlIT4+PqhlzS8yoqDIhHu+XOPQzt4wrRxurp+CE5fycC47H0IIJMZEokZyDPRhOuTkFyPOEI6f1x+3DH9fKSEKdVLisOrQRYTpbKvMffFoh1rQ6YBvS+5BVC4qHDklzS4d61VAYkwkEqMjEBkehnC9DvVTy+H9RftwPrsAXRtVxB3NK0FA4PTlq7iQU4B6FcuhXFQ4iowC+UVGlIsKR5hOB50OyC8yQQfp1igmk1SDEh8dDh10EBD4d286ft/qGBg0q5Jgc4Iwe7JTbXz731EUmwSur56Im+ql4NOlB7363B3qJqNXs8qIDA9DQbERRpPAt6uO4kzmVYdbDHz8QAtcvlKEuKhwGE0C4+fvRVSEHi/eVh9rDl/CvO1nLMtcfch6cnmmcx0cz8hzONnGRuoxsH1NxBrCEakPQ1iYDrGReoSF6aDX6VBkNCHGEA4dpJPkc7Kk3pE9GiIxJgK5BUZkXy1CarwBcYZwS61ZfpERkeFhMITrvRoFV+dmeHh5k+H57HzM2Xoa9StK+6q+5EUBYcnbiIkMh05nHY3ZG0IA+85lY9K/h1zO06ZWEjYctR2P4oHW1dCqZnlkXy1CXqERyXGREEJKUE+KjURYSfnOZF7FpuOX0axKAmokx8AkRMn+qMOVgmLsP5eDxJgI1KoQC51Oh8y8Qhy5cAUN08ohQh8GnQ545++9uHTFMSipVSEWhvAw3Fg7GTWTY1BoNMFoAirERUIfpkNuQTGOX8rDmcyrCNPpcHP9CoiODMcLv2yD0STQu0VldK6fgkhZ4mVOfjH+b461WWnsnU0ghED52EgAUmCu14chIToCQggIIQU+0ZF6xBkibMon//6uFBQjKkJvufeYK+5ezS824oVftgMAnutSD9XKRyMyPMzy+5beL3987dt7NhvpOQWIDA9DjeRYVE6IAgC8OW830nMKAAAtqyfi7uurIiJM2jaR4WHQQYeCYiPWH81AreRYVE2KRoQ+zHLLFWf+2XMev2+Rjo9f9L/e4XX5Ozcfv4z953NwW+OKqBBnAACbY4RRCMSW/F4BqQbbJAQiw8Msv20lFJkEio0mdKhbARXjoxRbLuDb+VvVQOXMmTOoUqUK1qxZg3bt2lmmv/LKK1ixYgXWr19vM39BQQEKCgosz7OyslC9enWcPHky6IGKWXp2PmZuOIltJzOx4RgHAypLrq+eiC0nMtUuBhFRqWpZLRE/Pt5W0WVmZ2ejWrVqyMzMREKC8xYLs5C6KeH48eMxduxYh+nVqlVToTRU1pz0PAsR0TXnJICEl4Kz7JycHG0HKhUqVIBer8f587ZtdufPn0daWprD/CNHjsSLL75oeW4ymZCRkYHk5GToFKzuAqzRXmnW1lxLuP0Cw+0XGG6/wHD7BYbbzzMhBHJyclC5cmWP86oaqERGRqJVq1ZYunSpJUfFZDJh6dKlGDZsmMP8BoMBBoPBZlpiYmJQyxgfH88dLQDcfoHh9gsMt19guP0Cw+3nnqeaFDPVm35efPFFDBw4EK1bt0abNm0wceJEXLlyBYMHD1a7aERERKQy1QOVBx54ABcuXMDo0aNx7tw5XHfddVi4cCEqVqyodtGIiIhIZaoHKgAwbNgwp009ajIYDHjzzTcdmprIO9x+geH2Cwy3X2C4/QLD7acsVbsnExEREbmj+si0RERERK4wUCEiIiLNYqBCREREmsVAhYiIiDSLgYoTn3/+OWrWrImoqCi0bdsWGzZcm3e99dX48eNxww03oFy5ckhNTUWfPn2wf/9+m3ny8/MxdOhQJCcnIy4uDvfcc4/DyMMnTpxAr169EBMTg9TUVLz88ssoLi4uzY+iugkTJkCn02H48OGWadx2np0+fRoPP/wwkpOTER0djWbNmmHTpk2W14UQGD16NCpVqoTo6Gh07doVBw/a3ugyIyMD/fv3R3x8PBITE/HYY48hN9f3u2KHGqPRiDfeeAO1atVCdHQ06tSpg7feesvmTsrcflYrV65E7969UblyZeh0OsydO9fmdaW21Y4dO9CxY0dERUWhWrVqeP/994P90UKPIBszZ84UkZGR4rvvvhO7d+8WTzzxhEhMTBTnz59Xu2iq69atm5g6darYtWuX2LZtm+jZs6eoXr26yM3Ntczz1FNPiWrVqomlS5eKTZs2iRtvvFG0b9/e8npxcbFo2rSp6Nq1q9i6dauYP3++qFChghg5cqQaH0kVGzZsEDVr1hTNmzcXzz//vGU6t517GRkZokaNGmLQoEFi/fr14siRI2LRokXi0KFDlnkmTJggEhISxNy5c8X27dvFnXfeKWrVqiWuXr1qmad79+6iRYsWYt26deK///4TdevWFf369VPjI5Wqd955RyQnJ4u//vpLHD16VMyaNUvExcWJTz75xDIPt5/V/PnzxahRo8Tvv/8uAIg5c+bYvK7EtsrKyhIVK1YU/fv3F7t27RIzZswQ0dHRYsqUKaX1MUMCAxU7bdq0EUOHDrU8NxqNonLlymL8+PEqlkqb0tPTBQCxYsUKIYQQmZmZIiIiQsyaNcsyz969ewUAsXbtWiGE9OMPCwsT586ds8wzefJkER8fLwoKCkr3A6ggJydH1KtXTyxevFh06tTJEqhw23n26quviptuusnl6yaTSaSlpYkPPvjAMi0zM1MYDAYxY8YMIYQQe/bsEQDExo0bLfMsWLBA6HQ6cfr06eAVXgN69eolHn30UZtpd999t+jfv78QgtvPHftARalt9cUXX4jy5cvb/H5fffVV0aBBgyB/otDCph+ZwsJCbN68GV27drVMCwsLQ9euXbF27VoVS6ZNWVlZAICkpCQAwObNm1FUVGSz/Ro2bIjq1atbtt/atWvRrFkzm5GHu3XrhuzsbOzevbsUS6+OoUOHolevXjbbCOC288a8efPQunVr3HfffUhNTUXLli3x9ddfW14/evQozp07Z7MNExIS0LZtW5ttmJiYiNatW1vm6dq1K8LCwrB+/frS+zAqaN++PZYuXYoDBw4AALZv345Vq1ahR48eALj9fKHUtlq7di1uvvlmREZGWubp1q0b9u/fj8uXL5fSp9E+TYxMqxUXL16E0Wh0GL6/YsWK2Ldvn0ql0iaTyYThw4ejQ4cOaNq0KQDg3LlziIyMdLhRZMWKFXHu3DnLPM62r/m1a9nMmTOxZcsWbNy40eE1bjvPjhw5gsmTJ+PFF1/E//3f/2Hjxo147rnnEBkZiYEDB1q2gbNtJN+GqampNq+Hh4cjKSnpmt+Gr732GrKzs9GwYUPo9XoYjUa888476N+/PwBw+/lAqW117tw51KpVy2EZ5tfKly8flPKHGgYq5JehQ4di165dWLVqldpFCQknT57E888/j8WLFyMqKkrt4oQkk8mE1q1b49133wUAtGzZErt27cKXX36JgQMHqlw67fv111/x888/Y/r06WjSpAm2bduG4cOHo3Llytx+pGls+pGpUKEC9Hq9Q0+L8+fPIy0tTaVSac+wYcPw119/YdmyZahataplelpaGgoLC5GZmWkzv3z7paWlOd2+5teuVZs3b0Z6ejquv/56hIeHIzw8HCtWrMCnn36K8PBwVKxYkdvOg0qVKqFx48Y20xo1aoQTJ04AsG4Dd7/ftLQ0pKen27xeXFyMjIyMa34bvvzyy3jttdfw4IMPolmzZhgwYABeeOEFjB8/HgC3ny+U2lZl/TftLQYqMpGRkWjVqhWWLl1qmWYymbB06VK0a9dOxZJpgxACw4YNw5w5c/Dvv/86VFm2atUKERERNttv//79OHHihGX7tWvXDjt37rT5AS9evBjx8fEOJ6FrSZcuXbBz505s27bN8te6dWv079/f8pjbzr0OHTo4dIc/cOAAatSoAQCoVasW0tLSbLZhdnY21q9fb7MNMzMzsXnzZss8//77L0wmE9q2bVsKn0I9eXl5CAuzPeTr9XqYTCYA3H6+UGpbtWvXDitXrkRRUZFlnsWLF6NBgwZs9pFTO5tXa2bOnCkMBoOYNm2a2LNnjxgyZIhITEy06WlRVj399NMiISFBLF++XJw9e9byl5eXZ5nnqaeeEtWrVxf//vuv2LRpk2jXrp1o166d5XVzF9vbb79dbNu2TSxcuFCkpKSUmS62cvJeP0Jw23myYcMGER4eLt555x1x8OBB8fPPP4uYmBjx008/WeaZMGGCSExMFH/88YfYsWOHuOuuu5x2GW3ZsqVYv369WLVqlahXr9412b3W3sCBA0WVKlUs3ZN///13UaFCBfHKK69Y5uH2s8rJyRFbt24VW7duFQDERx99JLZu3SqOHz8uhFBmW2VmZoqKFSuKAQMGiF27domZM2eKmJgYdk+2w0DFiUmTJonq1auLyMhI0aZNG7Fu3Tq1i6QJAJz+TZ061TLP1atXxTPPPCPKly8vYmJiRN++fcXZs2dtlnPs2DHRo0cPER0dLSpUqCBeeuklUVRUVMqfRn32gQq3nWd//vmnaNq0qTAYDKJhw4biq6++snndZDKJN954Q1SsWFEYDAbRpUsXsX//fpt5Ll26JPr16yfi4uJEfHy8GDx4sMjJySnNj6GK7Oxs8fzzz4vq1auLqKgoUbt2bTFq1CibrrHcflbLli1zerwbOHCgEEK5bbV9+3Zx0003CYPBIKpUqSImTJhQWh8xZOiEkA1LSERERKQhzFEhIiIizWKgQkRERJrFQIWIiIg0i4EKERERaRYDFSIiItIsBipERESkWQxUiIiISLMYqBBRyNPpdJg7d67axSCiIGCgQkQBGTRoEHQ6ncNf9+7d1S4aEV0DwtUuABGFvu7du2Pq1Kk20wwGg0qlIaJrCWtUiChgBoMBaWlpNn/mu7/qdDpMnjwZPXr0QHR0NGrXro3Zs2fbvH/nzp249dZbER0djeTkZAwZMgS5ubk283z33Xdo0qQJDAYDKlWqhGHDhtm8fvHiRfTt2xcxMTGoV68e5s2bZ3nt8uXL6N+/P1JSUhAdHY169eo5BFZEpE0MVIgo6N544w3cc8892L59O/r3748HH3wQe/fuBQBcuXIF3bp1Q/ny5bFx40bMmjULS5YssQlEJk+ejKFDh2LIkCHYuXMn5s2bh7p169qsY+zYsbj//vuxY8cO9OzZE/3790dGRoZl/Xv27MGCBQuwd+9eTJ48GRUqVCi9DUBE/lP7rohEFNoGDhwo9Hq9iI2Ntfl75513hBDSXbefeuopm/e0bdtWPP3000IIIb766itRvnx5kZuba3n977//FmFhYeLcuXNCCCEqV64sRo0a5bIMAMTrr79ueZ6bmysAiAULFgghhOjdu7cYPHiwMh+YiEoVc1SIKGC33HILJk+ebDMtKSnJ8rhdu3Y2r7Vr1w7btm0DAOzduxctWrRAbGys5fUOHTrAZDJh//790Ol0OHPmDLp06eK2DM2bN7c8jo2NRXx8PNLT0wEATz/9NO655x5s2bIFt99+O/r06YP27dv79VmJqHQxUCGigMXGxjo0xSglOjraq/kiIiJsnut0OphMJgBAjx49cPz4ccyfPx+LFy9Gly5dMHToUHz44YeKl5eIlMUcFSIKunXr1jk8b9SoEQCgUaNG2L59O65cuWJ5ffXq1QgLC0ODBg1Qrlw51KxZE0uXLg2oDCkpKRg4cCB++uknTJw4EV999VVAyyOi0sEaFSIKWEFBAc6dO2czLTw83JKwOmvWLLRu3Ro33XQTfv75Z2zYsAHffvstAKB///548803MXDgQIwZMwYXLlzAs88+iwEDBqBixYoAgDFjxuCpp55CamoqevTogZycHKxevRrPPvusV+UbPXo0WrVqhSZNmqCgoAB//fWXJVAiIm1joEJEAVu4cCEqVapkM61BgwbYt28fAKlHzsyZM/HMM8+gUqVKmDFjBho3bgwAiImJwaJFi/D888/jhhtuQExMDO655x589NFHlmUNHDgQ+fn5+PjjjzFixAhUqFAB9957r9fli4yMxMiRI3Hs2DFER0ejY8eOmDlzpgKfnIiCTSeEEGoXgoiuXTqdDnPmzEGfPn3ULgoRhSDmqBAREZFmMVAhIiIizWKOChEFFVuXiSgQrFEhIiIizWKgQkRERJrFQIWIiIg0i4EKERERaRYDFSIiItIsBipERESkWQxUiIiISLMYqBAREZFmMVAhIiIizfp/yofc1jcD+Q0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "def ShowTrainLoss(train_losses,val_losses,save):\n",
    "    # 日本時間のタイムゾーンを取得\n",
    "    jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "    # 現在の日本時間を取得\n",
    "    now = datetime.now(jst)\n",
    "\n",
    "    # 時刻を指定された形式の文字列に変換\n",
    "    time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # 学習曲線の可視化\n",
    "\n",
    "    title = 'Training and Validation Losses Material'\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0,5)\n",
    "    plt.legend()\n",
    "    if save == True:\n",
    "        plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "ShowTrainLoss(train_losses,val_losses,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.4%\n",
      "Accuracy: 87.7%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8766)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y[0], dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            # x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net5(x)\n",
    "            \n",
    "            y_label = torch.argmax(y[0], dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### object 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1050, 1, 128, 130])\n",
      "525 262 263\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7fdcf0d088b0>\n",
      "[tensor([[[[-15.7372, -12.7907, -12.2806,  ..., -16.2258, -12.1957, -14.6959],\n",
      "          [-15.7418, -11.8346, -11.9373,  ..., -12.7932, -11.7111, -12.4843],\n",
      "          [-22.5785, -21.3953, -21.5793,  ..., -20.6679, -21.5296, -17.3727],\n",
      "          ...,\n",
      "          [-58.1976, -55.0280, -55.0888,  ..., -53.4471, -52.7718, -53.7474],\n",
      "          [-56.4661, -53.7698, -54.6103,  ..., -54.0908, -53.9045, -56.2288],\n",
      "          [-57.3117, -54.9557, -55.6911,  ..., -54.7845, -54.3604, -56.0656]]],\n",
      "\n",
      "\n",
      "        [[[ -5.8755,  -1.3352,   0.0000,  ...,  -8.2323,  -7.3307,  -8.7717],\n",
      "          [ -7.0860,  -4.6320,  -2.7805,  ...,  -6.8078,  -5.4152,  -6.6856],\n",
      "          [-14.4937, -18.4999, -18.0805,  ..., -15.1023, -14.4274, -11.6789],\n",
      "          ...,\n",
      "          [-50.1694, -46.3330, -44.8377,  ..., -47.9001, -46.6421, -47.7369],\n",
      "          [-49.2638, -46.9567, -46.7122,  ..., -46.9204, -46.5079, -49.3187],\n",
      "          [-46.9555, -45.9099, -47.1923,  ..., -47.8846, -48.9719, -50.9079]]],\n",
      "\n",
      "\n",
      "        [[[-14.0626, -12.4793, -12.4311,  ...,  -6.8308,  -6.2901, -10.4582],\n",
      "          [-18.8385, -19.3206, -16.3264,  ...,  -9.3470,  -9.8862, -12.6103],\n",
      "          [-26.0905, -30.3457, -25.2675,  ..., -20.0117, -23.9119, -21.9449],\n",
      "          ...,\n",
      "          [-53.3047, -52.0847, -53.4519,  ..., -52.4061, -53.3940, -56.5739],\n",
      "          [-58.1525, -54.5277, -52.5746,  ..., -53.0982, -53.9163, -56.1266],\n",
      "          [-55.2106, -52.8737, -53.1973,  ..., -52.8028, -52.4231, -54.3603]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -9.9831,  -7.1871, -11.7807,  ..., -11.2343,  -9.8302, -13.3886],\n",
      "          [-11.8676,  -9.5992, -15.2492,  ..., -12.9284, -12.4264, -17.9736],\n",
      "          [-19.0413, -18.4740, -26.9585,  ..., -21.7851, -23.7197, -26.1367],\n",
      "          ...,\n",
      "          [-53.6593, -52.2464, -51.7386,  ..., -51.2787, -51.4993, -56.2754],\n",
      "          [-55.0183, -52.9384, -52.6564,  ..., -51.3566, -51.8909, -54.7269],\n",
      "          [-56.5075, -52.0982, -52.3580,  ..., -51.7871, -52.0791, -53.2282]]],\n",
      "\n",
      "\n",
      "        [[[-17.2652, -11.0746,  -9.8907,  ...,  -0.6295,   0.0000,  -3.5875],\n",
      "          [-18.6370, -15.4748, -16.1502,  ...,  -6.1369,  -3.3467,  -4.0424],\n",
      "          [-28.6770, -30.6238, -34.6265,  ..., -19.3636, -16.2683, -12.0035],\n",
      "          ...,\n",
      "          [-56.7433, -54.9483, -56.3357,  ..., -56.7504, -55.6961, -54.8034],\n",
      "          [-59.7806, -56.2284, -55.0864,  ..., -54.5428, -54.2212, -54.7591],\n",
      "          [-60.2414, -56.0917, -55.5884,  ..., -56.2427, -55.2146, -53.6850]]],\n",
      "\n",
      "\n",
      "        [[[ -9.3511,  -5.2951,  -9.8728,  ..., -10.9083,  -9.2532, -11.2135],\n",
      "          [ -8.2031,  -6.5688, -12.9695,  ..., -10.1815, -11.6199, -10.9543],\n",
      "          [-13.0035, -13.6482, -18.5944,  ..., -16.5582, -14.2727, -13.9899],\n",
      "          ...,\n",
      "          [-45.4077, -44.2285, -46.0337,  ..., -45.8847, -45.8283, -47.6377],\n",
      "          [-47.8298, -45.4274, -44.8245,  ..., -45.7963, -45.1360, -47.9109],\n",
      "          [-46.2646, -44.5052, -46.9336,  ..., -47.0090, -46.8320, -47.4182]]]]), tensor([19,  4, 16, 18,  2,  7,  6, 13,  5, 11,  2, 18, 10, 18, 19, 18,  0,  0,\n",
      "         1,  6,  9,  9, 12, 17, 10])]\n",
      "[tensor([[[[ -6.0762,  -3.5017,  -3.3377,  ...,  -4.1093,  -2.1572,  -5.0010],\n",
      "          [ -8.7918,  -7.3907,  -5.0249,  ...,  -8.1448,  -4.9479,  -9.1982],\n",
      "          [ -9.1813,  -6.6263, -11.7422,  ...,  -8.8395, -12.1046, -19.2009],\n",
      "          ...,\n",
      "          [-52.7497, -48.8865, -48.6537,  ..., -51.1285, -49.8177, -50.1686],\n",
      "          [-50.9880, -48.3031, -49.1782,  ..., -49.3246, -50.4652, -51.6474],\n",
      "          [-53.7844, -50.3416, -49.3829,  ..., -49.5337, -51.0771, -51.4142]]],\n",
      "\n",
      "\n",
      "        [[[-23.0836, -17.6527, -16.0622,  ..., -10.6483, -10.1918, -12.0575],\n",
      "          [-23.1806, -22.3402, -18.6569,  ..., -13.4887, -13.7516, -13.3281],\n",
      "          [-26.3015, -25.4151, -28.7933,  ..., -27.0607, -24.7454, -19.3046],\n",
      "          ...,\n",
      "          [-66.6998, -62.6790, -60.6387,  ..., -61.7790, -61.7823, -62.4379],\n",
      "          [-63.1558, -60.9635, -61.3787,  ..., -63.1781, -63.1277, -62.9624],\n",
      "          [-64.4473, -63.1082, -63.1545,  ..., -62.6057, -62.2202, -63.7380]]],\n",
      "\n",
      "\n",
      "        [[[-19.4677, -13.8089, -14.6049,  ..., -10.6197,  -9.1130, -14.6017],\n",
      "          [-26.8576, -22.7456, -24.1618,  ..., -10.5441, -12.6558, -19.9263],\n",
      "          [-35.0707, -34.8668, -34.4597,  ..., -19.6834, -21.1026, -24.3130],\n",
      "          ...,\n",
      "          [-57.2477, -53.7524, -52.4263,  ..., -53.7950, -53.9968, -55.4982],\n",
      "          [-55.1792, -53.1644, -54.2603,  ..., -52.6724, -53.1959, -54.9959],\n",
      "          [-54.3971, -52.5030, -52.5609,  ..., -53.9797, -53.4432, -55.9142]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -6.2664,  -2.9890,  -5.2798,  ...,  -5.7535,  -4.7177,  -6.9648],\n",
      "          [ -7.5614,  -3.9616,  -7.6979,  ...,  -7.0264,  -8.9588, -11.5580],\n",
      "          [-15.4290, -14.8272, -17.7061,  ..., -19.6478, -22.2260, -23.2930],\n",
      "          ...,\n",
      "          [-51.9192, -50.1242, -49.7132,  ..., -47.8093, -47.7594, -49.0973],\n",
      "          [-52.1852, -48.6977, -48.1595,  ..., -47.4365, -47.7249, -49.1994],\n",
      "          [-51.3106, -48.8156, -48.8151,  ..., -47.7161, -48.4147, -50.3677]]],\n",
      "\n",
      "\n",
      "        [[[-12.9531,  -8.4623, -10.9949,  ..., -13.9743, -12.5583, -12.9040],\n",
      "          [-12.9575,  -9.1291,  -9.6971,  ..., -12.4427, -10.5136, -12.3491],\n",
      "          [-18.2892, -20.0374, -20.3422,  ..., -16.5155, -15.7638, -17.3400],\n",
      "          ...,\n",
      "          [-54.6013, -51.4329, -50.6813,  ..., -50.8779, -51.4110, -53.4678],\n",
      "          [-52.1137, -49.6309, -49.8039,  ..., -51.3086, -50.1676, -51.5474],\n",
      "          [-52.6111, -51.0972, -51.9317,  ..., -52.1191, -50.8958, -52.4753]]],\n",
      "\n",
      "\n",
      "        [[[-25.9034, -21.9119, -14.0451,  ...,  -5.3250,  -9.2805, -16.3978],\n",
      "          [-19.3675, -13.7969, -12.1835,  ...,  -7.1418,  -7.7071, -15.4302],\n",
      "          [-19.0328, -17.3201, -16.0753,  ..., -17.0908, -13.7243, -22.8432],\n",
      "          ...,\n",
      "          [-48.0925, -46.5962, -46.7822,  ..., -47.8841, -46.8159, -47.6297],\n",
      "          [-47.8132, -45.3680, -44.6936,  ..., -46.3455, -46.1164, -49.3973],\n",
      "          [-49.8005, -47.0284, -47.1830,  ..., -46.4303, -46.3429, -48.1432]]]]), tensor([ 0, 17, 13,  2, 10, 19,  5,  7, 13,  5,  0,  2,  0,  1,  5, 15,  2,  6,\n",
      "        12, 17, 12,  3,  6,  5, 10])]\n",
      "[tensor([[[[-10.0279,  -7.8579, -11.8001,  ..., -12.3195,  -7.2473,  -9.8667],\n",
      "          [-10.8272,  -8.6687, -14.2134,  ..., -12.5902,  -6.6770,  -8.9679],\n",
      "          [-17.5238, -18.0341, -23.8566,  ..., -20.1754, -14.4655, -14.4317],\n",
      "          ...,\n",
      "          [-53.8049, -51.9219, -53.2467,  ..., -50.7193, -51.2442, -53.0188],\n",
      "          [-54.4185, -52.8468, -53.4759,  ..., -52.1240, -51.0827, -54.4927],\n",
      "          [-55.8065, -52.5886, -52.4451,  ..., -53.5472, -51.6183, -53.5764]]],\n",
      "\n",
      "\n",
      "        [[[-10.7324,  -4.6517,  -3.8478,  ...,  -8.2309, -14.8002, -18.0520],\n",
      "          [-11.8236,  -6.3387,  -9.1619,  ..., -12.2978, -17.8332, -16.8948],\n",
      "          [-21.9459, -15.6345, -17.6357,  ..., -23.1039, -19.1691, -19.0841],\n",
      "          ...,\n",
      "          [-53.8330, -49.2684, -48.2273,  ..., -48.3188, -49.0298, -52.3784],\n",
      "          [-53.0411, -49.3866, -48.0516,  ..., -49.6745, -49.0690, -51.8535],\n",
      "          [-53.7364, -49.5175, -48.6195,  ..., -50.3162, -49.5507, -49.6395]]],\n",
      "\n",
      "\n",
      "        [[[ -7.1616,  -0.9457,   0.0000,  ...,  -5.7713,  -8.1283, -18.2104],\n",
      "          [ -7.6271,  -3.1601,  -2.3634,  ...,  -8.6473,  -7.9879, -13.6696],\n",
      "          [-13.9333, -14.6354, -14.1242,  ..., -19.9669, -18.1613, -17.1388],\n",
      "          ...,\n",
      "          [-54.6771, -51.6242, -50.7401,  ..., -50.1866, -50.7028, -51.4649],\n",
      "          [-54.6167, -51.3566, -50.3548,  ..., -51.2736, -51.6761, -52.4059],\n",
      "          [-52.7593, -50.6332, -51.0717,  ..., -49.3423, -51.7091, -53.6027]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -8.3681,  -5.1823,  -7.4577,  ...,  -3.7348,  -2.5485,  -6.6958],\n",
      "          [ -8.0277,  -4.9073,  -4.9623,  ...,  -4.2416,  -4.8608,  -9.5555],\n",
      "          [-13.0840, -13.7098, -12.8687,  ..., -17.7461, -19.1325, -21.0760],\n",
      "          ...,\n",
      "          [-50.0689, -46.2291, -45.4716,  ..., -46.8236, -47.4431, -49.0650],\n",
      "          [-50.4353, -47.2231, -45.5502,  ..., -46.8992, -46.7623, -48.7872],\n",
      "          [-48.1989, -46.7950, -47.2719,  ..., -46.1326, -46.5750, -47.0558]]],\n",
      "\n",
      "\n",
      "        [[[-24.0054, -16.5717, -12.2069,  ..., -10.8894, -11.0717, -14.5653],\n",
      "          [-26.5346, -21.9115, -16.5898,  ..., -15.5828, -16.0140, -14.1760],\n",
      "          [-30.1219, -23.5671, -23.9182,  ..., -19.3224, -19.7878, -16.0493],\n",
      "          ...,\n",
      "          [-55.0039, -50.1655, -47.9797,  ..., -48.1771, -49.0459, -50.6193],\n",
      "          [-50.9413, -48.6363, -49.1542,  ..., -50.7510, -50.4623, -51.4882],\n",
      "          [-51.2350, -50.3329, -50.0501,  ..., -51.2576, -50.9684, -51.8375]]],\n",
      "\n",
      "\n",
      "        [[[ -9.2767,  -5.4631,  -1.6625,  ..., -10.1021,  -7.4068,  -9.1599],\n",
      "          [ -7.2520,  -3.3959,  -2.4361,  ...,  -7.8024,  -6.9836,  -7.6628],\n",
      "          [-12.1627, -14.2867, -15.8049,  ..., -17.6147, -16.5750, -12.0232],\n",
      "          ...,\n",
      "          [-56.9290, -53.3854, -53.6736,  ..., -53.6213, -53.0371, -55.1418],\n",
      "          [-55.0039, -54.3032, -54.7474,  ..., -54.4607, -53.4741, -54.6051],\n",
      "          [-55.0830, -54.0245, -54.1530,  ..., -54.0167, -54.1413, -55.7217]]]]), tensor([ 9,  9,  7,  9, 10, 14, 14,  6,  4, 11,  7, 14, 19, 18, 10, 10, 19, 12,\n",
      "         5, 19,  0, 17, 20, 15, 18])]\n",
      "[tensor([[[[ -8.9003,  -5.6950,  -8.4137,  ...,  -7.9397, -14.6901, -13.7975],\n",
      "          [ -7.0621,  -4.2965,  -5.2679,  ...,  -6.8257, -10.7655, -12.5228],\n",
      "          [-12.1692, -14.2089, -16.3282,  ..., -14.7645, -16.9071, -14.4980],\n",
      "          ...,\n",
      "          [-51.3359, -48.0489, -47.7460,  ..., -48.3099, -47.7784, -49.3869],\n",
      "          [-49.6297, -48.2010, -48.3301,  ..., -48.2575, -48.2402, -50.6874],\n",
      "          [-50.8940, -48.3321, -48.8617,  ..., -48.8092, -48.8599, -50.0928]]],\n",
      "\n",
      "\n",
      "        [[[-17.7462, -15.1062, -26.7662,  ...,  -8.3707, -11.2060, -17.8887],\n",
      "          [-19.8870, -15.9270, -17.0375,  ..., -11.2934, -13.8616, -16.8674],\n",
      "          [-27.6479, -24.2454, -21.9514,  ..., -25.1244, -26.2341, -22.6001],\n",
      "          ...,\n",
      "          [-61.9573, -58.3460, -58.4538,  ..., -57.4640, -59.4890, -60.6936],\n",
      "          [-60.5880, -58.2899, -57.2648,  ..., -59.2312, -58.1507, -59.4468],\n",
      "          [-59.8953, -57.4230, -57.5208,  ..., -58.3148, -57.9805, -58.8456]]],\n",
      "\n",
      "\n",
      "        [[[-13.5176, -11.6368,  -8.7873,  ..., -17.7489, -16.9146, -20.3726],\n",
      "          [-16.1134, -14.8937, -12.4694,  ..., -18.9430, -14.6921, -16.7794],\n",
      "          [-22.4209, -19.2131, -22.1324,  ..., -22.3883, -22.1521, -21.7480],\n",
      "          ...,\n",
      "          [-51.0376, -48.7682, -49.6154,  ..., -49.2334, -49.2060, -50.9532],\n",
      "          [-54.0740, -50.1427, -49.8437,  ..., -49.6026, -50.2182, -51.0737],\n",
      "          [-50.7706, -48.5343, -48.9691,  ..., -50.4240, -50.7928, -52.9936]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-15.8294, -11.2537, -10.9465,  ..., -11.9487, -14.0252, -14.7746],\n",
      "          [-17.5562, -16.3954, -18.2899,  ..., -14.2846, -11.2523, -12.0967],\n",
      "          [-25.0954, -28.1919, -22.7930,  ..., -19.2034, -19.1958, -15.9922],\n",
      "          ...,\n",
      "          [-50.6322, -49.0325, -47.4819,  ..., -48.4302, -47.1102, -48.7352],\n",
      "          [-51.8628, -47.9553, -48.7344,  ..., -49.1368, -49.6521, -51.7342],\n",
      "          [-51.8983, -47.6698, -48.2550,  ..., -47.4888, -47.7807, -50.4829]]],\n",
      "\n",
      "\n",
      "        [[[-14.3831, -12.1354, -12.6169,  ..., -15.8074, -16.5729, -17.3791],\n",
      "          [-18.5885, -19.1402, -17.1982,  ..., -10.2863, -16.8677, -18.6861],\n",
      "          [-22.7160, -21.8464, -18.4663,  ..., -16.2206, -17.2931, -20.8829],\n",
      "          ...,\n",
      "          [-53.3006, -49.5118, -47.8410,  ..., -48.6413, -49.1530, -49.6687],\n",
      "          [-51.7591, -49.3027, -49.3969,  ..., -48.9461, -49.3949, -50.4807],\n",
      "          [-51.4795, -50.4085, -50.9016,  ..., -50.5438, -49.8652, -51.7285]]],\n",
      "\n",
      "\n",
      "        [[[-11.6841, -10.6428, -10.8915,  ...,  -1.7235,  -4.8453, -10.9071],\n",
      "          [-13.1581, -10.0602, -10.0689,  ...,  -3.7508,  -5.8531, -10.0624],\n",
      "          [-19.0680, -19.6948, -21.7907,  ..., -19.0947, -19.8550, -18.1728],\n",
      "          ...,\n",
      "          [-56.3883, -55.2090, -55.1556,  ..., -54.6343, -55.5138, -58.5798],\n",
      "          [-57.3524, -55.6003, -55.8850,  ..., -54.4737, -53.9710, -56.3188],\n",
      "          [-56.3898, -54.3298, -55.1854,  ..., -54.6399, -55.4026, -57.7112]]]]), tensor([20, 15,  4, 20, 17, 11,  9,  9,  0,  2, 15, 10,  8, 16, 16,  3, 18, 10,\n",
      "        17,  2, 20,  3, 10,  4, 14])]\n",
      "[tensor([[[[ -9.1439,  -6.3815,  -8.6553,  ...,  -9.9656, -15.8904, -22.7964],\n",
      "          [-12.4257, -10.7954, -15.2085,  ..., -11.7822, -20.2603, -23.9475],\n",
      "          [-20.7228, -24.3895, -28.4178,  ..., -24.0787, -26.8945, -27.7306],\n",
      "          ...,\n",
      "          [-50.6917, -48.3092, -48.8301,  ..., -50.6481, -49.7191, -51.0505],\n",
      "          [-51.6069, -48.9763, -49.3845,  ..., -50.7629, -50.2760, -51.0789],\n",
      "          [-52.5421, -50.3477, -51.9593,  ..., -49.8749, -50.1946, -52.2247]]],\n",
      "\n",
      "\n",
      "        [[[-12.8183,  -8.8736,  -9.9669,  ...,  -0.9775,  -1.1875,  -3.4887],\n",
      "          [-17.7811, -14.6838, -12.9425,  ...,  -5.8998,  -5.5387,  -6.5439],\n",
      "          [-26.6312, -26.0636, -23.6724,  ..., -25.0167, -22.3263, -16.4586],\n",
      "          ...,\n",
      "          [-58.4294, -54.7695, -54.3107,  ..., -55.4369, -54.4335, -56.1671],\n",
      "          [-59.0020, -54.6001, -54.8849,  ..., -52.7717, -53.4871, -55.4511],\n",
      "          [-58.0232, -54.3704, -54.5316,  ..., -54.1423, -53.6740, -55.1368]]],\n",
      "\n",
      "\n",
      "        [[[-15.6181, -17.4919, -20.0049,  ..., -11.2635, -18.8130, -19.6856],\n",
      "          [-17.4799, -19.6151, -21.3630,  ..., -11.9547, -16.5333, -17.9439],\n",
      "          [-23.0230, -26.7643, -25.9644,  ..., -21.4136, -18.9200, -21.3353],\n",
      "          ...,\n",
      "          [-57.8216, -55.8503, -55.6969,  ..., -53.9801, -54.6264, -56.9200],\n",
      "          [-59.3948, -56.9479, -56.4685,  ..., -53.6779, -54.0244, -55.7368],\n",
      "          [-57.8211, -55.0197, -55.2547,  ..., -55.0715, -54.6728, -57.3392]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-19.3755, -15.8834, -19.4765,  ..., -15.2986, -18.9731, -28.3482],\n",
      "          [-18.2080, -16.1983, -15.6329,  ..., -20.2465, -22.4688, -29.8424],\n",
      "          [-22.2617, -25.5475, -24.1155,  ..., -31.1005, -25.8298, -27.9543],\n",
      "          ...,\n",
      "          [-59.2608, -56.9048, -56.1722,  ..., -54.8316, -56.1192, -58.8295],\n",
      "          [-58.3115, -55.2242, -55.7536,  ..., -55.2191, -55.8394, -58.2460],\n",
      "          [-58.3019, -55.6733, -56.1740,  ..., -56.5903, -55.3230, -55.6876]]],\n",
      "\n",
      "\n",
      "        [[[-20.7064, -12.7469, -10.5713,  ...,  -5.6322, -11.0249, -23.3230],\n",
      "          [-23.0129, -15.8259, -15.6464,  ...,  -9.6322, -13.9740, -25.6630],\n",
      "          [-32.3584, -28.0187, -26.3400,  ..., -21.2980, -21.1598, -23.0218],\n",
      "          ...,\n",
      "          [-58.6716, -54.6895, -55.8372,  ..., -56.8688, -56.7343, -59.0497],\n",
      "          [-58.0728, -55.9267, -56.6812,  ..., -55.3060, -55.7754, -58.9926],\n",
      "          [-57.1548, -55.0041, -56.1730,  ..., -55.2742, -56.0316, -58.6850]]],\n",
      "\n",
      "\n",
      "        [[[-17.7484,  -7.8096,  -5.0597,  ...,  -7.1552, -10.3615, -15.7479],\n",
      "          [-24.1250, -11.6381,  -9.1836,  ..., -10.0575, -14.9263, -20.7033],\n",
      "          [-24.6713, -22.2962, -22.8559,  ..., -17.8255, -21.8843, -28.1199],\n",
      "          ...,\n",
      "          [-52.9812, -49.4930, -49.4893,  ..., -47.8044, -48.4419, -50.2379],\n",
      "          [-51.8783, -48.7094, -48.4333,  ..., -49.4847, -48.6194, -51.0819],\n",
      "          [-51.4531, -49.4110, -49.6053,  ..., -48.9175, -49.1056, -51.0907]]]]), tensor([12,  0,  7, 16, 14,  9,  8, 15, 18, 16, 18, 18,  4,  4,  4,  0, 13,  1,\n",
      "        18, 14,  7,  2, 17,  5,  3])]\n",
      "[tensor([[[[-17.0427, -14.9856, -19.9267,  ...,  -5.5589,  -7.6223,  -9.4907],\n",
      "          [-18.2477, -14.8280, -17.3509,  ...,  -6.7090, -12.1974, -12.1394],\n",
      "          [-26.8981, -25.3371, -20.1127,  ..., -16.3102, -16.0153, -16.4981],\n",
      "          ...,\n",
      "          [-53.9200, -51.8853, -52.4520,  ..., -53.6749, -51.8540, -53.6749],\n",
      "          [-55.1911, -52.7323, -53.3232,  ..., -54.3976, -54.8286, -56.5963],\n",
      "          [-54.7715, -52.9818, -53.6572,  ..., -53.8595, -53.5804, -54.8806]]],\n",
      "\n",
      "\n",
      "        [[[-10.5205, -12.1467, -11.9641,  ..., -11.1011,  -7.8841, -10.2488],\n",
      "          [-10.7204, -10.2712, -14.8051,  ..., -17.4890, -10.1350,  -9.9657],\n",
      "          [-15.4316, -14.7884, -19.3225,  ..., -20.4244, -19.5974, -16.2358],\n",
      "          ...,\n",
      "          [-48.4588, -47.1349, -46.9040,  ..., -47.7909, -47.2344, -49.7415],\n",
      "          [-50.3802, -47.2370, -45.4467,  ..., -47.3579, -46.4145, -48.9298],\n",
      "          [-51.0459, -48.2725, -48.0139,  ..., -46.4444, -47.2485, -48.7807]]],\n",
      "\n",
      "\n",
      "        [[[-11.1962,  -5.1562,  -3.9529,  ..., -13.7877, -13.9695, -18.9762],\n",
      "          [-11.6165, -10.5394, -10.5728,  ..., -20.3477, -17.0996, -21.1129],\n",
      "          [-17.8774, -21.0547, -26.0836,  ..., -28.4353, -27.5213, -30.6109],\n",
      "          ...,\n",
      "          [-55.0200, -53.2546, -53.1739,  ..., -54.1681, -53.8253, -56.4622],\n",
      "          [-57.6203, -53.9981, -53.5916,  ..., -53.0469, -53.1876, -55.7428],\n",
      "          [-58.0921, -53.5759, -52.9358,  ..., -54.2606, -55.0854, -56.0155]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-13.0929,  -8.1490,  -6.0740,  ...,  -9.0175,  -8.1026, -11.2404],\n",
      "          [-10.8897,  -6.2664,  -5.4600,  ..., -10.1410, -10.2522, -13.9232],\n",
      "          [-16.1681, -14.1593, -16.3334,  ..., -17.0501, -17.4465, -21.9007],\n",
      "          ...,\n",
      "          [-51.3174, -47.6784, -46.9831,  ..., -50.6825, -49.8886, -49.5048],\n",
      "          [-51.6961, -49.0685, -48.9114,  ..., -49.4049, -49.1464, -50.9212],\n",
      "          [-50.2888, -48.5087, -49.5262,  ..., -49.4060, -50.3186, -50.6697]]],\n",
      "\n",
      "\n",
      "        [[[-10.5740,  -6.6337,  -8.5231,  ...,  -8.6571,  -5.7712,  -7.2641],\n",
      "          [-13.8897, -10.3217, -13.4287,  ..., -16.9600, -11.8110,  -9.2367],\n",
      "          [-23.7448, -22.1353, -25.4149,  ..., -25.1986, -20.3145, -14.5135],\n",
      "          ...,\n",
      "          [-56.6444, -52.8006, -52.6621,  ..., -51.8420, -53.6470, -55.4209],\n",
      "          [-55.7708, -51.4955, -51.6007,  ..., -51.9611, -51.7362, -53.4997],\n",
      "          [-55.3219, -52.4044, -52.4623,  ..., -52.5349, -53.7143, -56.9817]]],\n",
      "\n",
      "\n",
      "        [[[ -5.3598,  -3.5870,  -7.7213,  ...,  -2.1239,  -7.6019, -16.7891],\n",
      "          [ -5.8658,  -5.3685,  -7.8181,  ...,  -4.0615,  -8.9067, -14.8545],\n",
      "          [-11.5583, -15.3547, -19.3934,  ..., -16.7265, -17.2696, -18.3079],\n",
      "          ...,\n",
      "          [-47.5734, -45.8095, -45.9924,  ..., -44.0620, -45.6469, -47.2745],\n",
      "          [-48.5098, -45.7572, -45.2733,  ..., -44.6914, -46.3110, -48.8676],\n",
      "          [-49.0852, -46.0152, -45.1482,  ..., -44.7064, -45.7651, -47.9350]]]]), tensor([ 7,  4, 13, 20,  5,  9,  7, 14,  9, 17,  7,  2, 19, 15, 19, 18, 17, 12,\n",
      "        17, 13,  1,  9, 15, 13, 10])]\n",
      "[tensor([[[[-16.5098, -13.6158, -13.7698,  ..., -20.1823, -15.1784, -14.9491],\n",
      "          [-17.1146, -14.5767, -15.2056,  ..., -17.9235, -14.7208, -14.5118],\n",
      "          [-20.5487, -19.4128, -19.8824,  ..., -25.1827, -23.9422, -20.0301],\n",
      "          ...,\n",
      "          [-51.9878, -48.7872, -49.3824,  ..., -49.1425, -48.0484, -49.6893],\n",
      "          [-51.2758, -49.8633, -49.9142,  ..., -50.0475, -49.9551, -51.1813],\n",
      "          [-53.1391, -51.0403, -50.3494,  ..., -51.4081, -50.0263, -50.0482]]],\n",
      "\n",
      "\n",
      "        [[[-10.7208,  -5.1715,  -4.3676,  ..., -10.5834, -11.5595, -16.9046],\n",
      "          [-12.3766,  -8.8231, -10.9925,  ..., -15.4747, -12.9223, -19.2970],\n",
      "          [-18.7908, -21.4462, -20.5267,  ..., -22.6840, -21.4934, -24.3930],\n",
      "          ...,\n",
      "          [-49.9995, -48.0103, -48.4120,  ..., -49.7643, -49.8806, -51.6831],\n",
      "          [-47.4270, -47.3056, -48.4698,  ..., -49.4439, -47.8779, -49.5320],\n",
      "          [-51.3528, -48.1071, -48.6567,  ..., -48.5554, -48.1139, -51.5024]]],\n",
      "\n",
      "\n",
      "        [[[-15.0478, -13.8001, -14.4621,  ..., -15.5620, -12.5570, -13.9192],\n",
      "          [-16.9501, -15.3223, -15.4388,  ..., -23.5943, -17.3096, -17.4727],\n",
      "          [-21.4123, -20.9109, -20.8366,  ..., -28.2529, -30.6608, -29.5175],\n",
      "          ...,\n",
      "          [-51.7909, -49.2375, -49.9399,  ..., -50.1581, -49.0799, -51.5343],\n",
      "          [-50.2857, -49.8086, -50.5261,  ..., -49.6846, -49.2241, -50.3883],\n",
      "          [-55.8301, -51.5755, -50.2552,  ..., -49.5259, -50.5020, -52.1422]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -7.5071,  -3.8854,  -4.2999,  ...,  -9.5368,  -5.0302,  -8.2657],\n",
      "          [ -6.8737,  -3.2673,  -4.4442,  ...,  -7.8864,  -4.6115,  -6.8085],\n",
      "          [-12.2169, -13.6799, -16.4138,  ..., -11.7323,  -9.3301, -12.1456],\n",
      "          ...,\n",
      "          [-53.6855, -49.2084, -48.6956,  ..., -47.9869, -48.6832, -50.5034],\n",
      "          [-52.8633, -50.2232, -48.7245,  ..., -48.7317, -48.8106, -49.9419],\n",
      "          [-51.5715, -49.3451, -48.4451,  ..., -50.2108, -50.0642, -52.4181]]],\n",
      "\n",
      "\n",
      "        [[[-11.8320,  -9.3900, -12.8467,  ...,  -8.0388, -12.1001, -16.2452],\n",
      "          [-14.0154, -11.1234, -13.2705,  ..., -10.9791, -21.3799, -25.7574],\n",
      "          [-21.1259, -20.0579, -16.5633,  ..., -17.7590, -18.4349, -24.7722],\n",
      "          ...,\n",
      "          [-48.7344, -46.6707, -47.3893,  ..., -47.9304, -47.0027, -49.1107],\n",
      "          [-50.8510, -47.1817, -45.4753,  ..., -47.5742, -47.8928, -49.5717],\n",
      "          [-51.1758, -47.2426, -46.3059,  ..., -46.3051, -46.9690, -50.1339]]],\n",
      "\n",
      "\n",
      "        [[[-14.4391,  -9.1209, -13.9443,  ...,   0.0000,  -2.8345, -10.3333],\n",
      "          [-15.8548, -12.0871, -15.2193,  ...,  -4.8612,  -9.4798, -14.0009],\n",
      "          [-24.0867, -24.5031, -22.1925,  ..., -19.7124, -24.7431, -22.2317],\n",
      "          ...,\n",
      "          [-51.8401, -49.6562, -49.8052,  ..., -50.2163, -49.5208, -51.2952],\n",
      "          [-51.6299, -48.7858, -48.9311,  ..., -48.2765, -49.9220, -50.6108],\n",
      "          [-51.8833, -49.2698, -50.0158,  ..., -48.9768, -50.1476, -53.0972]]]]), tensor([15,  5, 13, 19, 19, 14,  1, 10, 16,  8, 14,  7, 15, 12, 11,  6,  8,  2,\n",
      "        15, 18, 17,  2, 20,  4, 18])]\n",
      "[tensor([[[[-12.9459, -10.7339, -10.5763,  ..., -20.9138, -20.2874, -14.5386],\n",
      "          [-16.2831, -17.0857, -17.3435,  ..., -20.9503, -15.2757, -11.8472],\n",
      "          [-19.1016, -23.3032, -27.8499,  ..., -24.8851, -16.8646, -13.7081],\n",
      "          ...,\n",
      "          [-56.1595, -54.5195, -52.6238,  ..., -53.5836, -51.8603, -54.6450],\n",
      "          [-55.6095, -52.5743, -51.9246,  ..., -53.2095, -52.6188, -55.5935],\n",
      "          [-56.4487, -52.2921, -53.7554,  ..., -52.4024, -51.2213, -51.8921]]],\n",
      "\n",
      "\n",
      "        [[[-18.0209, -11.7379, -10.2200,  ...,  -4.2470,   0.0000,  -3.4826],\n",
      "          [-23.1801, -15.6190, -14.9000,  ...,  -7.3462,  -2.9329,  -4.3133],\n",
      "          [-33.2646, -23.7604, -21.9551,  ..., -20.5872, -16.4038, -11.7417],\n",
      "          ...,\n",
      "          [-56.7785, -52.5463, -51.7002,  ..., -53.8370, -52.9018, -53.2154],\n",
      "          [-56.1939, -54.8628, -54.4604,  ..., -52.7387, -52.6176, -52.2500],\n",
      "          [-54.6674, -52.6126, -53.7326,  ..., -52.3661, -52.9609, -54.0416]]],\n",
      "\n",
      "\n",
      "        [[[-18.3027, -15.4641,  -9.5809,  ..., -11.0653, -12.1972, -19.5427],\n",
      "          [-19.2963, -18.3188, -13.0030,  ..., -15.4253, -15.2683, -24.6046],\n",
      "          [-20.2961, -20.8818, -20.8779,  ..., -24.6880, -25.6998, -30.8342],\n",
      "          ...,\n",
      "          [-48.0807, -45.6483, -45.3463,  ..., -47.3056, -47.6561, -47.9204],\n",
      "          [-47.8975, -44.5405, -43.8399,  ..., -47.5982, -47.1712, -48.2320],\n",
      "          [-48.5111, -45.4942, -44.9434,  ..., -46.1690, -44.6446, -46.2503]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.3386,  -8.1295,  -9.4182,  ...,  -3.5372,  -6.9823, -12.3089],\n",
      "          [-14.2323, -10.6343, -11.0549,  ...,  -6.1847, -12.1914, -14.8063],\n",
      "          [-23.5425, -23.3458, -19.9860,  ..., -17.2117, -20.5783, -20.5997],\n",
      "          ...,\n",
      "          [-49.5552, -46.5474, -46.3638,  ..., -47.1317, -46.2887, -47.9489],\n",
      "          [-50.2128, -46.6963, -46.5049,  ..., -46.7846, -48.3372, -50.4113],\n",
      "          [-49.7589, -48.1748, -49.3193,  ..., -48.4582, -49.2449, -50.2379]]],\n",
      "\n",
      "\n",
      "        [[[-11.0291,  -5.0556,  -7.3908,  ...,  -5.4382,  -8.5189, -14.6596],\n",
      "          [-11.8465,  -8.6335,  -9.1775,  ..., -10.5531, -13.6293, -21.6308],\n",
      "          [-17.3718, -17.8354, -16.5804,  ..., -19.8602, -21.2210, -25.3905],\n",
      "          ...,\n",
      "          [-50.1780, -48.1141, -49.1871,  ..., -47.1003, -47.3462, -50.3536],\n",
      "          [-49.9736, -48.0062, -49.3661,  ..., -47.9526, -48.1708, -51.8342],\n",
      "          [-52.2147, -48.4390, -48.6952,  ..., -48.9274, -48.7183, -51.3020]]],\n",
      "\n",
      "\n",
      "        [[[-12.6869,  -6.1255,  -5.5152,  ...,  -5.7381,  -3.4278,  -6.2596],\n",
      "          [-13.6166, -11.1559,  -8.7832,  ..., -11.3911,  -7.8598, -11.0899],\n",
      "          [-18.3389, -18.4038, -21.8603,  ..., -21.9691, -21.5309, -24.5514],\n",
      "          ...,\n",
      "          [-53.4539, -51.1406, -50.9320,  ..., -51.7844, -51.3928, -51.3885],\n",
      "          [-55.7355, -52.1812, -51.9173,  ..., -51.1953, -51.1556, -51.4325],\n",
      "          [-55.7891, -53.1854, -52.2578,  ..., -50.8765, -51.2024, -53.7012]]]]), tensor([ 2,  7, 11,  3, 11, 12,  1,  3, 13, 15, 19, 16,  1, 14, 11,  6, 12,  9,\n",
      "        10,  5,  1,  0, 10,  6,  6])]\n",
      "[tensor([[[[ -5.1685,  -3.5431,  -6.1680,  ...,  -0.0917,  -0.7231,  -5.5518],\n",
      "          [ -7.6702,  -7.7361, -11.8104,  ...,  -6.2485,  -5.7362,  -8.8374],\n",
      "          [-13.8354, -15.0222, -20.2270,  ..., -22.6714, -23.3922, -22.0796],\n",
      "          ...,\n",
      "          [-55.2056, -52.8139, -52.3971,  ..., -52.7700, -53.1397, -54.7791],\n",
      "          [-55.8079, -52.0751, -50.6632,  ..., -52.3088, -52.0392, -54.6527],\n",
      "          [-56.1405, -53.2581, -52.3736,  ..., -53.7071, -53.6263, -53.4978]]],\n",
      "\n",
      "\n",
      "        [[[-10.6643,  -7.3887,  -8.8921,  ...,  -8.2710,  -7.0803, -11.5905],\n",
      "          [-10.7584,  -8.7772,  -8.7842,  ..., -12.7270,  -8.9024, -12.9026],\n",
      "          [-16.5672, -21.2453, -18.7724,  ..., -17.3295, -18.4741, -22.8398],\n",
      "          ...,\n",
      "          [-53.2704, -50.3550, -51.5633,  ..., -50.3345, -51.2440, -53.5748],\n",
      "          [-51.9836, -50.0980, -50.9822,  ..., -50.7501, -52.0841, -52.2893],\n",
      "          [-52.8884, -51.2494, -51.7744,  ..., -50.7838, -51.9005, -53.4901]]],\n",
      "\n",
      "\n",
      "        [[[-12.4899, -12.6390, -18.3412,  ..., -11.5354, -11.1510, -11.5272],\n",
      "          [-10.6332, -11.0089, -16.0313,  ..., -11.6983, -10.5265, -11.8239],\n",
      "          [-14.1030, -14.8124, -21.2318,  ..., -15.8251, -16.3481, -18.2146],\n",
      "          ...,\n",
      "          [-52.3472, -50.5478, -50.0083,  ..., -51.3235, -50.5600, -52.0638],\n",
      "          [-54.1867, -51.5227, -51.9898,  ..., -53.0278, -52.5103, -52.9369],\n",
      "          [-53.4603, -51.6214, -52.9473,  ..., -52.4769, -51.4700, -52.2444]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-18.7897, -15.7237, -19.1669,  ...,  -2.5864,  -3.4854,  -8.3363],\n",
      "          [-17.5980, -15.9615, -24.4952,  ..., -10.9740,  -9.5510, -10.4342],\n",
      "          [-23.2868, -20.0114, -26.7704,  ..., -31.7439, -22.8537, -20.2259],\n",
      "          ...,\n",
      "          [-55.7549, -51.1689, -50.3053,  ..., -50.8378, -50.6562, -53.0983],\n",
      "          [-54.3370, -50.7302, -50.5244,  ..., -51.5256, -51.2671, -51.4067],\n",
      "          [-55.3706, -51.2870, -50.2594,  ..., -52.2861, -51.2770, -52.1787]]],\n",
      "\n",
      "\n",
      "        [[[-19.4503, -11.6368,  -6.7816,  ..., -12.0678,  -8.9254,  -9.2904],\n",
      "          [-14.8976,  -8.0731,  -6.4716,  ..., -15.7901, -11.9013, -12.1636],\n",
      "          [-17.3328, -15.8321, -17.5205,  ..., -22.3996, -16.8316, -18.6882],\n",
      "          ...,\n",
      "          [-55.9450, -52.5807, -53.6123,  ..., -52.4918, -53.1196, -56.1903],\n",
      "          [-56.1926, -52.4201, -52.3664,  ..., -52.7488, -52.3760, -53.7092],\n",
      "          [-56.5493, -52.8165, -52.9666,  ..., -53.1975, -52.5657, -54.5543]]],\n",
      "\n",
      "\n",
      "        [[[ -8.2463,  -1.5153,  -0.3417,  ...,  -0.0767,  -0.2532,  -5.6081],\n",
      "          [ -7.9649,  -2.4761,  -3.8179,  ...,  -1.0361,  -2.4826,  -7.4762],\n",
      "          [-15.5043, -13.3370, -16.3814,  ..., -13.8375, -16.0605, -16.8942],\n",
      "          ...,\n",
      "          [-52.0576, -47.6453, -47.5434,  ..., -50.1476, -49.5708, -50.5257],\n",
      "          [-52.1544, -48.6912, -47.6840,  ..., -50.1298, -51.6062, -52.9518],\n",
      "          [-53.5745, -50.4228, -49.4765,  ..., -49.7564, -49.9691, -51.0382]]]]), tensor([ 2,  9,  1, 13, 11, 13, 10,  6,  8, 14, 10, 12, 20, 18, 19,  9, 16,  0,\n",
      "        17, 14,  5,  2,  4,  2,  7])]\n",
      "[tensor([[[[-11.7756,  -7.0410,  -4.9498,  ...,  -9.3433,  -6.6749,  -8.1286],\n",
      "          [-16.8265, -12.4159, -10.2116,  ...,  -8.9402,  -7.7014,  -9.2996],\n",
      "          [-22.2347, -21.5294, -20.6842,  ..., -16.5950, -21.3083, -17.7230],\n",
      "          ...,\n",
      "          [-52.1803, -50.2204, -50.7931,  ..., -50.7613, -50.6474, -51.4796],\n",
      "          [-53.6427, -51.5287, -50.7069,  ..., -49.1984, -50.5256, -53.1105],\n",
      "          [-53.3888, -50.0538, -50.9244,  ..., -50.5473, -49.6493, -52.5006]]],\n",
      "\n",
      "\n",
      "        [[[-16.8677, -10.9837, -11.5365,  ..., -17.7769, -14.8101, -12.9792],\n",
      "          [-16.3892, -12.8971, -14.8058,  ..., -26.5489, -17.9043, -13.9401],\n",
      "          [-21.4324, -22.9268, -26.4240,  ..., -31.6903, -24.6109, -19.1836],\n",
      "          ...,\n",
      "          [-55.8700, -52.3636, -51.3638,  ..., -50.5106, -52.0963, -54.2482],\n",
      "          [-56.1806, -52.7200, -51.4017,  ..., -50.6342, -51.1227, -53.4283],\n",
      "          [-57.3869, -54.4889, -53.0539,  ..., -54.0687, -52.3150, -53.6756]]],\n",
      "\n",
      "\n",
      "        [[[-11.7163,  -4.6254,  -3.2696,  ..., -16.9017, -12.0346, -14.7881],\n",
      "          [-12.1810,  -7.0967,  -6.9876,  ..., -15.8202, -15.7874, -15.3310],\n",
      "          [-20.1109, -21.1059, -22.1745,  ..., -18.4897, -20.9831, -20.7972],\n",
      "          ...,\n",
      "          [-50.0040, -47.9352, -48.0505,  ..., -48.1633, -48.3408, -50.5797],\n",
      "          [-52.1636, -49.2911, -48.9361,  ..., -48.9829, -48.4587, -51.9963],\n",
      "          [-53.8949, -50.1011, -49.6775,  ..., -49.2414, -48.3503, -52.0036]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -8.0873,  -7.3582,  -7.8443,  ..., -12.2081, -11.0819,  -8.1737],\n",
      "          [-10.2855, -11.8433, -10.3012,  ...,  -9.5623,  -9.5996,  -8.4761],\n",
      "          [-16.7114, -16.3081, -19.1141,  ..., -15.3856, -15.3966, -14.3635],\n",
      "          ...,\n",
      "          [-52.9925, -51.6669, -51.2964,  ..., -47.6690, -50.3343, -54.7010],\n",
      "          [-53.0450, -50.2613, -51.2696,  ..., -49.3092, -50.2960, -51.7941],\n",
      "          [-51.0952, -48.8961, -50.2779,  ..., -48.1650, -49.5840, -52.3887]]],\n",
      "\n",
      "\n",
      "        [[[-11.7221,  -7.5009,  -4.9032,  ...,  -3.8887,  -2.3518,  -5.2582],\n",
      "          [-12.1687,  -6.4206,  -4.1923,  ...,  -3.6549,  -2.2777,  -4.3293],\n",
      "          [-19.7003, -17.7530, -17.0349,  ..., -15.9735, -14.7695, -11.0209],\n",
      "          ...,\n",
      "          [-55.3763, -53.5250, -53.1544,  ..., -53.0976, -53.6414, -54.5680],\n",
      "          [-57.2011, -54.6884, -53.9950,  ..., -53.2046, -54.7418, -55.1734],\n",
      "          [-54.8278, -52.9933, -53.7695,  ..., -55.1222, -55.4178, -56.0121]]],\n",
      "\n",
      "\n",
      "        [[[-32.0508, -18.6434, -15.1491,  ..., -23.5368, -24.9932, -32.0979],\n",
      "          [-31.0583, -20.0940, -18.5767,  ..., -30.2197, -28.5712, -33.5006],\n",
      "          [-35.3113, -28.8498, -30.7482,  ..., -34.2117, -27.9173, -28.0230],\n",
      "          ...,\n",
      "          [-58.8011, -56.6923, -58.5047,  ..., -56.8365, -55.2544, -56.6119],\n",
      "          [-59.9491, -56.5991, -56.6075,  ..., -57.2557, -57.4822, -59.0407],\n",
      "          [-60.0381, -57.1882, -55.2488,  ..., -54.3049, -55.9977, -60.8532]]]]), tensor([ 0, 16,  4, 12,  3, 10, 16, 17,  4,  7,  4,  2,  6, 18, 20,  1, 12, 16,\n",
      "        16, 17,  4, 14,  1, 14, 17])]\n",
      "[tensor([[[[-13.8820, -13.2763, -12.7538,  ...,  -5.6196,  -4.1067,  -8.6514],\n",
      "          [-15.5819, -19.0227, -19.7076,  ...,  -8.1158,  -7.6211, -10.1307],\n",
      "          [-18.5374, -20.9645, -31.7378,  ..., -14.6175, -18.0286, -17.5111],\n",
      "          ...,\n",
      "          [-51.7487, -49.4922, -50.8934,  ..., -48.3644, -49.7760, -52.1333],\n",
      "          [-51.9308, -50.1141, -51.3312,  ..., -50.5186, -50.3585, -52.3874],\n",
      "          [-53.7617, -50.5438, -50.3975,  ..., -50.3885, -49.3604, -51.6796]]],\n",
      "\n",
      "\n",
      "        [[[ -3.6491,  -0.1169,  -1.2708,  ..., -15.0683, -18.6120, -16.5309],\n",
      "          [ -7.5189,  -4.7812,  -6.0383,  ..., -12.9051, -12.8131, -14.1332],\n",
      "          [-17.1251, -19.8379, -17.7177,  ..., -18.6443, -15.8214, -17.1822],\n",
      "          ...,\n",
      "          [-53.1104, -50.6421, -50.9671,  ..., -49.0212, -50.9348, -53.4743],\n",
      "          [-54.4481, -52.0334, -51.3920,  ..., -50.2045, -51.1214, -52.6923],\n",
      "          [-53.0755, -51.1130, -49.9918,  ..., -50.5614, -50.6246, -53.7614]]],\n",
      "\n",
      "\n",
      "        [[[ -9.7955,  -5.9862,  -3.8906,  ...,  -1.4620,  -6.8214, -12.6527],\n",
      "          [ -8.9254,  -3.9711,  -3.1762,  ...,  -1.2694,  -3.6564,  -9.0598],\n",
      "          [-14.6580, -14.2811, -15.4592,  ..., -13.5096, -13.4330, -13.1754],\n",
      "          ...,\n",
      "          [-55.6674, -53.4809, -53.3736,  ..., -53.4829, -54.8861, -55.5131],\n",
      "          [-56.9255, -55.2635, -54.5886,  ..., -53.6918, -53.9781, -54.3855],\n",
      "          [-56.1894, -53.2439, -53.3132,  ..., -54.0230, -53.9033, -54.7176]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -9.3630,  -8.0156, -10.7116,  ..., -15.6980, -18.4390, -22.9805],\n",
      "          [-11.0363, -10.8332, -16.3648,  ..., -12.0238, -11.7764, -16.9739],\n",
      "          [-17.6310, -19.5291, -27.1900,  ..., -18.5102, -14.0359, -19.7002],\n",
      "          ...,\n",
      "          [-56.1942, -53.0955, -53.3711,  ..., -53.7066, -53.6759, -55.7073],\n",
      "          [-55.1096, -52.2083, -52.4010,  ..., -52.3425, -51.5793, -54.9182],\n",
      "          [-55.2412, -52.8344, -52.3349,  ..., -54.3277, -52.6744, -54.7175]]],\n",
      "\n",
      "\n",
      "        [[[-16.5507, -16.8092, -13.3030,  ..., -11.8545,  -7.5122,  -7.1141],\n",
      "          [-17.8905, -15.7555, -15.3671,  ..., -12.9508,  -8.6334,  -8.8057],\n",
      "          [-22.0580, -20.2114, -21.9231,  ..., -21.1280, -17.4335, -16.1876],\n",
      "          ...,\n",
      "          [-51.2254, -49.3412, -48.4575,  ..., -48.8502, -49.8611, -52.1791],\n",
      "          [-51.9451, -48.5081, -48.4278,  ..., -48.6097, -48.3876, -50.1398],\n",
      "          [-52.1920, -49.4794, -48.2586,  ..., -48.9832, -49.5116, -51.7586]]],\n",
      "\n",
      "\n",
      "        [[[-12.6704, -10.0989, -15.7285,  ...,  -1.1067,  -4.9090, -11.6635],\n",
      "          [-17.0735, -12.7654, -14.1774,  ...,  -4.9070,  -9.1263, -17.1113],\n",
      "          [-24.4590, -19.2597, -19.7641,  ..., -18.5482, -19.4238, -18.5840],\n",
      "          ...,\n",
      "          [-61.6435, -58.9187, -57.5728,  ..., -59.3153, -58.2450, -59.3043],\n",
      "          [-60.0850, -57.6033, -56.7001,  ..., -58.3688, -58.7643, -59.3651],\n",
      "          [-62.3474, -59.6540, -58.1206,  ..., -57.3825, -57.4624, -59.3069]]]]), tensor([ 1,  3, 14,  3,  9,  4, 14,  8,  1, 12, 15,  0, 10, 11, 20,  0, 15,  3,\n",
      "         7, 10, 18, 18,  0,  8,  8])]\n",
      "[tensor([[[[ -7.6809,  -1.3894,  -6.1454,  ...,  -3.2551,  -6.2737, -16.9419],\n",
      "          [ -8.9156,  -3.4992,  -4.9761,  ...,  -5.3517,  -9.1741, -21.1846],\n",
      "          [-18.6063, -13.1490, -12.8090,  ..., -17.3216, -20.5329, -24.9092],\n",
      "          ...,\n",
      "          [-46.4100, -42.4945, -41.8615,  ..., -41.1409, -42.9757, -43.2790],\n",
      "          [-46.7894, -42.9631, -42.8739,  ..., -42.9658, -42.4366, -46.0061],\n",
      "          [-46.6880, -43.2702, -43.5808,  ..., -42.4506, -41.8991, -46.7900]]],\n",
      "\n",
      "\n",
      "        [[[-10.9027,  -5.9879,  -4.8815,  ..., -12.9866, -12.6573, -23.0787],\n",
      "          [-11.0216, -12.6848, -10.1498,  ..., -14.9163, -13.8779, -19.4198],\n",
      "          [-14.9135, -17.6198, -21.9165,  ..., -25.8100, -23.9186, -22.0997],\n",
      "          ...,\n",
      "          [-54.8032, -52.6899, -51.4362,  ..., -49.7228, -49.5046, -52.7644],\n",
      "          [-54.9945, -53.0867, -51.7927,  ..., -52.5484, -52.0616, -53.3008],\n",
      "          [-52.5169, -51.2426, -52.4969,  ..., -52.0333, -51.2828, -52.8398]]],\n",
      "\n",
      "\n",
      "        [[[-15.9130,  -9.9528,  -7.5890,  ..., -11.2977, -10.1811, -12.3607],\n",
      "          [-21.2572, -14.8245, -11.5313,  ..., -16.5643, -16.8365, -18.4382],\n",
      "          [-33.1820, -24.2761, -21.9110,  ..., -27.6454, -28.7181, -27.4541],\n",
      "          ...,\n",
      "          [-50.6144, -49.4790, -49.2020,  ..., -49.9200, -50.9647, -52.2441],\n",
      "          [-52.9786, -50.4453, -50.5858,  ..., -49.9498, -49.8033, -51.3987],\n",
      "          [-53.1406, -51.3434, -51.0862,  ..., -49.2642, -49.5327, -49.3084]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -6.2205,  -3.8830,  -4.9260,  ...,  -3.4583,  -2.2113,  -4.2974],\n",
      "          [ -6.9878,  -3.6763,  -4.0112,  ...,  -3.6516,  -2.7743,  -4.7081],\n",
      "          [-14.9627, -15.9165, -17.0534,  ..., -17.2712, -15.9078, -12.9416],\n",
      "          ...,\n",
      "          [-55.6110, -51.7466, -50.3878,  ..., -52.5192, -50.9247, -53.7009],\n",
      "          [-53.5899, -49.8057, -50.3230,  ..., -52.8653, -52.6432, -55.3551],\n",
      "          [-55.4416, -52.3089, -51.4771,  ..., -51.5620, -51.0621, -52.7299]]],\n",
      "\n",
      "\n",
      "        [[[-18.3339,  -9.2998,  -4.6474,  ..., -12.3196, -14.5386, -20.0846],\n",
      "          [-20.7360, -15.5852,  -7.0846,  ..., -14.6952, -17.1643, -24.0331],\n",
      "          [-26.5389, -24.6012, -16.0612,  ..., -22.2092, -19.4099, -23.9425],\n",
      "          ...,\n",
      "          [-51.2855, -47.6523, -48.5198,  ..., -48.6568, -48.5462, -50.3284],\n",
      "          [-52.5481, -49.4531, -48.6133,  ..., -48.4802, -48.6068, -50.3791],\n",
      "          [-52.2420, -49.7171, -48.2370,  ..., -49.4797, -50.1228, -51.8326]]],\n",
      "\n",
      "\n",
      "        [[[-12.6616,  -8.2074,  -9.9863,  ...,  -9.5144, -17.3313, -22.6666],\n",
      "          [-15.6575, -12.6969, -15.0423,  ..., -11.6336, -14.0662, -18.8411],\n",
      "          [-19.4713, -17.0566, -17.6623,  ..., -18.6267, -19.1972, -20.3666],\n",
      "          ...,\n",
      "          [-50.4674, -48.8755, -48.1325,  ..., -48.3828, -48.9122, -51.1367],\n",
      "          [-51.4188, -49.2578, -49.7904,  ..., -48.0029, -47.9695, -50.3255],\n",
      "          [-52.1345, -49.0089, -48.0940,  ..., -48.2453, -48.6368, -51.7287]]]]), tensor([11, 16,  1,  1,  0, 15, 20,  4, 13,  1, 19,  3, 10,  1,  4, 12,  2,  9,\n",
      "         0,  5, 20,  3, 14,  6,  3])]\n",
      "[tensor([[[[-12.3534,  -8.1414,  -7.3962,  ...,  -9.6710, -10.2073, -18.5057],\n",
      "          [-15.8491, -12.5674, -10.7024,  ..., -13.2207, -11.3987, -18.4529],\n",
      "          [-24.6950, -25.3183, -25.8794,  ..., -25.2772, -20.0603, -21.6492],\n",
      "          ...,\n",
      "          [-58.5614, -54.2405, -53.9698,  ..., -55.7635, -55.6912, -56.3000],\n",
      "          [-57.0635, -54.4432, -55.9435,  ..., -54.1819, -54.7409, -55.6478],\n",
      "          [-57.2229, -55.7335, -56.3952,  ..., -56.5256, -54.9140, -55.9728]]],\n",
      "\n",
      "\n",
      "        [[[ -4.0662,  -0.3494,   0.0000,  ...,  -4.6714,  -3.9676,  -8.6064],\n",
      "          [-10.3888,  -7.2953,  -5.8475,  ...,  -9.4470,  -8.2664, -10.5236],\n",
      "          [-17.5188, -18.0142, -23.6312,  ..., -20.8997, -20.2381, -17.0905],\n",
      "          ...,\n",
      "          [-54.4361, -50.9694, -49.5850,  ..., -50.9147, -48.4651, -49.2708],\n",
      "          [-53.5730, -49.8567, -50.6208,  ..., -51.8278, -50.4198, -52.0098],\n",
      "          [-53.8774, -52.0039, -51.2027,  ..., -49.0434, -48.4871, -52.2826]]],\n",
      "\n",
      "\n",
      "        [[[ -6.0855,  -4.9794,  -8.9611,  ...,  -4.5734,  -8.1216, -14.2574],\n",
      "          [ -8.3703,  -7.9510, -12.9993,  ...,  -3.3616,  -4.6402, -10.8244],\n",
      "          [-15.2722, -17.3643, -18.1749,  ..., -13.3375, -12.6844, -15.5775],\n",
      "          ...,\n",
      "          [-53.7831, -50.6899, -50.5273,  ..., -49.9324, -49.5276, -51.8852],\n",
      "          [-54.1276, -53.2184, -51.3571,  ..., -50.0235, -49.4541, -51.1497],\n",
      "          [-52.8796, -50.6453, -50.6585,  ..., -50.6192, -50.4637, -52.1600]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.5110,  -7.9269,  -7.1359,  ...,  -6.5687,  -8.4930, -13.5501],\n",
      "          [-16.0248, -13.7008, -10.5023,  ...,  -9.8067, -12.3579, -14.6271],\n",
      "          [-23.0445, -20.5140, -20.6409,  ..., -22.6591, -21.4507, -22.0410],\n",
      "          ...,\n",
      "          [-54.8558, -53.1715, -52.6942,  ..., -55.3365, -54.3472, -55.8967],\n",
      "          [-55.5346, -53.1642, -52.5521,  ..., -53.4395, -53.8366, -55.6236],\n",
      "          [-56.6218, -53.3334, -55.0011,  ..., -53.3813, -52.2190, -54.2354]]],\n",
      "\n",
      "\n",
      "        [[[-21.5801, -15.6315, -14.7686,  ..., -19.2304, -22.4431, -26.7380],\n",
      "          [-26.2056, -20.6170, -16.6030,  ..., -16.2064, -18.8988, -23.0298],\n",
      "          [-33.2804, -28.7255, -21.4495,  ..., -24.0527, -27.0809, -27.6899],\n",
      "          ...,\n",
      "          [-55.4699, -52.1332, -50.2111,  ..., -51.3910, -51.0190, -54.0519],\n",
      "          [-54.2748, -50.5112, -50.0293,  ..., -52.0322, -52.3634, -54.5737],\n",
      "          [-53.5809, -51.2456, -51.6310,  ..., -51.4344, -51.5829, -53.4043]]],\n",
      "\n",
      "\n",
      "        [[[ -9.9556,  -8.0223, -15.5049,  ...,  -5.8669,  -7.9880, -15.8333],\n",
      "          [ -7.7237,  -6.1376, -10.2059,  ...,  -5.8948, -10.3746, -19.1705],\n",
      "          [-11.4615, -14.8107, -14.7004,  ..., -17.7533, -22.1156, -32.2179],\n",
      "          ...,\n",
      "          [-51.2957, -49.0700, -49.1583,  ..., -48.1738, -49.3872, -52.2161],\n",
      "          [-50.7348, -48.1175, -49.4220,  ..., -47.8958, -48.5351, -49.4556],\n",
      "          [-50.5864, -48.8926, -49.5004,  ..., -48.6794, -49.1842, -52.3914]]]]), tensor([ 4,  0,  8,  9, 12,  3,  3,  9,  0,  6,  3, 17,  6,  5, 11, 16, 15,  4,\n",
      "        12,  8,  9,  5,  6, 13,  8])]\n",
      "[tensor([[[[-17.3370, -13.6840, -18.9090,  ...,  -6.2777,  -8.6486, -16.0327],\n",
      "          [-22.4095, -18.8803, -17.4200,  ..., -10.2325, -13.0265, -21.1505],\n",
      "          [-28.2006, -22.0807, -20.6433,  ..., -18.2779, -23.1035, -28.7418],\n",
      "          ...,\n",
      "          [-58.2493, -54.7077, -52.7674,  ..., -55.4682, -53.3706, -53.8794],\n",
      "          [-56.9645, -54.1312, -52.3820,  ..., -53.6517, -52.9824, -54.0226],\n",
      "          [-58.1695, -54.5925, -53.9564,  ..., -52.4616, -52.3464, -54.8691]]],\n",
      "\n",
      "\n",
      "        [[[ -8.0931,  -3.0809,  -2.1194,  ...,  -2.4892,  -3.2072,  -5.9954],\n",
      "          [ -8.8219,  -3.6177,  -2.6965,  ...,  -2.7955,  -3.2077,  -5.1771],\n",
      "          [-16.2112, -16.0135, -16.6433,  ..., -16.2770, -15.9546, -12.2362],\n",
      "          ...,\n",
      "          [-54.1955, -53.2327, -54.2320,  ..., -53.0093, -53.6045, -54.3664],\n",
      "          [-55.6548, -53.5421, -54.4195,  ..., -52.1077, -52.6243, -54.1062],\n",
      "          [-58.7440, -54.3559, -54.2793,  ..., -52.4463, -52.1186, -54.6892]]],\n",
      "\n",
      "\n",
      "        [[[ -9.6498,  -6.2075,  -4.5347,  ...,  -3.5316,  -4.4289,  -4.4301],\n",
      "          [ -9.5448,  -5.8848,  -5.0769,  ...,  -2.5754,  -3.3229,  -4.6227],\n",
      "          [-15.3968, -16.7912, -18.0456,  ..., -14.1376, -15.4660, -11.7303],\n",
      "          ...,\n",
      "          [-54.1135, -51.7630, -51.7465,  ..., -51.6635, -52.8606, -52.8051],\n",
      "          [-53.7857, -51.8269, -51.9632,  ..., -53.6480, -53.6472, -54.0929],\n",
      "          [-55.9510, -54.0242, -53.8441,  ..., -52.1160, -53.5992, -55.9835]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-19.3030, -20.0919, -14.3340,  ...,  -1.1654,  -4.4234, -15.1536],\n",
      "          [-17.3505, -16.7345, -13.2978,  ...,  -1.8424,  -3.4892, -11.1512],\n",
      "          [-21.5774, -23.9938, -20.7966,  ..., -10.2834, -12.9977, -13.8153],\n",
      "          ...,\n",
      "          [-53.1820, -51.2893, -52.1281,  ..., -50.9769, -50.3367, -52.9549],\n",
      "          [-55.8379, -51.9040, -52.0206,  ..., -50.9986, -51.2125, -53.2668],\n",
      "          [-55.7550, -52.6171, -52.5296,  ..., -52.2303, -52.8020, -53.9154]]],\n",
      "\n",
      "\n",
      "        [[[-11.1603,  -5.8698,  -5.5590,  ..., -11.9730, -12.3221, -11.9913],\n",
      "          [-12.4443,  -8.4158,  -7.2249,  ..., -15.0613, -12.1208, -13.6823],\n",
      "          [-21.6478, -22.9541, -19.5704,  ..., -17.1054, -19.1276, -21.0368],\n",
      "          ...,\n",
      "          [-47.0859, -46.2030, -46.4313,  ..., -44.2340, -44.1578, -46.9369],\n",
      "          [-48.9116, -46.0197, -45.4827,  ..., -44.7112, -45.0200, -47.0736],\n",
      "          [-50.2629, -46.8827, -46.5767,  ..., -45.6073, -46.9797, -48.5544]]],\n",
      "\n",
      "\n",
      "        [[[ -8.9465,  -4.9386,  -3.4910,  ...,  -8.8267,  -6.6299, -10.4541],\n",
      "          [-11.3466,  -9.8318,  -8.1840,  ..., -11.4609,  -7.0067, -10.0628],\n",
      "          [-18.8256, -24.1063, -22.3295,  ..., -17.7201, -17.6753, -18.2109],\n",
      "          ...,\n",
      "          [-56.3092, -54.5021, -54.6962,  ..., -54.3815, -55.0944, -58.3650],\n",
      "          [-57.5449, -54.3026, -53.5777,  ..., -55.1495, -55.4923, -57.5995],\n",
      "          [-56.4856, -56.0001, -56.5582,  ..., -55.7848, -55.2925, -56.0462]]]]), tensor([15, 14, 18, 12,  4,  7, 17, 16,  2,  6, 19, 19, 11, 14,  2, 11,  9,  5,\n",
      "        19, 12,  7, 15, 19,  4,  8])]\n",
      "[tensor([[[[-1.3163e+01, -1.3713e+01, -5.7044e+00,  ..., -1.2634e+01,\n",
      "           -1.5390e+01, -1.5345e+01],\n",
      "          [-1.2363e+01, -1.0146e+01, -7.4118e+00,  ..., -1.5231e+01,\n",
      "           -2.1727e+01, -1.8272e+01],\n",
      "          [-1.7476e+01, -1.6215e+01, -1.7197e+01,  ..., -2.2400e+01,\n",
      "           -2.5497e+01, -2.2533e+01],\n",
      "          ...,\n",
      "          [-5.1182e+01, -4.7666e+01, -4.9066e+01,  ..., -4.9475e+01,\n",
      "           -4.9563e+01, -5.2183e+01],\n",
      "          [-5.2512e+01, -5.0168e+01, -5.0191e+01,  ..., -5.0816e+01,\n",
      "           -5.0405e+01, -5.3730e+01],\n",
      "          [-5.1582e+01, -5.0124e+01, -5.0477e+01,  ..., -4.9791e+01,\n",
      "           -4.8661e+01, -5.0672e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8231e+01, -1.5682e+01, -1.6320e+01,  ..., -1.0946e+01,\n",
      "           -1.6421e+01, -2.0916e+01],\n",
      "          [-2.1584e+01, -2.1924e+01, -1.9308e+01,  ..., -1.6133e+01,\n",
      "           -2.4725e+01, -2.7363e+01],\n",
      "          [-2.5565e+01, -2.4838e+01, -2.4402e+01,  ..., -2.5382e+01,\n",
      "           -2.8689e+01, -3.0411e+01],\n",
      "          ...,\n",
      "          [-5.5260e+01, -5.1811e+01, -5.1724e+01,  ..., -5.4572e+01,\n",
      "           -5.2932e+01, -5.4526e+01],\n",
      "          [-5.2874e+01, -5.1235e+01, -5.1454e+01,  ..., -5.2265e+01,\n",
      "           -5.3131e+01, -5.6713e+01],\n",
      "          [-5.5489e+01, -5.3212e+01, -5.2562e+01,  ..., -5.1594e+01,\n",
      "           -5.2086e+01, -5.4104e+01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1001e+01, -1.1171e+01, -5.3095e+00,  ..., -1.7959e+00,\n",
      "           -8.4892e-01, -4.4087e+00],\n",
      "          [-1.6136e+01, -8.5612e+00, -6.8571e+00,  ..., -4.9754e+00,\n",
      "           -1.9684e+00, -5.6396e+00],\n",
      "          [-1.9678e+01, -1.6660e+01, -1.9172e+01,  ..., -1.8701e+01,\n",
      "           -1.3089e+01, -1.4169e+01],\n",
      "          ...,\n",
      "          [-5.3229e+01, -5.2300e+01, -5.2039e+01,  ..., -5.1505e+01,\n",
      "           -5.0635e+01, -5.2131e+01],\n",
      "          [-5.2583e+01, -5.1240e+01, -5.1056e+01,  ..., -5.1894e+01,\n",
      "           -5.0664e+01, -5.1814e+01],\n",
      "          [-5.2456e+01, -5.0066e+01, -5.1281e+01,  ..., -5.1113e+01,\n",
      "           -5.1398e+01, -5.3474e+01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.7889e+00, -5.3173e-02,  0.0000e+00,  ..., -1.3146e+01,\n",
      "           -1.3671e+01, -1.9899e+01],\n",
      "          [-9.5718e+00, -9.7293e+00, -8.9567e+00,  ..., -1.0821e+01,\n",
      "           -1.3538e+01, -2.3663e+01],\n",
      "          [-1.7641e+01, -1.7799e+01, -2.0182e+01,  ..., -1.7725e+01,\n",
      "           -2.0284e+01, -2.8764e+01],\n",
      "          ...,\n",
      "          [-4.6298e+01, -4.3867e+01, -4.4462e+01,  ..., -4.2813e+01,\n",
      "           -4.3264e+01, -4.6480e+01],\n",
      "          [-4.7597e+01, -4.4798e+01, -4.6027e+01,  ..., -4.4467e+01,\n",
      "           -4.4975e+01, -4.6983e+01],\n",
      "          [-4.6886e+01, -4.2917e+01, -4.3735e+01,  ..., -4.4047e+01,\n",
      "           -4.4016e+01, -4.7508e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9714e+01, -1.4077e+01, -1.0484e+01,  ..., -9.4866e+00,\n",
      "           -1.0080e+01, -1.4313e+01],\n",
      "          [-2.1948e+01, -1.4893e+01, -1.1055e+01,  ..., -1.3739e+01,\n",
      "           -1.2502e+01, -1.8532e+01],\n",
      "          [-2.1884e+01, -2.0928e+01, -1.5884e+01,  ..., -2.1130e+01,\n",
      "           -1.9600e+01, -2.5277e+01],\n",
      "          ...,\n",
      "          [-5.3528e+01, -5.1130e+01, -5.1114e+01,  ..., -4.9709e+01,\n",
      "           -5.0251e+01, -5.3770e+01],\n",
      "          [-5.5577e+01, -5.1963e+01, -5.0338e+01,  ..., -4.9454e+01,\n",
      "           -5.0415e+01, -5.4143e+01],\n",
      "          [-5.5766e+01, -5.1828e+01, -5.1872e+01,  ..., -5.2364e+01,\n",
      "           -5.4275e+01, -5.4615e+01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0949e+01, -8.2982e+00, -9.4104e+00,  ..., -8.3833e+00,\n",
      "           -1.0680e+01, -1.7655e+01],\n",
      "          [-1.4225e+01, -1.3354e+01, -1.2044e+01,  ..., -1.1007e+01,\n",
      "           -1.4488e+01, -2.0791e+01],\n",
      "          [-2.1753e+01, -2.3312e+01, -2.4889e+01,  ..., -2.6160e+01,\n",
      "           -2.6580e+01, -3.0275e+01],\n",
      "          ...,\n",
      "          [-5.5445e+01, -5.1929e+01, -5.1407e+01,  ..., -5.1096e+01,\n",
      "           -5.0680e+01, -5.1394e+01],\n",
      "          [-5.6412e+01, -5.3327e+01, -5.2589e+01,  ..., -5.1193e+01,\n",
      "           -5.1988e+01, -5.4647e+01],\n",
      "          [-5.4574e+01, -5.2384e+01, -5.2588e+01,  ..., -5.1052e+01,\n",
      "           -5.2922e+01, -5.4676e+01]]]]), tensor([11, 16,  2, 15, 10, 13,  6, 15, 11, 18, 16,  5,  4, 12, 12, 20, 17, 17,\n",
      "         6, 14, 13, 17, 11,  1,  9])]\n",
      "[tensor([[[[-10.5757,  -3.9565,  -2.4490,  ..., -14.0344,  -9.8667,  -8.6727],\n",
      "          [-11.0136,  -6.4531,  -5.1831,  ..., -15.6522, -15.9574, -11.5940],\n",
      "          [-16.8577, -18.9107, -17.7916,  ..., -25.2219, -21.9087, -16.2473],\n",
      "          ...,\n",
      "          [-49.0824, -47.5911, -48.4652,  ..., -47.4768, -46.8074, -49.4357],\n",
      "          [-50.9669, -46.5640, -47.5060,  ..., -47.9900, -48.4327, -50.0647],\n",
      "          [-50.7123, -46.7355, -48.1979,  ..., -49.1863, -48.1227, -50.5570]]],\n",
      "\n",
      "\n",
      "        [[[ -5.2120,  -4.1334,  -4.2097,  ...,  -3.1277,  -4.9027,  -9.8809],\n",
      "          [ -5.6036,  -2.7944,  -3.4257,  ...,  -1.8790,  -2.7097,  -7.4012],\n",
      "          [-12.0036, -13.3965, -15.7236,  ..., -13.7522, -12.8860, -12.6874],\n",
      "          ...,\n",
      "          [-55.8372, -55.1540, -55.6561,  ..., -54.8882, -53.8076, -53.9245],\n",
      "          [-57.1962, -55.5976, -54.3309,  ..., -53.6039, -53.9144, -54.7926],\n",
      "          [-57.5957, -53.3097, -53.5559,  ..., -52.3026, -52.0629, -55.3671]]],\n",
      "\n",
      "\n",
      "        [[[-10.9055,  -8.4470,  -7.5049,  ...,  -7.8123,  -8.2866,  -8.0311],\n",
      "          [-11.2018, -12.1854, -13.8080,  ...,  -8.2462,  -6.4423,  -8.3171],\n",
      "          [-16.2980, -16.6967, -25.5274,  ..., -18.9832, -15.7927, -17.1252],\n",
      "          ...,\n",
      "          [-47.6100, -45.3317, -44.1492,  ..., -43.8832, -44.8364, -47.1210],\n",
      "          [-46.9981, -43.2093, -44.3806,  ..., -44.0768, -44.4132, -46.8178],\n",
      "          [-47.9968, -46.1935, -45.9198,  ..., -44.9125, -44.4910, -47.1867]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-21.2481, -13.2318, -11.4360,  ..., -15.2457, -15.5091, -14.6598],\n",
      "          [-17.2403, -12.1630, -12.5750,  ..., -13.9417, -12.8999, -13.9763],\n",
      "          [-21.7108, -21.8343, -25.2063,  ..., -23.5583, -21.1637, -18.0900],\n",
      "          ...,\n",
      "          [-57.6918, -54.9767, -55.4636,  ..., -55.7728, -55.3717, -57.3948],\n",
      "          [-56.7882, -55.5966, -55.6308,  ..., -56.3670, -58.5222, -60.3500],\n",
      "          [-56.5126, -56.1400, -57.2627,  ..., -55.5291, -55.8905, -58.4184]]],\n",
      "\n",
      "\n",
      "        [[[ -8.8491,  -3.4978,  -2.1545,  ...,  -1.4982,  -2.7293,  -5.5224],\n",
      "          [-10.6318,  -8.1585,  -9.1547,  ...,  -6.2677,  -6.8292,  -7.6696],\n",
      "          [-17.5509, -18.6270, -23.1745,  ..., -18.0806, -17.0130, -17.8795],\n",
      "          ...,\n",
      "          [-55.0710, -53.1003, -52.7147,  ..., -54.3135, -54.2095, -54.4146],\n",
      "          [-56.1594, -53.1380, -52.6578,  ..., -54.8881, -52.9731, -53.5724],\n",
      "          [-57.9322, -53.9722, -51.9583,  ..., -54.1590, -52.9439, -53.9007]]],\n",
      "\n",
      "\n",
      "        [[[-16.7492, -12.9213, -15.4992,  ..., -12.9660, -18.1481, -28.5464],\n",
      "          [-16.1996, -16.6247, -23.7688,  ..., -17.7725, -19.2445, -21.1943],\n",
      "          [-21.6059, -22.9027, -25.0755,  ..., -29.1831, -24.5935, -21.2665],\n",
      "          ...,\n",
      "          [-59.5307, -55.9166, -53.8853,  ..., -52.0816, -53.1255, -55.9003],\n",
      "          [-56.8013, -54.8264, -54.2567,  ..., -51.6883, -52.1367, -53.6113],\n",
      "          [-54.8412, -54.4343, -53.4510,  ..., -52.3981, -52.6179, -53.7668]]]]), tensor([ 4, 14, 10,  6, 17, 20, 11, 12,  7, 15,  5,  1, 19,  2,  1,  1,  0, 20,\n",
      "         7,  7, 15, 10, 20,  8, 16])]\n",
      "[tensor([[[[ -4.5473,  -6.2138,  -8.2985,  ...,  -9.9810,  -7.5181,  -8.0491],\n",
      "          [ -4.6183,  -6.6108,  -7.8492,  ...,  -9.0374, -12.7874, -10.7625],\n",
      "          [ -7.9839,  -7.1070, -11.3627,  ...,  -8.2434, -12.9951, -14.6108],\n",
      "          ...,\n",
      "          [-53.3331, -49.3938, -48.5414,  ..., -50.9687, -50.4058, -52.9669],\n",
      "          [-53.4087, -50.9847, -49.7883,  ..., -51.6659, -51.4237, -50.6602],\n",
      "          [-53.9578, -51.2299, -50.1041,  ..., -48.0495, -49.1640, -52.8801]]],\n",
      "\n",
      "\n",
      "        [[[-29.0853, -25.9006, -20.9731,  ...,  -4.6901,  -3.4193,  -6.6621],\n",
      "          [-31.8727, -30.8039, -26.8090,  ...,  -9.3810,  -8.3873, -10.8362],\n",
      "          [-34.7868, -31.7465, -26.1857,  ..., -22.7420, -23.9624, -23.2167],\n",
      "          ...,\n",
      "          [-56.9019, -54.4784, -53.9953,  ..., -51.4284, -52.9841, -54.8922],\n",
      "          [-55.0232, -53.2602, -52.1002,  ..., -51.9545, -52.1367, -54.1389],\n",
      "          [-57.8918, -54.3597, -53.4134,  ..., -53.0290, -53.1905, -53.7613]]],\n",
      "\n",
      "\n",
      "        [[[-12.3970, -12.6769, -11.6861,  ...,  -8.7590,  -8.7376, -15.7222],\n",
      "          [-13.7573, -12.4105, -11.5589,  ..., -10.1950,  -9.7541, -16.6158],\n",
      "          [-21.0281, -21.3274, -19.8277,  ..., -20.4875, -20.1054, -26.3162],\n",
      "          ...,\n",
      "          [-58.3173, -55.6905, -55.1446,  ..., -56.4763, -55.9175, -57.1586],\n",
      "          [-57.4746, -55.1483, -55.9968,  ..., -54.8604, -56.6697, -57.0417],\n",
      "          [-58.5717, -55.8531, -55.7319,  ..., -56.2001, -56.9702, -58.9404]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-13.5728, -14.9611, -20.2619,  ...,  -5.9169,  -4.7809,  -8.8456],\n",
      "          [-12.5747, -13.8058, -19.0077,  ...,  -9.9999,  -9.2723, -10.9084],\n",
      "          [-15.6077, -18.4661, -21.2161,  ..., -25.4814, -20.5172, -17.7988],\n",
      "          ...,\n",
      "          [-55.8372, -53.0905, -52.1294,  ..., -51.2333, -52.2833, -55.3700],\n",
      "          [-55.6846, -53.1335, -53.1861,  ..., -53.7703, -52.5696, -56.3729],\n",
      "          [-55.9756, -53.4670, -53.9101,  ..., -54.4707, -52.9915, -54.3717]]],\n",
      "\n",
      "\n",
      "        [[[-19.8387, -19.1716, -19.8422,  ..., -13.1208, -14.9518, -16.8472],\n",
      "          [-18.7445, -16.9057, -18.9242,  ..., -11.5250, -16.7029, -16.0062],\n",
      "          [-22.2301, -20.9569, -23.2562,  ..., -18.8113, -18.8529, -21.0423],\n",
      "          ...,\n",
      "          [-51.6377, -48.9324, -49.3959,  ..., -49.5261, -49.0410, -50.5903],\n",
      "          [-52.5942, -48.7486, -48.6424,  ..., -50.0788, -49.2967, -50.9648],\n",
      "          [-52.7858, -49.8041, -49.2364,  ..., -49.7302, -49.9798, -51.4836]]],\n",
      "\n",
      "\n",
      "        [[[-11.1326, -10.5856, -14.7633,  ..., -14.8453, -12.1551, -15.0998],\n",
      "          [-12.4634, -11.9332, -16.5080,  ..., -15.3169, -13.5214, -16.0434],\n",
      "          [-18.5694, -22.5046, -23.3326,  ..., -27.7116, -25.4419, -23.5093],\n",
      "          ...,\n",
      "          [-62.1397, -58.9528, -59.2467,  ..., -59.4400, -59.5343, -62.5773],\n",
      "          [-60.5881, -59.8082, -60.4605,  ..., -61.3787, -59.6531, -60.5962],\n",
      "          [-61.0361, -58.9775, -59.5100,  ..., -59.5443, -59.5720, -60.2610]]]]), tensor([ 3,  9, 11, 20,  7,  2,  6, 11, 17,  4,  9,  5, 18, 19,  8, 11,  0,  1,\n",
      "         3,  6, 11,  7,  0,  9, 18])]\n",
      "[tensor([[[[-14.5727,  -9.6321,  -9.2103,  ..., -11.8275, -12.9413, -14.7009],\n",
      "          [-14.8433, -10.5649, -10.4794,  ..., -11.4483, -14.5512, -22.0689],\n",
      "          [-19.2211, -19.8117, -23.7096,  ..., -19.3841, -21.9057, -22.2750],\n",
      "          ...,\n",
      "          [-48.0494, -45.3691, -45.0387,  ..., -44.0265, -44.6877, -46.3299],\n",
      "          [-47.9073, -45.6596, -44.2975,  ..., -43.3746, -44.3873, -46.3455],\n",
      "          [-46.8101, -43.1942, -42.5134,  ..., -44.2990, -44.3076, -46.7911]]],\n",
      "\n",
      "\n",
      "        [[[-11.4160,  -7.3010,  -6.6249,  ...,  -7.3409,  -7.4026,  -7.1805],\n",
      "          [-14.4316,  -9.6936,  -9.6551,  ..., -10.6789, -12.1702,  -8.9309],\n",
      "          [-23.1466, -21.0663, -21.5290,  ..., -16.4595, -22.0419, -14.9949],\n",
      "          ...,\n",
      "          [-53.4368, -51.5554, -52.7034,  ..., -53.0157, -51.8218, -53.0765],\n",
      "          [-55.1234, -52.2997, -52.0330,  ..., -52.9236, -53.6745, -53.7170],\n",
      "          [-55.4410, -52.7464, -54.5536,  ..., -52.0832, -51.6558, -53.0386]]],\n",
      "\n",
      "\n",
      "        [[[-25.4292, -21.1790, -22.2339,  ...,  -5.7871,  -9.1459, -14.4599],\n",
      "          [-26.4267, -23.9548, -24.4095,  ...,  -9.5116, -14.7796, -18.1322],\n",
      "          [-33.1059, -28.9126, -29.1085,  ..., -24.1106, -23.1945, -24.7255],\n",
      "          ...,\n",
      "          [-51.1722, -47.9533, -48.7014,  ..., -50.8125, -51.2782, -53.2235],\n",
      "          [-50.1713, -49.4649, -49.1165,  ..., -52.0051, -51.0308, -51.5985],\n",
      "          [-52.8469, -51.0000, -48.9094,  ..., -51.7971, -51.5983, -53.4973]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-10.5673,  -3.9909,  -2.2397,  ...,  -5.5005,  -9.2543, -11.1301],\n",
      "          [-12.1509, -11.3756,  -8.1727,  ...,  -9.4391, -16.0497, -16.9221],\n",
      "          [-18.5598, -21.9601, -23.0297,  ..., -23.3890, -22.1037, -25.7802],\n",
      "          ...,\n",
      "          [-52.5944, -51.0127, -51.3107,  ..., -49.6637, -48.0445, -49.6687],\n",
      "          [-52.9727, -50.3655, -51.2536,  ..., -50.5060, -49.5551, -51.8140],\n",
      "          [-51.6009, -49.8333, -50.5489,  ..., -49.9480, -49.9710, -53.0863]]],\n",
      "\n",
      "\n",
      "        [[[-31.1283, -19.7714, -13.0959,  ..., -15.0967, -13.8639, -12.3390],\n",
      "          [-28.8814, -18.6744, -14.8699,  ..., -15.0312, -14.5804, -12.8169],\n",
      "          [-27.4124, -22.4962, -26.7199,  ..., -21.2707, -22.0196, -19.5442],\n",
      "          ...,\n",
      "          [-56.3981, -53.3566, -54.6137,  ..., -54.7959, -55.6958, -57.0505],\n",
      "          [-60.1292, -54.9629, -54.1229,  ..., -53.5637, -53.8974, -56.5261],\n",
      "          [-59.2950, -54.1326, -54.6737,  ..., -53.2280, -54.1052, -56.9463]]],\n",
      "\n",
      "\n",
      "        [[[-15.2821, -11.3767, -11.9845,  ...,  -8.2670,  -8.7736, -12.1539],\n",
      "          [-16.1250, -13.5754, -12.0899,  ...,  -9.9776, -11.9258, -13.2226],\n",
      "          [-21.2551, -22.1299, -22.0504,  ..., -23.9481, -23.7623, -18.9937],\n",
      "          ...,\n",
      "          [-52.6190, -49.9110, -49.1751,  ..., -49.4075, -48.4457, -50.3696],\n",
      "          [-54.6232, -51.2046, -49.7113,  ..., -51.4984, -49.5948, -50.0063],\n",
      "          [-53.9702, -50.4028, -50.4095,  ..., -50.6015, -49.4070, -52.4006]]]]), tensor([16,  7, 13,  7,  5, 17,  0,  6,  3,  2,  0,  1,  7,  1, 18, 14,  2,  9,\n",
      "         6, 16, 18,  2,  5,  3, 12])]\n",
      "[tensor([[[[-20.4516, -17.9941, -20.7322,  ..., -10.1277,  -9.5659, -13.3434],\n",
      "          [-19.9730, -19.4323, -24.4138,  ..., -12.8505, -15.7333, -17.6391],\n",
      "          [-24.7819, -27.8253, -29.0989,  ..., -25.7507, -26.0385, -24.3234],\n",
      "          ...,\n",
      "          [-61.4442, -56.9441, -57.8352,  ..., -59.6203, -58.7586, -60.7551],\n",
      "          [-63.3090, -58.8948, -57.7879,  ..., -58.1593, -57.8995, -59.4014],\n",
      "          [-63.7417, -58.9781, -58.3609,  ..., -58.3074, -59.4399, -61.0138]]],\n",
      "\n",
      "\n",
      "        [[[-16.6691,  -6.9946,  -4.2131,  ...,  -4.6266,  -8.2105, -20.6552],\n",
      "          [-18.8094, -14.4730, -11.0312,  ...,  -8.4841, -11.0249, -22.1196],\n",
      "          [-30.1462, -28.0029, -26.0084,  ..., -21.5683, -20.1793, -19.5037],\n",
      "          ...,\n",
      "          [-56.2467, -52.7388, -52.5563,  ..., -53.2897, -53.3861, -55.1204],\n",
      "          [-56.1644, -53.2781, -54.2015,  ..., -55.0455, -55.1568, -57.1638],\n",
      "          [-56.9713, -53.0619, -52.9821,  ..., -55.6448, -54.6392, -57.0169]]],\n",
      "\n",
      "\n",
      "        [[[-18.9631, -13.8646,  -6.3394,  ...,  -5.7576,  -8.7145,  -9.8001],\n",
      "          [-14.4478,  -9.7717,  -6.0515,  ...,  -5.1902,  -6.5360,  -9.6219],\n",
      "          [-15.2846, -12.2192, -13.8214,  ..., -16.2318, -13.9726, -16.0866],\n",
      "          ...,\n",
      "          [-55.2470, -51.1208, -50.1670,  ..., -53.1796, -51.7913, -52.6755],\n",
      "          [-54.4827, -51.3380, -49.9832,  ..., -52.8669, -53.0000, -54.9691],\n",
      "          [-55.3948, -52.0201, -50.5608,  ..., -52.0717, -52.1901, -55.3488]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -7.9592,  -3.1344,  -2.6511,  ..., -10.3558, -11.6797, -17.3033],\n",
      "          [ -9.0071,  -7.6488, -11.3487,  ..., -11.8102,  -9.2244, -13.1895],\n",
      "          [-14.0929, -17.4014, -23.1372,  ..., -15.3419, -17.5167, -15.7416],\n",
      "          ...,\n",
      "          [-50.5680, -45.4783, -44.7638,  ..., -46.7668, -43.6946, -46.2976],\n",
      "          [-49.7016, -48.4203, -47.4780,  ..., -46.1984, -46.1178, -48.5836],\n",
      "          [-49.5079, -47.1403, -47.2599,  ..., -47.6474, -47.2906, -49.3603]]],\n",
      "\n",
      "\n",
      "        [[[-19.5398, -10.2152,  -8.2142,  ...,  -5.7538, -13.2875, -14.3327],\n",
      "          [-18.2087, -10.3713,  -9.4515,  ...,  -3.6821,  -9.0942, -14.3417],\n",
      "          [-25.1122, -20.6830, -19.5156,  ..., -10.5679, -16.3520, -18.6934],\n",
      "          ...,\n",
      "          [-54.8693, -52.6403, -53.0187,  ..., -53.9944, -51.9241, -53.2146],\n",
      "          [-55.0803, -53.3021, -52.8280,  ..., -52.2696, -52.6950, -55.4110],\n",
      "          [-56.9314, -52.7392, -52.0397,  ..., -52.4353, -52.6939, -54.9656]]],\n",
      "\n",
      "\n",
      "        [[[-21.1655,  -9.2806,  -5.2622,  ...,  -8.8647, -11.1282, -18.5056],\n",
      "          [-20.0558,  -9.4534,  -6.5965,  ..., -11.7341, -10.9992, -17.6177],\n",
      "          [-21.2958, -18.4667, -19.6582,  ..., -23.4726, -20.1104, -22.3423],\n",
      "          ...,\n",
      "          [-52.6853, -51.5193, -50.5851,  ..., -51.7641, -51.5040, -55.3226],\n",
      "          [-54.2208, -51.7189, -51.3510,  ..., -51.1839, -50.5015, -51.5194],\n",
      "          [-55.2196, -51.3944, -51.7383,  ..., -52.0318, -51.2384, -52.3445]]]]), tensor([ 6, 17, 11,  8, 18,  1, 14, 13,  2, 16,  0, 15,  7, 18,  2,  9,  1, 10,\n",
      "         3,  6,  4,  6,  5,  8, 19])]\n",
      "[tensor([[[[-24.0151, -14.0741,  -8.4813,  ...,  -7.1553,  -3.5366,  -4.7332],\n",
      "          [-23.5508, -12.4591,  -8.8935,  ..., -10.3823,  -6.3858,  -7.1951],\n",
      "          [-25.5836, -19.2200, -21.9387,  ..., -21.8384, -20.6047, -16.8313],\n",
      "          ...,\n",
      "          [-51.8312, -50.7193, -52.3980,  ..., -52.6845, -52.2245, -53.4746],\n",
      "          [-54.0043, -51.1681, -50.4154,  ..., -51.9934, -52.3931, -54.9598],\n",
      "          [-53.2392, -50.3139, -50.2935,  ..., -53.3171, -52.3102, -54.1964]]],\n",
      "\n",
      "\n",
      "        [[[ -6.1380,   0.0000,  -2.7168,  ..., -12.1368, -10.0503, -11.5785],\n",
      "          [ -6.2788,  -3.2301,  -6.3150,  ..., -10.3615, -11.0651, -13.5633],\n",
      "          [-13.6251, -15.8973, -17.5655,  ..., -20.3949, -22.2687, -22.6195],\n",
      "          ...,\n",
      "          [-51.9228, -51.6819, -54.1421,  ..., -51.6485, -50.9753, -53.2437],\n",
      "          [-52.7215, -51.4035, -51.8770,  ..., -55.0120, -55.5797, -56.5155],\n",
      "          [-54.9164, -52.4614, -52.8216,  ..., -53.7601, -53.2088, -53.1660]]],\n",
      "\n",
      "\n",
      "        [[[-42.9951, -36.3205, -36.3536,  ..., -48.3439, -42.3000, -41.3858],\n",
      "          [-43.3959, -39.5435, -39.7030,  ..., -49.3582, -46.7161, -47.5142],\n",
      "          [-50.4178, -53.0831, -55.0694,  ..., -57.7504, -54.0611, -50.6898],\n",
      "          ...,\n",
      "          [-80.0000, -79.2811, -80.0000,  ..., -79.9852, -79.7417, -80.0000],\n",
      "          [-80.0000, -80.0000, -80.0000,  ..., -79.3143, -79.0314, -80.0000],\n",
      "          [-80.0000, -79.0932, -79.6483,  ..., -79.6318, -79.4915, -80.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-12.7691, -12.9450,  -5.3312,  ..., -15.4166,  -9.5626,  -8.5781],\n",
      "          [-15.8101, -11.6237,  -6.9632,  ..., -18.2089, -12.4391, -10.7572],\n",
      "          [-20.8231, -16.4172, -15.3844,  ..., -20.1217, -24.1861, -17.7948],\n",
      "          ...,\n",
      "          [-47.6799, -43.9780, -42.7015,  ..., -42.8832, -45.8906, -47.8539],\n",
      "          [-45.3930, -43.2284, -43.3101,  ..., -42.7987, -44.2289, -46.8842],\n",
      "          [-45.2104, -43.1165, -44.7029,  ..., -43.2037, -42.8307, -45.3306]]],\n",
      "\n",
      "\n",
      "        [[[-12.8657, -11.2482, -13.4724,  ..., -10.0661, -11.7544,  -9.9558],\n",
      "          [-13.8016, -14.9496, -17.2188,  ..., -10.6228, -14.6726, -11.0705],\n",
      "          [-19.8329, -19.9795, -24.5743,  ..., -20.7737, -17.6161, -15.3557],\n",
      "          ...,\n",
      "          [-55.4961, -52.9254, -53.6704,  ..., -52.3865, -52.6815, -55.8604],\n",
      "          [-56.1053, -53.6912, -53.0935,  ..., -52.2997, -52.0639, -53.5094],\n",
      "          [-56.6315, -53.5775, -52.6498,  ..., -53.7087, -53.7046, -55.0886]]],\n",
      "\n",
      "\n",
      "        [[[-10.9037,  -9.6316, -15.9832,  ...,  -8.0860, -11.3804, -17.6645],\n",
      "          [-14.0838, -12.3146, -16.5750,  ..., -14.8592, -16.9757, -25.1795],\n",
      "          [-23.0597, -23.9344, -26.1906,  ..., -24.4917, -25.9262, -30.6096],\n",
      "          ...,\n",
      "          [-54.3032, -51.4389, -51.8348,  ..., -50.4987, -51.0670, -53.0224],\n",
      "          [-53.3753, -51.9854, -52.5193,  ..., -52.5263, -52.4781, -53.4447],\n",
      "          [-54.4793, -52.6034, -51.8446,  ..., -52.5953, -52.8672, -54.7190]]]]), tensor([ 3, 20, 16, 20,  6,  2,  6,  8,  4,  4, 20,  5,  6,  5, 18,  3,  9,  6,\n",
      "         5,  0,  7,  3, 10,  8, 17])]\n",
      "[tensor([[[[ -8.7493,  -4.5807,  -6.4738,  ..., -15.9647, -14.0820, -12.0870],\n",
      "          [-12.3815, -10.5802, -14.8960,  ..., -12.7258, -10.9269, -12.2491],\n",
      "          [-19.4824, -23.7299, -29.5765,  ..., -21.6016, -19.3830, -17.2908],\n",
      "          ...,\n",
      "          [-52.9048, -50.6366, -49.7437,  ..., -49.7154, -49.2230, -51.2233],\n",
      "          [-52.8697, -49.8926, -49.1587,  ..., -48.3543, -49.6159, -51.7414],\n",
      "          [-52.8566, -50.6728, -49.1883,  ..., -49.3658, -49.1887, -51.0989]]],\n",
      "\n",
      "\n",
      "        [[[ -7.6943,  -5.9382,  -7.4032,  ...,  -8.1046,  -6.6941,  -8.8680],\n",
      "          [-10.2469, -11.4874, -12.8954,  ..., -13.6241,  -9.5865, -11.0633],\n",
      "          [-16.2723, -19.8872, -23.0262,  ..., -26.5111, -22.3468, -21.9607],\n",
      "          ...,\n",
      "          [-54.4179, -52.9635, -53.7995,  ..., -54.1535, -54.6889, -56.2902],\n",
      "          [-55.2268, -52.4172, -53.1265,  ..., -54.1609, -53.8873, -56.5630],\n",
      "          [-56.8721, -53.6757, -53.8824,  ..., -52.9600, -53.5689, -56.0322]]],\n",
      "\n",
      "\n",
      "        [[[-21.2722, -15.7363,  -8.0751,  ...,  -7.4133,  -8.0877, -13.2537],\n",
      "          [-20.5599, -18.8401, -11.2284,  ..., -14.0391, -12.3484, -17.6471],\n",
      "          [-25.1204, -22.4697, -24.0603,  ..., -17.8006, -16.6104, -21.9891],\n",
      "          ...,\n",
      "          [-53.8747, -49.7312, -48.8353,  ..., -50.6623, -50.2794, -51.2271],\n",
      "          [-53.6322, -49.5831, -49.3631,  ..., -50.9076, -51.1527, -51.0633],\n",
      "          [-51.1943, -48.3772, -47.9430,  ..., -51.9853, -50.8899, -51.1673]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-20.3959, -16.9312,  -8.0731,  ...,  -4.7936, -11.8573, -10.2112],\n",
      "          [-19.3135, -13.2479,  -6.8360,  ...,  -4.4044,  -8.8201,  -9.5876],\n",
      "          [-21.3031, -17.6341, -14.4458,  ..., -12.8848, -15.2223, -13.6971],\n",
      "          ...,\n",
      "          [-51.9537, -48.4511, -47.5545,  ..., -47.8985, -46.5046, -47.7934],\n",
      "          [-52.2264, -48.3000, -47.6907,  ..., -45.9011, -46.9553, -50.1222],\n",
      "          [-52.2821, -48.0322, -48.4575,  ..., -46.2426, -46.7295, -50.8456]]],\n",
      "\n",
      "\n",
      "        [[[-12.5628,  -8.1854,  -7.5131,  ...,  -1.9018,  -2.7220,  -7.7348],\n",
      "          [-12.8445,  -8.3350,  -7.3685,  ...,  -5.0801,  -5.7026,  -8.7274],\n",
      "          [-18.6842, -20.4696, -18.0192,  ..., -18.9351, -18.2657, -18.4970],\n",
      "          ...,\n",
      "          [-53.3269, -52.5081, -53.6013,  ..., -52.3845, -53.6357, -55.7000],\n",
      "          [-55.8092, -53.5823, -53.8144,  ..., -51.1757, -51.5666, -53.6472],\n",
      "          [-56.6887, -53.7506, -53.7992,  ..., -50.3366, -51.5614, -52.8527]]],\n",
      "\n",
      "\n",
      "        [[[-13.8973,  -7.7259,  -5.2067,  ...,  -3.8277,  -7.8463, -10.4925],\n",
      "          [-16.4069, -15.3037,  -8.7685,  ...,  -8.0257, -12.5607, -11.9184],\n",
      "          [-19.6523, -18.2227, -19.9249,  ..., -21.0571, -15.6680, -14.9900],\n",
      "          ...,\n",
      "          [-54.9636, -52.6137, -52.2102,  ..., -51.4800, -52.3609, -53.2149],\n",
      "          [-53.9044, -51.6077, -52.3988,  ..., -53.3218, -53.4893, -53.3324],\n",
      "          [-53.8415, -52.4827, -53.0353,  ..., -54.9332, -53.2509, -52.9774]]]]), tensor([12,  9, 10,  9, 12, 13,  4, 15,  9,  4, 20, 10, 17,  3, 18,  3, 11, 15,\n",
      "         6, 18, 17,  8,  6, 14,  8])]\n"
     ]
    }
   ],
   "source": [
    "# ラベルの指定\n",
    "t_df = Dataset.objectNum\n",
    "\n",
    "# テンソル形式に変換\n",
    "df_tenosor = torch.tensor(df, dtype=torch.float32)\n",
    "df_tenosor = torch.unsqueeze(df_tenosor, 1)\n",
    "label_tensor = torch.tensor(t_df, dtype=torch.int64)\n",
    "print(df_tenosor.size())\n",
    "\n",
    "# x と t を組み合わせて TensorDataset を作成\n",
    "dataset = torch.utils.data.TensorDataset(df_tenosor, label_tensor)\n",
    "\n",
    "# 各データセットのサンプル数を決定\n",
    "# train : val: test = 50%　: 25% : 25%\n",
    "n_train = int(len(dataset) * 0.5)\n",
    "n_val = int(len(dataset) * 0.25)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "     \n",
    "# それぞれのサンプル数を確認\n",
    "print(n_train, n_val, n_test)\n",
    "\n",
    "# ランダムに分割を行うため、シードを固定して再現性を確保\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# データセットの分割\n",
    "train, val, test = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "# バッチサイズ\n",
    "batch_size = 25\n",
    "\n",
    "      \n",
    "# shuffle はデフォルトで False のため、学習データのみ True に指定\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size)\n",
    "\n",
    "print(train_loader)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DyMN(\n",
      "  (layers): ModuleList(\n",
      "    (0): DY_Block(\n",
      "      (exp_conv): DynamicWrapper(\n",
      "        (module): Identity()\n",
      "      )\n",
      "      (exp_norm): Identity()\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Identity()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (1): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=256, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (3): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=288, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(24, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (4-5): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): ReLU(inplace=True)\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=480, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=32, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(40, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (6): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=960, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(40, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (7): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=800, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(48, 200, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (8-9): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=736, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=48, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(48, 184, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (10): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=1920, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=120, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(80, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (11): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (12): DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=2688, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(112, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): AvgPool2d(kernel_size=(3, 1), stride=(2, 1), padding=(1, 0))\n",
      "        (pool_t): AvgPool2d(kernel_size=(1, 3), stride=(1, 2), padding=(0, 1))\n",
      "      )\n",
      "    )\n",
      "    (13-14): 2 x DY_Block(\n",
      "      (exp_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (exp_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (exp_act): DynamicWrapper(\n",
      "        (module): Hardswish()\n",
      "      )\n",
      "      (depth_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (depth_norm): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (depth_act): DyReLUB(\n",
      "        (coef_net): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=3840, bias=True)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (ca): CoordAtt()\n",
      "      (proj_conv): DynamicConv(\n",
      "        (residuals): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (proj_norm): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (context_gen): ContextGen(\n",
      "        (joint_conv): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (joint_norm): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (joint_act): Hardswish()\n",
      "        (conv_f): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (conv_t): Conv2d(128, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (pool_f): Sequential()\n",
      "        (pool_t): Sequential()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (in_c): ConvNormActivation(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (out_c): ConvNormActivation(\n",
      "    (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): Hardswish()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=960, out_features=1280, bias=False)\n",
      "    (3): Hardswish()\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Linear(in_features=1280, out_features=527, bias=False)\n",
      "    (6): Linear(in_features=527, out_features=176, bias=False)\n",
      "    (7): Linear(in_features=176, out_features=21, bias=False)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=21, out_features=2, bias=False)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=2, out_features=21, bias=False)\n",
      "    (12): ReLU()\n",
      "    (13): Linear(in_features=21, out_features=6, bias=False)\n",
      "    (14): ReLU()\n",
      "    (15): Linear(in_features=6, out_features=21, bias=True)\n",
      "    (16): ReLU()\n",
      "    (17): Linear(in_features=21, out_features=21, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "objModel_2 = matModel_2_trained\n",
    "\n",
    "#パラメータの更新を許可\n",
    "for param in objModel_2.parameters():\n",
    "    param.requires_gred = False\n",
    "\n",
    "\n",
    "# print(model.classifier)\n",
    "\n",
    "# 出力層の最後だけ変更\n",
    "# model.classifier[5] = torch.nn.Linear(1280,2)\n",
    "objModel_2.classifier= nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(output_size=1),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    nn.Linear(in_features=960, out_features=1280, bias=False),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(p=0.2, inplace=False),\n",
    "    nn.Linear(in_features=1280, out_features=527, bias=False),\n",
    "    nn.Linear(in_features=527, out_features=176, bias=False), \n",
    "    nn.Linear(in_features=176, out_features=21, bias=False), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=21, out_features=2, bias=False), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=2, out_features=21, bias=False),  \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=21, out_features=6, bias=False),  \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=6, out_features=21, bias=True),  # 新しい層\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=21, out_features=21, bias=True),  # 新しい層\n",
    ")\n",
    "print(objModel_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch [1/50], Train Loss: 3.0487, Validation Loss: 3.0682\n",
      "Epoch [2/50], Train Loss: 3.0455, Validation Loss: 3.0697\n",
      "Epoch [3/50], Train Loss: 3.0434, Validation Loss: 3.0714\n",
      "Epoch [4/50], Train Loss: 3.0415, Validation Loss: 3.0731\n",
      "Epoch [5/50], Train Loss: 3.0404, Validation Loss: 3.0747\n",
      "Epoch [6/50], Train Loss: 3.0393, Validation Loss: 3.0763\n",
      "Epoch [7/50], Train Loss: 3.0390, Validation Loss: 3.0777\n",
      "Epoch [8/50], Train Loss: 3.0381, Validation Loss: 3.0792\n",
      "Epoch [9/50], Train Loss: 3.0378, Validation Loss: 3.0804\n",
      "Epoch [10/50], Train Loss: 3.0380, Validation Loss: 3.0818\n",
      "Epoch [11/50], Train Loss: 3.0378, Validation Loss: 3.0828\n",
      "Epoch [12/50], Train Loss: 3.0373, Validation Loss: 3.0836\n",
      "Epoch [13/50], Train Loss: 3.0372, Validation Loss: 3.0843\n",
      "Epoch [14/50], Train Loss: 3.0369, Validation Loss: 3.0849\n",
      "Epoch [15/50], Train Loss: 3.0370, Validation Loss: 3.0855\n",
      "Epoch [16/50], Train Loss: 3.0372, Validation Loss: 3.0860\n",
      "Epoch [17/50], Train Loss: 3.0368, Validation Loss: 3.0863\n",
      "Epoch [18/50], Train Loss: 3.0370, Validation Loss: 3.0866\n",
      "Epoch [19/50], Train Loss: 3.0367, Validation Loss: 3.0869\n",
      "Epoch [20/50], Train Loss: 3.0369, Validation Loss: 3.0872\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(y[\u001b[38;5;241m0\u001b[39m], t)\n\u001b[1;32m     42\u001b[0m     train_epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# エポック全体の訓練データの損失に加算\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# 訓練データでのエポックごとの平均損失を計算し保存\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# エポックの数\n",
    "epoch = 0\n",
    "     \n",
    "# モデルの初期化\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# GPU の設定状況に基づいたデバイスの選択\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "net6 = objModel_2.cuda()\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "  \n",
    "# 最適化手法の選択\n",
    "optimizer = torch.optim.SGD(net6.parameters(), lr=0.1)\n",
    "# エポックごとの訓練データの損失と検証データの損失を保存するリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "train_epoch_loss = 1.0\n",
    "val_epoch_loss = 1.0\n",
    "# 学習ループ\n",
    "while (train_epoch_loss > 0.1 or val_epoch_loss  > 0.2 )or epoch<100:\n",
    "    train_epoch_loss = 0.0\n",
    "    val_epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練データでの学習\n",
    "    net6.train()\n",
    "    for batch in train_loader:\n",
    "        x, t = batch\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y = net6(x)\n",
    "        loss = criterion(y[0], t)\n",
    "        train_epoch_loss += loss.item()  # エポック全体の訓練データの損失に加算\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 訓練データでのエポックごとの平均損失を計算し保存\n",
    "    train_epoch_loss /= len(train_loader)\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    \n",
    "    # 検証データでの評価\n",
    "    net6.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, t = batch\n",
    "  \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net6(x)\n",
    "            loss = criterion(y[0], t)\n",
    "            val_epoch_loss += loss.item()  # エポック全体の検証データの損失に加算\n",
    "       \n",
    "    # 検証データでのエポックごとの平均損失を計算し保存\n",
    "    val_epoch_loss /= len(val_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    \n",
    "    # エポックごとに損失を表示\n",
    "    print(f'Epoch [{epoch+1}/{max_epoch}], Train Loss: {train_epoch_loss:.4f}, Validation Loss: {val_epoch_loss:.4f}')\n",
    "    epoch+=1\n",
    "\n",
    "objModel_2_trained = net6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAHHCAYAAACRAnNyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACAKklEQVR4nO3dd3gUVdsG8HuzSTaNJCQkhN57E0EQEEFBaaJgR0TAggVUVCx8KAIWsLyKoiI2sAEKCqJSBKRI7733ToCQRkjbPd8fk92d7W02M0vu33Xlyu7s7MzZ2dmZZ855zhmdEEKAiIiISIPC1C4AERERkSsMVIiIiEizGKgQERGRZjFQISIiIs1ioEJERESaxUCFiIiINIuBChEREWkWAxUiIiLSLAYqREREpFkMVEh1gwYNQs2aNf1675gxY6DT6ZQtkMYcO3YMOp0O06ZNK/V163Q6jBkzxvJ82rRp0Ol0OHbsmMf31qxZE4MGDVK0PIHsK1S2BPK78WU/p+BjoEIu6XQ6r/6WL1+udlHLvOeeew46nQ6HDh1yOc+oUaOg0+mwY8eOUiyZ786cOYMxY8Zg27ZtahfFwnzS+/DDD9UuSqlZvny55Tf+008/OZ2nQ4cO0Ol0aNq0qV/r+OKLL1QJwCm0hKtdANKuH3/80eb5Dz/8gMWLFztMb9SoUUDr+frrr2Eymfx67+uvv47XXnstoPVfC/r3749JkyZh+vTpGD16tNN5ZsyYgWbNmqF58+Z+r2fAgAF48MEHYTAY/F6GJ2fOnMHYsWNRs2ZNXHfddTavBbKvkH+ioqIwffp0PPzwwzbTjx07hjVr1iAqKsrvZX/xxReoUKGC4jVvAFCjRg1cvXoVERERii+bShcDFXLJ/sC0bt06LF682GG6vby8PMTExHi9nkAOJOHh4QgP527ctm1b1K1bFzNmzHAaqKxduxZHjx7FhAkTAlqPXq+HXq8PaBmB4Emn9PXs2RPz5s3DxYsXUaFCBcv06dOno2LFiqhXrx4uX76sYgltFRcXw2QyITIyMqAgirSDTT8UkM6dO6Np06bYvHkzbr75ZsTExOD//u//AAB//PEHevXqhcqVK8NgMKBOnTp46623YDQabZZhn3cgr2b/6quvUKdOHRgMBtxwww3YuHGjzXud5ajodDoMGzYMc+fORdOmTWEwGNCkSRMsXLjQofzLly9H69atERUVhTp16mDKlCle5738999/uO+++1C9enUYDAZUq1YNL7zwAq5everw+eLi4nD69Gn06dMHcXFxSElJwYgRIxy2RWZmJgYNGoSEhAQkJiZi4MCByMzM9FgWQKpV2bdvH7Zs2eLw2vTp06HT6dCvXz8UFhZi9OjRaNWqFRISEhAbG4uOHTti2bJlHtfhrO1eCIG3334bVatWRUxMDG655Rbs3r3b4b0ZGRkYMWIEmjVrhri4OMTHx6NHjx7Yvn27ZZ7ly5fjhhtuAAAMHjzY0vRgbh5wlqNy5coVvPTSS6hWrRoMBgMaNGiADz/8EPY3hvdlv/BXeno6HnvsMVSsWBFRUVFo0aIFvv/+e4f5Zs6ciVatWqFcuXKIj49Hs2bN8Mknn1heLyoqwtixY1GvXj1ERUUhOTkZN910ExYvXmyznH379uHee+9FUlISoqKi0Lp1a8ybN89mHm+X5cpdd90Fg8GAWbNm2UyfPn067r//fqeB69SpU3HrrbciNTUVBoMBjRs3xuTJk23mqVmzJnbv3o0VK1ZYvufOnTtbXs/MzMTw4cMt32vdunXx3nvv2dSoyY8VEydOtBwr9uzZ4zRHZceOHRg0aBBq166NqKgopKWl4dFHH8WlS5e82hakDl6KUsAuXbqEHj164MEHH8TDDz+MihUrApBOanFxcXjxxRcRFxeHf//9F6NHj0Z2djY++OADj8udPn06cnJy8OSTT0Kn0+H999/H3XffjSNHjni8sl61ahV+//13PPPMMyhXrhw+/fRT3HPPPThx4gSSk5MBAFu3bkX37t1RqVIljB07FkajEePGjUNKSopXn3vWrFnIy8vD008/jeTkZGzYsAGTJk3CqVOnHA7qRqMR3bp1Q9u2bfHhhx9iyZIl+N///oc6derg6aefBiCd8O+66y6sWrUKTz31FBo1aoQ5c+Zg4MCBXpWnf//+GDt2LKZPn47rr7/eZt2//vorOnbsiOrVq+PixYv45ptv0K9fPzzxxBPIycnBt99+i27dumHDhg0OzS2ejB49Gm+//TZ69uyJnj17YsuWLbj99ttRWFhoM9+RI0cwd+5c3HfffahVqxbOnz+PKVOmoFOnTtizZw8qV66MRo0aYdy4cRg9ejSGDBmCjh07AgDat2/vdN1CCNx5551YtmwZHnvsMVx33XVYtGgRXn75ZZw+fRoff/yxzfze7Bf+unr1Kjp37oxDhw5h2LBhqFWrFmbNmoVBgwYhMzMTzz//PABg8eLF6NevH7p06YL33nsPALB3716sXr3aMs+YMWMwfvx4PP7442jTpg2ys7OxadMmbNmyBbfddhsAYPfu3ejQoQOqVKmC1157DbGxsfj111/Rp08f/Pbbb+jbt6/Xy3InJiYGd911F2bMmGHZV7dv347du3fjm2++cZrzNHnyZDRp0gR33nknwsPD8eeff+KZZ56ByWTC0KFDAQATJ07Es88+i7i4OIwaNQoALMeOvLw8dOrUCadPn8aTTz6J6tWrY82aNRg5ciTOnj2LiRMn2qxv6tSpyM/Px5AhQ2AwGJCUlOS0iXDx4sU4cuQIBg8ejLS0NOzevRtfffUVdu/ejXXr1l3zifkhSxB5aejQocJ+l+nUqZMAIL788kuH+fPy8hymPfnkkyImJkbk5+dbpg0cOFDUqFHD8vzo0aMCgEhOThYZGRmW6X/88YcAIP7880/LtDfffNOhTABEZGSkOHTokGXa9u3bBQAxadIky7TevXuLmJgYcfr0acu0gwcPivDwcIdlOuPs840fP17odDpx/Phxm88HQIwbN85m3pYtW4pWrVpZns+dO1cAEO+//75lWnFxsejYsaMAIKZOneqxTDfccIOoWrWqMBqNlmkLFy4UAMSUKVMsyywoKLB53+XLl0XFihXFo48+ajMdgHjzzTctz6dOnSoAiKNHjwohhEhPTxeRkZGiV69ewmQyWeb7v//7PwFADBw40DItPz/fplxCSN+1wWCw2TYbN250+Xnt9xXzNnv77bdt5rv33nuFTqez2Qe83S+cMe+TH3zwgct5Jk6cKACIn376yTKtsLBQtGvXTsTFxYns7GwhhBDPP/+8iI+PF8XFxS6X1aJFC9GrVy+3ZerSpYto1qyZzW/JZDKJ9u3bi3r16vm0LGeWLVsmAIhZs2aJv/76S+h0OnHixAkhhBAvv/yyqF27thBCOgY0adLE5r3OfhvdunWzvMesSZMmolOnTg7zvvXWWyI2NlYcOHDAZvprr70m9Hq9pRzm7yU+Pl6kp6fbzGt+Tb4fOSvXjBkzBACxcuVKyzT7/ZzUxaYfCpjBYMDgwYMdpkdHR1se5+Tk4OLFi+jYsSPy8vKwb98+j8t94IEHUL58ectz89X1kSNHPL63a9euqFOnjuV58+bNER8fb3mv0WjEkiVL0KdPH1SuXNkyX926ddGjRw+PywdsP9+VK1dw8eJFtG/fHkIIbN261WH+p556yuZ5x44dbT7L/PnzER4ebrlqBaSckGeffdar8gBSXtGpU6ewcuVKy7Tp06cjMjIS9913n2WZkZGRAACTyYSMjAwUFxejdevWTpuN3FmyZAkKCwvx7LPP2lyNDh8+3GFeg8GAsDDpkGM0GnHp0iXExcWhQYMGPq/XbP78+dDr9Xjuuedspr/00ksQQmDBggU20z3tF4GYP38+0tLS0K9fP8u0iIgIPPfcc8jNzcWKFSsAAImJibhy5YrbppfExETs3r0bBw8edPp6RkYG/v33X9x///2W39bFixdx6dIldOvWDQcPHsTp06e9WpY3br/9diQlJWHmzJkQQmDmzJk2n9Oe/LeRlZWFixcvolOnTjhy5AiysrI8rm/WrFno2LEjypcvb/lsFy9eRNeuXWE0Gm32bwC45557vKoJlZcrPz8fFy9exI033ggAfu+DFHwMVChgVapUsZz45Hbv3o2+ffsiISEB8fHxSElJsSTienOwql69us1zc9DiTeKe/XvN7ze/Nz09HVevXkXdunUd5nM2zZkTJ05g0KBBSEpKsuSddOrUCYDj54uKinI4kMrLAwDHjx9HpUqVEBcXZzNfgwYNvCoPADz44IPQ6/WYPn06AOlgPGfOHPTo0cMm6Pv+++/RvHlzS85CSkoK/v77b6++F7njx48DAOrVq2czPSUlxWZ9gBQUffzxx6hXrx4MBgMqVKiAlJQU7Nixw+f1ytdfuXJllCtXzma6uSeauXxmnvaLQBw/fhz16tWzBGOuyvLMM8+gfv366NGjB6pWrYpHH33UIU9m3LhxyMzMRP369dGsWTO8/PLLNk0shw4dghACb7zxBlJSUmz+3nzzTQDSPu7NsrwRERGB++67D9OnT8fKlStx8uRJPPTQQy7nX716Nbp27YrY2FgkJiYiJSXFkrvmzXd98OBBLFy40OGzde3a1eazmdWqVcurz5GRkYHnn38eFStWRHR0NFJSUizv9XcfpOBjjgoFTH6VYpaZmYlOnTohPj4e48aNQ506dRAVFYUtW7bg1Vdf9aqLqaveJcIuSVLp93rDaDTitttuQ0ZGBl599VU0bNgQsbGxOH36NAYNGuTw+Uqrp0xqaipuu+02/Pbbb/j888/x559/IicnB/3797fM89NPP2HQoEHo06cPXn75ZaSmpkKv12P8+PE4fPhw0Mr27rvv4o033sCjjz6Kt956C0lJSQgLC8Pw4cNLrctxsPcLb6SmpmLbtm1YtGgRFixYgAULFmDq1Kl45JFHLIm3N998Mw4fPow//vgD//zzD7755ht8/PHH+PLLL/H4449btteIESPQrVs3p+sxB9yeluWthx56CF9++SXGjBmDFi1aoHHjxk7nO3z4MLp06YKGDRvio48+QrVq1RAZGYn58+fj448/9uq7NplMuO222/DKK684fb1+/fo2z50dg5y5//77sWbNGrz88su47rrrEBcXB5PJhO7du7Pbu4YxUKGgWL58OS5duoTff/8dN998s2X60aNHVSyVVWpqKqKiopwOkOZu0DSznTt34sCBA/j+++/xyCOPWKZ725PCmRo1amDp0qXIzc21qVXZv3+/T8vp378/Fi5ciAULFmD69OmIj49H7969La/Pnj0btWvXxu+//27TXGO+Eve1zIB0BVy7dm3L9AsXLjjUUsyePRu33HILvv32W5vpmZmZNt1efUlorFGjBpYsWYKcnBybWhVz06K5fKWhRo0a2LFjB0wmk02tirOyREZGonfv3ujduzdMJhOeeeYZTJkyBW+88YYlwEhKSsLgwYMxePBg5Obm4uabb8aYMWPw+OOPW7Z1RESEpZbBHXfL8tZNN92E6tWrY/ny5ZYkYGf+/PNPFBQUYN68eTY1WM56lbn6ruvUqYPc3FyvPpu3Ll++jKVLl2Ls2LE2XfgDaRKj0sGmHwoK85Wr/Eq1sLAQX3zxhVpFsqHX69G1a1fMnTsXZ86csUw/dOiQQ16Dq/cDtp9PCGHTxdRXPXv2RHFxsU03TqPRiEmTJvm0nD59+iAmJgZffPEFFixYgLvvvttmPAlnZV+/fj3Wrl3rc5m7du2KiIgITJo0yWZ59r0yzOu1r7mYNWuWJZfCLDY2FgC86pbds2dPGI1GfPbZZzbTP/74Y+h0Oq/zjZTQs2dPnDt3Dr/88otlWnFxMSZNmoS4uDhLs6B9V9iwsDDLIHwFBQVO54mLi0PdunUtr6empqJz586YMmUKzp4961CWCxcuWB57Wpa3dDodPv30U7z55psYMGCAy/mc7V9ZWVmYOnWqw7yxsbFOv+f7778fa9euxaJFixxey8zMRHFxsU9ld1UuwPm+StrCGhUKivbt26N8+fIYOHCgZXj3H3/8sVSr2D0ZM2YM/vnnH3To0AFPP/205YTXtGlTj8O3N2zYEHXq1MGIESNw+vRpxMfH47fffgso16F3797o0KEDXnvtNRw7dgyNGzfG77//7nPbeVxcHPr06WPJU5E3+wDAHXfcgd9//x19+/ZFr169cPToUXz55Zdo3LgxcnNzfVqXeTyY8ePH44477kDPnj2xdetWLFiwwKaWxLzecePGYfDgwWjfvj127tyJn3/+2aYmBpCuphMTE/Hll1+iXLlyiI2NRdu2bZ3mIfTu3Ru33HILRo0ahWPHjqFFixb4559/8Mcff2D48OE2ibNKWLp0KfLz8x2m9+nTB0OGDMGUKVMwaNAgbN68GTVr1sTs2bOxevVqTJw40VLj8/jjjyMjIwO33norqlatiuPHj2PSpEm47rrrLPksjRs3RufOndGqVSskJSVh06ZNmD17NoYNG2ZZ5+eff46bbroJzZo1wxNPPIHatWvj/PnzWLt2LU6dOmUZn8abZXnrrrvuwl133eV2nttvv91SY/Tkk08iNzcXX3/9NVJTUx2CqlatWmHy5Ml4++23UbduXaSmpuLWW2/Fyy+/jHnz5uGOO+7AoEGD0KpVK1y5cgU7d+7E7NmzcezYMYf9y5P4+HjcfPPNeP/991FUVIQqVargn3/+0UwtL7lR+h2NKFS56p5s3zXRbPXq1eLGG28U0dHRonLlyuKVV14RixYtEgDEsmXLLPO56p7srCso7LrLuuqePHToUIf31qhRw6a7rBBCLF26VLRs2VJERkaKOnXqiG+++Ua89NJLIioqysVWsNqzZ4/o2rWriIuLExUqVBBPPPGEpburvEvkwIEDRWxsrMP7nZX90qVLYsCAASI+Pl4kJCSIAQMGiK1bt3rdPdns77//FgBEpUqVHLoEm0wm8e6774oaNWoIg8EgWrZsKf766y+H70EIz92ThRDCaDSKsWPHikqVKono6GjRuXNnsWvXLoftnZ+fL1566SXLfB06dBBr164VnTp1cuii+scff4jGjRtbuoqbP7uzMubk5IgXXnhBVK5cWURERIh69eqJDz74wKa7tPmzeLtf2DPvk67+fvzxRyGEEOfPnxeDBw8WFSpUEJGRkaJZs2YO39vs2bPF7bffLlJTU0VkZKSoXr26ePLJJ8XZs2ct87z99tuiTZs2IjExUURHR4uGDRuKd955RxQWFtos6/Dhw+KRRx4RaWlpIiIiQlSpUkXccccdYvbs2T4vy568e7I7zo4B8+bNE82bNxdRUVGiZs2a4r333hPfffedw75z7tw50atXL1GuXDkBwGY/yMnJESNHjhR169YVkZGRokKFCqJ9+/biww8/tJTd3bHCWffkU6dOib59+4rExESRkJAg7rvvPnHmzBmv9nNSj04IDV3iEmlAnz59Au7OSUREymCOCpVp9sPdHzx4EPPnz7cZypuIiNTDGhUq0ypVqmS598fx48cxefJkFBQUYOvWrQ5jgxARUeljMi2Vad27d8eMGTNw7tw5GAwGtGvXDu+++y6DFCIijVC1RmXMmDEYO3aszbQGDRp4Nbw6ERERXftUr1Fp0qQJlixZYnkeHq56kYiIiEgjVI8KwsPDkZaWpnYxiIiISINUD1QOHjyIypUrIyoqCu3atcP48eOd3jgMkEZtlI+maL7za3Jysk/DbhMREZF6hBDIyclB5cqVHW7kaU/VHJUFCxYgNzcXDRo0wNmzZzF27FicPn0au3btcrgbKuA8p4WIiIhC08mTJ1G1alW382iqe3JmZiZq1KiBjz76CI899pjD6/Y1KllZWahevTpOnjyJ+Pj40iwqERER+Sk7OxvVqlVDZmYmEhIS3M6retOPXGJiIurXr+/y7rUGgwEGg8Fhenx8PAMVIiKiEONN2oamRqbNzc3F4cOHUalSJbWLQkRERBqgaqAyYsQIrFixAseOHcOaNWvQt29f6PV69OvXT81iUSBObgA2fA1op0WRiIhCmKpNP6dOnUK/fv1w6dIlpKSk4KabbsK6deuQkpKiZrEoEN/eJv1PqAY06K5uWYiIKOSpGqjMnDlTzdVTMF08wECFiHxiNBpRVFSkdjFIAREREdDr9YosS1PJtEREVPYIIXDu3DlkZmaqXRRSUGJiItLS0gIe54yBChERqcocpKSmpiImJoYDeIY4IQTy8vKQnp4OAAF3kGGgQkHCZFoi8sxoNFqClOTkZLWLQwqJjo4GAKSnpyM1NTWgZiBNdU8mIqKyxZyTEhMTo3JJSGnm7zTQvCMGKkREpDo291x7lPpOGahQcHAcFSIiUgADFSIiIo2oWbMmJk6cqHYxNIWBChERkY90Op3bvzFjxvi13I0bN2LIkCHKFjbEsdcPBQmbfojo2nX27FnL419++QWjR4/G/v37LdPi4uIsj4UQMBqNCA/3fMrlyOyOWKNCRETko7S0NMtfQkICdDqd5fm+fftQrlw5LFiwAK1atYLBYMCqVatw+PBh3HXXXahYsSLi4uJwww03YMmSJTbLtW/60el0+Oabb9C3b1/ExMSgXr16mDdvXil/WnUxUCEiIk0RQiCvsFiVP6FgR4DXXnsNEyZMwN69e9G8eXPk5uaiZ8+eWLp0KbZu3Yru3bujd+/eOHHihNvljB07Fvfffz927NiBnj17on///sjIyFCsnFrHph8KDvb6ISI/XS0yovHoRaqse8+4boiJVObUOG7cONx2222W50lJSWjRooXl+VtvvYU5c+Zg3rx5GDZsmMvlDBo0CP369QMAvPvuu/j000+xYcMGdO9eNu6nxhoVIiKiIGjdurXN89zcXIwYMQKNGjVCYmIi4uLisHfvXo81Ks2bN7c8jo2NRXx8vGV4+rKANSpERKQp0RF67BnXTbV1KyU2Ntbm+YgRI7B48WJ8+OGHqFu3LqKjo3HvvfeisLDQ7XIiIiJsnut0OphMJsXKqXUMVChI2PRDRP7R6XSKNb9oyerVqzFo0CD07dsXgFTDcuzYMXULFQLY9ENERFQK6tWrh99//x3btm3D9u3b8dBDD5WpmhF/MVAhIiIqBR999BHKly+P9u3bo3fv3ujWrRuuv/56tYuleTqhZF+sUpadnY2EhARkZWUhPj5e7eIQAIxJkP7f+gZw8wh1y0JEmpefn4+jR4+iVq1aiIqKUrs4pCB3360v52/WqBAREZFmMVAhIiIizWKgQkESsi2KRESkIQxUiIiISLMYqBAREZFmMVCh4GDLDxERKYCBCgUJIxUiIgocAxUiIiLSLAYqREREpFkMVCg4QnfAYyKiUtG5c2cMHz7c8rxmzZqYOHGi2/fodDrMnTs34HUrtZzSwECFiIjIR71790b37t2dvvbff/9Bp9Nhx44dPi1z48aNGDJkiBLFsxgzZgyuu+46h+lnz55Fjx49FF1XsDBQISIi8tFjjz2GxYsX49SpUw6vTZ06Fa1bt0bz5s19WmZKSgpiYmKUKqJbaWlpMBgMpbKuQDFQoSBh0w8RXbvuuOMOpKSkYNq0aTbTc3NzMWvWLPTp0wf9+vVDlSpVEBMTg2bNmmHGjBlul2nf9HPw4EHcfPPNiIqKQuPGjbF48WKH97z66quoX78+YmJiULt2bbzxxhsoKioCAEybNg1jx47F9u3bodPpoNPpLOW1b/rZuXMnbr31VkRHRyM5ORlDhgxBbm6u5fVBgwahT58++PDDD1GpUiUkJydj6NChlnUFU3jQ10BEROQLIYCiPHXWHRED6HQeZwsPD8cjjzyCadOmYdSoUdCVvGfWrFkwGo14+OGHMWvWLLz66quIj4/H33//jQEDBqBOnTpo06aNx+WbTCbcfffdqFixItavX4+srCybfBazcuXKYdq0aahcuTJ27tyJJ554AuXKlcMrr7yCBx54ALt27cLChQuxZMkSAEBCQoLDMq5cuYJu3bqhXbt22LhxI9LT0/H4449j2LBhNoHYsmXLUKlSJSxbtgyHDh3CAw88gOuuuw5PPPGEx88TCAYqRESkLUV5wLuV1Vn3/50BImO9mvXRRx/FBx98gBUrVqBz584ApGafe+65BzVq1MCIESMs8z777LNYtGgRfv31V68ClSVLlmDfvn1YtGgRKleWtsW7777rkFfy+uuvWx7XrFkTI0aMwMyZM/HKK68gOjoacXFxCA8PR1pamst1TZ8+Hfn5+fjhhx8QGyt99s8++wy9e/fGe++9h4oVKwIAypcvj88++wx6vR4NGzZEr169sHTp0qAHKmz6oeBgrx8iusY1bNgQ7du3x3fffQcAOHToEP777z889thjMBqNeOutt9CsWTMkJSUhLi4OixYtwokTJ7xa9t69e1GtWjVLkAIA7dq1c5jvl19+QYcOHZCWloa4uDi8/vrrXq9Dvq4WLVpYghQA6NChA0wmE/bv32+Z1qRJE+j1esvzSpUqIT093ad1+YM1KkREpC0RMVLNhlrr9sFjjz2GZ599Fp9//jmmTp2KOnXqoFOnTnjvvffwySefYOLEiWjWrBliY2MxfPhwFBYWKlbUtWvXon///hg7diy6deuGhIQEzJw5E//73/8UW4dcRESEzXOdTgeTyRSUdckxUCEiIm3R6bxuflHb/fffj+effx7Tp0/HDz/8gKeffho6nQ6rV6/GXXfdhYcffhiAlHNy4MABNG7c2KvlNmrUCCdPnsTZs2dRqVIlAMC6dets5lmzZg1q1KiBUaNGWaYdP37cZp7IyEgYjUaP65o2bRquXLliqVVZvXo1wsLC0KBBA6/KG0xs+qEgYdMPEV374uLi8MADD2DkyJE4e/YsBg0aBACoV68eFi9ejDVr1mDv3r148skncf78ea+X27VrV9SvXx8DBw7E9u3b8d9//9kEJOZ1nDhxAjNnzsThw4fx6aefYs6cOTbz1KxZE0ePHsW2bdtw8eJFFBQUOKyrf//+iIqKwsCBA7Fr1y4sW7YMzz77LAYMGGDJT1ETAxUiIqIAPPbYY7h8+TK6detmySl5/fXXcf3116Nbt27o3Lkz0tLS0KdPH6+XGRYWhjlz5uDq1ato06YNHn/8cbzzzjs289x555144YUXMGzYMFx33XVYs2YN3njjDZt57rnnHnTv3h233HILUlJSnHaRjomJwaJFi5CRkYEbbrgB9957L7p06YLPPvvM940RBDohQjfrMTs7GwkJCcjKykJ8fLzaxSEAGFPS9a3Tq8At/6duWYhI8/Lz83H06FHUqlULUVFRaheHFOTuu/Xl/M0aFQqO0I1/iYhIQxioEBERkWYxUCEiIiLNYqBCQcKmHyIiChwDFSIiUl0I9+sgF5T6ThmoEBGRasyjneblqXQTQgoa83dqP6KtrzgyLQUHr46IyAt6vR6JiYmWe8bExMRY7kRMoUkIgby8PKSnpyMxMdHm/kD+YKBCRESqMt/ZtzRucEelJzEx0e1dm73FQIWIiFSl0+lQqVIlpKamoqioSO3ikAIiIiICrkkxY6BCQcKmHyLyjV6vV+zkRtcOJtMSERGRZjFQISIiIs1ioELBwV4/RESkAAYqREREpFkMVIhIGYUcsIuIlMdAhYKETT9lyoLXgHcrASfWq10SIrrGMFAhosCtnyz9//ctdctBRNccBipEpBwmURORwhioUHDwhFU2CZPaJSCiawwDFSJSEANUIlIWAxUiUo7JqHYJiOgaw0CFgoRX1mUSm36ISGEMVIhIQQxQiUhZDFSISDmsUSEihWkmUJkwYQJ0Oh2GDx+udlFICez1UzbxeycihWkiUNm4cSOmTJmC5s2bq10UIgqEYDItESlL9UAlNzcX/fv3x9dff43y5curXRwiCgRrVIhIYaoHKkOHDkWvXr3QtWtXj/MWFBQgOzvb5o+0iiesMomBChEpLFzNlc+cORNbtmzBxo0bvZp//PjxGDt2bJBLRUR+YzItESlMtRqVkydP4vnnn8fPP/+MqKgor94zcuRIZGVlWf5OnjwZ5FISkW9Yo0JEylKtRmXz5s1IT0/H9ddfb5lmNBqxcuVKfPbZZygoKIBer7d5j8FggMFgKO2ikj/YBFA2cWRaIlKYaoFKly5dsHPnTptpgwcPRsOGDfHqq686BClEFALY9ENEClMtUClXrhyaNm1qMy02NhbJyckO04koVLAmjYiUpXqvHyK6hrBGhYgUpmqvH3vLly9XuwhEFAjmJhGRwlijQkTKYaBCRApjoELBwRNW2cSmHyJSGAMVIlIOAxUiUhgDFQoS1qiUSQxUiEhhDFSISEEMUIlIWQxUiEg5rFEhIoUxUKHgYDJt2cRAhYgUxkCFiJTDQIWIFMZAhYiUw0CFiBTGQIWChE0/ZRK/diJSGAMVIlIOa1SISGEMVIhIOQxUiEhhDFQoONjrp2xioEJECmOgQkTKYaBCRApjoEJECmJNGhEpi4EKBQlPWGUSa1SISGEMVIhIOQxUiEhhDFSISDkMVIhIYQxUKDjY64eIiBTAQIWIiIg0i4EKERERaRYDFQoSNv0QEVHgGKgQERGRZjFQISIiIs1ioELBwV4/RESkAAYqREREpFkMVIiIiEizGKhQkLDph4iIAsdAhYgCFxaudgmI6BrFQIWIAle+lvVxfrZ65SCiaw4DFQoO9vopWwzlrI+zz6hXDiK65jBQoSBhoFK2yL5vYVSvGER0zWGgQkTKEia1S0BE1xAGKkSkLDb7EZGCGKhQcPBkVbbYfN/87olIOQxUSDkMTghg0w8RKYqBChEpQJ5My4CViJTDQIWChCersovfPREph4EKKYdX0gQwTiEiRTFQIaLAyYNU5qgQkYIYqFBwsHalDON3T0TKYaBCCuIJquxiMi0RBQcDFSJSFpt+iEhBDFQoSHhVXXbxuyci5TBQIeWwyr/sshmYlvsBESmHgQoRKYtNP0SkIAYqFBy8qC7D+OUTkXIYqJCCeIIqu9jrh4iCg4EKESmMgQoRKYeBCgUJT1ZlCkemJaIgYaBCymGVPwHcD4hIUQxUiEhhDFSISDkMVCg4eFVdxjCZloiCg4EKKYgnKAIDFSJSFAMVIgqcTXDCQIWIlMNAhYKEJ6syi71+iEhBDFRIOazyJ4D7AREpioEKESmATT9EFBwMVCg4eFVddrHph4gUxECFFMTgpMwS7J5MRMHBQIWIFMZAhYiUw0CFgoQnqzKLNSpEpCAGKqQcnqDKMN6UkIiCQ9VAZfLkyWjevDni4+MRHx+Pdu3aYcGCBWoWiYgCxoCViJSjaqBStWpVTJgwAZs3b8amTZtw66234q677sLu3bvVLBYpgbUrZQuTaYkoSMLVXHnv3r1tnr/zzjuYPHky1q1bhyZNmqhUKvIfT1AEBipEpChVAxU5o9GIWbNm4cqVK2jXrp3TeQoKClBQUGB5np2dXVrFIyKvMVAhIuWonky7c+dOxMXFwWAw4KmnnsKcOXPQuHFjp/OOHz8eCQkJlr9q1aqVcmnJezxZlS1s+iGi4FA9UGnQoAG2bduG9evX4+mnn8bAgQOxZ88ep/OOHDkSWVlZlr+TJ0+WcmnJLZ6gCGCvHyJSlOpNP5GRkahbty4AoFWrVti4cSM++eQTTJkyxWFeg8EAg8FQ2kUkIk8E7/VDRMGheo2KPZPJZJOHQiGKtStlF797IlKQqjUqI0eORI8ePVC9enXk5ORg+vTpWL58ORYtWqRmschvPEER2PRDRIpSNVBJT0/HI488grNnzyIhIQHNmzfHokWLcNttt6lZLCLyGZt+iCg4VA1Uvv32WzVXT0HFk1WZxaYfIlKQ5nJUKIQpfYIymYDLx5VdJpUCBipEpBwGKqRdfz4LfNIc2DxN7ZKQJ4I3JSSi4GCgQsGhxMlq60/S/2XjA18WlR42/RCRghiokIKCdVXNE5/2MZmWiIKDgQoFB6v/yy7WqBCRghioUHAoebLiiS+08PsiIgUxUCHlBC2hkic+zeMQ+kQUJAxUKDjY9FN28bsnIgUxUKHgUPJkxaaEECCvTeP3RUTKYaBCCmLTDwH8vohISQxUKDhYo1J2semHiBTEQIWCw2RUcGEMVDTPJpeW3xcRKYeBCiknWL1+eOILMfy+iEg5DFQoOBhclDFMpiWi4GCgQsHBZNqyizkqRKQgBioUHIo2/Si3KCoN/MKISDkMVCg4eFVdtgg2/RBRcDBQoeAQ7PVTZjFQISIF+RWonDx5EqdOnbI837BhA4YPH46vvvpKsYJRCGKvnzKM9/ohouDwK1B56KGHsGzZMgDAuXPncNttt2HDhg0YNWoUxo0bp2gBKUQxmbbsYmBJRAryK1DZtWsX2rRpAwD49ddf0bRpU6xZswY///wzpk2bpmT5KFQxR6Xs4ndPRAryK1ApKiqCwWAAACxZsgR33nknAKBhw4Y4e/ascqWjEBOkhEpeoWufYNMPEQWHX4FKkyZN8OWXX+K///7D4sWL0b17dwDAmTNnkJycrGgBKUSx6afsYmBJRAryK1B57733MGXKFHTu3Bn9+vVDixYtAADz5s2zNAlRGcdk2jKGNSpEFBzh/rypc+fOuHjxIrKzs1G+fHnL9CFDhiAmJkaxwlGIkQcUvClh2cUcFSJSkF81KlevXkVBQYElSDl+/DgmTpyI/fv3IzU1VdECUohijUrZxe+LiBTkV6By11134YcffgAAZGZmom3btvjf//6HPn36YPLkyYoWkEKUogO+keYxmZaIgsSvQGXLli3o2LEjAGD27NmoWLEijh8/jh9++AGffvqpogWkUBKkAd944gstbPohIgX5Fajk5eWhXLlyAIB//vkHd999N8LCwnDjjTfi+PHjihaQQpSJTT9lFr8vIlKQX4FK3bp1MXfuXJw8eRKLFi3C7bffDgBIT09HfHy8ogWkEMWr6jKGTT9EFBx+BSqjR4/GiBEjULNmTbRp0wbt2rUDINWutGzZUtECUgixudcPe/2UWaxRISIF+dU9+d5778VNN92Es2fPWsZQAYAuXbqgb9++ihWOQhh7/ZQtIkijEhNRmedXoAIAaWlpSEtLs9xFuWrVqhzsjaw4jkoZxu+LiJTjV9OPyWTCuHHjkJCQgBo1aqBGjRpITEzEW2+9BZOSSZQUYoLV64dCCr97IlKQXzUqo0aNwrfffosJEyagQ4cOAIBVq1ZhzJgxyM/PxzvvvKNoISkEsemnjGHTDxEFh1+Byvfff49vvvnGctdkAGjevDmqVKmCZ555hoEKcRyVMo3fFxEpx6+mn4yMDDRs2NBhesOGDZGRkRFwoTTv0FLg7Ha1S6E9gk0/ZRaTaYkoSPwKVFq0aIHPPvvMYfpnn32G5s2bB1woTbt0GPjpbmDKzWqXRNsUTaal0MJAhYiU41fTz/vvv49evXphyZIlljFU1q5di5MnT2L+/PmKFlBzLh9VuwShgTUqRESkAL9qVDp16oQDBw6gb9++yMzMRGZmJu6++27s3r0bP/74o9Jl1BZeLLoRrAHfSPvY9ENEweH3OCqVK1d2SJrdvn07vv32W3z11VcBF4xCHGtUyjAGKkSkHL9qVMo0ndoF8MKeP4DD/6pdCmVvTEjaxmRaIgoSv2tUSKOyzwK/PiI9HpNVuuu2P0EJExgLl0UMVIhIOTyL+Errx+C8i2qXwIp5KkREFCCfalTuvvtut69nZmYGUhZSmhCATsW2KuaplCFs+iGi4PApUElISPD4+iOPPBJQgShQssCk1AMV+6YfnrDKJn7vRKQcnwKVqVOnBqscpBSbwETtE4ba66dSw2RaIgoS5qj4LIQOwmqfMNReP6mE3zsRKYeByjVH3vRTyjkiDoEJT1hERBQYBio+C4WBVMxYo0KlRTh9SEQUKAYqPlPgKGwyAlt+BC4eCnxZ7qgeKKi9flIHv3ciUg4HfFPD5mnA3y9Kj5UelE2nYtMPe/2UXfKvmt87ESmINSpqOLm+lFak9glD7fUTEVGoY6ByzbEbR0VNaq+fVMLvnYiUw0DFV6F08lW91w+VHRxHhYiCg4HKtUZLA75xCP0yioEKESmHgUogtH7lqHb51F4/qYPfOxEpiIGKr3QaygHxRO1eP7yyLju0/lsgopDFQMVXihyQgzlonIYGpOPJq4zi905EymGgEhCNH5BVDxTUXj+VHibTElFwMFAJhBYPyGom09pvDy1uHyoFTr73DV8D/2sEXDhQ+sUhopDGQCUgGjwRy4MD1XvdaHD7UPA5C1DnjwByzlhHZCYi8hIDFZ9p/eSroSp4tddPpcfb79pUHNxyENE1R9VAZfz48bjhhhtQrlw5pKamok+fPti/f7+aRfKNFk/ENmUq7fKx1w8Bbr93Lf5miEjTVA1UVqxYgaFDh2LdunVYvHgxioqKcPvtt+PKlStqFssDBXJAdMHsmaOhph+elMoQDdXkEdE1RdW7Jy9cuNDm+bRp05CamorNmzfj5ptvVqlUpaC0DuSqnzDUXj+pw933zn2CiHyjaqBiLysrCwCQlJTk9PWCggIUFBRYnmdnZ5dKuWxp/MpRzaYf9vohT7hPEJGPNJNMazKZMHz4cHTo0AFNmzZ1Os/48eORkJBg+atWrVopl9Iem37cUnv9VHqEtwE8AxUi8o1mApWhQ4di165dmDlzpst5Ro4ciaysLMvfyZMnS7GETmjx6tDrE0ZpUHv9pA4m0xKRcjTR9DNs2DD89ddfWLlyJapWrepyPoPBAIPBUIolC0Vq9vqxw5NSGcIaFSIKDlUDFSEEnn32WcyZMwfLly9HrVq11CyOd1Tt/usFTQ34RkREFBhVA5WhQ4di+vTp+OOPP1CuXDmcO3cOAJCQkIDo6Gg1i+YdTdYYaKjpR+31k/ZwnyAiH6maozJ58mRkZWWhc+fOqFSpkuXvl19+UbNY7ql5Lx2tczgJcfuUGd7mRrGWj4h8pHrTT9kUxF4/Wmr6KbPfb1nHHBUiUo5mev2EDE31qnFGS+VTe/1UerS03xHRtYSBSkA0eEDW0r1+eMIqo9g9mYiUw0AlEJo86Grpylbt9ZP2cJ8gIt8wUNGiA4uA6Q8Cuem+v9emQoU5KlRKvE6mDX5RiOjawkDFZ6XQtDL9fuDAAmDhawEuSO17/bCHR9nEZFoiUg4DlUD4W2Pg7b1+cs77sXA2/ZAavK1R4T5BRL5hoOIzBboWe32w9uOgzu7JRESBEwK4mql2KQgMVJw6ciEXP649hvk7z6pbEL9O9Brq9cMalTKKTT90DfjzOeC9GsCxVWqXpMxjoOLE/n27sPuvSdi//GcnryrQtOJt04+rg/rxNcDcoUBehpO3aKjpR+31U+nxOpmW+wSFiC0/SP9XvKduOUgbd0/WmnpXNqNHxDfYnNkcwAg3cwb5oOvqoD61R8nrJqDvZPs3yR6qnczKk1LZxCH06RoSFqF2Cco81qg4EVP9egBAneIjECY3B9agXx16WH7GESdvUbHpx6HXDwOVskNDNXlEStIzUFEbAxUnkmq1QJHQI1GXi+wLJ2xfVPogHNDyPLxX9fOF6gUgzeE+QSEmjA0PamOg4kRUdAwu6soDADLOHnczpwIH3UDa851Wo2uo6YfnpDKKOSp0DWGgojoGKi7k6KVAJfviabtXFK7idhtMeApUnLyupXv9MFIpO7xO4uY+QSGGTT+qY6DiwlVDMgAg77JdF2VFrghlvX7cBSp+1YhoKFdA7fWTSlijQtcQJtOqjoGKC8XRFaT/2fajwypcY+E2UPG0fA81Kmo3/fDquWxijQpdS8L0apegzGOg4oIxMgEAoC/Itn1B6XFKAgkmnK5fS71+1A6UqPR4ua+xRoVCDZt+VMdAxYWw8EgAgDAV272idCAQwNWns0CAA74RESmHTT+qY6Digq4kihbGItsXFO+eHMxxWtQOFNReP6mCTT90LWGNiurY78qFsPCSndMcqJiMwPQHgAv7rDMpEbRcPg5UqA+U1ODY8iNHRdXuyRzwjQAm01LIMxmtj9k9WXWsUXFBb65RMTf9HF8NHFoMZJ2UzaXAQffLDsC0Xs5f8zTSq6fuyaqfFNReP2kP9wkKAcUF1scMVFTHQMUFa41KSaBiLHScSalA4NQGFy/Ilj93KDCpFVCY52H9ao6jYkf1QIlKhS+3Tgj6XSeE85t1EvnCKAtU2PSjOgYqLuhLmmJ0piIPc5aSbT8BGYeBfX+5n0/N7skOJ6hAz0re3mWatEXFHJX5I4D3awH7FwZ3PXRtk+cm6tg9WW0MVFzQR0hRtM6h149csO+e7GyaydMMsochXqOi01CgcnAJ8PcI2yphkmjpZpQbv5H+Lx2nXhko9Nl3oiBVsfHNhXBzcqtwE6j4e0D2uqYj0BwUtZterqEalZ/vkf4nVgc6PKduWTRPC8m0au/7FNLkx2iOB6U61qi4YK5RCQtGjYq3O76nHBSn46h4en8wKXxlLa9RUbt2yMwmmZp8VloHfa3sLxSaGKhoCgMVF8w1KmHualT85u1B1NNNBz28R/WDtYI1Kqp/FnLNlwC1lL5HnlwoIFq6FQkxUHEh3JyjIoyuZwp604/TN7t4bJ50rfb60UqgoqHmKM3SwnelhTJQyNLUPdOIgYoL5l4/erc1Kio0/XjMUdFQr59QafopyA3esssCn7onl1aNCgMVCgQDFS1hoOKCeQj98KAk0/rY9OMqutf6vX4UbfoJ0sHi8DJgfBXgn9eDs/wySQNNP6xRoUCwRkVTGKi4oC8Z8C0Mbpp+/OVrjYp8OGefhtVn049H5gBlzSTv5tdSl+lQxBoVCgVaakInBiqumEemDYcRJlMp3ojQdkbpn7znkS8/ILXv9RPoD1xXCjUqpAANJtPy5EIBYY2KljBQcSFML+WoRMAIo6sDr99XbV6+z7x84aJGRev3+gl4/ez1E5q0kKPCkwsFwKaJnccetTFQccE8jooeRhgVr1HxcXnyph+PNSpaqrJ0sX5jMbDw/4D9C9y/nTUqoUFLI9NqqQwUupijoikMVFwIK0mmjdAZUewyUCmlkWltBp3TcI2KtyesnbOAdZ8DMx70ZeF+F8s9X3NOmKMSGDb9UChgoKIlDFRcMHdPDocRRqPCTT/evs/S9OOqGlJj3ZMduPicuee9fL+PNSrGYuvdrklFWmj6KZ3V0DWKNSqawkDFBX24dBskPYwoNrnaUYM9jkrJfPKmH5fNQM6maTRHpST/xyNfxlERAviyAzCxGYOVUufLOCqlddBnpEIBYI6KpjBQcUEnT6Y1CSha5R9I04+pyPF1l28v7R+Yl71+SprVfFu0h21WXABc2AfknAEuH/N9+aQgDRzYeXKhgLBGRUsYqLiil2pUwmHOUfFUe+ELH98n7/Vj01XZw7LVPlgHWqPib3BYdMW/95F/HHKT3M4czJLIVsOTCwWATT+awkDFlTBroOK6108pDaEvb+4xukistX+Pq9dLk6vPKQ9U3AVTPjX9yNZVdNVz2fzFAd8CU2q7JGtUKBAMVLSEgYorYdYB34pdNf0E/aaETgIVl4O/2b3H5etB5LA+L5p+TF7mk3jcZrJ1FbJGRV0aGPBN7dpECm2eblVCpYqBiivme/3oTDAajVD0AOt1rx/zf3mg4iFHRUtVlt40/RTne7sw79cVzBoVcsKXZFp2T6YQoKWBM4mBikthesvD4uIiFzOpMI6KLzUqqh+svahRKS5083Yfgi6bpp88z0Uz87klh00/nrFGhUKdhi74iIGKS2HWk6mxuAjKNv34OI6Kvzkqavf6cbl+2bZ0W6Piy2dh049maCJI0EIZKGQJl09IBQxUXJFd9ZtcXvWr3evHhwRTLZGXy1jgZr5SqFGhwPkSmPBePxQKmKOiKQxUXHGoUXFRe1GQ4/uylUqm9RjwqN3rx4veUsVuAhVX7/G0Lvb6URmbfijUselHSxiouBIWBlNJE4VwNdLpn88B46sCpzb5tmxnO/75PcBP9wCnN8vmcxKoeBoxUc1kWofiuDhZyMvlNlDxpUZFS7k5ZQ2Taekao6VOCcRAxZ1iSAm1Rlcn0zNbpf8r3vdtwc4O1j/dDRxaAnx9q3zGkn8uAhWP9/rRaI2K8LJGxad8G+H0IamBNSqaVZALXM1UuxTax6YfTWGg4oYR0qBvpuIiZY+vznb8nLNO5nPS60f4cK8f+byq8KJGxeSqR5WXy3K2TJ8OLGzKKVWsUVHX+CrAezWYcO4Ra1S0hIGKG0adVKNiKi5Wbmctugqc9rGpyOWNCD3UqLi8mWKweNsEIC+juwHf/Gz6UT1AK2MchtDXQo1K6awmZGUcUbsE2sZxVDSFgYobxpKmH5PRRTKtP/5+yYeZPTT9XBM1Km4CFV8OFqyq1RANHNi5Dzhi3oUPuK20hIGKG0ad1PQjjIXKRdXbfvZ+Xk/JtJ5OCCaVAxVXP3D5tnSVqOzuPc5n8Lxeb+ycDfz6CFDILs7eYzJtSPB0kUNW3FaaEq52AbTMZG76MRZDnQRBZ92TPeSoQMUaFW+bAOTTvW368SVHJZAA7bfHpP9pzYCbX/Z/OWWau0CllK5OeXJxxFpH77H2SVMYqLhhTqYVRoWTab1l/rG4PMBorHuygwBzVHwa8E3hz33lYuDLICdYo6Ia5l34QEvHUWLTjxuWpp/iInV+2OYfiKtAxWmR5EGA2k0/AeaoeLMsZ8tU4sDian0c8M2RT8m0pUQLZdAa1qh4T1MXfMRAxQ1R0vQjPDb9BK0EJf/kBxij4+s2b1HzB2ZfHm+aftwFU758FoU/N9uoA8AcFU1ioOI9bitNYaDihjWZtkidndVp04+n6ttQq1FxM46KL6PN+huguaohYaDiAy12T+Z35oi1BN7z4dhDQcdAxQ2TpUbFQ6+fYB0U/clRsXm/Rrsnu8tRuXgQ+LoLsH+h7Xy+NP0oEqC5Oqiz6cczDRzYeSJ2xFoC79nEKdxWamMyrRsmc42KSaWmH485Khpr+vG614+bHJXfHgfObgNmPADowpy/x2M5FG760cKJl3zE78wBAxXvcVtpCmtU3DCFlcRxxmLtJNOaPOSoaKnpx58clasZzufzaQh9BT43k+m85xCgqlMMG2z6ccQbd/qAPaS0hIGKGyZdBABAmNTKUQm0RiUUclTsalRKmttKZnT+Hk/rUjyZVvaYvX68oIUDuxbKoDGsJfAeL1Q0hYGKG+amH52xUKUS+JOjIq+tULvXjxfzOQQqLnbJUh9Cn1dU3mP35JDDk68HDFS0hIGKG6YwqUYFRk/jqAQrmdZZjUoI3T3Z5RD6sulGu14//gYqfgdornr98EAV2hioOGCNivfY609TVA1UVq5cid69e6Ny5crQ6XSYO3eumsVxYA5UdMZClZp+nAyh79Pdk9UOVPzIUXEVqPiUoxLEph/yAg/smmTT5Mp92i0tXfCRuoHKlStX0KJFC3z++edqFsMlS41KKPX6cfb+0uKQVOnFTQm9bvrxJUdF4WRam++eOSoOtDgyLTniydcHGrrgI3W7J/fo0QM9evRQswhuCZsaFY0EKsdXy2dw8h4NHYxcBhchlqNy4B8FlleWMFDRJH9uXVFWaek4SqE1jkpBQQEKCgosz7Ozs4O6PlHSPVlnKoI6B19zMq2f61b7SsDVD9xtrx8/m36COYT+748HvryyhDUq2qT4oIjXMDaTaUpIJdOOHz8eCQkJlr9q1aoFdX2WGhW1uicDwL9ve9eE4mya2vf68arpxz5HxYsh7T29rsRBmDclvGbkFRZj1qaTuJRb4Hnma5qbmkyywxoVLQmpQGXkyJHIysqy/J08eTKo6/O6108wryBXfuBdzYR1ovWh2ldNLtcvL6NCvX6COY6KL+UgaK3pZ9yfe/Dy7B0Y8O0GtYuiLiaIe89dHh2VupBq+jEYDDAYDKW3Qn0kACBMtaafEkVXXbwQojkq7pp+wvRwytNnKa1ARWMnYU2wD95yzwMFOYChnDrlsfP3jrMAgD1ng9tUrHnMUfEem8k0JaRqVEqbueknTKjY9ANIB31/hGKvH1e9ajweWP0MVFw25XjRtZpcW/au2iUge+6aXMk1tS/4SN1AJTc3F9u2bcO2bdsAAEePHsW2bdtw4sQJNYtlpS8JVEyeBnwLssIrPszsxcFoxyzgi3bApcMBFcsjV+t3d7XiqunHfmA4d8tUpEbFi+H/ybXzu9UuAdljjYr3bII6/ubVpmqgsmnTJrRs2RItW7YEALz44oto2bIlRo8erWaxLITenEyr0jgqZoW53s/rTdPP748D6XuAP4YFVi6PZfGje7Krph+PgYrCV4sMSHzg5LfhsvcWgAIf9mcFVMBljAufinq6U6W6Xs3RUrOw5jFHRUtUzVHp3LkzhJar0sNKclSESkPom/kSqPgylHx+ll/F8WrdgLLdk+2Tbt2tO5hBhpb3Vy1xF6jMfhTo/2upFWUCPkXb8N14UP8vgCdLbb3aw6Yfryl9N3YKCHNU3ClJptWr2T0Z8HwFuvl7YGJz4OJB366agv0DdNn0IyujQ02Ji5wRX5p+jiwDvroFOL/HYxFdlsubRGCSOAve3AUqBxd5v+zDy4BfBgA5530vV4nGuiMAgEhdGT/hMEHUe8zn0RQGKm7o5DkqavJUo/Lnc0DmceDP5+HTVVOwf4BKjqPiS9MPAJzZAvw6wP177MnLcnwNYHRW5csaFa+4C1R88WMfYO88YP5Lfi9C8LYHEna59QGbybSEgYob5hwVvShWpso/94J/7/O2Tb8oz7duukofrLzt9eNPjoqnYNHZuvIuuX8PAJsaHPky8jOBFe95tx5ypFSgYnb5mLLLK4vYnOE91qhoCgMVN3Th5hyVYmVOUKs+9u99F/Z6N5/9D6q0m34O2t0Tx59xVPzt9aNETYd9eVd95GQe1qg48rHpxx8BnSxYowKAvX58wWYyTWGg4o45R0V4GPDN25OXsTDwMrkjTPCt6UfB2oH8LGDNp3bL9yJHxdtxVHzJUfGXfeDm9GDOQMUrSt9qwGOg6hq/MTN3uWFky8umn8vHgeIgH9eJgYo7OkvTj0LjqETGBr4Md87vsm0m8nh/HAWvFDKOer98t1crLrazx6YfJ++7ehm4ctH9+1yVK5B5yhpfk2n9wRqAwMn3XX8HkSwrvGn6ObkB+KQ58G3X0ilTGcZAxQ2dpUZFoXFUDHGBL8Oe/Ulixy/Wxx5rVBQ8+Gced5y26TvHEUozjtg2EdkHIK6COU+1Ua4CiLWfuX+fN8uwmYfX516RBypKbLMA9lUm05awCVTK+O0EPPGmmWz7DOn/2e3BL08Zx0DFDXOOil6pHJXIYAQqduWS1yB4TKZVsEYl08UNIle8B2TJBtr6tCVwdpv1ubEQOLUJKMqXnrs6qTntgSPn4n3m5XrDm+3BGhXvKB2osKkicPLvIZ+BinvC9rGzfTgspG6VF9IYqLhhrlEJV6rXT8nyFGV/4iySDbd/agOwe67r9yoZqLgb5v/sDtevndkKfNMF+O0x92Xyp+nHm/d5swzbmbxfXpnhqelH3RoVKiHfv1mj4p79scDZcUnnoociKY6Bihth4VKOSrinZFp3r5lM1rsfB+Nq3NMyZw10814FA5ViWc1FahPb15w1C9nb95f7MhkLgcWjgb9fcp4E7LImxodENzb9KEfxpp9AkmnZ9AOAOSo+8WKUbVdDKZDiGKi4YalRgYemH3cH4h/vAt5JA2Y8FJyrQm9qRVwdlOzfm5vu/0nFHKh0GA5c18/2NV+q7V1t56uZwOpPgI3fAPv/9v59ntYt753iTeDGQMVRqSTT+h9U8xszk22Jq5fVK0Yo8KZGhYFKqWGg4kZYhAJNP0dXSv/3/x2cQMWbWoCccy7eK/vx7ZwNfFjPMfnVW+ZAJSLasUrUl8/t6oQkv9PzmW1OZnBVo+JDkOTVyZCnPa9ouemnrHYnlR8rMo4AF/arVxatcwhUnOx/zFEpNQxU3NCFGwAAiciWhlQPlKtmiOjy/i/Tq0DlrPPp8h/f3yVDlK98379yFBdI/8MNjlcavpxkXNVqnJBt/+zTTt7nYjv40mQwz8ndpIsLgLRmntdDtjSVTCurNcs+A7xXA5g7NOAihRz77+HUJnXKERK8afphoFJaGKi4oQ+XJb8eWhz4AgvznE+PTfV/md6cOLNdBCry9wbaI8mchxMe7VjtbyoG8jKAc7vcL0MIaw2UWdexjvPJexHJ3+uMLye4w/86TivIsbstAWtUHDlr+tG5f93nVSiUT7Xha+lWE9t+UmZ5ocT+WOFN7lhZ5VCj4uQ4y2TaUsOQ0A1zMq1nXh6Ii1wEKnGpwEU/q2G9CVS8uedNZIx/6zeT16jYl8lUDHx2A5DnYfC1/fMdp5XUatlwWkOkQDKtXESs1IOqINuuSYiBileUrlHxhxCATmebTBuMnnehwv53eZmBikv228pTMq3JBITxuj9YuGXdCHN2kvSFfRTu6i7IUQnWxxXqWx/HpgL1urlfhzeBypUL0n2G3FX1ygda8+fEUlxSoxLhpEbFWOQ5SAGAo/9ZH+v0QO9PgXq3O1lXgeM0f5NpXTGUk/7nXrA9SLHpx5HTZFqFa1T8URJg2qxd7+3FhxurPwWm3eG6hlSz7L4H1qi44U2OiixQCfbtUco4BipumJNp/bLnD2DlB7bTXI01Yj4pAkCz+6yPX9zjPB9DTn7ivGUU8PhSIKWh7TzrvgCWjJHGK3FFHlwUezFI2skN0siz5toGtzkqXlbby2t+HvgRaDUQSK4DdHrVdj5nwYer4MpZM5ENF11Xo+Kl/9/dDlw84Hk9ZEsLN3JzFlQqUaOy+A3g2H/S/h9KHGpUjqlSjJDgVa8fWYMEA5WgYtOPG/pAalR+fcRxmrNARae3zQ+pc6v0PLq8dPXnabwD+TKv6w8kVAGGrgfGyGppPAUeqz8FTm+2XWZEtPv3zH4MyDoB/PUCcONQa3fH8GjHz+ltMu3VDOtjeeBk3xbs7KDgqqYj47DUy0Oeb7R8grRdu73juiwxyc6ns0bFNV2Ydfvkngcm3wS0fBi43slvoTSUlCVoTT+h1sXX/N2UqyQ1n+aclUZujohSt1xa5FXTDwOV0sIaFTfCA6lRccb+BF63K/DEv7b3ANKFAe2esY5F4qyZI6UhEFZShf3P69bp/mah23dJdhUcFRdYuwlnnbBOX/c5kL5HehxucNI92cvmF/n2MSfnAo4HUqfNOW5qOnJl3bONxcDy8dI9gNy10SfVcfFCiNao7P0TmP6glNSsuJJtEhYO3PaW9PjgP8D5ncDCV6HaNnNaoyJr+gl0WH6jk9+mlplrCWIqWC+Oslzc+qLM86JGRb5/MVAJKgYqboSHe3nit68mdHWTKvsclYdmAZWvs61RsW82yc9yXI4uzFrjYB7RFbANVNo+5bwM8gAAkE7cyXYnZXnAcGI9kHNeerzsXWDS9e6rvA3l/O+eLG/6kZez5QAgvirQoGdJmZ3VqLgLVNKtj+XvdZXcDDhuE2/Wo2W/PAwcWAAsddKLSjE654NgqZZM6+TkIq8ltf8t+CrUxmMxfw86HZBYQ3rM5h/nvGn6kU9zdkFp78pFYGIz4J83AitbGcRAxQ19mI9Db5/cCMx5Gphys/PX7ZPvzAmH8hwV+0TUNo87WZCLE4JeFqj0eA942snYL/ZX1MVXHavDzQHV2R1SjsYnzaXnqydK//96QfofHg28mQnc8rpUA9FuGFD5eifdk73MV5Dnk8iDiJgk4IVdQO9PpOfGQscDidtA5bysLLKraHflqtra+fRQb/rJPqP8MuXb3mmXTXVrVGyafuTlCzhQ8eGGl1pg3nd1OqA8AxX3vBhHRT7Nm9q5Y/8BmSeANZ9yu/uIgYob4WFhOCUqeP+Gb7sC26e7ft3+Ct4cqETaNf3I3eok+tbpnA9Rbt/0k1DNcZ68S44Ha/tyFZQEKua8leJ8YNNUx2XFpkhl6fQy8NwWKecjLMyxbN5cbQC25XC2rSyfTzgGGe4CCJsaFXmg4qamp3p7Fy/4cdK9dBhY8BqQ5SExujQE5TYOJcsMC1d3WHGH4NXZPaHkV8GBBioh1vRj3nd1YUD5mtJj9vxxzn7fcRaIyI9B7mpnzeTH3ZMb/CtXGcVAxQ29XocnC1/EblMNZRboqnuyfGRa+8HfnCX0ehuomHuuyF3NsP0RFuVZa3rMNSuFucCiUcBfw63zyR+b1eroOA1wLJs/V65VnNRoyGt+HJp/vG36kR1wXLUrJ9eTaqcG/un4mj/NGN/fCayfDPw6wPnrW34E/vuodJpIAs3LcLrMku2oj3C+X5ZW0483g3TZnFwCDFRCLkfFXKMSJmv6YaDilMO+5KynoWz/8tQ7034ZZ7b6V64yir1+3AgP02G3qIm1psZoEubmB+1t04ar7sl1bpFySmp0AOJSPC9HF2Y3TkWJMC/GiLhyETYn9aJ8aWAzAIirKCXXrZ9iO2S9vZf2W+d3xv6q2purDbnbxgE1OzhOdwhUZIPUuatRuSILVOQHC/sTVeO7gB4fWMe1KVfJcVn+nHSzS5q05D2r5MxD91drA9S8yffl+yIY3YbNgYqzrukASq/px3mNik3Tj1AwUAm5HBXzb8Su6acgB1g1EWjSx/Z2EWWa3b5kdFITKT/meBPwyZfBQMUnrFFxw5yjEgUPByRvT8SuruAjoqWcksZ3elkynfNcAGcjIz66yPb5FbuB1y7ss9aopDaS/tsHKW2eBAbMkdbZ6E6gXJr05yxYApzUqPgYqDTo5Xy6ux4b3uaoyN9XnG9392QBlKto7WUUlei4LKWbTuRX/c6G8FdaMJp+zCdsvZMeX0Ap1qjYdyl1EqjIA7VAe2qEXI6KrOnHPLBk+l5gyVjgvw+BL4McJIcS+13W2b4i35e8aUKTXySd3RGc2s1rFAMVN/QlJzEDPOxQvp6IA+Ws6afVIOfzVr8RGJMFXD9Qei6vXQCAWQOtbfWdRwIpjRxP0FEJ0vgub1yUBmLzxP7E5Gr7JFQHwqOsvXnMXA3nr9NZa43sDxzualT2/mm9ejba1aic2mh9bj80f3Si47KU7oYoX56ru1wrKRiBirkJJDxS3RoVhxwVDz01Au6erMC+YCwG/h4B7Pot8GV5Im/6Sa4DVGwmnTw3fi2bJ0R7tSnNIUfFWU9DeaBywvF1ezbHniuhN2CgihiouBEWpkOYDojSyXbSdk7usBvsobT7TAZSm8gm2AUqjy2x9ohxJSZJ+n/gH9fzpDQAhq4DXjsO9PnSOt3cFOLtvSzsc3HO7XQ+X5vHgdfPAy0etJ0e4ea+Q+bmH2MhcPGQNOKufXOWM/v+tr7PbP8C23nse8ToIxxv1qj0VZA8z6EgW9llO+PL3aS9ZU4qdVWj4mzslkCbXZxy1fQjn6axGpUjy6RAYfajpRAkyLonA0Cdzo6zyGsfyzT7ph8PybTeNP3YXyQsGROcXnjXIAYqHoSHhWGhsY11grO7+RbleTFUu0yNm4CHfbiCuu4h4BlZc4wuzDZR1pu8lsotpf/nZUFDr/9ZH8ckS92NzeTdcyvKgyQveBpN117VNkBkSRftJnc7r8kwMzf/7F8A/NJfuofR3Kc9dxs+sU76Lz9RZxyxnafza47vkyc6A8onUMp7juRlAL8/Cfz3P9fzByqoOSoualQmXe84zXwnbWORFHAqwZteP/LPH2jtkhK9fuRlvKTQdvC0LvNFTu3OjvP4chy7ltnvSx5rVI57DjTNwU6DnlJtVlEea1W8xEDFA32YDn+b2iL9nt+BV45KvUH6z7adqSgP+O0J7xd63UPSqLT+0ulsb15ocNK7x17DOxyntXxEahZ6eg3w6D+2NSbJdaXaow7POz+gueOqdxMAxKVZH5vvoRNfCXj5kDQmy31OukHLmWtUFo2U8msAaRTUq5mO8z69BrhvmvTYHKjIr4zktVKdXpMGlrPnEKgo3PQjP9kdXw3smAksHRekEWThYoRNYe2S7g9LjUqk814/zvzSv+T/AOCzVsDuOf6v38Kb0UQDrFGR5xS5en/OOWDuM66Tp22WJyvPyfW+l8cX8mRaAKjVCYhOsp2nrAUq856Txr2y7+jgTdOPfF8ozAUuH3W/LvNFUlQC0LFkLKq1XzhP1AWkmugL+90vs4xgoOJBeJgOgA55lW60Np/Uuw14cIZ1puJ8971k7Hm6j45H9oFKOdezmoXppV4t9tMAqcakQl27VeikcVFuG+c6adaVlEbOp5erBLy0z/pc3osnIsrL9bi4atnsJMCp2ASodqP0+Pwu6WQsD1Tko/5GJzpff7W2ts+V7unh6mS3c7bURfzHu4Hss87n8Yez5ordvwPjq0jdpL3lrJu33lWOihPm38CBkua3tV94v25XXNaoyJNpZScFf5rxbMZhcdH08+dwYNvPwNe3el6ePH8r6IGKXdOPPgJofr/tPGUtUNnyvTSS+I5fbafbByrOat/sc6DObHO/LvP+FhYONO4j/V6Krlh7BcrlZ0vJzZ+3sR5zhJBGCZcft4rypSD/Gm9CYqDigV4v/aiLTXYHwdqdAUOC4xu8Ye4a6K/o8sBNLwBVWgFN+np/6/o7PwMemQfU7CjVsARrcK763ZxPzzkrHSQf/Qdoei/QcYTvy75ywfl0+5Ee690u/Y+vVJIcLKSEN3lgcFF2teLsVgUA0Ki37fNg1qjI7f5duh/R4aXARw2B9H3O5/OGycPJdeFI6f88J/lXgNR19bcnpLyS/Gxg7lDgrQrSCMXp++zunO3liAf+BAnOxkWx4cVoxTY1Iv6UQb4tXewLF324CpZ/H8EeBEze68esy5vATS9an/8zCljzWXDLoRXy/eOfN2yPAfa1wt7cCDXjsPv1mfc3fYR07DUPuues5k1+PNvwFbDxG+DTlsD/6gPv1wGOrJBe2/IDMGsQ8FEj6Ua0Bxe7L0OIYqDiQXhJF2WjfaASGSM1V5i5G8PEfryR8rX8K8w930q5Jr0+lGoAnvjX2rThjah4oHYnYNBfwIM/+1cGb+h0QESs43RzM0r1tsC930p3eg5UI7su3Q3vkLbL/T9YpyVWl/5nnrC9MpIfaFz1mqrRAZlC9ln8ClRkV/RrJkknS/OVqznnJb4KMOIg0Pox6fmJtbaLcFY9vWQsMLO/52Yb+55OckLYJlDmpgO75wJ/DAW2/izlGy15E9j5K/BOGjChGrDtJ2neTd8BX7QF/nhGeq43OB+g0Bn7PCZvatM85ZS4uOOty3FU/Eks9qZGxdUdmoWQmrpm9LMGTPLv48K+4DX5AbZD6JtFxgBd3wSGyoKkf0YFtxxaIf89FeYA3/e2Bi/5dont7ronmwM/T8Pim/c38/6RVFv6v9pJRwj5sv4ZBfz9krVpyVRkzW05s8X2fT/fK7330BIvAvvQwUDFA/NYKsXOvvTwSGsPlVi7hFb583KVrHkkeoNj3oO3mt0LDFluPfFqmX0tT3xVqRYoUAl2n735A47zVGll27xm3l7zX3Z+Fd1ygDQujDP6cLQvmIQHC0vuUu1PoCLvOfTP68C48sDHTaSruGJZs0lcqvOEXkAKaJaPlz0vAlZ9JN2U8r8P3a/f5kaMdoHKoaW2zz9vK3VZ3/qTFIB818P1cstVkvZns/BIqbu5NwpyfD+QOutunHNeKqvJ6LLpx2ZqoOOoePN+VxcthVeAvfOA/fOtJxj77+PUJt/L5DUnNSpmKQ2k5gizyR2u2atzC/tak7PbgaMrpcf2NazOjhvm/dF8p/VLXtaomGsdm94j/b98zHHf/fsl58tIbVzynqNSTef2GY7zfNIC+OkeKd/tGsGRaT0IL0kwLTa6yI1Irguc2wHknHGcbm6myDwO3P+91FOlw3Dfcz5C0Q2PWXuvdB0L3DRcmeU+MldKgGt+H1ChgTROTIOe0sEfkIIUe5VbSif0giznJxcPOT55iMIFUdLM509Pj5gk6YrN3ppPpfID1poI+4A3oRpQ62Yp52HNJKl3VLtnbJvA9v0tVd9HxUuPDy0F4itLJ8Gcs7aJ1KYiKXnPfANL83Yzu2p3JW3uJRZfReomn30GSKkPVGopJV//+zaw8gNpHr0PgQqE823ijrMale/vkJKyC/OAFnZBq8ccFT96/djUqLjYF/QuDqvyoOToSqlnnX2tzMF/gPq3+14ub9j3+rF373fAkUekHJusE9LV+Q2PSzcabdDDmqNXmCeNYJ3SQAo2Lx6QXvv6Vmlk244jpGT3KxekC7nqN0rNHCmNgEotpP3U25q3YHJWE/n3S8CwjdahAvSR0jHDXY1KlVbApYNSE07hFSDSSW0yYN33zBdxjXoD0ElB0cKRUs1W5gmphsU83tW9U6VtVpwvBTRJtYEvbpSCqrPb3X++rT9JHTeuAQxUPLDWqLgIVG58Wuoea+/KRSCloVSdW729NGBaHS+S664VnUdKn7t6W++Sfb2VXAcY/LfttH4zpKuV3HTnzUlthgD/viUdEPIzHV93dWCRKTT/VPzJa3AXmM4sOZCYq4N1OuCp1VJtRl6GVMPS8mEpUFj5PrD8XekvWZb8fPEAMKG6dFIouuK4jm12zXwF2daTjrwm6d6pwJ/PS69XvUGqlTq6UrovzO1vSc2G9lIaWh/rIzyfgB74WWpTNxU5Vq97Yh+o5Gdbe47t+AVIbWg3v7npR0bJXj+mIum5/fhCrmpU5N/Nlh+kGkZz8FKhvvRZNn4t/d0yCuj4krJ5ZM4CN7kwPVC3C/D0aumO6VcvS7kRgLR/tugn5eb9OVwK+gGpplSeDJp10jH4Pb/LcV2N7gRaDZR6HgkTkHEUqFBPKkN+trSc/JL90FXgFyhzoBwWAfSeKDV3XjoIbJsOHC/pHBGVIAVci0cD7Z+zG8m6ZHumNpRqerNOAMdWuw40LTUqJftHRLR0PLt0SLoX2PrJtvPX6gQ0vdv6vGITKTguV9l6YZxQTTqvbPleet7zQ+liYtVHUs7TpcPSOkIcAxUPXOaomF33kPNApSBHygPZO0864JQ1+gigXgBdsP1Zn6ucl6h4qemtIBs4v9vxdWd3mbZTJMyBih81KvLgpv1z0v7wnl1CtfwEn9YUeHKl7eu3jpKasBaPlmo9HMbcENYTYbUbgaRaUqBz+ZhjcmfeJan58cxW6arLrElfoMr10smpSV+p1iTvEhBbwXWwZR98e6pRaXSHtO4r6VLtgTv2TUP23Y3lA+TlXZRq2uScDqFvF2j4yj5YOvKv41ADrnJU5DUql49KoyKbpzXoKTUhmHtBLXtHuqVCj/ekK2olOEumdSYqHuj7FbDwNSmAOr9bOglv+d56QjRz1mPFrOUAKdC4eEAaHuDqZWvC6d550h9QEmDnSfO2fkwKGMwBZfV2QNsnpeaSOl1cj1rtq5zz1p5m5dKki4E1nwEX9lpzrgCpzGZjE6Xeng1LRtK25KiUBHibp0rfn6tAxZKjIgtk7/teyj+TB9C1OkmDYNqP2A1Ix4lnN0nfSXR56YJlyw/W7yUmSaoFO7NVGkxw03dS780Qx0DFA7c5Ks7cN02qxuv9qVS1Kx84jdSTWENqxjBfITboKQUMuemueynJFKLk4GIqdn4VLZd5UqoBMc9jvnJPqgPc/LLzu1rrvagKv36A1J309yeAPX9I01o/Kl1FXbkgVT1HxEhXvebAorgA+F8D2wPuusnS1ZZ88L9bX5feU74mcPvb1umeBhOMSZJOaivek4Ibb6r0Wz8KrJjguh3ezFMX0SJZs8nl4465X84GfLOpUQkwmRYATqx3EqjIDqtCWL8L+1tJ/PqI9bYNETFS8/DvQ4A9c6Vg4sRaYNZg4Dm7hEn5sovypO0SWc5xnyzIkfbvjCNS8/OWkgRzb5qe699uPeEWF0j724GF0rLObpe2bVJtab+peoO0rp2zpAuCmh2Bajc4X27WaWDZu9JnNOeImLfLqY22t7QApG1gTixveo/UPOWvoqtS+Vd9LJXVzBxct3hAGi3WLCxCqm2V18Iue8caqJj3L/PQD5unSrdC6Pau8yEozE2N8p5xaU2B4TuBb2+T9oHb35Ka2dyJjJVuYGpmHjkckHo46nTAdf2lQMW8PQtyAYPdKNshhIGKB3pPNSoA8NCv0kHgtnFSNVuTvqVUOvJas3tsT8zlKvkURBbJfyoX91tv4Gjv2CpgWi/pSrDPZKlmw3xCfOgXa5CSVMe2O6MXzU8ApEDg3mnAN12khMzWj0oHynJpQEMnN3MMN0i3WLh4ANj6o1Qtv+lbx/n8TfAGpAO8OT8k10X3cbnOr0nNAfv+cj+fp0ClWFZDAeHYlONs4EGb8V8C7J4MOL/Hi7xGpTjfetIy155ExkmfTX5vqdgK0nd1f8mV8enNUs5HxmGpZiwmScoN+fdtadtd2Cc1jZi3QWxKSWK/kE6IRXnOmzkBH/KIzPMbpADZfswVe96MYJ1QBejzudTUMv9lKaej0R1S4LD3T2mesAhg2AZg8/fA2W3S+CT5mVKzitnl48DRFVKAlL5HCsgyT0onbVOx9HuKSpDel58lbbuMI7aBZkSsVENz41PS85tekI7dK96XajUqNgZ+6GNbfnlvNSGrUanVSaqZzToJrP4U6Pyq42d3VqNi3iYv7vG87VyJS7U+Tmkg/a/UXPp/bhewfIJ0IdFxhPQZI6I9B6tCSH+Xj0q9VL29fUqQMFDxINzVOCpy9bt5dVVOKmo5wHq1FBEL3PiM29ntFcp/Kl+U3OjRfEUrDzLMbdsn1gJTOgH9f7UdP8Hs0YXSAF8n10sH3RudNB+6EhYGPL5EWrc3+T8V6kp/+siS+xsJoEYH6aD1873SPIk1vV+/O97UqOh0QLuhtoGKsxtX2tde2AcJRXaJqNFJtsFJrpSQWCz/7uS9OfzJUbEvk7O75soDlbPbrQnT5nuCJdeReqst+j/pebUbpStguSqtpBqLjCPAV51LchkOu75Lr6vxhQCpdi+ptrRtzCNOq01fkhdiFp0kjcSaWEMaDTupNnBbye1KCq8A71YBcs8Bk2+STvjmUal9ZUiQLhZq3iRdSNifsMvXBPrIBh+MjJWaFc2yT0s99cIjbbsnh4VJ5Z4/QsohazvEMfg3J1+7G8rCH9VulDosVG4JJFSVpiXXteaymHsLrnxf+qvcUvr9A9IwCTU6SPvV0RVSk1hBjvTbMO/rzR8A7v5K2TL7iIGKB+ZeP0ZXvX4oNMRWkA4kB/4B7vjYcSReDwqd/VTWfyk18/X8AGhTcgsF+R2QC7KA72QBrHxsmbhUKevffkA5b4XpfU9SrtcVeGqVlLdS7zbpAFu/u1SWABO9d5zKxN87z+LZTjXgVQVzjfZS8u7swdLzczulgE0+GKJPNSpw7HlX8l3kQxY8yU9w3t7r5/QWqWff9QMdg6UTa4Fdv0tde81XnfLlbp9pDVTMwVhErBSoJdWRavluetF50myrwcDiN6STiDxAafu01PwQlybt12F6qQkqMlZqVriaIdWupDWTmmKClYyqpFodgedd9GKJjJV6EW781rZWtHwtqekktbFUQ5pQVWrijIiWAtKrmdKI15Fx0lhWFer7PnbTfdOAv1+Uastn9pfyoi4dkmpbzCdy8/fecoA0/EBxPvBeTSn4iooHuk+QyrVnrjSf0t9HWJhjr8owPdB+mDUYljuzVfozM5fLlSPLAyxg4EJgD1ZXuKdePxQ6bhsn/flB2A85ZCyWkg0B6Srq+kek2gRzU0CXN4GVH1oTXJvd793NI4Mtran0Z/bQL4os9s7PpGr5oiITRruaachy2+dN75b+JrWWeltkegpUPNSomAMEc3JmrhSo6CBbjrwHirc1Kl/fIv2PqWC9dUVUgtTccumQFGzduEmqoUrfbTuQ2OapJePjjLQ2/Zibghp0l/5cufFp6So3fa90JQ9IIzr3mOA4b7C6NGtFr/9J+V3HVkn7RVozqcdZsId6qHK9db9NaSDlfEzrKa0775I03XzH8IgoKXF16biSQClD+pshuzt8RKx0E9bS0Gqw1HxmTqZ/dosUvO+aLdX0la9pvetzWlOpFiuuopS8bSySmh1nDZJ6sHrKywsyBioeeJWjQmVPul2b8vHV0onzUMkgWdXaSKPvrvpYGs6//bOlX0YV7D3nYmyU5HrWO3jbi6soBSr2zRf2gYm8pqIg17FGxax8LSlgyJFG3A1zdX8oX3NUjq60dvUMC5eChhUlQcO6z6U/Z1a8J42NYR6sy9t7fekjrHdZ3/OH1HOmLPYgNCuXJg16qZbWj0qBytXLtiNHy5Njb3hcql07slxqcvvlYanpSBcmDZNw6+vKDtfgTmSM1MS88oOSHkJ1pL+aHbx7vzkPTxilgCu2QvDK6gEDFQ+sOSrqD0f838ELiDOEo2X1ABIfSRl/v2j7/EdZAnXd26R2X53OcwZ/WWE/Aquc+QB45aLtdPsalb9ekE4KSTWl4f1dBSBJJYFKSY2Ky0DFXZnM5IO65Z637ZLaTBaoeFxOvnU0Wvtbanij8V2ONxWl0nXdQ1KS/L6/S/I+dNK+WOtm2/liK1gDqqf+kxLYa3RwnYAfTDFJQPfxnudzRh8hBThXL0u1RHd+qmzZfMBAxQO9OUdF5RqV89n5GPCtdD+OYxOc9O6goDsjklFZV1Lda9+N0qzGTdJ9hsrC6MNOCAig+YPS8N2d/09KLATcj7dhDlT+fUcaH+LyMemgbr+NT66T/h9f5b4Q5pu9ldSomJt+Lop4VNDJxl7xdKfgs9ulMS7MzmyR5SXopQHK7vhYSq7c84fjHdQ7PC+N1WE/XkudW9yvl7QrqZaU+9Hey4Tk+MpSLUuoSq4r/Q5LEtPVwkDFA63kqJzLsrbHCyGgK6MnQjU9XPQ6/o2U3a9IFwY8v0MaoCoiWkqKrN5WvQJqgBAA7p4C9P1SCtZOrJXGc6h8ves3me/FVJBlHbjq6Ar3K0qu62TQuxJJtaT/ubZNP4dFZdtAxVUPGrNNU22fZ54A9pWMumrOS2j9qPT/xqekGqEPZKOA1uki5UQV5ADZZ6Uux7nngAa80KAQcffX0g0OzTdQVAkDFQ+0mKNiNAlLkxSVnuNIk/ISds2WJgz8E0isBgycp27BtMgcSN/xEbB/oe1Q4PbaDJFG3JWr29U6QFdac+DgIml6nS5Svk/tztJIoWZxFa13ga7YDNI9VDKBY6tRC1Ii6mzjzWjboIZ0r6I1k6QEVWOR47gWFk5+8+amHme9dGIrAPV7SKOTlqtkHVfEUA5IKSetlyiUJNWy9mhUEQMVD5zVqMzZegoz1p/EZw+1RGq8j4Mn+UlegVJsEghX8BYg5IO7v5Yy+6OTpLEUyIbDqT2ptnQTRXcioqUTu3kAtCf+dby55ILXpHuhdHzJmgx4z7fAb48BPd6XApvtM4CYZCmRucr1Ug3GNOsw5IdNlYH+H0jVPhu+lvJGsk66vlo058xc/4g09sjXXWT3h3HxA7z7K+kKtG5X5yMQE5HP1B1uLgRYalSM1sS+F37Zjg3HMvDZMhdVz0FWZFQ/sbfMCguTeh8wSHHO34rHvl8CTe4GXtzr/A7Y3d4FRhy07bHQ7F7g1ePSvWCS60g9Km58Worqu46Vel3IROtKEmN1Omtz06Gl0kBqwknBzTU09W6XuqZ2f9fz54iKl2qPGKQQKYY1Kh64y1FRK29FS81QZYlwdjIjG8LfSKV2Z+nPlbAw26HCzaITnc9fq6NlWPJ/xvZAS9Nu7DLVsr6eWEO6rcD8EdZpd06Sak+KrgJrP7cOimUOaq5/BLh4EFjzqfNgioiCgoGKB/a9fkyyICEppvSuquWxSRFHySXy2v/pX0TG1XyY5BXI1dpYx7wxm/cssH4K0Ow+4N+3pGmN+0g5Mma3vyUN7BbIvZGIyCds+vHAvkblcp51NMvEGIXv2eCGUTaOixbGdCFyRquVTib7Q12rwc5nPL9LuvEfII0i2ucLx67mMUlltvs5kRoYqHig19v2+sm6ah0TwVSKR+ViWS1KMWtUVGESQHp2vucZSfviUoB+JbcPuP1tKSHXzDzuSd8vvb+rNREFDQMVD+xrVApliayl2QQjz0tRe0yXsmzyisNqF0HTQmrPbNAdeOUocONQ63goZlEJ1jvMEpGqGKh4YO71U2w04ciFXHy36qjltcLi0muCKZIHKhru9fPrxpN44ZdtpbptShNrs64xMUlSoq4+AnjyPylxtn4P4NF/gNhktUtHRGAyrUfyGpVb/2c7WmZpdhPOL7LeoE3LybSv/LYDANC8agIGd6jlYW661mizZ5SX+SSVmgPDdwa3KETkM9aoeBBrkGK5KwXFDq+VVqBy4lIenvxxs+V5KCTT7j6T7XkmL1zKLcCYebux96wyywuU391vywhuHSJSGgMVD+KjpJ498iRas9Jq3vjcbmC5UMhROXU5T5HljJ63G9PWHEOPT/5TZHmB0mSFARHRNYyBigfx0VKgkp3vWKNSqFITTCjkSVwpMHqeyQs7T2UpshwqHQzk6Fqw50w2HvxqLTYfz1C7KAQGKh4lRLuuUVFrKHutJtPK8xPUTqYN1ui9PA+HNm3m0JDWPPnTJqw7koF7Jq9VuygEBioexUdJOSo5KgYq9mNLFWm06ce263bg22bnqSycyPC9CemXjSfQbMwirDl0MeAy2ON5zpF8tGYtbh7574e3nyBvnMnkeElawkDFg4SS0WczZCPSmpVWoGJ/ctRqjUqBrBalQIEald6frfLrfa/+thN5hUYMm7E14DKQZ1rPmYqKsB7mrhQq0yRJ17aocJ4atYTfhgdVEqMRodchM89ZMq1KOSoaPTHIu1AXFPt3QjiUnou7Pl+NpXvPK1oepZg0uu3VZFNL4aLK6cd1x9Fhwr84lJ5bSqWyitBbD3OXrxSyVoU8iorQq10EktFEoPL555+jZs2aiIqKQtu2bbFhwwa1i2RRLioCLas5vwFZoUpNP1pNpi0osm4PZ8nH3njttx3YfjITj32/KeDyBOOElO9nAHYtk3eXl2/yc1n5llrHN+buwunMq3jn7z2lXTyb9qi9Z7PR6u3FeH0ux0sh1xioaIvqgcovv/yCF198EW+++Sa2bNmCFi1aoFu3bkhPT1e7aBYf3tfC6fSVBy7gx3XHvV5OsdGET5cexI5TmQ6v7TqdhV6f/of1Ry45vGZ/kZpbUISxf+7GygMXLNOy84twLkvddlV5c09hsQmHL/h+9XzOzb103v5rj0/NXv7ci+lKQTFOusmLuepH08GGoxm487NV2H3m2uzBJA8Ij128ApNJYPeZLNw4fimG/7LNZt6jF6+UekKrfD/4YvlhZOYV4ad1J0q1DBRaYg3WQMWf3zwpS/VA5aOPPsITTzyBwYMHo3Hjxvjyyy8RExOD7777Tu2iWVRPjkHzqglOX3tj7i6vxwz5ef0JfLT4AO78bLXNdCEEhvywCbvPZOOBr9bh8IVcfLz4AFqO+wctx/2DXzadtJl/zLw9mLr6GB75zlrzNPC7Dbj1f8txJvMqZm8+hQU7z7osR36REbtOK3/StG/u6fK/FZbmlw1HMzB19VHM3Xoao+bstEy/fKUQB87nWN5z6vJVl8v/ZtVRjPtrD37bfMqrk12RUeCPbacdpgshLE04Qgi8/dcevD53J0wmgRd/3YbOHy53GVQc9KPpYsC367HjVBYGfqedmkIlyZsicwqKsf98Dh76ej0A4O8dtvvhsUt5+H7NsdIsnk2C707Zfp/pJO/MG5l5hTiUnuPy9TOZV/HotI1Ye9jxokNtP607ji+WH2LvJw/Cw6ynRn8S+p3JLzLi9bk7sWRP4M3aZY1OqLjHFhYWIiYmBrNnz0afPn0s0wcOHIjMzEz88ccfbt+fnZ2NhIQEZGVlIT4+PqhlzS8yoqDIhHu+XOPQzt4wrRxurp+CE5fycC47H0IIJMZEokZyDPRhOuTkFyPOEI6f1x+3DH9fKSEKdVLisOrQRYTpbKvMffFoh1rQ6YBvS+5BVC4qHDklzS4d61VAYkwkEqMjEBkehnC9DvVTy+H9RftwPrsAXRtVxB3NK0FA4PTlq7iQU4B6FcuhXFQ4iowC+UVGlIsKR5hOB50OyC8yQQfp1igmk1SDEh8dDh10EBD4d286ft/qGBg0q5Jgc4Iwe7JTbXz731EUmwSur56Im+ql4NOlB7363B3qJqNXs8qIDA9DQbERRpPAt6uO4kzmVYdbDHz8QAtcvlKEuKhwGE0C4+fvRVSEHi/eVh9rDl/CvO1nLMtcfch6cnmmcx0cz8hzONnGRuoxsH1NxBrCEakPQ1iYDrGReoSF6aDX6VBkNCHGEA4dpJPkc7Kk3pE9GiIxJgK5BUZkXy1CarwBcYZwS61ZfpERkeFhMITrvRoFV+dmeHh5k+H57HzM2Xoa9StK+6q+5EUBYcnbiIkMh05nHY3ZG0IA+85lY9K/h1zO06ZWEjYctR2P4oHW1dCqZnlkXy1CXqERyXGREEJKUE+KjURYSfnOZF7FpuOX0axKAmokx8AkRMn+qMOVgmLsP5eDxJgI1KoQC51Oh8y8Qhy5cAUN08ohQh8GnQ545++9uHTFMSipVSEWhvAw3Fg7GTWTY1BoNMFoAirERUIfpkNuQTGOX8rDmcyrCNPpcHP9CoiODMcLv2yD0STQu0VldK6fgkhZ4mVOfjH+b461WWnsnU0ghED52EgAUmCu14chIToCQggIIQU+0ZF6xBkibMon//6uFBQjKkJvufeYK+5ezS824oVftgMAnutSD9XKRyMyPMzy+5beL3987dt7NhvpOQWIDA9DjeRYVE6IAgC8OW830nMKAAAtqyfi7uurIiJM2jaR4WHQQYeCYiPWH81AreRYVE2KRoQ+zHLLFWf+2XMev2+Rjo9f9L/e4XX5Ozcfv4z953NwW+OKqBBnAACbY4RRCMSW/F4BqQbbJAQiw8Msv20lFJkEio0mdKhbARXjoxRbLuDb+VvVQOXMmTOoUqUK1qxZg3bt2lmmv/LKK1ixYgXWr19vM39BQQEKCgosz7OyslC9enWcPHky6IGKWXp2PmZuOIltJzOx4RgHAypLrq+eiC0nMtUuBhFRqWpZLRE/Pt5W0WVmZ2ejWrVqyMzMREKC8xYLs5C6KeH48eMxduxYh+nVqlVToTRU1pz0PAsR0TXnJICEl4Kz7JycHG0HKhUqVIBer8f587ZtdufPn0daWprD/CNHjsSLL75oeW4ymZCRkYHk5GToFKzuAqzRXmnW1lxLuP0Cw+0XGG6/wHD7BYbbzzMhBHJyclC5cmWP86oaqERGRqJVq1ZYunSpJUfFZDJh6dKlGDZsmMP8BoMBBoPBZlpiYmJQyxgfH88dLQDcfoHh9gsMt19guP0Cw+3nnqeaFDPVm35efPFFDBw4EK1bt0abNm0wceJEXLlyBYMHD1a7aERERKQy1QOVBx54ABcuXMDo0aNx7tw5XHfddVi4cCEqVqyodtGIiIhIZaoHKgAwbNgwp009ajIYDHjzzTcdmprIO9x+geH2Cwy3X2C4/QLD7acsVbsnExEREbmj+si0RERERK4wUCEiIiLNYqBCREREmsVAhYiIiDSLgYoTn3/+OWrWrImoqCi0bdsWGzZcm3e99dX48eNxww03oFy5ckhNTUWfPn2wf/9+m3ny8/MxdOhQJCcnIy4uDvfcc4/DyMMnTpxAr169EBMTg9TUVLz88ssoLi4uzY+iugkTJkCn02H48OGWadx2np0+fRoPP/wwkpOTER0djWbNmmHTpk2W14UQGD16NCpVqoTo6Gh07doVBw/a3ugyIyMD/fv3R3x8PBITE/HYY48hN9f3u2KHGqPRiDfeeAO1atVCdHQ06tSpg7feesvmTsrcflYrV65E7969UblyZeh0OsydO9fmdaW21Y4dO9CxY0dERUWhWrVqeP/994P90UKPIBszZ84UkZGR4rvvvhO7d+8WTzzxhEhMTBTnz59Xu2iq69atm5g6darYtWuX2LZtm+jZs6eoXr26yM3Ntczz1FNPiWrVqomlS5eKTZs2iRtvvFG0b9/e8npxcbFo2rSp6Nq1q9i6dauYP3++qFChghg5cqQaH0kVGzZsEDVr1hTNmzcXzz//vGU6t517GRkZokaNGmLQoEFi/fr14siRI2LRokXi0KFDlnkmTJggEhISxNy5c8X27dvFnXfeKWrVqiWuXr1qmad79+6iRYsWYt26deK///4TdevWFf369VPjI5Wqd955RyQnJ4u//vpLHD16VMyaNUvExcWJTz75xDIPt5/V/PnzxahRo8Tvv/8uAIg5c+bYvK7EtsrKyhIVK1YU/fv3F7t27RIzZswQ0dHRYsqUKaX1MUMCAxU7bdq0EUOHDrU8NxqNonLlymL8+PEqlkqb0tPTBQCxYsUKIYQQmZmZIiIiQsyaNcsyz969ewUAsXbtWiGE9OMPCwsT586ds8wzefJkER8fLwoKCkr3A6ggJydH1KtXTyxevFh06tTJEqhw23n26quviptuusnl6yaTSaSlpYkPPvjAMi0zM1MYDAYxY8YMIYQQe/bsEQDExo0bLfMsWLBA6HQ6cfr06eAVXgN69eolHn30UZtpd999t+jfv78QgtvPHftARalt9cUXX4jy5cvb/H5fffVV0aBBgyB/otDCph+ZwsJCbN68GV27drVMCwsLQ9euXbF27VoVS6ZNWVlZAICkpCQAwObNm1FUVGSz/Ro2bIjq1atbtt/atWvRrFkzm5GHu3XrhuzsbOzevbsUS6+OoUOHolevXjbbCOC288a8efPQunVr3HfffUhNTUXLli3x9ddfW14/evQozp07Z7MNExIS0LZtW5ttmJiYiNatW1vm6dq1K8LCwrB+/frS+zAqaN++PZYuXYoDBw4AALZv345Vq1ahR48eALj9fKHUtlq7di1uvvlmREZGWubp1q0b9u/fj8uXL5fSp9E+TYxMqxUXL16E0Wh0GL6/YsWK2Ldvn0ql0iaTyYThw4ejQ4cOaNq0KQDg3LlziIyMdLhRZMWKFXHu3DnLPM62r/m1a9nMmTOxZcsWbNy40eE1bjvPjhw5gsmTJ+PFF1/E//3f/2Hjxo147rnnEBkZiYEDB1q2gbNtJN+GqampNq+Hh4cjKSnpmt+Gr732GrKzs9GwYUPo9XoYjUa888476N+/PwBw+/lAqW117tw51KpVy2EZ5tfKly8flPKHGgYq5JehQ4di165dWLVqldpFCQknT57E888/j8WLFyMqKkrt4oQkk8mE1q1b49133wUAtGzZErt27cKXX36JgQMHqlw67fv111/x888/Y/r06WjSpAm2bduG4cOHo3Llytx+pGls+pGpUKEC9Hq9Q0+L8+fPIy0tTaVSac+wYcPw119/YdmyZahataplelpaGgoLC5GZmWkzv3z7paWlOd2+5teuVZs3b0Z6ejquv/56hIeHIzw8HCtWrMCnn36K8PBwVKxYkdvOg0qVKqFx48Y20xo1aoQTJ04AsG4Dd7/ftLQ0pKen27xeXFyMjIyMa34bvvzyy3jttdfw4IMPolmzZhgwYABeeOEFjB8/HgC3ny+U2lZl/TftLQYqMpGRkWjVqhWWLl1qmWYymbB06VK0a9dOxZJpgxACw4YNw5w5c/Dvv/86VFm2atUKERERNttv//79OHHihGX7tWvXDjt37rT5AS9evBjx8fEOJ6FrSZcuXbBz505s27bN8te6dWv079/f8pjbzr0OHTo4dIc/cOAAatSoAQCoVasW0tLSbLZhdnY21q9fb7MNMzMzsXnzZss8//77L0wmE9q2bVsKn0I9eXl5CAuzPeTr9XqYTCYA3H6+UGpbtWvXDitXrkRRUZFlnsWLF6NBgwZs9pFTO5tXa2bOnCkMBoOYNm2a2LNnjxgyZIhITEy06WlRVj399NMiISFBLF++XJw9e9byl5eXZ5nnqaeeEtWrVxf//vuv2LRpk2jXrp1o166d5XVzF9vbb79dbNu2TSxcuFCkpKSUmS62cvJeP0Jw23myYcMGER4eLt555x1x8OBB8fPPP4uYmBjx008/WeaZMGGCSExMFH/88YfYsWOHuOuuu5x2GW3ZsqVYv369WLVqlahXr9412b3W3sCBA0WVKlUs3ZN///13UaFCBfHKK69Y5uH2s8rJyRFbt24VW7duFQDERx99JLZu3SqOHz8uhFBmW2VmZoqKFSuKAQMGiF27domZM2eKmJgYdk+2w0DFiUmTJonq1auLyMhI0aZNG7Fu3Tq1i6QJAJz+TZ061TLP1atXxTPPPCPKly8vYmJiRN++fcXZs2dtlnPs2DHRo0cPER0dLSpUqCBeeuklUVRUVMqfRn32gQq3nWd//vmnaNq0qTAYDKJhw4biq6++snndZDKJN954Q1SsWFEYDAbRpUsXsX//fpt5Ll26JPr16yfi4uJEfHy8GDx4sMjJySnNj6GK7Oxs8fzzz4vq1auLqKgoUbt2bTFq1CibrrHcflbLli1zerwbOHCgEEK5bbV9+3Zx0003CYPBIKpUqSImTJhQWh8xZOiEkA1LSERERKQhzFEhIiIizWKgQkRERJrFQIWIiIg0i4EKERERaRYDFSIiItIsBipERESkWQxUiIiISLMYqBBRyNPpdJg7d67axSCiIGCgQkQBGTRoEHQ6ncNf9+7d1S4aEV0DwtUuABGFvu7du2Pq1Kk20wwGg0qlIaJrCWtUiChgBoMBaWlpNn/mu7/qdDpMnjwZPXr0QHR0NGrXro3Zs2fbvH/nzp249dZbER0djeTkZAwZMgS5ubk283z33Xdo0qQJDAYDKlWqhGHDhtm8fvHiRfTt2xcxMTGoV68e5s2bZ3nt8uXL6N+/P1JSUhAdHY169eo5BFZEpE0MVIgo6N544w3cc8892L59O/r3748HH3wQe/fuBQBcuXIF3bp1Q/ny5bFx40bMmjULS5YssQlEJk+ejKFDh2LIkCHYuXMn5s2bh7p169qsY+zYsbj//vuxY8cO9OzZE/3790dGRoZl/Xv27MGCBQuwd+9eTJ48GRUqVCi9DUBE/lP7rohEFNoGDhwo9Hq9iI2Ntfl75513hBDSXbefeuopm/e0bdtWPP3000IIIb766itRvnx5kZuba3n977//FmFhYeLcuXNCCCEqV64sRo0a5bIMAMTrr79ueZ6bmysAiAULFgghhOjdu7cYPHiwMh+YiEoVc1SIKGC33HILJk+ebDMtKSnJ8rhdu3Y2r7Vr1w7btm0DAOzduxctWrRAbGys5fUOHTrAZDJh//790Ol0OHPmDLp06eK2DM2bN7c8jo2NRXx8PNLT0wEATz/9NO655x5s2bIFt99+O/r06YP27dv79VmJqHQxUCGigMXGxjo0xSglOjraq/kiIiJsnut0OphMJgBAjx49cPz4ccyfPx+LFy9Gly5dMHToUHz44YeKl5eIlMUcFSIKunXr1jk8b9SoEQCgUaNG2L59O65cuWJ5ffXq1QgLC0ODBg1Qrlw51KxZE0uXLg2oDCkpKRg4cCB++uknTJw4EV999VVAyyOi0sEaFSIKWEFBAc6dO2czLTw83JKwOmvWLLRu3Ro33XQTfv75Z2zYsAHffvstAKB///548803MXDgQIwZMwYXLlzAs88+iwEDBqBixYoAgDFjxuCpp55CamoqevTogZycHKxevRrPPvusV+UbPXo0WrVqhSZNmqCgoAB//fWXJVAiIm1joEJEAVu4cCEqVapkM61BgwbYt28fAKlHzsyZM/HMM8+gUqVKmDFjBho3bgwAiImJwaJFi/D888/jhhtuQExMDO655x589NFHlmUNHDgQ+fn5+PjjjzFixAhUqFAB9957r9fli4yMxMiRI3Hs2DFER0ejY8eOmDlzpgKfnIiCTSeEEGoXgoiuXTqdDnPmzEGfPn3ULgoRhSDmqBAREZFmMVAhIiIizWKOChEFFVuXiSgQrFEhIiIizWKgQkRERJrFQIWIiIg0i4EKERERaRYDFSIiItIsBipERESkWQxUiIiISLMYqBAREZFmMVAhIiIizfp/yofc1jcD+Q0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "def ShowTrainLoss(train_losses,val_losses,save):\n",
    "    # 日本時間のタイムゾーンを取得\n",
    "    jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "    # 現在の日本時間を取得\n",
    "    now = datetime.now(jst)\n",
    "\n",
    "    # 時刻を指定された形式の文字列に変換\n",
    "    time = \"_\"+now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # 学習曲線の可視化\n",
    "\n",
    "    title = 'Training and Validation Losses Material'\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim(0,5)\n",
    "    plt.legend()\n",
    "    if save == True:\n",
    "        plt.savefig(\"data/\"+title+time+\".pdf\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "ShowTrainLoss(train_losses,val_losses,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net6' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_acc\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# 検証データで確認\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[43mcalc_acc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# テストデータで確認\u001b[39;00m\n\u001b[1;32m     45\u001b[0m calc_acc(test_loader)\n",
      "Cell \u001b[0;32mIn[54], line 30\u001b[0m, in \u001b[0;36mcalc_acc\u001b[0;34m(data_loader)\u001b[0m\n\u001b[1;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     29\u001b[0m t \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 30\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mnet6\u001b[49m(x)\n\u001b[1;32m     32\u001b[0m y_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(y[\u001b[38;5;241m0\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     33\u001b[0m acc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(y_label \u001b[38;5;241m==\u001b[39m t) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(t)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net6' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# dim=1 で行ごとの最大値に対する要素番号を取得（dim=0 は列ごと）\n",
    "y_label = torch.argmax(y[0], dim=1)\n",
    "# 予測値から最大となるクラスの番号を取り出した結果\n",
    "y_label\n",
    "# 目的変数\n",
    "t\n",
    "# 値が一致しているか確認\n",
    "y_label == t\n",
    "# int => float \n",
    "torch.sum(y_label == t) * 1.0\n",
    "# 正解率\n",
    "acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "acc\n",
    "\n",
    "\n",
    "# 正解率の計算\n",
    "def calc_acc(data_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        accs = [] # 各バッチごとの結果格納用\n",
    "        \n",
    "        for batch in data_loader:\n",
    "            x, t = batch\n",
    "            \n",
    "            # x = torch.unsqueeze(x,1)\n",
    "            \n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net6(x)\n",
    "            \n",
    "            y_label = torch.argmax(y[0], dim=1)\n",
    "            acc = torch.sum(y_label == t) * 1.0 / len(t)\n",
    "            accs.append(acc)\n",
    "            \n",
    "    # 全体の平均を算出\n",
    "    avg_acc = torch.tensor(accs).mean()\n",
    "    print('Accuracy: {:.1f}%'.format(avg_acc * 100))\n",
    "    \n",
    "    return avg_acc\n",
    "      \n",
    "# 検証データで確認\n",
    "calc_acc(val_loader)\n",
    "# テストデータで確認\n",
    "calc_acc(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
